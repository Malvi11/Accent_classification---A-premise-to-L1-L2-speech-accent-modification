{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "960c61fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9814adcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mfcc_1</th>\n",
       "      <th>mfcc_2</th>\n",
       "      <th>mfcc_3</th>\n",
       "      <th>mfcc_4</th>\n",
       "      <th>mfcc_5</th>\n",
       "      <th>mfcc_6</th>\n",
       "      <th>mfcc_7</th>\n",
       "      <th>mfcc_8</th>\n",
       "      <th>mfcc_9</th>\n",
       "      <th>mfcc_10</th>\n",
       "      <th>...</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>English Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-330.49750</td>\n",
       "      <td>-5.631140e-02</td>\n",
       "      <td>-1.305158e-02</td>\n",
       "      <td>129.82634</td>\n",
       "      <td>5.654399e-04</td>\n",
       "      <td>-1.087543e-03</td>\n",
       "      <td>-4.971954</td>\n",
       "      <td>3.198393e-02</td>\n",
       "      <td>1.747995e-03</td>\n",
       "      <td>31.724367</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.752345</td>\n",
       "      <td>-1.821501e-03</td>\n",
       "      <td>9.363368e-04</td>\n",
       "      <td>-4.558670</td>\n",
       "      <td>6.158995e-03</td>\n",
       "      <td>3.925575e-03</td>\n",
       "      <td>-0.389210</td>\n",
       "      <td>1.502641e-03</td>\n",
       "      <td>2.480886e-03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-322.01425</td>\n",
       "      <td>-3.602875e-03</td>\n",
       "      <td>-2.423903e-02</td>\n",
       "      <td>128.47772</td>\n",
       "      <td>-6.527488e-03</td>\n",
       "      <td>-9.426854e-03</td>\n",
       "      <td>-19.397339</td>\n",
       "      <td>-2.809185e-05</td>\n",
       "      <td>6.502475e-03</td>\n",
       "      <td>38.388363</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.544018</td>\n",
       "      <td>7.676435e-03</td>\n",
       "      <td>7.934333e-04</td>\n",
       "      <td>-1.401703</td>\n",
       "      <td>5.644315e-03</td>\n",
       "      <td>-5.167238e-04</td>\n",
       "      <td>-5.707905</td>\n",
       "      <td>-2.998314e-03</td>\n",
       "      <td>1.379392e-04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-340.64084</td>\n",
       "      <td>-1.116015e-02</td>\n",
       "      <td>-1.194324e-02</td>\n",
       "      <td>97.25810</td>\n",
       "      <td>-4.836332e-03</td>\n",
       "      <td>-6.452511e-03</td>\n",
       "      <td>-5.416280</td>\n",
       "      <td>-8.388211e-03</td>\n",
       "      <td>1.998641e-03</td>\n",
       "      <td>21.495487</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.403498</td>\n",
       "      <td>-6.431966e-03</td>\n",
       "      <td>6.693075e-04</td>\n",
       "      <td>0.850455</td>\n",
       "      <td>-6.629119e-04</td>\n",
       "      <td>-1.358620e-03</td>\n",
       "      <td>-11.889046</td>\n",
       "      <td>-1.693906e-03</td>\n",
       "      <td>1.692394e-04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-377.72028</td>\n",
       "      <td>2.176717e-08</td>\n",
       "      <td>-6.462130e-09</td>\n",
       "      <td>140.99352</td>\n",
       "      <td>3.265076e-08</td>\n",
       "      <td>-5.951962e-09</td>\n",
       "      <td>-15.099728</td>\n",
       "      <td>-1.020336e-09</td>\n",
       "      <td>1.360448e-09</td>\n",
       "      <td>19.818373</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.418817</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-2.380785e-09</td>\n",
       "      <td>-4.824514</td>\n",
       "      <td>-3.401121e-10</td>\n",
       "      <td>1.020336e-09</td>\n",
       "      <td>-3.209569</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.211649e-09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-330.79733</td>\n",
       "      <td>-9.279275e-03</td>\n",
       "      <td>3.626792e-03</td>\n",
       "      <td>98.38888</td>\n",
       "      <td>2.809254e-03</td>\n",
       "      <td>2.656345e-03</td>\n",
       "      <td>-2.800510</td>\n",
       "      <td>7.261699e-03</td>\n",
       "      <td>1.559843e-03</td>\n",
       "      <td>30.394365</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.268788</td>\n",
       "      <td>-2.190437e-03</td>\n",
       "      <td>1.166201e-03</td>\n",
       "      <td>-1.180020</td>\n",
       "      <td>-6.167702e-04</td>\n",
       "      <td>-1.668033e-03</td>\n",
       "      <td>0.379468</td>\n",
       "      <td>-3.115617e-03</td>\n",
       "      <td>2.192514e-03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2133</th>\n",
       "      <td>-321.37543</td>\n",
       "      <td>2.145348e-08</td>\n",
       "      <td>-1.592251e-09</td>\n",
       "      <td>125.37948</td>\n",
       "      <td>8.045056e-09</td>\n",
       "      <td>5.195765e-09</td>\n",
       "      <td>-18.120020</td>\n",
       "      <td>6.704213e-10</td>\n",
       "      <td>8.380267e-10</td>\n",
       "      <td>24.798357</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.950925</td>\n",
       "      <td>2.681685e-09</td>\n",
       "      <td>-2.430277e-09</td>\n",
       "      <td>-10.296289</td>\n",
       "      <td>6.704213e-10</td>\n",
       "      <td>5.195765e-09</td>\n",
       "      <td>-6.076538</td>\n",
       "      <td>-1.340843e-09</td>\n",
       "      <td>4.190133e-11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2134</th>\n",
       "      <td>-334.67572</td>\n",
       "      <td>2.969725e-03</td>\n",
       "      <td>-7.079506e-03</td>\n",
       "      <td>115.60187</td>\n",
       "      <td>2.633094e-03</td>\n",
       "      <td>-3.973560e-03</td>\n",
       "      <td>-10.139031</td>\n",
       "      <td>-6.183048e-04</td>\n",
       "      <td>-9.918020e-04</td>\n",
       "      <td>27.466146</td>\n",
       "      <td>...</td>\n",
       "      <td>-22.601553</td>\n",
       "      <td>-3.429410e-03</td>\n",
       "      <td>-3.406802e-04</td>\n",
       "      <td>-8.010031</td>\n",
       "      <td>3.347575e-04</td>\n",
       "      <td>1.722395e-04</td>\n",
       "      <td>-8.633924</td>\n",
       "      <td>2.589215e-03</td>\n",
       "      <td>-7.905327e-05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2135</th>\n",
       "      <td>-237.90643</td>\n",
       "      <td>2.993488e-02</td>\n",
       "      <td>-6.727289e-03</td>\n",
       "      <td>103.26113</td>\n",
       "      <td>3.290961e-02</td>\n",
       "      <td>-5.506047e-03</td>\n",
       "      <td>-23.400814</td>\n",
       "      <td>1.604700e-02</td>\n",
       "      <td>-2.868054e-04</td>\n",
       "      <td>33.581520</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.508986</td>\n",
       "      <td>-5.677356e-04</td>\n",
       "      <td>-7.979744e-04</td>\n",
       "      <td>-8.856752</td>\n",
       "      <td>3.319585e-05</td>\n",
       "      <td>-1.515660e-04</td>\n",
       "      <td>-2.979901</td>\n",
       "      <td>-5.256697e-04</td>\n",
       "      <td>1.029256e-03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2136</th>\n",
       "      <td>-312.73398</td>\n",
       "      <td>5.774686e-02</td>\n",
       "      <td>2.157346e-04</td>\n",
       "      <td>130.01166</td>\n",
       "      <td>4.117964e-02</td>\n",
       "      <td>-3.729525e-04</td>\n",
       "      <td>-6.817431</td>\n",
       "      <td>5.208343e-03</td>\n",
       "      <td>-5.306819e-04</td>\n",
       "      <td>19.614530</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.335617</td>\n",
       "      <td>-9.031654e-05</td>\n",
       "      <td>2.355064e-03</td>\n",
       "      <td>-6.252686</td>\n",
       "      <td>-1.106754e-03</td>\n",
       "      <td>1.026079e-03</td>\n",
       "      <td>-0.870628</td>\n",
       "      <td>-1.179720e-03</td>\n",
       "      <td>-9.064542e-04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2137</th>\n",
       "      <td>-307.59650</td>\n",
       "      <td>6.353763e-02</td>\n",
       "      <td>1.284335e-02</td>\n",
       "      <td>123.73421</td>\n",
       "      <td>1.195807e-02</td>\n",
       "      <td>9.860430e-03</td>\n",
       "      <td>-18.446918</td>\n",
       "      <td>-1.816876e-02</td>\n",
       "      <td>5.292204e-03</td>\n",
       "      <td>65.722305</td>\n",
       "      <td>...</td>\n",
       "      <td>3.844791</td>\n",
       "      <td>-1.532581e-03</td>\n",
       "      <td>8.469080e-04</td>\n",
       "      <td>2.360198</td>\n",
       "      <td>5.612976e-03</td>\n",
       "      <td>2.984365e-04</td>\n",
       "      <td>-4.568026</td>\n",
       "      <td>-1.764863e-03</td>\n",
       "      <td>1.253004e-03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2138 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         mfcc_1        mfcc_2        mfcc_3     mfcc_4        mfcc_5  \\\n",
       "0    -330.49750 -5.631140e-02 -1.305158e-02  129.82634  5.654399e-04   \n",
       "1    -322.01425 -3.602875e-03 -2.423903e-02  128.47772 -6.527488e-03   \n",
       "2    -340.64084 -1.116015e-02 -1.194324e-02   97.25810 -4.836332e-03   \n",
       "3    -377.72028  2.176717e-08 -6.462130e-09  140.99352  3.265076e-08   \n",
       "4    -330.79733 -9.279275e-03  3.626792e-03   98.38888  2.809254e-03   \n",
       "...         ...           ...           ...        ...           ...   \n",
       "2133 -321.37543  2.145348e-08 -1.592251e-09  125.37948  8.045056e-09   \n",
       "2134 -334.67572  2.969725e-03 -7.079506e-03  115.60187  2.633094e-03   \n",
       "2135 -237.90643  2.993488e-02 -6.727289e-03  103.26113  3.290961e-02   \n",
       "2136 -312.73398  5.774686e-02  2.157346e-04  130.01166  4.117964e-02   \n",
       "2137 -307.59650  6.353763e-02  1.284335e-02  123.73421  1.195807e-02   \n",
       "\n",
       "            mfcc_6     mfcc_7        mfcc_8        mfcc_9    mfcc_10  ...  \\\n",
       "0    -1.087543e-03  -4.971954  3.198393e-02  1.747995e-03  31.724367  ...   \n",
       "1    -9.426854e-03 -19.397339 -2.809185e-05  6.502475e-03  38.388363  ...   \n",
       "2    -6.452511e-03  -5.416280 -8.388211e-03  1.998641e-03  21.495487  ...   \n",
       "3    -5.951962e-09 -15.099728 -1.020336e-09  1.360448e-09  19.818373  ...   \n",
       "4     2.656345e-03  -2.800510  7.261699e-03  1.559843e-03  30.394365  ...   \n",
       "...            ...        ...           ...           ...        ...  ...   \n",
       "2133  5.195765e-09 -18.120020  6.704213e-10  8.380267e-10  24.798357  ...   \n",
       "2134 -3.973560e-03 -10.139031 -6.183048e-04 -9.918020e-04  27.466146  ...   \n",
       "2135 -5.506047e-03 -23.400814  1.604700e-02 -2.868054e-04  33.581520  ...   \n",
       "2136 -3.729525e-04  -6.817431  5.208343e-03 -5.306819e-04  19.614530  ...   \n",
       "2137  9.860430e-03 -18.446918 -1.816876e-02  5.292204e-03  65.722305  ...   \n",
       "\n",
       "             35            36            37         38            39  \\\n",
       "0     -2.752345 -1.821501e-03  9.363368e-04  -4.558670  6.158995e-03   \n",
       "1     -1.544018  7.676435e-03  7.934333e-04  -1.401703  5.644315e-03   \n",
       "2    -10.403498 -6.431966e-03  6.693075e-04   0.850455 -6.629119e-04   \n",
       "3     -4.418817  0.000000e+00 -2.380785e-09  -4.824514 -3.401121e-10   \n",
       "4     -0.268788 -2.190437e-03  1.166201e-03  -1.180020 -6.167702e-04   \n",
       "...         ...           ...           ...        ...           ...   \n",
       "2133  -5.950925  2.681685e-09 -2.430277e-09 -10.296289  6.704213e-10   \n",
       "2134 -22.601553 -3.429410e-03 -3.406802e-04  -8.010031  3.347575e-04   \n",
       "2135  -3.508986 -5.677356e-04 -7.979744e-04  -8.856752  3.319585e-05   \n",
       "2136  -1.335617 -9.031654e-05  2.355064e-03  -6.252686 -1.106754e-03   \n",
       "2137   3.844791 -1.532581e-03  8.469080e-04   2.360198  5.612976e-03   \n",
       "\n",
       "                40         41            42            43  English Type  \n",
       "0     3.925575e-03  -0.389210  1.502641e-03  2.480886e-03             1  \n",
       "1    -5.167238e-04  -5.707905 -2.998314e-03  1.379392e-04             0  \n",
       "2    -1.358620e-03 -11.889046 -1.693906e-03  1.692394e-04             0  \n",
       "3     1.020336e-09  -3.209569  0.000000e+00  1.211649e-09             0  \n",
       "4    -1.668033e-03   0.379468 -3.115617e-03  2.192514e-03             0  \n",
       "...            ...        ...           ...           ...           ...  \n",
       "2133  5.195765e-09  -6.076538 -1.340843e-09  4.190133e-11             0  \n",
       "2134  1.722395e-04  -8.633924  2.589215e-03 -7.905327e-05             0  \n",
       "2135 -1.515660e-04  -2.979901 -5.256697e-04  1.029256e-03             0  \n",
       "2136  1.026079e-03  -0.870628 -1.179720e-03 -9.064542e-04             0  \n",
       "2137  2.984365e-04  -4.568026 -1.764863e-03  1.253004e-03             0  \n",
       "\n",
       "[2138 rows x 40 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the features from the CSV file\n",
    "df = pd.read_csv(r'Original_Features8.csv')\n",
    "df=df.drop(['rolloff','zero_crossing_rate','chroma_stft','spectral_centroid','spectral_bandwidth'],axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d99f810",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,0:39]\n",
    "y = df.iloc[:,39]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "101a0a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1710, 39) (1710,)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(X_train.shape,y_train.shape)\n",
    "\n",
    "# scale data\n",
    "t = MinMaxScaler()\n",
    "t.fit(X_train)\n",
    "X_train = t.transform(X_train)\n",
    "X_test = t.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2516a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the input features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "889ff4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "43/43 [==============================] - 2s 12ms/step - loss: 1.1690 - val_loss: 1.0359\n",
      "Epoch 2/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.0151 - val_loss: 0.9272\n",
      "Epoch 3/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.9320 - val_loss: 0.8683\n",
      "Epoch 4/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.8819 - val_loss: 0.8263\n",
      "Epoch 5/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.8435 - val_loss: 0.7927\n",
      "Epoch 6/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.8130 - val_loss: 0.7665\n",
      "Epoch 7/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.7888 - val_loss: 0.7466\n",
      "Epoch 8/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.7699 - val_loss: 0.7305\n",
      "Epoch 9/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.7545 - val_loss: 0.7174\n",
      "Epoch 10/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.7417 - val_loss: 0.7063\n",
      "Epoch 11/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.7309 - val_loss: 0.6967\n",
      "Epoch 12/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.7216 - val_loss: 0.6885\n",
      "Epoch 13/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.7135 - val_loss: 0.6811\n",
      "Epoch 14/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.7064 - val_loss: 0.6747\n",
      "Epoch 15/1500\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.7003 - val_loss: 0.6689\n",
      "Epoch 16/1500\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.6948 - val_loss: 0.6637\n",
      "Epoch 17/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6899 - val_loss: 0.6589\n",
      "Epoch 18/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6854 - val_loss: 0.6546\n",
      "Epoch 19/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6814 - val_loss: 0.6507\n",
      "Epoch 20/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6778 - val_loss: 0.6470\n",
      "Epoch 21/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6744 - val_loss: 0.6438\n",
      "Epoch 22/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6713 - val_loss: 0.6407\n",
      "Epoch 23/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6685 - val_loss: 0.6379\n",
      "Epoch 24/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6659 - val_loss: 0.6354\n",
      "Epoch 25/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6635 - val_loss: 0.6331\n",
      "Epoch 26/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6613 - val_loss: 0.6309\n",
      "Epoch 27/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6592 - val_loss: 0.6290\n",
      "Epoch 28/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6573 - val_loss: 0.6272\n",
      "Epoch 29/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6555 - val_loss: 0.6253\n",
      "Epoch 30/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6539 - val_loss: 0.6236\n",
      "Epoch 31/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6523 - val_loss: 0.6219\n",
      "Epoch 32/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6508 - val_loss: 0.6204\n",
      "Epoch 33/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6494 - val_loss: 0.6190\n",
      "Epoch 34/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6481 - val_loss: 0.6176\n",
      "Epoch 35/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6469 - val_loss: 0.6163\n",
      "Epoch 36/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6457 - val_loss: 0.6150\n",
      "Epoch 37/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6446 - val_loss: 0.6138\n",
      "Epoch 38/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6436 - val_loss: 0.6127\n",
      "Epoch 39/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6426 - val_loss: 0.6117\n",
      "Epoch 40/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6416 - val_loss: 0.6106\n",
      "Epoch 41/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6407 - val_loss: 0.6096\n",
      "Epoch 42/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6399 - val_loss: 0.6087\n",
      "Epoch 43/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6390 - val_loss: 0.6079\n",
      "Epoch 44/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6382 - val_loss: 0.6070\n",
      "Epoch 45/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6375 - val_loss: 0.6062\n",
      "Epoch 46/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6368 - val_loss: 0.6055\n",
      "Epoch 47/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6361 - val_loss: 0.6048\n",
      "Epoch 48/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6354 - val_loss: 0.6041\n",
      "Epoch 49/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6348 - val_loss: 0.6033\n",
      "Epoch 50/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6342 - val_loss: 0.6027\n",
      "Epoch 51/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6336 - val_loss: 0.6020\n",
      "Epoch 52/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6330 - val_loss: 0.6014\n",
      "Epoch 53/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6325 - val_loss: 0.6008\n",
      "Epoch 54/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6320 - val_loss: 0.6002\n",
      "Epoch 55/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6315 - val_loss: 0.5997\n",
      "Epoch 56/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6310 - val_loss: 0.5992\n",
      "Epoch 57/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6305 - val_loss: 0.5986\n",
      "Epoch 58/1500\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.6301 - val_loss: 0.5981\n",
      "Epoch 59/1500\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.6297 - val_loss: 0.5977\n",
      "Epoch 60/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6293 - val_loss: 0.5972\n",
      "Epoch 61/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6289 - val_loss: 0.5969\n",
      "Epoch 62/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6285 - val_loss: 0.5963\n",
      "Epoch 63/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6282 - val_loss: 0.5959\n",
      "Epoch 64/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6278 - val_loss: 0.5956\n",
      "Epoch 65/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6274 - val_loss: 0.5951\n",
      "Epoch 66/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6271 - val_loss: 0.5947\n",
      "Epoch 67/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6268 - val_loss: 0.5944\n",
      "Epoch 68/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6265 - val_loss: 0.5941\n",
      "Epoch 69/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6262 - val_loss: 0.5937\n",
      "Epoch 70/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6259 - val_loss: 0.5934\n",
      "Epoch 71/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6256 - val_loss: 0.5931\n",
      "Epoch 72/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6253 - val_loss: 0.5928\n",
      "Epoch 73/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6251 - val_loss: 0.5925\n",
      "Epoch 74/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6248 - val_loss: 0.5922\n",
      "Epoch 75/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6246 - val_loss: 0.5920\n",
      "Epoch 76/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6244 - val_loss: 0.5917\n",
      "Epoch 77/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6241 - val_loss: 0.5915\n",
      "Epoch 78/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6239 - val_loss: 0.5912\n",
      "Epoch 79/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6237 - val_loss: 0.5910\n",
      "Epoch 80/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6235 - val_loss: 0.5909\n",
      "Epoch 81/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6233 - val_loss: 0.5905\n",
      "Epoch 82/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6231 - val_loss: 0.5903\n",
      "Epoch 83/1500\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.6230 - val_loss: 0.5901\n",
      "Epoch 84/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6228 - val_loss: 0.5899\n",
      "Epoch 85/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6226 - val_loss: 0.5896\n",
      "Epoch 86/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6225 - val_loss: 0.5894\n",
      "Epoch 87/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6223 - val_loss: 0.5892\n",
      "Epoch 88/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6221 - val_loss: 0.5891\n",
      "Epoch 89/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6220 - val_loss: 0.5889\n",
      "Epoch 90/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6219 - val_loss: 0.5886\n",
      "Epoch 91/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6217 - val_loss: 0.5885\n",
      "Epoch 92/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6216 - val_loss: 0.5883\n",
      "Epoch 93/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6214 - val_loss: 0.5881\n",
      "Epoch 94/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6213 - val_loss: 0.5880\n",
      "Epoch 95/1500\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.6212 - val_loss: 0.5878\n",
      "Epoch 96/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6211 - val_loss: 0.5877\n",
      "Epoch 97/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6209 - val_loss: 0.5875\n",
      "Epoch 98/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6208 - val_loss: 0.5874\n",
      "Epoch 99/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6207 - val_loss: 0.5872\n",
      "Epoch 100/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6206 - val_loss: 0.5871\n",
      "Epoch 101/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6205 - val_loss: 0.5870\n",
      "Epoch 102/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6204 - val_loss: 0.5869\n",
      "Epoch 103/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6203 - val_loss: 0.5866\n",
      "Epoch 104/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6201 - val_loss: 0.5866\n",
      "Epoch 105/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6200 - val_loss: 0.5864\n",
      "Epoch 106/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6199 - val_loss: 0.5863\n",
      "Epoch 107/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6199 - val_loss: 0.5862\n",
      "Epoch 108/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6197 - val_loss: 0.5860\n",
      "Epoch 109/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6197 - val_loss: 0.5860\n",
      "Epoch 110/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6196 - val_loss: 0.5858\n",
      "Epoch 111/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6195 - val_loss: 0.5857\n",
      "Epoch 112/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6194 - val_loss: 0.5856\n",
      "Epoch 113/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6193 - val_loss: 0.5855\n",
      "Epoch 114/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6192 - val_loss: 0.5853\n",
      "Epoch 115/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6191 - val_loss: 0.5853\n",
      "Epoch 116/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6191 - val_loss: 0.5852\n",
      "Epoch 117/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6190 - val_loss: 0.5851\n",
      "Epoch 118/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6189 - val_loss: 0.5850\n",
      "Epoch 119/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6188 - val_loss: 0.5849\n",
      "Epoch 120/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6188 - val_loss: 0.5848\n",
      "Epoch 121/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6187 - val_loss: 0.5846\n",
      "Epoch 122/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6186 - val_loss: 0.5846\n",
      "Epoch 123/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6186 - val_loss: 0.5844\n",
      "Epoch 124/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6185 - val_loss: 0.5844\n",
      "Epoch 125/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6184 - val_loss: 0.5844\n",
      "Epoch 126/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6184 - val_loss: 0.5842\n",
      "Epoch 127/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6183 - val_loss: 0.5841\n",
      "Epoch 128/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6182 - val_loss: 0.5841\n",
      "Epoch 129/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6182 - val_loss: 0.5840\n",
      "Epoch 130/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6181 - val_loss: 0.5839\n",
      "Epoch 131/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6181 - val_loss: 0.5839\n",
      "Epoch 132/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6180 - val_loss: 0.5837\n",
      "Epoch 133/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6179 - val_loss: 0.5837\n",
      "Epoch 134/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6179 - val_loss: 0.5837\n",
      "Epoch 135/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6178 - val_loss: 0.5836\n",
      "Epoch 136/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6178 - val_loss: 0.5835\n",
      "Epoch 137/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6177 - val_loss: 0.5834\n",
      "Epoch 138/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6177 - val_loss: 0.5834\n",
      "Epoch 139/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6176 - val_loss: 0.5833\n",
      "Epoch 140/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6176 - val_loss: 0.5832\n",
      "Epoch 141/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6175 - val_loss: 0.5831\n",
      "Epoch 142/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6175 - val_loss: 0.5831\n",
      "Epoch 143/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6174 - val_loss: 0.5830\n",
      "Epoch 144/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6174 - val_loss: 0.5829\n",
      "Epoch 145/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6174 - val_loss: 0.5829\n",
      "Epoch 146/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6173 - val_loss: 0.5828\n",
      "Epoch 147/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6172 - val_loss: 0.5827\n",
      "Epoch 148/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6172 - val_loss: 0.5827\n",
      "Epoch 149/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6172 - val_loss: 0.5826\n",
      "Epoch 150/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6171 - val_loss: 0.5825\n",
      "Epoch 151/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6171 - val_loss: 0.5826\n",
      "Epoch 152/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6170 - val_loss: 0.5824\n",
      "Epoch 153/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6170 - val_loss: 0.5824\n",
      "Epoch 154/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6170 - val_loss: 0.5823\n",
      "Epoch 155/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6169 - val_loss: 0.5823\n",
      "Epoch 156/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6169 - val_loss: 0.5823\n",
      "Epoch 157/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6169 - val_loss: 0.5822\n",
      "Epoch 158/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6168 - val_loss: 0.5822\n",
      "Epoch 159/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6168 - val_loss: 0.5821\n",
      "Epoch 160/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6168 - val_loss: 0.5821\n",
      "Epoch 161/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6167 - val_loss: 0.5820\n",
      "Epoch 162/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6167 - val_loss: 0.5820\n",
      "Epoch 163/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6167 - val_loss: 0.5820\n",
      "Epoch 164/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6167 - val_loss: 0.5819\n",
      "Epoch 165/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6166 - val_loss: 0.5819\n",
      "Epoch 166/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6166 - val_loss: 0.5818\n",
      "Epoch 167/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6166 - val_loss: 0.5818\n",
      "Epoch 168/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6165 - val_loss: 0.5817\n",
      "Epoch 169/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6165 - val_loss: 0.5817\n",
      "Epoch 170/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6165 - val_loss: 0.5816\n",
      "Epoch 171/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6165 - val_loss: 0.5816\n",
      "Epoch 172/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6165 - val_loss: 0.5816\n",
      "Epoch 173/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6164 - val_loss: 0.5815\n",
      "Epoch 174/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6164 - val_loss: 0.5815\n",
      "Epoch 175/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6164 - val_loss: 0.5815\n",
      "Epoch 176/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6164 - val_loss: 0.5814\n",
      "Epoch 177/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6164 - val_loss: 0.5814\n",
      "Epoch 178/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6163 - val_loss: 0.5814\n",
      "Epoch 179/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6163 - val_loss: 0.5814\n",
      "Epoch 180/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6163 - val_loss: 0.5813\n",
      "Epoch 181/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6163 - val_loss: 0.5813\n",
      "Epoch 182/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6163 - val_loss: 0.5812\n",
      "Epoch 183/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6162 - val_loss: 0.5812\n",
      "Epoch 184/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6162 - val_loss: 0.5812\n",
      "Epoch 185/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6162 - val_loss: 0.5811\n",
      "Epoch 186/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6162 - val_loss: 0.5811\n",
      "Epoch 187/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6162 - val_loss: 0.5811\n",
      "Epoch 188/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6161 - val_loss: 0.5811\n",
      "Epoch 189/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6161 - val_loss: 0.5811\n",
      "Epoch 190/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6161 - val_loss: 0.5810\n",
      "Epoch 191/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6161 - val_loss: 0.5810\n",
      "Epoch 192/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6161 - val_loss: 0.5809\n",
      "Epoch 193/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6161 - val_loss: 0.5809\n",
      "Epoch 194/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6161 - val_loss: 0.5810\n",
      "Epoch 195/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6160 - val_loss: 0.5809\n",
      "Epoch 196/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6160 - val_loss: 0.5809\n",
      "Epoch 197/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6160 - val_loss: 0.5809\n",
      "Epoch 198/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6160 - val_loss: 0.5808\n",
      "Epoch 199/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6160 - val_loss: 0.5808\n",
      "Epoch 200/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6160 - val_loss: 0.5808\n",
      "Epoch 201/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6160 - val_loss: 0.5808\n",
      "Epoch 202/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6159 - val_loss: 0.5807\n",
      "Epoch 203/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6159 - val_loss: 0.5807\n",
      "Epoch 204/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6159 - val_loss: 0.5807\n",
      "Epoch 205/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6159 - val_loss: 0.5807\n",
      "Epoch 206/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6159 - val_loss: 0.5807\n",
      "Epoch 207/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6159 - val_loss: 0.5806\n",
      "Epoch 208/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6159 - val_loss: 0.5806\n",
      "Epoch 209/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6159 - val_loss: 0.5806\n",
      "Epoch 210/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6159 - val_loss: 0.5806\n",
      "Epoch 211/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6158 - val_loss: 0.5806\n",
      "Epoch 212/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6158 - val_loss: 0.5806\n",
      "Epoch 213/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6158 - val_loss: 0.5805\n",
      "Epoch 214/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6158 - val_loss: 0.5805\n",
      "Epoch 215/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6158 - val_loss: 0.5805\n",
      "Epoch 216/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6158 - val_loss: 0.5805\n",
      "Epoch 217/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6158 - val_loss: 0.5805\n",
      "Epoch 218/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6158 - val_loss: 0.5804\n",
      "Epoch 219/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6158 - val_loss: 0.5804\n",
      "Epoch 220/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6158 - val_loss: 0.5804\n",
      "Epoch 221/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6158 - val_loss: 0.5803\n",
      "Epoch 222/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6158 - val_loss: 0.5804\n",
      "Epoch 223/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6157 - val_loss: 0.5803\n",
      "Epoch 224/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6157 - val_loss: 0.5804\n",
      "Epoch 225/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6157 - val_loss: 0.5804\n",
      "Epoch 226/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6157 - val_loss: 0.5803\n",
      "Epoch 227/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6157 - val_loss: 0.5803\n",
      "Epoch 228/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6157 - val_loss: 0.5803\n",
      "Epoch 229/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6157 - val_loss: 0.5803\n",
      "Epoch 230/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6157 - val_loss: 0.5802\n",
      "Epoch 231/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6157 - val_loss: 0.5802\n",
      "Epoch 232/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6157 - val_loss: 0.5802\n",
      "Epoch 233/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6157 - val_loss: 0.5802\n",
      "Epoch 234/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6157 - val_loss: 0.5802\n",
      "Epoch 235/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6156 - val_loss: 0.5802\n",
      "Epoch 236/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6156 - val_loss: 0.5801\n",
      "Epoch 237/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6157 - val_loss: 0.5802\n",
      "Epoch 238/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6157 - val_loss: 0.5802\n",
      "Epoch 239/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6156 - val_loss: 0.5801\n",
      "Epoch 240/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6156 - val_loss: 0.5801\n",
      "Epoch 241/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6156 - val_loss: 0.5801\n",
      "Epoch 242/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6156 - val_loss: 0.5801\n",
      "Epoch 243/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6156 - val_loss: 0.5801\n",
      "Epoch 244/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6156 - val_loss: 0.5801\n",
      "Epoch 245/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6156 - val_loss: 0.5800\n",
      "Epoch 246/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6156 - val_loss: 0.5800\n",
      "Epoch 247/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6156 - val_loss: 0.5800\n",
      "Epoch 248/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6156 - val_loss: 0.5800\n",
      "Epoch 249/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6156 - val_loss: 0.5800\n",
      "Epoch 250/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6156 - val_loss: 0.5800\n",
      "Epoch 251/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6156 - val_loss: 0.5800\n",
      "Epoch 252/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6156 - val_loss: 0.5799\n",
      "Epoch 253/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6156 - val_loss: 0.5800\n",
      "Epoch 254/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6156 - val_loss: 0.5800\n",
      "Epoch 255/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6155 - val_loss: 0.5799\n",
      "Epoch 256/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6156 - val_loss: 0.5800\n",
      "Epoch 257/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6156 - val_loss: 0.5799\n",
      "Epoch 258/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6155 - val_loss: 0.5800\n",
      "Epoch 259/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6155 - val_loss: 0.5799\n",
      "Epoch 260/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6155 - val_loss: 0.5800\n",
      "Epoch 261/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6155 - val_loss: 0.5800\n",
      "Epoch 262/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6155 - val_loss: 0.5799\n",
      "Epoch 263/1500\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.6155 - val_loss: 0.5799\n",
      "Epoch 264/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6155 - val_loss: 0.5799\n",
      "Epoch 265/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6155 - val_loss: 0.5799\n",
      "Epoch 266/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6155 - val_loss: 0.5799\n",
      "Epoch 267/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6155 - val_loss: 0.5799\n",
      "Epoch 268/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6155 - val_loss: 0.5799\n",
      "Epoch 269/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6155 - val_loss: 0.5799\n",
      "Epoch 270/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6155 - val_loss: 0.5798\n",
      "Epoch 271/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6155 - val_loss: 0.5799\n",
      "Epoch 272/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6155 - val_loss: 0.5798\n",
      "Epoch 273/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6155 - val_loss: 0.5798\n",
      "Epoch 274/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6155 - val_loss: 0.5798\n",
      "Epoch 275/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6155 - val_loss: 0.5798\n",
      "Epoch 276/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6155 - val_loss: 0.5798\n",
      "Epoch 277/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6155 - val_loss: 0.5798\n",
      "Epoch 278/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6155 - val_loss: 0.5798\n",
      "Epoch 279/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6155 - val_loss: 0.5797\n",
      "Epoch 280/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6155 - val_loss: 0.5798\n",
      "Epoch 281/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6155 - val_loss: 0.5798\n",
      "Epoch 282/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6155 - val_loss: 0.5798\n",
      "Epoch 283/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6155 - val_loss: 0.5798\n",
      "Epoch 284/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6155 - val_loss: 0.5798\n",
      "Epoch 285/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6154 - val_loss: 0.5797\n",
      "Epoch 286/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6154 - val_loss: 0.5797\n",
      "Epoch 287/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6155 - val_loss: 0.5798\n",
      "Epoch 288/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6154 - val_loss: 0.5798\n",
      "Epoch 289/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6154 - val_loss: 0.5798\n",
      "Epoch 290/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6154 - val_loss: 0.5797\n",
      "Epoch 291/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6154 - val_loss: 0.5798\n",
      "Epoch 292/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6154 - val_loss: 0.5797\n",
      "Epoch 293/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6154 - val_loss: 0.5797\n",
      "Epoch 294/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6154 - val_loss: 0.5797\n",
      "Epoch 295/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6154 - val_loss: 0.5797\n",
      "Epoch 296/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6154 - val_loss: 0.5797\n",
      "Epoch 297/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6154 - val_loss: 0.5797\n",
      "Epoch 298/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6154 - val_loss: 0.5797\n",
      "Epoch 299/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6154 - val_loss: 0.5797\n",
      "Epoch 300/1500\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.6154 - val_loss: 0.5796\n",
      "Epoch 301/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6154 - val_loss: 0.5797\n",
      "Epoch 302/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6154 - val_loss: 0.5796\n",
      "Epoch 303/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6154 - val_loss: 0.5797\n",
      "Epoch 304/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6154 - val_loss: 0.5797\n",
      "Epoch 305/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6154 - val_loss: 0.5797\n",
      "Epoch 306/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6154 - val_loss: 0.5796\n",
      "Epoch 307/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6153 - val_loss: 0.5796\n",
      "Epoch 308/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6154 - val_loss: 0.5797\n",
      "Epoch 309/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6154 - val_loss: 0.5796\n",
      "Epoch 310/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6154 - val_loss: 0.5797\n",
      "Epoch 311/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6154 - val_loss: 0.5796\n",
      "Epoch 312/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6154 - val_loss: 0.5796\n",
      "Epoch 313/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6154 - val_loss: 0.5796\n",
      "Epoch 314/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6153 - val_loss: 0.5796\n",
      "Epoch 315/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6153 - val_loss: 0.5796\n",
      "Epoch 316/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6154 - val_loss: 0.5796\n",
      "Epoch 317/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6153 - val_loss: 0.5796\n",
      "Epoch 318/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6153 - val_loss: 0.5796\n",
      "Epoch 319/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6153 - val_loss: 0.5797\n",
      "Epoch 320/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6153 - val_loss: 0.5796\n",
      "Epoch 321/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6153 - val_loss: 0.5796\n",
      "Epoch 322/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6153 - val_loss: 0.5796\n",
      "Epoch 323/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6153 - val_loss: 0.5796\n",
      "Epoch 324/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6153 - val_loss: 0.5796\n",
      "Epoch 325/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6153 - val_loss: 0.5796\n",
      "Epoch 326/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6153 - val_loss: 0.5796\n",
      "Epoch 327/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6153 - val_loss: 0.5796\n",
      "Epoch 328/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6153 - val_loss: 0.5796\n",
      "Epoch 329/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6153 - val_loss: 0.5795\n",
      "Epoch 330/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6153 - val_loss: 0.5795\n",
      "Epoch 331/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6153 - val_loss: 0.5796\n",
      "Epoch 332/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5795\n",
      "Epoch 333/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5795\n",
      "Epoch 334/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6153 - val_loss: 0.5795\n",
      "Epoch 335/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6153 - val_loss: 0.5795\n",
      "Epoch 336/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6153 - val_loss: 0.5795\n",
      "Epoch 337/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6153 - val_loss: 0.5795\n",
      "Epoch 338/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6153 - val_loss: 0.5795\n",
      "Epoch 339/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6153 - val_loss: 0.5795\n",
      "Epoch 340/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5795\n",
      "Epoch 341/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5795\n",
      "Epoch 342/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5795\n",
      "Epoch 343/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6153 - val_loss: 0.5795\n",
      "Epoch 344/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6153 - val_loss: 0.5795\n",
      "Epoch 345/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5795\n",
      "Epoch 346/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6153 - val_loss: 0.5796\n",
      "Epoch 347/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6153 - val_loss: 0.5795\n",
      "Epoch 348/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6153 - val_loss: 0.5795\n",
      "Epoch 349/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6153 - val_loss: 0.5795\n",
      "Epoch 350/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6153 - val_loss: 0.5795\n",
      "Epoch 351/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6153 - val_loss: 0.5795\n",
      "Epoch 352/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6153 - val_loss: 0.5795\n",
      "Epoch 353/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5795\n",
      "Epoch 354/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5795\n",
      "Epoch 355/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5795\n",
      "Epoch 356/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6153 - val_loss: 0.5794\n",
      "Epoch 357/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6153 - val_loss: 0.5795\n",
      "Epoch 358/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6153 - val_loss: 0.5794\n",
      "Epoch 359/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6153 - val_loss: 0.5795\n",
      "Epoch 360/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6153 - val_loss: 0.5795\n",
      "Epoch 361/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6153 - val_loss: 0.5794\n",
      "Epoch 362/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6153 - val_loss: 0.5795\n",
      "Epoch 363/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6153 - val_loss: 0.5795\n",
      "Epoch 364/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5794\n",
      "Epoch 365/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6153 - val_loss: 0.5794\n",
      "Epoch 366/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6153 - val_loss: 0.5795\n",
      "Epoch 367/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6153 - val_loss: 0.5794\n",
      "Epoch 368/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5794\n",
      "Epoch 369/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6153 - val_loss: 0.5794\n",
      "Epoch 370/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6153 - val_loss: 0.5794\n",
      "Epoch 371/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6153 - val_loss: 0.5794\n",
      "Epoch 372/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6153 - val_loss: 0.5794\n",
      "Epoch 373/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6153 - val_loss: 0.5794\n",
      "Epoch 374/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6153 - val_loss: 0.5794\n",
      "Epoch 375/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6153 - val_loss: 0.5794\n",
      "Epoch 376/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6153 - val_loss: 0.5795\n",
      "Epoch 377/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6153 - val_loss: 0.5793\n",
      "Epoch 378/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6153 - val_loss: 0.5794\n",
      "Epoch 379/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6153 - val_loss: 0.5794\n",
      "Epoch 380/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6153 - val_loss: 0.5794\n",
      "Epoch 381/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5794\n",
      "Epoch 382/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6153 - val_loss: 0.5794\n",
      "Epoch 383/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6153 - val_loss: 0.5794\n",
      "Epoch 384/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6153 - val_loss: 0.5794\n",
      "Epoch 385/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6153 - val_loss: 0.5794\n",
      "Epoch 386/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6153 - val_loss: 0.5794\n",
      "Epoch 387/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5794\n",
      "Epoch 388/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5794\n",
      "Epoch 389/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6153 - val_loss: 0.5794\n",
      "Epoch 390/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 391/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5794\n",
      "Epoch 392/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5794\n",
      "Epoch 393/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5794\n",
      "Epoch 394/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5794\n",
      "Epoch 395/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 396/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 397/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6152 - val_loss: 0.5794\n",
      "Epoch 398/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5794\n",
      "Epoch 399/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5794\n",
      "Epoch 400/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 401/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 402/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5794\n",
      "Epoch 403/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5794\n",
      "Epoch 404/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 405/1500\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 406/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 407/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 408/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6153 - val_loss: 0.5794\n",
      "Epoch 409/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 410/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5794\n",
      "Epoch 411/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5794\n",
      "Epoch 412/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 413/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 414/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5794\n",
      "Epoch 415/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 416/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 417/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5794\n",
      "Epoch 418/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5794\n",
      "Epoch 419/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 420/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 421/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 422/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 423/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 424/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 425/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 426/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 427/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 428/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 429/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5794\n",
      "Epoch 430/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 431/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 432/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 433/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 434/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 435/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 436/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 437/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 438/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 439/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 440/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 441/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 442/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 443/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 444/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 445/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 446/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 447/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 448/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 449/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 450/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 451/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 452/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 453/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 454/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 455/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 456/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 457/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 458/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 459/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 460/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 461/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 462/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 463/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 464/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 465/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 466/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 467/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 468/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 469/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 470/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 471/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 472/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 473/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 474/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 475/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 476/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 477/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 478/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 479/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 480/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 481/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 482/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 483/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 484/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 485/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 486/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 487/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 488/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 489/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 490/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 491/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 492/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 493/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 494/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 495/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 496/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 497/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 498/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 499/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 500/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 501/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 502/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 503/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 504/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 505/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 506/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 507/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 508/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 509/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 510/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 511/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5793\n",
      "Epoch 512/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 513/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 514/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 515/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 516/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 517/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 518/1500\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 519/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 520/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 521/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 522/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 523/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 524/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 525/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 526/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 527/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 528/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 529/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 530/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 531/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 532/1500\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 533/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 534/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 535/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 536/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 537/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 538/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 539/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 540/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 541/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 542/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 543/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 544/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 545/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 546/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 547/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 548/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 549/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 550/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 551/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 552/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 553/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 554/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 555/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 556/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 557/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 558/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 559/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 560/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 561/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 562/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 563/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 564/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 565/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 566/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 567/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 568/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 569/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 570/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 571/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 572/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 573/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 574/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 575/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 576/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 577/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 578/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 579/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 580/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 581/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 582/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 583/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 584/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 585/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 586/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 587/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 588/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 589/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 590/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 591/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 592/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 593/1500\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 594/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 595/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 596/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 597/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 598/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 599/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 600/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 601/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 602/1500\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 603/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 604/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 605/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 606/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 607/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 608/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 609/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 610/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 611/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 612/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 613/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 614/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 615/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 616/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 617/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 618/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 619/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 620/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 621/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 622/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 623/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 624/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 625/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 626/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 627/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 628/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 629/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 630/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 631/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 632/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 633/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 634/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 635/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 636/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 637/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 638/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 639/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 640/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 641/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 642/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 643/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 644/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 645/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 646/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 647/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 648/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 649/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 650/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 651/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 652/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 653/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 654/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 655/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 656/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 657/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 658/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 659/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 660/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 661/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 662/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 663/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 664/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 665/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 666/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 667/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 668/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 669/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 670/1500\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 671/1500\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 672/1500\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 673/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 674/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 675/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 676/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 677/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 678/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 679/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 680/1500\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 681/1500\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 682/1500\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 683/1500\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 684/1500\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 685/1500\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 686/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 687/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 688/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 689/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 690/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 691/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 692/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 693/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 694/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 695/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 696/1500\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 697/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 698/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 699/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 700/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 701/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 702/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 703/1500\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 704/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 705/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 706/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 707/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 708/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 709/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 710/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 711/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 712/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 713/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 714/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 715/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 716/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 717/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 718/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 719/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 720/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 721/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 722/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 723/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 724/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 725/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 726/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 727/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 728/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 729/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 730/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 731/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 732/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 733/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 734/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 735/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 736/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 737/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 738/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 739/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 740/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 741/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 742/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 743/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 744/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 745/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 746/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 747/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 748/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 749/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 750/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 751/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 752/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 753/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 754/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 755/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 756/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 757/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 758/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 759/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 760/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 761/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 762/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 763/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 764/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 765/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 766/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 767/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 768/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 769/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 770/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 771/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 772/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 773/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 774/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 775/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 776/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 777/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 778/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 779/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 780/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 781/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 782/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 783/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 784/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 785/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 786/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 787/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 788/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 789/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 790/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 791/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 792/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 793/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 794/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 795/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 796/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 797/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 798/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 799/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 800/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 801/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 802/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 803/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 804/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 805/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 806/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 807/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 808/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 809/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 810/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 811/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 812/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 813/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 814/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 815/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 816/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 817/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 818/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 819/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 820/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 821/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 822/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 823/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 824/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 825/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 826/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 827/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 828/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 829/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 830/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 831/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 832/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 833/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 834/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 835/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 836/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 837/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 838/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 839/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 840/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 841/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 842/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 843/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 844/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 845/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 846/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 847/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 848/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 849/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 850/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 851/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 852/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 853/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 854/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 855/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 856/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 857/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 858/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 859/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 860/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 861/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 862/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 863/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 864/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 865/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 866/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 867/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 868/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 869/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 870/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 871/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 872/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 873/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 874/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 875/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 876/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 877/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 878/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 879/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 880/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 881/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 882/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 883/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 884/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 885/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 886/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 887/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 888/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 889/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 890/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 891/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 892/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 893/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 894/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 895/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 896/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5790\n",
      "Epoch 897/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 898/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 899/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 900/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 901/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 902/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 903/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 904/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 905/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 906/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 907/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 908/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 909/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 910/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 911/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 912/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 913/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 914/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 915/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 916/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 917/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 918/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 919/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 920/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 921/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 922/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 923/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 924/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 925/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 926/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 927/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 928/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 929/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 930/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 931/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 932/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 933/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 934/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 935/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 936/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 937/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 938/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 939/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 940/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 941/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 942/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 943/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 944/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 945/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 946/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 947/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 948/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 949/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 950/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 951/1500\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 952/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 953/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 954/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 955/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 956/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 957/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 958/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 959/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 960/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 961/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 962/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 963/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 964/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 965/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 966/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 967/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 968/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 969/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 970/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 971/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 972/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 973/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 974/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 975/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 976/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 977/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 978/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 979/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 980/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 981/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 982/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 983/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 984/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 985/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 986/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 987/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5790\n",
      "Epoch 988/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 989/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 990/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 991/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 992/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 993/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 994/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 995/1500\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 996/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 997/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 998/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 999/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1000/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1001/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1002/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1003/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1004/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5790\n",
      "Epoch 1005/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1006/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1007/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1008/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1009/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1010/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1011/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1012/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1013/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1014/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1015/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1016/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1017/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1018/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 1019/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1020/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1021/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1022/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1023/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1024/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1025/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1026/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1027/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1028/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1029/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1030/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1031/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1032/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1033/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1034/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1035/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1036/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1037/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1038/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1039/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1040/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1041/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1042/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1043/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1044/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1045/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1046/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1047/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1048/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1049/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1050/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1051/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1052/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1053/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1054/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1055/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1056/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1057/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1058/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1059/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1060/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1061/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1062/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1063/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1064/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1065/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 1066/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1067/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1068/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1069/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1070/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1071/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1072/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1073/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1074/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5790\n",
      "Epoch 1075/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1076/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1077/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1078/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1079/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1080/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1081/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1082/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1083/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 1084/1500\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1085/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1086/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1087/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1088/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1089/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5790\n",
      "Epoch 1090/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1091/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1092/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1093/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1094/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5790\n",
      "Epoch 1095/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1096/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1097/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1098/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1099/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1100/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1101/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1102/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1103/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1104/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1105/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1106/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1107/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1108/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1109/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1110/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1111/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1112/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1113/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1114/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1115/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1116/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1117/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1118/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1119/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1120/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 1121/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1122/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1123/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1124/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1125/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1126/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1127/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1128/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1129/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1130/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1131/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1132/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1133/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1134/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1135/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1136/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1137/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1138/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1139/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 1140/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1141/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1142/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1143/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1144/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1145/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1146/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1147/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1148/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 1149/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1150/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1151/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1152/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1153/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1154/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1155/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1156/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1157/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1158/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1159/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1160/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1161/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1162/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1163/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 1164/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 1165/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1166/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1167/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 1168/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1169/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1170/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1171/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1172/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1173/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1174/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1175/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1176/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 1177/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1178/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1179/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1180/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1181/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1182/1500\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1183/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 1184/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1185/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1186/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1187/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1188/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1189/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1190/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1191/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1192/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1193/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1194/1500\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1195/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1196/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1197/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1198/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1199/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1200/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1201/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1202/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 1203/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1204/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1205/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1206/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1207/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1208/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1209/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1210/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1211/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1212/1500\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1213/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5790\n",
      "Epoch 1214/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 1215/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1216/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1217/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1218/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1219/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1220/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1221/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1222/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 1223/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1224/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1225/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1226/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1227/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1228/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1229/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1230/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1231/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1232/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1233/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1234/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1235/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 1236/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1237/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1238/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1239/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1240/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 1241/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1242/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1243/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1244/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 1245/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1246/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 1247/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1248/1500\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1249/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1250/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1251/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1252/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1253/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 1254/1500\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1255/1500\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 1256/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1257/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 1258/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1259/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1260/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1261/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1262/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1263/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1264/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1265/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 1266/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1267/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1268/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1269/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1270/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1271/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1272/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1273/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1274/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1275/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1276/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1277/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1278/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1279/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1280/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1281/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1282/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1283/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1284/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1285/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1286/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1287/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1288/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 1289/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1290/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1291/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 1292/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1293/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1294/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1295/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1296/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1297/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1298/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1299/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1300/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1301/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1302/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1303/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1304/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5790\n",
      "Epoch 1305/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1306/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1307/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1308/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1309/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1310/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 1311/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1312/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1313/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1314/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1315/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 1316/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1317/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1318/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1319/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1320/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1321/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1322/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1323/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1324/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1325/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1326/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1327/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1328/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1329/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 1330/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1331/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1332/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1333/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1334/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1335/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 1336/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1337/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1338/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1339/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1340/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1341/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 1342/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1343/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1344/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1345/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1346/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1347/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1348/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1349/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1350/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1351/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1352/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1353/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1354/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1355/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1356/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1357/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1358/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1359/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1360/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 1361/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1362/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1363/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1364/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1365/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1366/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1367/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1368/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1369/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1370/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1371/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1372/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 1373/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 1374/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1375/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1376/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1377/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1378/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1379/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1380/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1381/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1382/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1383/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1384/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1385/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 1386/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1387/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1388/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1389/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1390/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1391/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1392/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1393/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1394/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1395/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1396/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1397/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 1398/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1399/1500\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1400/1500\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1401/1500\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1402/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1403/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1404/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1405/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1406/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 1407/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1408/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1409/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1410/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1411/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 1412/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1413/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1414/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1415/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1416/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1417/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1418/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1419/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1420/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1421/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1422/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1423/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1424/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1425/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1426/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1427/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1428/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1429/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1430/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1431/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1432/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1433/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1434/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1435/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1436/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1437/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1438/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1439/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1440/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1441/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1442/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1443/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 1444/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1445/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1446/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 1447/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1448/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 1449/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1450/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 1451/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1452/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1453/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1454/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1455/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1456/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1457/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1458/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1459/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1460/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1461/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1462/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 1463/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1464/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1465/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1466/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1467/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1468/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 1469/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1470/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1471/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1472/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 1473/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1474/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1475/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1476/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1477/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1478/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1479/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1480/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1481/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1482/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1483/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 1484/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1485/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1486/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 1487/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1488/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1489/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1490/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1491/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1492/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1493/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1494/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1495/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1496/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5792\n",
      "Epoch 1497/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1498/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1499/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "Epoch 1500/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5791\n",
      "54/54 [==============================] - 0s 2ms/step\n",
      "14/14 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Define the autoencoder architecture\n",
    "input_dim = X_train_scaled.shape[1]\n",
    "encoding_dim = 64\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "encoder = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "decoder = Dense(input_dim, activation='sigmoid')(encoder)\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the autoencoder\n",
    "autoencoder.fit(X_train_scaled, X_train_scaled, epochs=1500, batch_size=40,\n",
    "                validation_data=(X_test_scaled, X_test_scaled))\n",
    "\n",
    "# Extract the encoded representations\n",
    "encoder = Model(inputs=input_layer, outputs=encoder)\n",
    "X_train_encoded = encoder.predict(X_train_scaled)\n",
    "X_test_encoded = encoder.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "968e24a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8457943925233645\n",
      "Precision:  0.7153681544239672\n",
      "Recall:  0.8457943925233645\n",
      "F1-score:  0.7751330888441973\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       362\n",
      "           1       0.00      0.00      0.00        66\n",
      "\n",
      "    accuracy                           0.85       428\n",
      "   macro avg       0.42      0.50      0.46       428\n",
      "weighted avg       0.72      0.85      0.78       428\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Train a classifier\n",
    "from sklearn.svm import SVC\n",
    "clf = SVC()\n",
    "clf.fit(X_train_encoded, y_train)\n",
    "\n",
    "# Evaluate the performance\n",
    "y_pred = clf.predict(X_test_encoded)\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision: \", precision_score(y_test, y_pred, average='weighted'))\n",
    "print(\"Recall: \", recall_score(y_test, y_pred, average='weighted'))\n",
    "print(\"F1-score: \", f1_score(y_test, y_pred, average='weighted'))\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import plot_confusion_matrix, classification_report\n",
    "import warnings\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "859c689c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 84.58%\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "model = XGBClassifier()\n",
    "history = model.fit(X_train_encoded, y_train)\n",
    "#print(model)\n",
    "\n",
    "y_pred = model.predict(X_test_encoded)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fe7a26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8457943925233645\n",
      "Precision:  0.7994678710369807\n",
      "Recall:  0.8457943925233645\n",
      "F1-score:  0.7945173862045479\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.99      0.92       362\n",
      "           1       0.50      0.08      0.13        66\n",
      "\n",
      "    accuracy                           0.85       428\n",
      "   macro avg       0.68      0.53      0.52       428\n",
      "weighted avg       0.80      0.85      0.79       428\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import plot_confusion_matrix, classification_report\n",
    "import warnings\n",
    "\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision: \", precision_score(y_test, y_pred, average='weighted'))\n",
    "print(\"Recall: \", recall_score(y_test, y_pred, average='weighted'))\n",
    "print(\"F1-score: \", f1_score(y_test, y_pred, average='weighted'))\n",
    "\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a25a5f",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70ed4e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9405b9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,0:39]\n",
    "y = df.iloc[:,39]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca662d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the accent labels to integers\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Convert the accent labels to one-hot vectors\n",
    "num_classes = len(np.unique(y_train_encoded))\n",
    "y_train_onehot = to_categorical(y_train_encoded, num_classes)\n",
    "y_test_onehot = to_categorical(y_test_encoded, num_classes)\n",
    "\n",
    "# Reshape the input features for the CNN\n",
    "n_timesteps, n_features = X_train.shape[1], 1\n",
    "X_train_reshaped = X_train.values.reshape((X_train.shape[0], n_timesteps, n_features))\n",
    "X_test_reshaped = X_test.values.reshape((X_test.shape[0], n_timesteps, n_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16bed7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN architecture\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(n_timesteps, n_features)))\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99978040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "38/38 [==============================] - 2s 18ms/step - loss: 0.8036 - accuracy: 0.7540 - val_loss: 0.4932 - val_accuracy: 0.8131\n",
      "Epoch 2/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.5133 - accuracy: 0.8015 - val_loss: 0.5233 - val_accuracy: 0.8255\n",
      "Epoch 3/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.4874 - accuracy: 0.8048 - val_loss: 0.4538 - val_accuracy: 0.8271\n",
      "Epoch 4/1500\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.4671 - accuracy: 0.8189 - val_loss: 0.4665 - val_accuracy: 0.8287\n",
      "Epoch 5/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.4489 - accuracy: 0.8255 - val_loss: 0.4472 - val_accuracy: 0.8287\n",
      "Epoch 6/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.4537 - accuracy: 0.8229 - val_loss: 0.4509 - val_accuracy: 0.8302\n",
      "Epoch 7/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.4514 - accuracy: 0.8222 - val_loss: 0.4429 - val_accuracy: 0.8287\n",
      "Epoch 8/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.4492 - accuracy: 0.8229 - val_loss: 0.4420 - val_accuracy: 0.8287\n",
      "Epoch 9/1500\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.4412 - accuracy: 0.8269 - val_loss: 0.4430 - val_accuracy: 0.8318\n",
      "Epoch 10/1500\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.4478 - accuracy: 0.8249 - val_loss: 0.4463 - val_accuracy: 0.8318\n",
      "Epoch 11/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.4447 - accuracy: 0.8215 - val_loss: 0.4558 - val_accuracy: 0.8302\n",
      "Epoch 12/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.4509 - accuracy: 0.8189 - val_loss: 0.4425 - val_accuracy: 0.8287\n",
      "Epoch 13/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.4433 - accuracy: 0.8202 - val_loss: 0.4429 - val_accuracy: 0.8287\n",
      "Epoch 14/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.4429 - accuracy: 0.8282 - val_loss: 0.4485 - val_accuracy: 0.8302\n",
      "Epoch 15/1500\n",
      "38/38 [==============================] - 0s 13ms/step - loss: 0.4324 - accuracy: 0.8275 - val_loss: 0.4407 - val_accuracy: 0.8287\n",
      "Epoch 16/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.4385 - accuracy: 0.8249 - val_loss: 0.4480 - val_accuracy: 0.8318\n",
      "Epoch 17/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.4384 - accuracy: 0.8235 - val_loss: 0.4589 - val_accuracy: 0.8318\n",
      "Epoch 18/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.4489 - accuracy: 0.8249 - val_loss: 0.4559 - val_accuracy: 0.8302\n",
      "Epoch 19/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.4486 - accuracy: 0.8282 - val_loss: 0.4418 - val_accuracy: 0.8302\n",
      "Epoch 20/1500\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.4395 - accuracy: 0.8262 - val_loss: 0.4412 - val_accuracy: 0.8287\n",
      "Epoch 21/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.4423 - accuracy: 0.8262 - val_loss: 0.4437 - val_accuracy: 0.8287\n",
      "Epoch 22/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.4321 - accuracy: 0.8295 - val_loss: 0.4536 - val_accuracy: 0.8349\n",
      "Epoch 23/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.4308 - accuracy: 0.8255 - val_loss: 0.4377 - val_accuracy: 0.8287\n",
      "Epoch 24/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.4217 - accuracy: 0.8249 - val_loss: 0.4411 - val_accuracy: 0.8302\n",
      "Epoch 25/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.4445 - accuracy: 0.8255 - val_loss: 0.4426 - val_accuracy: 0.8287\n",
      "Epoch 26/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4269 - accuracy: 0.8309 - val_loss: 0.4495 - val_accuracy: 0.8287\n",
      "Epoch 27/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.4171 - accuracy: 0.8289 - val_loss: 0.4405 - val_accuracy: 0.8271\n",
      "Epoch 28/1500\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.4271 - accuracy: 0.8302 - val_loss: 0.4534 - val_accuracy: 0.8349\n",
      "Epoch 29/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4245 - accuracy: 0.8249 - val_loss: 0.4500 - val_accuracy: 0.8302\n",
      "Epoch 30/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4210 - accuracy: 0.8289 - val_loss: 0.4428 - val_accuracy: 0.8318\n",
      "Epoch 31/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.4133 - accuracy: 0.8309 - val_loss: 0.4554 - val_accuracy: 0.8364\n",
      "Epoch 32/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.4187 - accuracy: 0.8309 - val_loss: 0.4427 - val_accuracy: 0.8271\n",
      "Epoch 33/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4088 - accuracy: 0.8322 - val_loss: 0.4435 - val_accuracy: 0.8240\n",
      "Epoch 34/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4088 - accuracy: 0.8329 - val_loss: 0.4447 - val_accuracy: 0.8287\n",
      "Epoch 35/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4033 - accuracy: 0.8342 - val_loss: 0.4433 - val_accuracy: 0.8302\n",
      "Epoch 36/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3960 - accuracy: 0.8349 - val_loss: 0.4479 - val_accuracy: 0.8287\n",
      "Epoch 37/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4041 - accuracy: 0.8322 - val_loss: 0.4509 - val_accuracy: 0.8302\n",
      "Epoch 38/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4015 - accuracy: 0.8356 - val_loss: 0.4421 - val_accuracy: 0.8302\n",
      "Epoch 39/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3953 - accuracy: 0.8382 - val_loss: 0.4393 - val_accuracy: 0.8318\n",
      "Epoch 40/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3931 - accuracy: 0.8336 - val_loss: 0.4511 - val_accuracy: 0.8240\n",
      "Epoch 41/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3948 - accuracy: 0.8322 - val_loss: 0.4414 - val_accuracy: 0.8287\n",
      "Epoch 42/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3856 - accuracy: 0.8449 - val_loss: 0.4460 - val_accuracy: 0.8224\n",
      "Epoch 43/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3797 - accuracy: 0.8356 - val_loss: 0.4435 - val_accuracy: 0.8318\n",
      "Epoch 44/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3690 - accuracy: 0.8409 - val_loss: 0.4376 - val_accuracy: 0.8240\n",
      "Epoch 45/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3703 - accuracy: 0.8496 - val_loss: 0.4526 - val_accuracy: 0.8318\n",
      "Epoch 46/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3643 - accuracy: 0.8436 - val_loss: 0.4654 - val_accuracy: 0.8084\n",
      "Epoch 47/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3659 - accuracy: 0.8389 - val_loss: 0.4563 - val_accuracy: 0.8271\n",
      "Epoch 48/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3661 - accuracy: 0.8416 - val_loss: 0.4526 - val_accuracy: 0.8271\n",
      "Epoch 49/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3612 - accuracy: 0.8456 - val_loss: 0.4507 - val_accuracy: 0.8193\n",
      "Epoch 50/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3538 - accuracy: 0.8362 - val_loss: 0.4442 - val_accuracy: 0.8224\n",
      "Epoch 51/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3439 - accuracy: 0.8489 - val_loss: 0.4647 - val_accuracy: 0.8146\n",
      "Epoch 52/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3455 - accuracy: 0.8503 - val_loss: 0.4662 - val_accuracy: 0.8069\n",
      "Epoch 53/1500\n",
      "38/38 [==============================] - 1s 13ms/step - loss: 0.3404 - accuracy: 0.8590 - val_loss: 0.4748 - val_accuracy: 0.8100\n",
      "Epoch 54/1500\n",
      "38/38 [==============================] - 1s 13ms/step - loss: 0.3429 - accuracy: 0.8516 - val_loss: 0.4736 - val_accuracy: 0.8224\n",
      "Epoch 55/1500\n",
      "38/38 [==============================] - 0s 13ms/step - loss: 0.3403 - accuracy: 0.8543 - val_loss: 0.4603 - val_accuracy: 0.8255\n",
      "Epoch 56/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3225 - accuracy: 0.8523 - val_loss: 0.4661 - val_accuracy: 0.8209\n",
      "Epoch 57/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3223 - accuracy: 0.8656 - val_loss: 0.4642 - val_accuracy: 0.8287\n",
      "Epoch 58/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3174 - accuracy: 0.8603 - val_loss: 0.4777 - val_accuracy: 0.8333\n",
      "Epoch 59/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3132 - accuracy: 0.8656 - val_loss: 0.4871 - val_accuracy: 0.8115\n",
      "Epoch 60/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3140 - accuracy: 0.8603 - val_loss: 0.4888 - val_accuracy: 0.7819\n",
      "Epoch 61/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3018 - accuracy: 0.8757 - val_loss: 0.4894 - val_accuracy: 0.8146\n",
      "Epoch 62/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3149 - accuracy: 0.8630 - val_loss: 0.4948 - val_accuracy: 0.8037\n",
      "Epoch 63/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2985 - accuracy: 0.8737 - val_loss: 0.5037 - val_accuracy: 0.8006\n",
      "Epoch 64/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3035 - accuracy: 0.8636 - val_loss: 0.5005 - val_accuracy: 0.7991\n",
      "Epoch 65/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2851 - accuracy: 0.8650 - val_loss: 0.5182 - val_accuracy: 0.7991\n",
      "Epoch 66/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2906 - accuracy: 0.8810 - val_loss: 0.5013 - val_accuracy: 0.8240\n",
      "Epoch 67/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2944 - accuracy: 0.8737 - val_loss: 0.5351 - val_accuracy: 0.8069\n",
      "Epoch 68/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2964 - accuracy: 0.8703 - val_loss: 0.5085 - val_accuracy: 0.8131\n",
      "Epoch 69/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2682 - accuracy: 0.8817 - val_loss: 0.5135 - val_accuracy: 0.8178\n",
      "Epoch 70/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2824 - accuracy: 0.8717 - val_loss: 0.5200 - val_accuracy: 0.8037\n",
      "Epoch 71/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2560 - accuracy: 0.8924 - val_loss: 0.5281 - val_accuracy: 0.8069\n",
      "Epoch 72/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2479 - accuracy: 0.8850 - val_loss: 0.5596 - val_accuracy: 0.8131\n",
      "Epoch 73/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2550 - accuracy: 0.8864 - val_loss: 0.5548 - val_accuracy: 0.8162\n",
      "Epoch 74/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2509 - accuracy: 0.8857 - val_loss: 0.5449 - val_accuracy: 0.8115\n",
      "Epoch 75/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2635 - accuracy: 0.8870 - val_loss: 0.5381 - val_accuracy: 0.8037\n",
      "Epoch 76/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2642 - accuracy: 0.8857 - val_loss: 0.5616 - val_accuracy: 0.7991\n",
      "Epoch 77/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2409 - accuracy: 0.8971 - val_loss: 0.5602 - val_accuracy: 0.7960\n",
      "Epoch 78/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2329 - accuracy: 0.9024 - val_loss: 0.5949 - val_accuracy: 0.7882\n",
      "Epoch 79/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2270 - accuracy: 0.8991 - val_loss: 0.6289 - val_accuracy: 0.8209\n",
      "Epoch 80/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2344 - accuracy: 0.8957 - val_loss: 0.5822 - val_accuracy: 0.7991\n",
      "Epoch 81/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2424 - accuracy: 0.8951 - val_loss: 0.5713 - val_accuracy: 0.8069\n",
      "Epoch 82/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2180 - accuracy: 0.9158 - val_loss: 0.5726 - val_accuracy: 0.7991\n",
      "Epoch 83/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2193 - accuracy: 0.9011 - val_loss: 0.6087 - val_accuracy: 0.8084\n",
      "Epoch 84/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2063 - accuracy: 0.9057 - val_loss: 0.6501 - val_accuracy: 0.8053\n",
      "Epoch 85/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2130 - accuracy: 0.9091 - val_loss: 0.6184 - val_accuracy: 0.7555\n",
      "Epoch 86/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2066 - accuracy: 0.9084 - val_loss: 0.6294 - val_accuracy: 0.8006\n",
      "Epoch 87/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2082 - accuracy: 0.9164 - val_loss: 0.6585 - val_accuracy: 0.8084\n",
      "Epoch 88/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2094 - accuracy: 0.9144 - val_loss: 0.6206 - val_accuracy: 0.7991\n",
      "Epoch 89/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2059 - accuracy: 0.9104 - val_loss: 0.6622 - val_accuracy: 0.8069\n",
      "Epoch 90/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1925 - accuracy: 0.9171 - val_loss: 0.6662 - val_accuracy: 0.7991\n",
      "Epoch 91/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1939 - accuracy: 0.9131 - val_loss: 0.6358 - val_accuracy: 0.8006\n",
      "Epoch 92/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1811 - accuracy: 0.9298 - val_loss: 0.6911 - val_accuracy: 0.8037\n",
      "Epoch 93/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1720 - accuracy: 0.9245 - val_loss: 0.7025 - val_accuracy: 0.8037\n",
      "Epoch 94/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1761 - accuracy: 0.9238 - val_loss: 0.6881 - val_accuracy: 0.8069\n",
      "Epoch 95/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1850 - accuracy: 0.9251 - val_loss: 0.7188 - val_accuracy: 0.8100\n",
      "Epoch 96/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1707 - accuracy: 0.9251 - val_loss: 0.6719 - val_accuracy: 0.7850\n",
      "Epoch 97/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1797 - accuracy: 0.9278 - val_loss: 0.7498 - val_accuracy: 0.8006\n",
      "Epoch 98/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1803 - accuracy: 0.9238 - val_loss: 0.6884 - val_accuracy: 0.7928\n",
      "Epoch 99/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1716 - accuracy: 0.9258 - val_loss: 0.7652 - val_accuracy: 0.7991\n",
      "Epoch 100/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1707 - accuracy: 0.9245 - val_loss: 0.7261 - val_accuracy: 0.7975\n",
      "Epoch 101/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1484 - accuracy: 0.9385 - val_loss: 0.7953 - val_accuracy: 0.7897\n",
      "Epoch 102/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1614 - accuracy: 0.9352 - val_loss: 0.7684 - val_accuracy: 0.7726\n",
      "Epoch 103/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1574 - accuracy: 0.9372 - val_loss: 0.7467 - val_accuracy: 0.7928\n",
      "Epoch 104/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1532 - accuracy: 0.9385 - val_loss: 0.8103 - val_accuracy: 0.7788\n",
      "Epoch 105/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.1616 - accuracy: 0.9405 - val_loss: 0.7678 - val_accuracy: 0.8037\n",
      "Epoch 106/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.1467 - accuracy: 0.9398 - val_loss: 0.7494 - val_accuracy: 0.8006\n",
      "Epoch 107/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1296 - accuracy: 0.9539 - val_loss: 0.7987 - val_accuracy: 0.7773\n",
      "Epoch 108/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.1319 - accuracy: 0.9492 - val_loss: 0.8555 - val_accuracy: 0.7835\n",
      "Epoch 109/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1356 - accuracy: 0.9452 - val_loss: 0.8365 - val_accuracy: 0.7960\n",
      "Epoch 110/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1322 - accuracy: 0.9405 - val_loss: 0.8545 - val_accuracy: 0.7944\n",
      "Epoch 111/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1388 - accuracy: 0.9418 - val_loss: 0.8217 - val_accuracy: 0.7975\n",
      "Epoch 112/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1526 - accuracy: 0.9325 - val_loss: 0.8248 - val_accuracy: 0.7835\n",
      "Epoch 113/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1403 - accuracy: 0.9432 - val_loss: 0.8178 - val_accuracy: 0.7804\n",
      "Epoch 114/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1344 - accuracy: 0.9412 - val_loss: 0.8264 - val_accuracy: 0.7944\n",
      "Epoch 115/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1295 - accuracy: 0.9459 - val_loss: 0.8686 - val_accuracy: 0.7819\n",
      "Epoch 116/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1358 - accuracy: 0.9465 - val_loss: 0.8959 - val_accuracy: 0.7991\n",
      "Epoch 117/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1310 - accuracy: 0.9519 - val_loss: 0.8336 - val_accuracy: 0.7757\n",
      "Epoch 118/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1193 - accuracy: 0.9525 - val_loss: 0.9188 - val_accuracy: 0.7882\n",
      "Epoch 119/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1208 - accuracy: 0.9519 - val_loss: 0.8967 - val_accuracy: 0.7944\n",
      "Epoch 120/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1264 - accuracy: 0.9505 - val_loss: 0.8808 - val_accuracy: 0.7757\n",
      "Epoch 121/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1339 - accuracy: 0.9425 - val_loss: 0.8393 - val_accuracy: 0.7710\n",
      "Epoch 122/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.1200 - accuracy: 0.9552 - val_loss: 0.9377 - val_accuracy: 0.7928\n",
      "Epoch 123/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1210 - accuracy: 0.9552 - val_loss: 0.8677 - val_accuracy: 0.7850\n",
      "Epoch 124/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1172 - accuracy: 0.9592 - val_loss: 0.9202 - val_accuracy: 0.7991\n",
      "Epoch 125/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1146 - accuracy: 0.9559 - val_loss: 0.8943 - val_accuracy: 0.8037\n",
      "Epoch 126/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1005 - accuracy: 0.9606 - val_loss: 0.9124 - val_accuracy: 0.7757\n",
      "Epoch 127/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1167 - accuracy: 0.9586 - val_loss: 0.9003 - val_accuracy: 0.7882\n",
      "Epoch 128/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1043 - accuracy: 0.9639 - val_loss: 0.9768 - val_accuracy: 0.7928\n",
      "Epoch 129/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0940 - accuracy: 0.9639 - val_loss: 0.9860 - val_accuracy: 0.7897\n",
      "Epoch 130/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1101 - accuracy: 0.9592 - val_loss: 0.9399 - val_accuracy: 0.7897\n",
      "Epoch 131/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0952 - accuracy: 0.9599 - val_loss: 0.9641 - val_accuracy: 0.7944\n",
      "Epoch 132/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0999 - accuracy: 0.9626 - val_loss: 0.9956 - val_accuracy: 0.7928\n",
      "Epoch 133/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0910 - accuracy: 0.9652 - val_loss: 0.9935 - val_accuracy: 0.7788\n",
      "Epoch 134/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0933 - accuracy: 0.9652 - val_loss: 0.9952 - val_accuracy: 0.8084\n",
      "Epoch 135/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0884 - accuracy: 0.9666 - val_loss: 1.0682 - val_accuracy: 0.7960\n",
      "Epoch 136/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1069 - accuracy: 0.9559 - val_loss: 1.0928 - val_accuracy: 0.8037\n",
      "Epoch 137/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1093 - accuracy: 0.9639 - val_loss: 1.0817 - val_accuracy: 0.7897\n",
      "Epoch 138/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1020 - accuracy: 0.9612 - val_loss: 1.0205 - val_accuracy: 0.7835\n",
      "Epoch 139/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0960 - accuracy: 0.9686 - val_loss: 1.0911 - val_accuracy: 0.7975\n",
      "Epoch 140/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0914 - accuracy: 0.9599 - val_loss: 1.0577 - val_accuracy: 0.7991\n",
      "Epoch 141/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0867 - accuracy: 0.9666 - val_loss: 1.0530 - val_accuracy: 0.7882\n",
      "Epoch 142/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0742 - accuracy: 0.9739 - val_loss: 1.0771 - val_accuracy: 0.7882\n",
      "Epoch 143/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0872 - accuracy: 0.9672 - val_loss: 1.0754 - val_accuracy: 0.7679\n",
      "Epoch 144/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0744 - accuracy: 0.9746 - val_loss: 1.1205 - val_accuracy: 0.7866\n",
      "Epoch 145/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0891 - accuracy: 0.9652 - val_loss: 1.1275 - val_accuracy: 0.7804\n",
      "Epoch 146/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0959 - accuracy: 0.9672 - val_loss: 1.0880 - val_accuracy: 0.7695\n",
      "Epoch 147/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0959 - accuracy: 0.9659 - val_loss: 1.1365 - val_accuracy: 0.7757\n",
      "Epoch 148/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0964 - accuracy: 0.9639 - val_loss: 1.1836 - val_accuracy: 0.8006\n",
      "Epoch 149/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0916 - accuracy: 0.9599 - val_loss: 1.1281 - val_accuracy: 0.7726\n",
      "Epoch 150/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0777 - accuracy: 0.9713 - val_loss: 1.0796 - val_accuracy: 0.7695\n",
      "Epoch 151/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0851 - accuracy: 0.9713 - val_loss: 1.1601 - val_accuracy: 0.7664\n",
      "Epoch 152/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0989 - accuracy: 0.9586 - val_loss: 1.1216 - val_accuracy: 0.7726\n",
      "Epoch 153/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0839 - accuracy: 0.9679 - val_loss: 1.1781 - val_accuracy: 0.7695\n",
      "Epoch 154/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0785 - accuracy: 0.9699 - val_loss: 1.1279 - val_accuracy: 0.7866\n",
      "Epoch 155/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0785 - accuracy: 0.9719 - val_loss: 1.1100 - val_accuracy: 0.7804\n",
      "Epoch 156/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0657 - accuracy: 0.9786 - val_loss: 1.2066 - val_accuracy: 0.7882\n",
      "Epoch 157/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0661 - accuracy: 0.9759 - val_loss: 1.2018 - val_accuracy: 0.7835\n",
      "Epoch 158/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0650 - accuracy: 0.9799 - val_loss: 1.1728 - val_accuracy: 0.7601\n",
      "Epoch 159/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0878 - accuracy: 0.9652 - val_loss: 1.2013 - val_accuracy: 0.7788\n",
      "Epoch 160/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0686 - accuracy: 0.9759 - val_loss: 1.2143 - val_accuracy: 0.7726\n",
      "Epoch 161/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0569 - accuracy: 0.9806 - val_loss: 1.2101 - val_accuracy: 0.7726\n",
      "Epoch 162/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0707 - accuracy: 0.9739 - val_loss: 1.2898 - val_accuracy: 0.7882\n",
      "Epoch 163/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0762 - accuracy: 0.9739 - val_loss: 1.2311 - val_accuracy: 0.7897\n",
      "Epoch 164/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0655 - accuracy: 0.9753 - val_loss: 1.2990 - val_accuracy: 0.7726\n",
      "Epoch 165/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0893 - accuracy: 0.9666 - val_loss: 1.1952 - val_accuracy: 0.7991\n",
      "Epoch 166/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0858 - accuracy: 0.9672 - val_loss: 1.2493 - val_accuracy: 0.7928\n",
      "Epoch 167/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0601 - accuracy: 0.9739 - val_loss: 1.1977 - val_accuracy: 0.7773\n",
      "Epoch 168/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0697 - accuracy: 0.9733 - val_loss: 1.1923 - val_accuracy: 0.7539\n",
      "Epoch 169/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0856 - accuracy: 0.9719 - val_loss: 1.2100 - val_accuracy: 0.7866\n",
      "Epoch 170/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0749 - accuracy: 0.9686 - val_loss: 1.1899 - val_accuracy: 0.7804\n",
      "Epoch 171/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0621 - accuracy: 0.9739 - val_loss: 1.2589 - val_accuracy: 0.7866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0498 - accuracy: 0.9820 - val_loss: 1.2299 - val_accuracy: 0.7804\n",
      "Epoch 173/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0601 - accuracy: 0.9813 - val_loss: 1.3422 - val_accuracy: 0.7897\n",
      "Epoch 174/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0646 - accuracy: 0.9779 - val_loss: 1.2650 - val_accuracy: 0.7741\n",
      "Epoch 175/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0650 - accuracy: 0.9799 - val_loss: 1.2915 - val_accuracy: 0.7804\n",
      "Epoch 176/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0680 - accuracy: 0.9753 - val_loss: 1.3598 - val_accuracy: 0.7648\n",
      "Epoch 177/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0595 - accuracy: 0.9793 - val_loss: 1.2949 - val_accuracy: 0.7850\n",
      "Epoch 178/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0563 - accuracy: 0.9793 - val_loss: 1.3430 - val_accuracy: 0.7710\n",
      "Epoch 179/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0523 - accuracy: 0.9826 - val_loss: 1.3436 - val_accuracy: 0.7773\n",
      "Epoch 180/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0652 - accuracy: 0.9786 - val_loss: 1.3280 - val_accuracy: 0.7850\n",
      "Epoch 181/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0633 - accuracy: 0.9779 - val_loss: 1.3945 - val_accuracy: 0.7975\n",
      "Epoch 182/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0556 - accuracy: 0.9820 - val_loss: 1.3079 - val_accuracy: 0.7664\n",
      "Epoch 183/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0988 - accuracy: 0.9646 - val_loss: 1.3047 - val_accuracy: 0.7695\n",
      "Epoch 184/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0954 - accuracy: 0.9706 - val_loss: 1.2582 - val_accuracy: 0.7773\n",
      "Epoch 185/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0589 - accuracy: 0.9779 - val_loss: 1.3491 - val_accuracy: 0.7928\n",
      "Epoch 186/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0931 - accuracy: 0.9746 - val_loss: 1.2200 - val_accuracy: 0.7913\n",
      "Epoch 187/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0552 - accuracy: 0.9793 - val_loss: 1.2737 - val_accuracy: 0.7679\n",
      "Epoch 188/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0422 - accuracy: 0.9826 - val_loss: 1.3250 - val_accuracy: 0.7788\n",
      "Epoch 189/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0623 - accuracy: 0.9726 - val_loss: 1.3303 - val_accuracy: 0.7601\n",
      "Epoch 190/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0549 - accuracy: 0.9806 - val_loss: 1.3890 - val_accuracy: 0.7819\n",
      "Epoch 191/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0544 - accuracy: 0.9820 - val_loss: 1.4193 - val_accuracy: 0.7788\n",
      "Epoch 192/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0569 - accuracy: 0.9793 - val_loss: 1.4861 - val_accuracy: 0.7757\n",
      "Epoch 193/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0568 - accuracy: 0.9779 - val_loss: 1.3694 - val_accuracy: 0.7695\n",
      "Epoch 194/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0361 - accuracy: 0.9893 - val_loss: 1.4207 - val_accuracy: 0.7539\n",
      "Epoch 195/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0482 - accuracy: 0.9853 - val_loss: 1.3669 - val_accuracy: 0.7850\n",
      "Epoch 196/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0361 - accuracy: 0.9886 - val_loss: 1.4923 - val_accuracy: 0.7757\n",
      "Epoch 197/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0391 - accuracy: 0.9880 - val_loss: 1.5144 - val_accuracy: 0.7835\n",
      "Epoch 198/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0649 - accuracy: 0.9773 - val_loss: 1.4381 - val_accuracy: 0.7882\n",
      "Epoch 199/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0467 - accuracy: 0.9833 - val_loss: 1.4015 - val_accuracy: 0.7773\n",
      "Epoch 200/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0446 - accuracy: 0.9880 - val_loss: 1.4053 - val_accuracy: 0.7913\n",
      "Epoch 201/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0420 - accuracy: 0.9833 - val_loss: 1.4854 - val_accuracy: 0.7586\n",
      "Epoch 202/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0550 - accuracy: 0.9813 - val_loss: 1.4092 - val_accuracy: 0.7741\n",
      "Epoch 203/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0473 - accuracy: 0.9806 - val_loss: 1.3616 - val_accuracy: 0.7601\n",
      "Epoch 204/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0720 - accuracy: 0.9759 - val_loss: 1.3411 - val_accuracy: 0.7913\n",
      "Epoch 205/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0527 - accuracy: 0.9799 - val_loss: 1.3487 - val_accuracy: 0.7741\n",
      "Epoch 206/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0618 - accuracy: 0.9826 - val_loss: 1.3864 - val_accuracy: 0.7773\n",
      "Epoch 207/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0521 - accuracy: 0.9820 - val_loss: 1.4055 - val_accuracy: 0.7632\n",
      "Epoch 208/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0498 - accuracy: 0.9826 - val_loss: 1.3817 - val_accuracy: 0.7819\n",
      "Epoch 209/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0397 - accuracy: 0.9846 - val_loss: 1.4918 - val_accuracy: 0.7804\n",
      "Epoch 210/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0536 - accuracy: 0.9833 - val_loss: 1.4486 - val_accuracy: 0.7695\n",
      "Epoch 211/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0533 - accuracy: 0.9840 - val_loss: 1.4225 - val_accuracy: 0.7726\n",
      "Epoch 212/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0613 - accuracy: 0.9753 - val_loss: 1.5008 - val_accuracy: 0.7757\n",
      "Epoch 213/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0583 - accuracy: 0.9779 - val_loss: 1.4615 - val_accuracy: 0.7617\n",
      "Epoch 214/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0452 - accuracy: 0.9853 - val_loss: 1.5033 - val_accuracy: 0.7788\n",
      "Epoch 215/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0481 - accuracy: 0.9826 - val_loss: 1.4271 - val_accuracy: 0.7788\n",
      "Epoch 216/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0490 - accuracy: 0.9813 - val_loss: 1.4016 - val_accuracy: 0.7648\n",
      "Epoch 217/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0411 - accuracy: 0.9873 - val_loss: 1.4960 - val_accuracy: 0.7850\n",
      "Epoch 218/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0341 - accuracy: 0.9886 - val_loss: 1.4517 - val_accuracy: 0.7695\n",
      "Epoch 219/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0424 - accuracy: 0.9866 - val_loss: 1.6556 - val_accuracy: 0.7944\n",
      "Epoch 220/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0477 - accuracy: 0.9813 - val_loss: 1.5446 - val_accuracy: 0.7835\n",
      "Epoch 221/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0402 - accuracy: 0.9826 - val_loss: 1.5453 - val_accuracy: 0.7632\n",
      "Epoch 222/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0366 - accuracy: 0.9886 - val_loss: 1.6103 - val_accuracy: 0.7695\n",
      "Epoch 223/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0436 - accuracy: 0.9840 - val_loss: 1.5539 - val_accuracy: 0.7835\n",
      "Epoch 224/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0509 - accuracy: 0.9799 - val_loss: 1.5446 - val_accuracy: 0.7757\n",
      "Epoch 225/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0290 - accuracy: 0.9906 - val_loss: 1.5743 - val_accuracy: 0.7913\n",
      "Epoch 226/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0399 - accuracy: 0.9886 - val_loss: 1.5711 - val_accuracy: 0.7944\n",
      "Epoch 227/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0664 - accuracy: 0.9786 - val_loss: 1.6015 - val_accuracy: 0.7741\n",
      "Epoch 228/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0362 - accuracy: 0.9886 - val_loss: 1.5983 - val_accuracy: 0.7601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0422 - accuracy: 0.9860 - val_loss: 1.5733 - val_accuracy: 0.7757\n",
      "Epoch 230/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0560 - accuracy: 0.9746 - val_loss: 1.4316 - val_accuracy: 0.7648\n",
      "Epoch 231/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0512 - accuracy: 0.9799 - val_loss: 1.6056 - val_accuracy: 0.7726\n",
      "Epoch 232/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0464 - accuracy: 0.9799 - val_loss: 1.5802 - val_accuracy: 0.7804\n",
      "Epoch 233/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0367 - accuracy: 0.9873 - val_loss: 1.6141 - val_accuracy: 0.7741\n",
      "Epoch 234/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0470 - accuracy: 0.9873 - val_loss: 1.5785 - val_accuracy: 0.7773\n",
      "Epoch 235/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0585 - accuracy: 0.9846 - val_loss: 1.5317 - val_accuracy: 0.7788\n",
      "Epoch 236/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0440 - accuracy: 0.9826 - val_loss: 1.7053 - val_accuracy: 0.7773\n",
      "Epoch 237/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0612 - accuracy: 0.9820 - val_loss: 1.6514 - val_accuracy: 0.7804\n",
      "Epoch 238/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0291 - accuracy: 0.9886 - val_loss: 1.6282 - val_accuracy: 0.7648\n",
      "Epoch 239/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0485 - accuracy: 0.9833 - val_loss: 1.6820 - val_accuracy: 0.7710\n",
      "Epoch 240/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0466 - accuracy: 0.9793 - val_loss: 1.6762 - val_accuracy: 0.7882\n",
      "Epoch 241/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0338 - accuracy: 0.9880 - val_loss: 1.6753 - val_accuracy: 0.7679\n",
      "Epoch 242/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0421 - accuracy: 0.9866 - val_loss: 1.6976 - val_accuracy: 0.7788\n",
      "Epoch 243/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0325 - accuracy: 0.9906 - val_loss: 1.6996 - val_accuracy: 0.7726\n",
      "Epoch 244/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0412 - accuracy: 0.9866 - val_loss: 1.7543 - val_accuracy: 0.7741\n",
      "Epoch 245/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0493 - accuracy: 0.9799 - val_loss: 1.7018 - val_accuracy: 0.7835\n",
      "Epoch 246/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0309 - accuracy: 0.9866 - val_loss: 1.7104 - val_accuracy: 0.7788\n",
      "Epoch 247/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0444 - accuracy: 0.9880 - val_loss: 1.6944 - val_accuracy: 0.7632\n",
      "Epoch 248/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0337 - accuracy: 0.9893 - val_loss: 1.7469 - val_accuracy: 0.7788\n",
      "Epoch 249/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0426 - accuracy: 0.9820 - val_loss: 1.6954 - val_accuracy: 0.7617\n",
      "Epoch 250/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0312 - accuracy: 0.9880 - val_loss: 1.8145 - val_accuracy: 0.7882\n",
      "Epoch 251/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0397 - accuracy: 0.9840 - val_loss: 1.6851 - val_accuracy: 0.7710\n",
      "Epoch 252/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0341 - accuracy: 0.9906 - val_loss: 1.6929 - val_accuracy: 0.7866\n",
      "Epoch 253/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0328 - accuracy: 0.9900 - val_loss: 1.6280 - val_accuracy: 0.7539\n",
      "Epoch 254/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0360 - accuracy: 0.9860 - val_loss: 1.6940 - val_accuracy: 0.7850\n",
      "Epoch 255/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0324 - accuracy: 0.9880 - val_loss: 1.7155 - val_accuracy: 0.7773\n",
      "Epoch 256/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0380 - accuracy: 0.9846 - val_loss: 1.7953 - val_accuracy: 0.7726\n",
      "Epoch 257/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0428 - accuracy: 0.9846 - val_loss: 1.7530 - val_accuracy: 0.7773\n",
      "Epoch 258/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0323 - accuracy: 0.9900 - val_loss: 1.7830 - val_accuracy: 0.7726\n",
      "Epoch 259/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0316 - accuracy: 0.9886 - val_loss: 1.8176 - val_accuracy: 0.7648\n",
      "Epoch 260/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0539 - accuracy: 0.9846 - val_loss: 1.8233 - val_accuracy: 0.7897\n",
      "Epoch 261/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0470 - accuracy: 0.9846 - val_loss: 1.7200 - val_accuracy: 0.7741\n",
      "Epoch 262/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0424 - accuracy: 0.9833 - val_loss: 1.7274 - val_accuracy: 0.7773\n",
      "Epoch 263/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0393 - accuracy: 0.9820 - val_loss: 1.7516 - val_accuracy: 0.7695\n",
      "Epoch 264/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0340 - accuracy: 0.9893 - val_loss: 1.7162 - val_accuracy: 0.7679\n",
      "Epoch 265/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0300 - accuracy: 0.9886 - val_loss: 1.7827 - val_accuracy: 0.7695\n",
      "Epoch 266/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0362 - accuracy: 0.9813 - val_loss: 1.7980 - val_accuracy: 0.7648\n",
      "Epoch 267/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0446 - accuracy: 0.9886 - val_loss: 1.7272 - val_accuracy: 0.7773\n",
      "Epoch 268/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0298 - accuracy: 0.9880 - val_loss: 1.7360 - val_accuracy: 0.7601\n",
      "Epoch 269/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0256 - accuracy: 0.9900 - val_loss: 1.7927 - val_accuracy: 0.7648\n",
      "Epoch 270/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0407 - accuracy: 0.9866 - val_loss: 1.7031 - val_accuracy: 0.7695\n",
      "Epoch 271/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0475 - accuracy: 0.9853 - val_loss: 1.7529 - val_accuracy: 0.7477\n",
      "Epoch 272/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0274 - accuracy: 0.9880 - val_loss: 1.8340 - val_accuracy: 0.7741\n",
      "Epoch 273/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0486 - accuracy: 0.9873 - val_loss: 1.9133 - val_accuracy: 0.7617\n",
      "Epoch 274/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0353 - accuracy: 0.9840 - val_loss: 1.7632 - val_accuracy: 0.7664\n",
      "Epoch 275/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0323 - accuracy: 0.9900 - val_loss: 1.7961 - val_accuracy: 0.7913\n",
      "Epoch 276/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0569 - accuracy: 0.9813 - val_loss: 1.8598 - val_accuracy: 0.7819\n",
      "Epoch 277/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0483 - accuracy: 0.9766 - val_loss: 1.8590 - val_accuracy: 0.7804\n",
      "Epoch 278/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0322 - accuracy: 0.9886 - val_loss: 1.9138 - val_accuracy: 0.7866\n",
      "Epoch 279/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0324 - accuracy: 0.9913 - val_loss: 1.8209 - val_accuracy: 0.7726\n",
      "Epoch 280/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0364 - accuracy: 0.9860 - val_loss: 1.8497 - val_accuracy: 0.7804\n",
      "Epoch 281/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0321 - accuracy: 0.9920 - val_loss: 1.8850 - val_accuracy: 0.7819\n",
      "Epoch 282/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0337 - accuracy: 0.9853 - val_loss: 1.8265 - val_accuracy: 0.7757\n",
      "Epoch 283/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0378 - accuracy: 0.9873 - val_loss: 1.8912 - val_accuracy: 0.7741\n",
      "Epoch 284/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0388 - accuracy: 0.9900 - val_loss: 1.8865 - val_accuracy: 0.7773\n",
      "Epoch 285/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0259 - accuracy: 0.9913 - val_loss: 1.9622 - val_accuracy: 0.7695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0335 - accuracy: 0.9880 - val_loss: 1.8240 - val_accuracy: 0.7632\n",
      "Epoch 287/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0400 - accuracy: 0.9813 - val_loss: 1.8676 - val_accuracy: 0.7695\n",
      "Epoch 288/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0309 - accuracy: 0.9900 - val_loss: 1.8796 - val_accuracy: 0.7866\n",
      "Epoch 289/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0337 - accuracy: 0.9880 - val_loss: 1.7106 - val_accuracy: 0.7819\n",
      "Epoch 290/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0379 - accuracy: 0.9853 - val_loss: 1.7757 - val_accuracy: 0.7601\n",
      "Epoch 291/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0302 - accuracy: 0.9880 - val_loss: 1.7544 - val_accuracy: 0.7757\n",
      "Epoch 292/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0451 - accuracy: 0.9833 - val_loss: 1.7575 - val_accuracy: 0.7819\n",
      "Epoch 293/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0286 - accuracy: 0.9886 - val_loss: 1.8306 - val_accuracy: 0.7913\n",
      "Epoch 294/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0389 - accuracy: 0.9886 - val_loss: 1.6629 - val_accuracy: 0.7617\n",
      "Epoch 295/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0436 - accuracy: 0.9826 - val_loss: 1.6959 - val_accuracy: 0.7601\n",
      "Epoch 296/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0358 - accuracy: 0.9840 - val_loss: 1.6316 - val_accuracy: 0.7648\n",
      "Epoch 297/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0275 - accuracy: 0.9886 - val_loss: 1.7492 - val_accuracy: 0.7726\n",
      "Epoch 298/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0283 - accuracy: 0.9926 - val_loss: 1.9106 - val_accuracy: 0.7664\n",
      "Epoch 299/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0279 - accuracy: 0.9893 - val_loss: 1.9391 - val_accuracy: 0.7757\n",
      "Epoch 300/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0235 - accuracy: 0.9913 - val_loss: 1.8902 - val_accuracy: 0.7664\n",
      "Epoch 301/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0291 - accuracy: 0.9886 - val_loss: 1.9089 - val_accuracy: 0.7695\n",
      "Epoch 302/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0382 - accuracy: 0.9860 - val_loss: 1.8212 - val_accuracy: 0.7710\n",
      "Epoch 303/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0503 - accuracy: 0.9820 - val_loss: 1.8340 - val_accuracy: 0.7804\n",
      "Epoch 304/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0342 - accuracy: 0.9846 - val_loss: 1.8491 - val_accuracy: 0.7710\n",
      "Epoch 305/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0379 - accuracy: 0.9873 - val_loss: 1.7605 - val_accuracy: 0.7648\n",
      "Epoch 306/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0376 - accuracy: 0.9893 - val_loss: 1.8016 - val_accuracy: 0.7632\n",
      "Epoch 307/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0293 - accuracy: 0.9886 - val_loss: 1.8362 - val_accuracy: 0.7944\n",
      "Epoch 308/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0428 - accuracy: 0.9866 - val_loss: 1.7928 - val_accuracy: 0.7866\n",
      "Epoch 309/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0367 - accuracy: 0.9853 - val_loss: 1.7639 - val_accuracy: 0.7788\n",
      "Epoch 310/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0288 - accuracy: 0.9906 - val_loss: 1.7715 - val_accuracy: 0.7928\n",
      "Epoch 311/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0431 - accuracy: 0.9840 - val_loss: 1.7931 - val_accuracy: 0.7773\n",
      "Epoch 312/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0274 - accuracy: 0.9893 - val_loss: 1.8327 - val_accuracy: 0.7726\n",
      "Epoch 313/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0303 - accuracy: 0.9913 - val_loss: 1.8509 - val_accuracy: 0.7648\n",
      "Epoch 314/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0241 - accuracy: 0.9933 - val_loss: 1.8393 - val_accuracy: 0.7695\n",
      "Epoch 315/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0303 - accuracy: 0.9913 - val_loss: 1.8960 - val_accuracy: 0.7850\n",
      "Epoch 316/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0264 - accuracy: 0.9906 - val_loss: 1.9118 - val_accuracy: 0.7679\n",
      "Epoch 317/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0323 - accuracy: 0.9906 - val_loss: 1.9436 - val_accuracy: 0.7804\n",
      "Epoch 318/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0344 - accuracy: 0.9860 - val_loss: 1.7719 - val_accuracy: 0.7866\n",
      "Epoch 319/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0447 - accuracy: 0.9880 - val_loss: 1.8378 - val_accuracy: 0.7617\n",
      "Epoch 320/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0288 - accuracy: 0.9913 - val_loss: 1.9332 - val_accuracy: 0.7664\n",
      "Epoch 321/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0337 - accuracy: 0.9866 - val_loss: 1.8946 - val_accuracy: 0.7819\n",
      "Epoch 322/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0144 - accuracy: 0.9973 - val_loss: 1.8925 - val_accuracy: 0.7773\n",
      "Epoch 323/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0528 - accuracy: 0.9826 - val_loss: 1.8310 - val_accuracy: 0.7695\n",
      "Epoch 324/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0408 - accuracy: 0.9860 - val_loss: 1.7502 - val_accuracy: 0.7586\n",
      "Epoch 325/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0320 - accuracy: 0.9893 - val_loss: 1.7504 - val_accuracy: 0.7757\n",
      "Epoch 326/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0228 - accuracy: 0.9913 - val_loss: 1.8065 - val_accuracy: 0.7695\n",
      "Epoch 327/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0231 - accuracy: 0.9926 - val_loss: 1.8629 - val_accuracy: 0.7586\n",
      "Epoch 328/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0410 - accuracy: 0.9853 - val_loss: 1.8485 - val_accuracy: 0.7741\n",
      "Epoch 329/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0289 - accuracy: 0.9913 - val_loss: 1.8214 - val_accuracy: 0.7741\n",
      "Epoch 330/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0334 - accuracy: 0.9893 - val_loss: 1.8651 - val_accuracy: 0.7695\n",
      "Epoch 331/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0258 - accuracy: 0.9893 - val_loss: 1.7955 - val_accuracy: 0.7664\n",
      "Epoch 332/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0277 - accuracy: 0.9926 - val_loss: 1.8994 - val_accuracy: 0.7695\n",
      "Epoch 333/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0196 - accuracy: 0.9926 - val_loss: 1.9683 - val_accuracy: 0.7788\n",
      "Epoch 334/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0286 - accuracy: 0.9913 - val_loss: 2.1219 - val_accuracy: 0.7788\n",
      "Epoch 335/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0603 - accuracy: 0.9806 - val_loss: 1.9454 - val_accuracy: 0.7617\n",
      "Epoch 336/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0589 - accuracy: 0.9820 - val_loss: 1.8762 - val_accuracy: 0.7648\n",
      "Epoch 337/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0380 - accuracy: 0.9853 - val_loss: 1.9446 - val_accuracy: 0.7741\n",
      "Epoch 338/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0450 - accuracy: 0.9860 - val_loss: 1.9649 - val_accuracy: 0.7710\n",
      "Epoch 339/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0373 - accuracy: 0.9900 - val_loss: 1.9243 - val_accuracy: 0.7695\n",
      "Epoch 340/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0338 - accuracy: 0.9886 - val_loss: 1.9308 - val_accuracy: 0.7586\n",
      "Epoch 341/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0279 - accuracy: 0.9900 - val_loss: 1.9638 - val_accuracy: 0.7850\n",
      "Epoch 342/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0396 - accuracy: 0.9853 - val_loss: 1.7763 - val_accuracy: 0.7710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0256 - accuracy: 0.9920 - val_loss: 1.8437 - val_accuracy: 0.7632\n",
      "Epoch 344/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0170 - accuracy: 0.9940 - val_loss: 1.9146 - val_accuracy: 0.7741\n",
      "Epoch 345/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0303 - accuracy: 0.9893 - val_loss: 2.0306 - val_accuracy: 0.7757\n",
      "Epoch 346/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0220 - accuracy: 0.9926 - val_loss: 1.9768 - val_accuracy: 0.7788\n",
      "Epoch 347/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0232 - accuracy: 0.9900 - val_loss: 1.9318 - val_accuracy: 0.7710\n",
      "Epoch 348/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0178 - accuracy: 0.9933 - val_loss: 2.0276 - val_accuracy: 0.7632\n",
      "Epoch 349/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0335 - accuracy: 0.9906 - val_loss: 2.0769 - val_accuracy: 0.7788\n",
      "Epoch 350/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0372 - accuracy: 0.9900 - val_loss: 1.9411 - val_accuracy: 0.7570\n",
      "Epoch 351/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0317 - accuracy: 0.9913 - val_loss: 1.9440 - val_accuracy: 0.7882\n",
      "Epoch 352/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0294 - accuracy: 0.9900 - val_loss: 1.8454 - val_accuracy: 0.7555\n",
      "Epoch 353/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0417 - accuracy: 0.9840 - val_loss: 1.9263 - val_accuracy: 0.7679\n",
      "Epoch 354/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0193 - accuracy: 0.9926 - val_loss: 1.9431 - val_accuracy: 0.7773\n",
      "Epoch 355/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0273 - accuracy: 0.9900 - val_loss: 1.8795 - val_accuracy: 0.7477\n",
      "Epoch 356/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0189 - accuracy: 0.9933 - val_loss: 1.9070 - val_accuracy: 0.7664\n",
      "Epoch 357/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0398 - accuracy: 0.9880 - val_loss: 1.9781 - val_accuracy: 0.7757\n",
      "Epoch 358/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0284 - accuracy: 0.9906 - val_loss: 1.9284 - val_accuracy: 0.7726\n",
      "Epoch 359/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0226 - accuracy: 0.9920 - val_loss: 1.9405 - val_accuracy: 0.7617\n",
      "Epoch 360/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0187 - accuracy: 0.9933 - val_loss: 1.9443 - val_accuracy: 0.7757\n",
      "Epoch 361/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0186 - accuracy: 0.9940 - val_loss: 1.9723 - val_accuracy: 0.7819\n",
      "Epoch 362/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0354 - accuracy: 0.9906 - val_loss: 1.9187 - val_accuracy: 0.7679\n",
      "Epoch 363/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0269 - accuracy: 0.9920 - val_loss: 1.8737 - val_accuracy: 0.7679\n",
      "Epoch 364/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0244 - accuracy: 0.9906 - val_loss: 1.8545 - val_accuracy: 0.7570\n",
      "Epoch 365/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0223 - accuracy: 0.9906 - val_loss: 1.9008 - val_accuracy: 0.7523\n",
      "Epoch 366/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0224 - accuracy: 0.9947 - val_loss: 2.0285 - val_accuracy: 0.7632\n",
      "Epoch 367/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0269 - accuracy: 0.9906 - val_loss: 2.0253 - val_accuracy: 0.7726\n",
      "Epoch 368/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0554 - accuracy: 0.9840 - val_loss: 1.9817 - val_accuracy: 0.7664\n",
      "Epoch 369/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0344 - accuracy: 0.9893 - val_loss: 2.0496 - val_accuracy: 0.7804\n",
      "Epoch 370/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0323 - accuracy: 0.9893 - val_loss: 2.1039 - val_accuracy: 0.7757\n",
      "Epoch 371/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0357 - accuracy: 0.9866 - val_loss: 2.0773 - val_accuracy: 0.7648\n",
      "Epoch 372/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0180 - accuracy: 0.9920 - val_loss: 1.9735 - val_accuracy: 0.7508\n",
      "Epoch 373/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0294 - accuracy: 0.9933 - val_loss: 2.0531 - val_accuracy: 0.7741\n",
      "Epoch 374/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0198 - accuracy: 0.9940 - val_loss: 2.0035 - val_accuracy: 0.7726\n",
      "Epoch 375/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0333 - accuracy: 0.9893 - val_loss: 2.0647 - val_accuracy: 0.7866\n",
      "Epoch 376/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0175 - accuracy: 0.9947 - val_loss: 2.0515 - val_accuracy: 0.7710\n",
      "Epoch 377/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0221 - accuracy: 0.9913 - val_loss: 2.0608 - val_accuracy: 0.7695\n",
      "Epoch 378/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0287 - accuracy: 0.9926 - val_loss: 2.1788 - val_accuracy: 0.7477\n",
      "Epoch 379/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0455 - accuracy: 0.9886 - val_loss: 2.0302 - val_accuracy: 0.7570\n",
      "Epoch 380/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0271 - accuracy: 0.9926 - val_loss: 1.9865 - val_accuracy: 0.7757\n",
      "Epoch 381/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0258 - accuracy: 0.9906 - val_loss: 2.1417 - val_accuracy: 0.7804\n",
      "Epoch 382/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0223 - accuracy: 0.9926 - val_loss: 1.9584 - val_accuracy: 0.7492\n",
      "Epoch 383/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0292 - accuracy: 0.9893 - val_loss: 1.9743 - val_accuracy: 0.7679\n",
      "Epoch 384/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0339 - accuracy: 0.9873 - val_loss: 2.0863 - val_accuracy: 0.7695\n",
      "Epoch 385/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0250 - accuracy: 0.9913 - val_loss: 1.9872 - val_accuracy: 0.7617\n",
      "Epoch 386/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0356 - accuracy: 0.9906 - val_loss: 2.0258 - val_accuracy: 0.7695\n",
      "Epoch 387/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0298 - accuracy: 0.9880 - val_loss: 2.0625 - val_accuracy: 0.7819\n",
      "Epoch 388/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0163 - accuracy: 0.9947 - val_loss: 1.9701 - val_accuracy: 0.7664\n",
      "Epoch 389/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0231 - accuracy: 0.9913 - val_loss: 2.2164 - val_accuracy: 0.7975\n",
      "Epoch 390/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0398 - accuracy: 0.9886 - val_loss: 2.0068 - val_accuracy: 0.7695\n",
      "Epoch 391/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0273 - accuracy: 0.9913 - val_loss: 2.0428 - val_accuracy: 0.7928\n",
      "Epoch 392/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0203 - accuracy: 0.9940 - val_loss: 2.0609 - val_accuracy: 0.7773\n",
      "Epoch 393/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0301 - accuracy: 0.9853 - val_loss: 2.1628 - val_accuracy: 0.7819\n",
      "Epoch 394/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0250 - accuracy: 0.9900 - val_loss: 2.0496 - val_accuracy: 0.7741\n",
      "Epoch 395/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0178 - accuracy: 0.9926 - val_loss: 2.0274 - val_accuracy: 0.7850\n",
      "Epoch 396/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0263 - accuracy: 0.9926 - val_loss: 1.9449 - val_accuracy: 0.7726\n",
      "Epoch 397/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0286 - accuracy: 0.9900 - val_loss: 1.9045 - val_accuracy: 0.7617\n",
      "Epoch 398/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0247 - accuracy: 0.9926 - val_loss: 1.9577 - val_accuracy: 0.7664\n",
      "Epoch 399/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0120 - accuracy: 0.9960 - val_loss: 1.9992 - val_accuracy: 0.7617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0171 - accuracy: 0.9913 - val_loss: 2.0619 - val_accuracy: 0.7679\n",
      "Epoch 401/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0153 - accuracy: 0.9940 - val_loss: 2.0666 - val_accuracy: 0.7788\n",
      "Epoch 402/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0206 - accuracy: 0.9906 - val_loss: 1.9759 - val_accuracy: 0.7773\n",
      "Epoch 403/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0320 - accuracy: 0.9913 - val_loss: 1.9876 - val_accuracy: 0.7695\n",
      "Epoch 404/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0214 - accuracy: 0.9933 - val_loss: 1.9923 - val_accuracy: 0.7648\n",
      "Epoch 405/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0233 - accuracy: 0.9900 - val_loss: 2.0150 - val_accuracy: 0.7695\n",
      "Epoch 406/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0173 - accuracy: 0.9913 - val_loss: 2.1144 - val_accuracy: 0.7757\n",
      "Epoch 407/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0111 - accuracy: 0.9967 - val_loss: 2.1766 - val_accuracy: 0.7741\n",
      "Epoch 408/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0325 - accuracy: 0.9913 - val_loss: 2.0606 - val_accuracy: 0.7804\n",
      "Epoch 409/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0319 - accuracy: 0.9900 - val_loss: 2.0656 - val_accuracy: 0.7835\n",
      "Epoch 410/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0376 - accuracy: 0.9886 - val_loss: 1.8962 - val_accuracy: 0.7726\n",
      "Epoch 411/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0293 - accuracy: 0.9886 - val_loss: 1.9939 - val_accuracy: 0.7773\n",
      "Epoch 412/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0290 - accuracy: 0.9913 - val_loss: 2.0870 - val_accuracy: 0.7741\n",
      "Epoch 413/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0224 - accuracy: 0.9940 - val_loss: 2.0031 - val_accuracy: 0.7757\n",
      "Epoch 414/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0198 - accuracy: 0.9913 - val_loss: 2.0438 - val_accuracy: 0.7741\n",
      "Epoch 415/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0209 - accuracy: 0.9953 - val_loss: 2.0829 - val_accuracy: 0.7726\n",
      "Epoch 416/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0188 - accuracy: 0.9947 - val_loss: 2.2101 - val_accuracy: 0.7664\n",
      "Epoch 417/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0206 - accuracy: 0.9926 - val_loss: 2.2703 - val_accuracy: 0.7897\n",
      "Epoch 418/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0425 - accuracy: 0.9846 - val_loss: 2.1716 - val_accuracy: 0.7897\n",
      "Epoch 419/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0253 - accuracy: 0.9906 - val_loss: 2.0619 - val_accuracy: 0.7804\n",
      "Epoch 420/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0294 - accuracy: 0.9913 - val_loss: 1.9855 - val_accuracy: 0.7601\n",
      "Epoch 421/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0245 - accuracy: 0.9920 - val_loss: 2.0242 - val_accuracy: 0.7710\n",
      "Epoch 422/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0172 - accuracy: 0.9933 - val_loss: 2.1149 - val_accuracy: 0.7819\n",
      "Epoch 423/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0283 - accuracy: 0.9900 - val_loss: 2.0701 - val_accuracy: 0.7726\n",
      "Epoch 424/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0125 - accuracy: 0.9960 - val_loss: 1.9249 - val_accuracy: 0.7586\n",
      "Epoch 425/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0423 - accuracy: 0.9853 - val_loss: 2.0991 - val_accuracy: 0.7788\n",
      "Epoch 426/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0250 - accuracy: 0.9893 - val_loss: 2.2453 - val_accuracy: 0.7819\n",
      "Epoch 427/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0260 - accuracy: 0.9913 - val_loss: 2.1729 - val_accuracy: 0.7850\n",
      "Epoch 428/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0229 - accuracy: 0.9933 - val_loss: 2.1019 - val_accuracy: 0.7710\n",
      "Epoch 429/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0293 - accuracy: 0.9906 - val_loss: 2.1821 - val_accuracy: 0.7648\n",
      "Epoch 430/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0264 - accuracy: 0.9920 - val_loss: 2.1086 - val_accuracy: 0.7664\n",
      "Epoch 431/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0158 - accuracy: 0.9940 - val_loss: 2.1812 - val_accuracy: 0.7757\n",
      "Epoch 432/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0110 - accuracy: 0.9967 - val_loss: 2.1549 - val_accuracy: 0.7695\n",
      "Epoch 433/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0273 - accuracy: 0.9913 - val_loss: 2.1192 - val_accuracy: 0.7632\n",
      "Epoch 434/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0167 - accuracy: 0.9953 - val_loss: 2.3065 - val_accuracy: 0.7773\n",
      "Epoch 435/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0134 - accuracy: 0.9940 - val_loss: 2.2523 - val_accuracy: 0.7773\n",
      "Epoch 436/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0203 - accuracy: 0.9933 - val_loss: 2.3779 - val_accuracy: 0.7648\n",
      "Epoch 437/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0191 - accuracy: 0.9933 - val_loss: 2.4020 - val_accuracy: 0.7866\n",
      "Epoch 438/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0115 - accuracy: 0.9967 - val_loss: 2.3082 - val_accuracy: 0.7819\n",
      "Epoch 439/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0178 - accuracy: 0.9940 - val_loss: 2.2301 - val_accuracy: 0.7726\n",
      "Epoch 440/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0238 - accuracy: 0.9886 - val_loss: 2.1817 - val_accuracy: 0.7850\n",
      "Epoch 441/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0363 - accuracy: 0.9893 - val_loss: 2.1280 - val_accuracy: 0.7648\n",
      "Epoch 442/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0473 - accuracy: 0.9880 - val_loss: 2.2089 - val_accuracy: 0.7882\n",
      "Epoch 443/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0245 - accuracy: 0.9906 - val_loss: 2.1704 - val_accuracy: 0.7664\n",
      "Epoch 444/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0256 - accuracy: 0.9920 - val_loss: 2.1321 - val_accuracy: 0.7679\n",
      "Epoch 445/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0321 - accuracy: 0.9920 - val_loss: 2.1630 - val_accuracy: 0.7757\n",
      "Epoch 446/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0445 - accuracy: 0.9900 - val_loss: 2.1540 - val_accuracy: 0.7710\n",
      "Epoch 447/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0370 - accuracy: 0.9893 - val_loss: 2.1293 - val_accuracy: 0.7773\n",
      "Epoch 448/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0296 - accuracy: 0.9900 - val_loss: 2.1114 - val_accuracy: 0.7710\n",
      "Epoch 449/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0273 - accuracy: 0.9920 - val_loss: 2.0646 - val_accuracy: 0.7710\n",
      "Epoch 450/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0207 - accuracy: 0.9940 - val_loss: 2.1400 - val_accuracy: 0.7773\n",
      "Epoch 451/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0263 - accuracy: 0.9926 - val_loss: 2.0596 - val_accuracy: 0.7648\n",
      "Epoch 452/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0260 - accuracy: 0.9906 - val_loss: 2.1125 - val_accuracy: 0.7710\n",
      "Epoch 453/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0191 - accuracy: 0.9920 - val_loss: 2.0456 - val_accuracy: 0.7773\n",
      "Epoch 454/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0384 - accuracy: 0.9880 - val_loss: 1.9803 - val_accuracy: 0.7850\n",
      "Epoch 455/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0201 - accuracy: 0.9913 - val_loss: 1.9548 - val_accuracy: 0.7757\n",
      "Epoch 456/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0257 - accuracy: 0.9886 - val_loss: 1.8753 - val_accuracy: 0.7835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0162 - accuracy: 0.9940 - val_loss: 2.0628 - val_accuracy: 0.7804\n",
      "Epoch 458/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0365 - accuracy: 0.9893 - val_loss: 2.0235 - val_accuracy: 0.7866\n",
      "Epoch 459/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0206 - accuracy: 0.9933 - val_loss: 2.0668 - val_accuracy: 0.7679\n",
      "Epoch 460/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0157 - accuracy: 0.9947 - val_loss: 2.0710 - val_accuracy: 0.7648\n",
      "Epoch 461/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0205 - accuracy: 0.9926 - val_loss: 2.0391 - val_accuracy: 0.7804\n",
      "Epoch 462/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0161 - accuracy: 0.9940 - val_loss: 2.0514 - val_accuracy: 0.7695\n",
      "Epoch 463/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0227 - accuracy: 0.9926 - val_loss: 2.0615 - val_accuracy: 0.7726\n",
      "Epoch 464/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0361 - accuracy: 0.9886 - val_loss: 2.0254 - val_accuracy: 0.7726\n",
      "Epoch 465/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0232 - accuracy: 0.9940 - val_loss: 2.0850 - val_accuracy: 0.7773\n",
      "Epoch 466/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0226 - accuracy: 0.9953 - val_loss: 2.0343 - val_accuracy: 0.7710\n",
      "Epoch 467/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0175 - accuracy: 0.9960 - val_loss: 2.0895 - val_accuracy: 0.7819\n",
      "Epoch 468/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0252 - accuracy: 0.9940 - val_loss: 2.0008 - val_accuracy: 0.7835\n",
      "Epoch 469/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0364 - accuracy: 0.9920 - val_loss: 1.9832 - val_accuracy: 0.7866\n",
      "Epoch 470/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0240 - accuracy: 0.9940 - val_loss: 2.0375 - val_accuracy: 0.7757\n",
      "Epoch 471/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0280 - accuracy: 0.9920 - val_loss: 1.9282 - val_accuracy: 0.7835\n",
      "Epoch 472/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0177 - accuracy: 0.9933 - val_loss: 1.9529 - val_accuracy: 0.7850\n",
      "Epoch 473/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0303 - accuracy: 0.9900 - val_loss: 2.1002 - val_accuracy: 0.7835\n",
      "Epoch 474/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0282 - accuracy: 0.9920 - val_loss: 2.0796 - val_accuracy: 0.7804\n",
      "Epoch 475/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0225 - accuracy: 0.9920 - val_loss: 2.0063 - val_accuracy: 0.7664\n",
      "Epoch 476/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0246 - accuracy: 0.9933 - val_loss: 2.1245 - val_accuracy: 0.7773\n",
      "Epoch 477/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0135 - accuracy: 0.9953 - val_loss: 2.0675 - val_accuracy: 0.7648\n",
      "Epoch 478/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0143 - accuracy: 0.9947 - val_loss: 2.0210 - val_accuracy: 0.7741\n",
      "Epoch 479/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0130 - accuracy: 0.9933 - val_loss: 2.0475 - val_accuracy: 0.7710\n",
      "Epoch 480/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0129 - accuracy: 0.9967 - val_loss: 2.0876 - val_accuracy: 0.7679\n",
      "Epoch 481/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0162 - accuracy: 0.9920 - val_loss: 2.1278 - val_accuracy: 0.7819\n",
      "Epoch 482/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0207 - accuracy: 0.9920 - val_loss: 2.2922 - val_accuracy: 0.7913\n",
      "Epoch 483/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0116 - accuracy: 0.9940 - val_loss: 2.2006 - val_accuracy: 0.7757\n",
      "Epoch 484/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0267 - accuracy: 0.9926 - val_loss: 2.3563 - val_accuracy: 0.8006\n",
      "Epoch 485/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0213 - accuracy: 0.9933 - val_loss: 2.1899 - val_accuracy: 0.7788\n",
      "Epoch 486/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0228 - accuracy: 0.9933 - val_loss: 2.0645 - val_accuracy: 0.7570\n",
      "Epoch 487/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0289 - accuracy: 0.9920 - val_loss: 2.2102 - val_accuracy: 0.7695\n",
      "Epoch 488/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0216 - accuracy: 0.9900 - val_loss: 2.2789 - val_accuracy: 0.7757\n",
      "Epoch 489/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0533 - accuracy: 0.9880 - val_loss: 2.0380 - val_accuracy: 0.7757\n",
      "Epoch 490/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0325 - accuracy: 0.9893 - val_loss: 2.0518 - val_accuracy: 0.7539\n",
      "Epoch 491/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0249 - accuracy: 0.9913 - val_loss: 2.1477 - val_accuracy: 0.7617\n",
      "Epoch 492/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0305 - accuracy: 0.9926 - val_loss: 2.0417 - val_accuracy: 0.7726\n",
      "Epoch 493/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0183 - accuracy: 0.9940 - val_loss: 1.9775 - val_accuracy: 0.7695\n",
      "Epoch 494/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0163 - accuracy: 0.9953 - val_loss: 2.0124 - val_accuracy: 0.7741\n",
      "Epoch 495/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0333 - accuracy: 0.9906 - val_loss: 2.0059 - val_accuracy: 0.7773\n",
      "Epoch 496/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0205 - accuracy: 0.9926 - val_loss: 2.0132 - val_accuracy: 0.7710\n",
      "Epoch 497/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0292 - accuracy: 0.9913 - val_loss: 2.0053 - val_accuracy: 0.7741\n",
      "Epoch 498/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0190 - accuracy: 0.9940 - val_loss: 2.0699 - val_accuracy: 0.7679\n",
      "Epoch 499/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0104 - accuracy: 0.9973 - val_loss: 2.0766 - val_accuracy: 0.7726\n",
      "Epoch 500/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0078 - accuracy: 0.9967 - val_loss: 2.1064 - val_accuracy: 0.7726\n",
      "Epoch 501/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0088 - accuracy: 0.9973 - val_loss: 2.1222 - val_accuracy: 0.7757\n",
      "Epoch 502/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0068 - accuracy: 0.9987 - val_loss: 2.0380 - val_accuracy: 0.7679\n",
      "Epoch 503/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0093 - accuracy: 0.9967 - val_loss: 2.1361 - val_accuracy: 0.7788\n",
      "Epoch 504/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0102 - accuracy: 0.9967 - val_loss: 2.1101 - val_accuracy: 0.7726\n",
      "Epoch 505/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0168 - accuracy: 0.9953 - val_loss: 2.1209 - val_accuracy: 0.7508\n",
      "Epoch 506/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0135 - accuracy: 0.9953 - val_loss: 2.1722 - val_accuracy: 0.7570\n",
      "Epoch 507/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0108 - accuracy: 0.9940 - val_loss: 2.1805 - val_accuracy: 0.7710\n",
      "Epoch 508/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0145 - accuracy: 0.9967 - val_loss: 2.2474 - val_accuracy: 0.7586\n",
      "Epoch 509/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0191 - accuracy: 0.9940 - val_loss: 2.2511 - val_accuracy: 0.7648\n",
      "Epoch 510/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0100 - accuracy: 0.9967 - val_loss: 2.2483 - val_accuracy: 0.7648\n",
      "Epoch 511/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0181 - accuracy: 0.9940 - val_loss: 2.2843 - val_accuracy: 0.7726\n",
      "Epoch 512/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0143 - accuracy: 0.9953 - val_loss: 2.1520 - val_accuracy: 0.7617\n",
      "Epoch 513/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0212 - accuracy: 0.9933 - val_loss: 2.1022 - val_accuracy: 0.7617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 514/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0248 - accuracy: 0.9886 - val_loss: 2.1338 - val_accuracy: 0.7741\n",
      "Epoch 515/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0280 - accuracy: 0.9913 - val_loss: 2.0543 - val_accuracy: 0.7617\n",
      "Epoch 516/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0257 - accuracy: 0.9900 - val_loss: 2.0883 - val_accuracy: 0.7679\n",
      "Epoch 517/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0225 - accuracy: 0.9913 - val_loss: 2.2619 - val_accuracy: 0.7617\n",
      "Epoch 518/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0244 - accuracy: 0.9913 - val_loss: 2.1828 - val_accuracy: 0.7648\n",
      "Epoch 519/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0258 - accuracy: 0.9926 - val_loss: 2.2209 - val_accuracy: 0.7835\n",
      "Epoch 520/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0166 - accuracy: 0.9947 - val_loss: 2.0745 - val_accuracy: 0.7477\n",
      "Epoch 521/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0457 - accuracy: 0.9866 - val_loss: 1.9622 - val_accuracy: 0.7757\n",
      "Epoch 522/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0330 - accuracy: 0.9913 - val_loss: 2.0695 - val_accuracy: 0.7850\n",
      "Epoch 523/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0226 - accuracy: 0.9926 - val_loss: 2.0413 - val_accuracy: 0.7664\n",
      "Epoch 524/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0261 - accuracy: 0.9880 - val_loss: 2.0973 - val_accuracy: 0.7679\n",
      "Epoch 525/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0292 - accuracy: 0.9893 - val_loss: 2.1400 - val_accuracy: 0.7679\n",
      "Epoch 526/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0263 - accuracy: 0.9900 - val_loss: 2.1694 - val_accuracy: 0.7757\n",
      "Epoch 527/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0179 - accuracy: 0.9926 - val_loss: 2.1211 - val_accuracy: 0.7679\n",
      "Epoch 528/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0240 - accuracy: 0.9940 - val_loss: 2.1277 - val_accuracy: 0.7632\n",
      "Epoch 529/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0628 - accuracy: 0.9846 - val_loss: 2.0860 - val_accuracy: 0.7523\n",
      "Epoch 530/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0269 - accuracy: 0.9893 - val_loss: 1.9361 - val_accuracy: 0.7679\n",
      "Epoch 531/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0287 - accuracy: 0.9906 - val_loss: 2.1344 - val_accuracy: 0.7726\n",
      "Epoch 532/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0341 - accuracy: 0.9920 - val_loss: 1.9443 - val_accuracy: 0.7570\n",
      "Epoch 533/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0267 - accuracy: 0.9906 - val_loss: 2.2012 - val_accuracy: 0.7804\n",
      "Epoch 534/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0330 - accuracy: 0.9893 - val_loss: 1.9733 - val_accuracy: 0.7555\n",
      "Epoch 535/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0155 - accuracy: 0.9947 - val_loss: 2.0384 - val_accuracy: 0.7726\n",
      "Epoch 536/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0139 - accuracy: 0.9940 - val_loss: 2.0647 - val_accuracy: 0.7617\n",
      "Epoch 537/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0122 - accuracy: 0.9967 - val_loss: 2.1129 - val_accuracy: 0.7617\n",
      "Epoch 538/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0181 - accuracy: 0.9940 - val_loss: 2.1254 - val_accuracy: 0.7570\n",
      "Epoch 539/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0165 - accuracy: 0.9940 - val_loss: 2.1319 - val_accuracy: 0.7679\n",
      "Epoch 540/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0182 - accuracy: 0.9926 - val_loss: 2.1028 - val_accuracy: 0.7648\n",
      "Epoch 541/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0399 - accuracy: 0.9846 - val_loss: 2.2741 - val_accuracy: 0.7710\n",
      "Epoch 542/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0460 - accuracy: 0.9860 - val_loss: 2.1541 - val_accuracy: 0.7804\n",
      "Epoch 543/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0271 - accuracy: 0.9900 - val_loss: 2.0365 - val_accuracy: 0.7710\n",
      "Epoch 544/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0365 - accuracy: 0.9860 - val_loss: 2.2277 - val_accuracy: 0.7757\n",
      "Epoch 545/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0351 - accuracy: 0.9920 - val_loss: 2.1644 - val_accuracy: 0.7632\n",
      "Epoch 546/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0364 - accuracy: 0.9926 - val_loss: 2.1659 - val_accuracy: 0.7601\n",
      "Epoch 547/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0151 - accuracy: 0.9933 - val_loss: 2.1330 - val_accuracy: 0.7695\n",
      "Epoch 548/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0103 - accuracy: 0.9960 - val_loss: 2.0345 - val_accuracy: 0.7555\n",
      "Epoch 549/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0182 - accuracy: 0.9900 - val_loss: 2.0097 - val_accuracy: 0.7695\n",
      "Epoch 550/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0144 - accuracy: 0.9940 - val_loss: 2.1230 - val_accuracy: 0.7710\n",
      "Epoch 551/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0238 - accuracy: 0.9933 - val_loss: 2.1861 - val_accuracy: 0.7601\n",
      "Epoch 552/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0106 - accuracy: 0.9960 - val_loss: 2.1716 - val_accuracy: 0.7508\n",
      "Epoch 553/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0221 - accuracy: 0.9940 - val_loss: 2.2170 - val_accuracy: 0.7664\n",
      "Epoch 554/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0204 - accuracy: 0.9973 - val_loss: 2.2780 - val_accuracy: 0.7648\n",
      "Epoch 555/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0145 - accuracy: 0.9926 - val_loss: 2.2880 - val_accuracy: 0.7664\n",
      "Epoch 556/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0131 - accuracy: 0.9960 - val_loss: 2.2576 - val_accuracy: 0.7664\n",
      "Epoch 557/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0297 - accuracy: 0.9900 - val_loss: 2.5131 - val_accuracy: 0.7835\n",
      "Epoch 558/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0311 - accuracy: 0.9900 - val_loss: 2.5011 - val_accuracy: 0.7648\n",
      "Epoch 559/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0257 - accuracy: 0.9933 - val_loss: 2.0814 - val_accuracy: 0.7632\n",
      "Epoch 560/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0340 - accuracy: 0.9900 - val_loss: 2.3311 - val_accuracy: 0.7586\n",
      "Epoch 561/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0169 - accuracy: 0.9947 - val_loss: 2.3990 - val_accuracy: 0.7804\n",
      "Epoch 562/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0163 - accuracy: 0.9933 - val_loss: 2.4838 - val_accuracy: 0.7741\n",
      "Epoch 563/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0226 - accuracy: 0.9913 - val_loss: 2.4176 - val_accuracy: 0.7741\n",
      "Epoch 564/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0180 - accuracy: 0.9906 - val_loss: 2.5374 - val_accuracy: 0.7741\n",
      "Epoch 565/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0168 - accuracy: 0.9913 - val_loss: 2.4564 - val_accuracy: 0.7695\n",
      "Epoch 566/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0128 - accuracy: 0.9933 - val_loss: 2.4704 - val_accuracy: 0.7710\n",
      "Epoch 567/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0147 - accuracy: 0.9920 - val_loss: 2.4547 - val_accuracy: 0.7741\n",
      "Epoch 568/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0134 - accuracy: 0.9967 - val_loss: 2.4213 - val_accuracy: 0.7695\n",
      "Epoch 569/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0247 - accuracy: 0.9913 - val_loss: 2.3936 - val_accuracy: 0.7773\n",
      "Epoch 570/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0232 - accuracy: 0.9926 - val_loss: 2.3463 - val_accuracy: 0.7710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 571/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0251 - accuracy: 0.9933 - val_loss: 2.5511 - val_accuracy: 0.7850\n",
      "Epoch 572/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0294 - accuracy: 0.9900 - val_loss: 2.3120 - val_accuracy: 0.7539\n",
      "Epoch 573/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0361 - accuracy: 0.9913 - val_loss: 2.3860 - val_accuracy: 0.7477\n",
      "Epoch 574/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0191 - accuracy: 0.9940 - val_loss: 2.3136 - val_accuracy: 0.7632\n",
      "Epoch 575/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0218 - accuracy: 0.9900 - val_loss: 2.1758 - val_accuracy: 0.7648\n",
      "Epoch 576/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0286 - accuracy: 0.9906 - val_loss: 2.3275 - val_accuracy: 0.7741\n",
      "Epoch 577/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0146 - accuracy: 0.9933 - val_loss: 2.2118 - val_accuracy: 0.7664\n",
      "Epoch 578/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0148 - accuracy: 0.9947 - val_loss: 2.3543 - val_accuracy: 0.7679\n",
      "Epoch 579/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0403 - accuracy: 0.9893 - val_loss: 2.3588 - val_accuracy: 0.7726\n",
      "Epoch 580/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0157 - accuracy: 0.9947 - val_loss: 2.3250 - val_accuracy: 0.7757\n",
      "Epoch 581/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0223 - accuracy: 0.9926 - val_loss: 2.3074 - val_accuracy: 0.7710\n",
      "Epoch 582/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0261 - accuracy: 0.9920 - val_loss: 2.3124 - val_accuracy: 0.7632\n",
      "Epoch 583/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0091 - accuracy: 0.9960 - val_loss: 2.3258 - val_accuracy: 0.7788\n",
      "Epoch 584/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0312 - accuracy: 0.9933 - val_loss: 2.2766 - val_accuracy: 0.7617\n",
      "Epoch 585/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0184 - accuracy: 0.9940 - val_loss: 2.3793 - val_accuracy: 0.7741\n",
      "Epoch 586/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0182 - accuracy: 0.9960 - val_loss: 2.3007 - val_accuracy: 0.7804\n",
      "Epoch 587/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0120 - accuracy: 0.9967 - val_loss: 2.3510 - val_accuracy: 0.7788\n",
      "Epoch 588/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0101 - accuracy: 0.9967 - val_loss: 2.3576 - val_accuracy: 0.7664\n",
      "Epoch 589/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0129 - accuracy: 0.9960 - val_loss: 2.3732 - val_accuracy: 0.7617\n",
      "Epoch 590/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0110 - accuracy: 0.9960 - val_loss: 2.3570 - val_accuracy: 0.7773\n",
      "Epoch 591/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0121 - accuracy: 0.9960 - val_loss: 2.3466 - val_accuracy: 0.7570\n",
      "Epoch 592/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0159 - accuracy: 0.9953 - val_loss: 2.3975 - val_accuracy: 0.7664\n",
      "Epoch 593/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0169 - accuracy: 0.9940 - val_loss: 2.4294 - val_accuracy: 0.7617\n",
      "Epoch 594/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0192 - accuracy: 0.9933 - val_loss: 2.3866 - val_accuracy: 0.7695\n",
      "Epoch 595/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0176 - accuracy: 0.9947 - val_loss: 2.4461 - val_accuracy: 0.7523\n",
      "Epoch 596/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0281 - accuracy: 0.9893 - val_loss: 2.4859 - val_accuracy: 0.7617\n",
      "Epoch 597/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0286 - accuracy: 0.9906 - val_loss: 2.2777 - val_accuracy: 0.7679\n",
      "Epoch 598/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0147 - accuracy: 0.9947 - val_loss: 2.3084 - val_accuracy: 0.7804\n",
      "Epoch 599/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0326 - accuracy: 0.9913 - val_loss: 2.4664 - val_accuracy: 0.7710\n",
      "Epoch 600/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0229 - accuracy: 0.9940 - val_loss: 2.1618 - val_accuracy: 0.7726\n",
      "Epoch 601/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0257 - accuracy: 0.9913 - val_loss: 2.3518 - val_accuracy: 0.7492\n",
      "Epoch 602/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0245 - accuracy: 0.9953 - val_loss: 2.3770 - val_accuracy: 0.7804\n",
      "Epoch 603/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0147 - accuracy: 0.9947 - val_loss: 2.3165 - val_accuracy: 0.7835\n",
      "Epoch 604/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0240 - accuracy: 0.9913 - val_loss: 2.3170 - val_accuracy: 0.7648\n",
      "Epoch 605/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0169 - accuracy: 0.9926 - val_loss: 2.2515 - val_accuracy: 0.7960\n",
      "Epoch 606/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0186 - accuracy: 0.9933 - val_loss: 2.2506 - val_accuracy: 0.7773\n",
      "Epoch 607/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0207 - accuracy: 0.9926 - val_loss: 2.3587 - val_accuracy: 0.7679\n",
      "Epoch 608/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0234 - accuracy: 0.9913 - val_loss: 2.3234 - val_accuracy: 0.7648\n",
      "Epoch 609/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0194 - accuracy: 0.9913 - val_loss: 2.3430 - val_accuracy: 0.7679\n",
      "Epoch 610/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0170 - accuracy: 0.9940 - val_loss: 2.2575 - val_accuracy: 0.7788\n",
      "Epoch 611/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0120 - accuracy: 0.9960 - val_loss: 2.2285 - val_accuracy: 0.7601\n",
      "Epoch 612/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0166 - accuracy: 0.9953 - val_loss: 2.2418 - val_accuracy: 0.7601\n",
      "Epoch 613/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0188 - accuracy: 0.9960 - val_loss: 2.3821 - val_accuracy: 0.7757\n",
      "Epoch 614/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0219 - accuracy: 0.9926 - val_loss: 2.3920 - val_accuracy: 0.7601\n",
      "Epoch 615/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0171 - accuracy: 0.9947 - val_loss: 2.2772 - val_accuracy: 0.7726\n",
      "Epoch 616/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0139 - accuracy: 0.9967 - val_loss: 2.2540 - val_accuracy: 0.7710\n",
      "Epoch 617/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0141 - accuracy: 0.9967 - val_loss: 2.2736 - val_accuracy: 0.7648\n",
      "Epoch 618/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0117 - accuracy: 0.9960 - val_loss: 2.3436 - val_accuracy: 0.7773\n",
      "Epoch 619/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0069 - accuracy: 0.9980 - val_loss: 2.4370 - val_accuracy: 0.7804\n",
      "Epoch 620/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0129 - accuracy: 0.9947 - val_loss: 2.2311 - val_accuracy: 0.7695\n",
      "Epoch 621/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0132 - accuracy: 0.9953 - val_loss: 2.3345 - val_accuracy: 0.7835\n",
      "Epoch 622/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0182 - accuracy: 0.9933 - val_loss: 2.3935 - val_accuracy: 0.7741\n",
      "Epoch 623/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0156 - accuracy: 0.9940 - val_loss: 2.3282 - val_accuracy: 0.7788\n",
      "Epoch 624/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0083 - accuracy: 0.9960 - val_loss: 2.4483 - val_accuracy: 0.7726\n",
      "Epoch 625/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0130 - accuracy: 0.9967 - val_loss: 2.4488 - val_accuracy: 0.7773\n",
      "Epoch 626/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0185 - accuracy: 0.9940 - val_loss: 2.4109 - val_accuracy: 0.7804\n",
      "Epoch 627/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0205 - accuracy: 0.9933 - val_loss: 2.2617 - val_accuracy: 0.7788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 628/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0155 - accuracy: 0.9947 - val_loss: 2.3348 - val_accuracy: 0.7741\n",
      "Epoch 629/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0196 - accuracy: 0.9920 - val_loss: 2.4445 - val_accuracy: 0.7726\n",
      "Epoch 630/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0165 - accuracy: 0.9953 - val_loss: 2.5832 - val_accuracy: 0.7632\n",
      "Epoch 631/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0275 - accuracy: 0.9953 - val_loss: 2.6151 - val_accuracy: 0.7648\n",
      "Epoch 632/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0419 - accuracy: 0.9886 - val_loss: 2.3336 - val_accuracy: 0.7819\n",
      "Epoch 633/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0216 - accuracy: 0.9940 - val_loss: 2.3538 - val_accuracy: 0.7757\n",
      "Epoch 634/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0176 - accuracy: 0.9947 - val_loss: 2.3888 - val_accuracy: 0.7835\n",
      "Epoch 635/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0131 - accuracy: 0.9947 - val_loss: 2.3587 - val_accuracy: 0.7648\n",
      "Epoch 636/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0108 - accuracy: 0.9973 - val_loss: 2.3732 - val_accuracy: 0.7430\n",
      "Epoch 637/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0165 - accuracy: 0.9973 - val_loss: 2.5240 - val_accuracy: 0.7835\n",
      "Epoch 638/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0115 - accuracy: 0.9953 - val_loss: 2.3664 - val_accuracy: 0.7695\n",
      "Epoch 639/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0236 - accuracy: 0.9913 - val_loss: 2.2646 - val_accuracy: 0.7741\n",
      "Epoch 640/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0289 - accuracy: 0.9906 - val_loss: 2.3077 - val_accuracy: 0.7570\n",
      "Epoch 641/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0223 - accuracy: 0.9933 - val_loss: 2.3984 - val_accuracy: 0.7804\n",
      "Epoch 642/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0146 - accuracy: 0.9960 - val_loss: 2.2648 - val_accuracy: 0.7695\n",
      "Epoch 643/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0093 - accuracy: 0.9980 - val_loss: 2.3862 - val_accuracy: 0.7726\n",
      "Epoch 644/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0155 - accuracy: 0.9953 - val_loss: 2.3559 - val_accuracy: 0.7539\n",
      "Epoch 645/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0333 - accuracy: 0.9900 - val_loss: 2.4399 - val_accuracy: 0.7617\n",
      "Epoch 646/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0064 - accuracy: 0.9973 - val_loss: 2.3039 - val_accuracy: 0.7539\n",
      "Epoch 647/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0124 - accuracy: 0.9967 - val_loss: 2.2924 - val_accuracy: 0.7726\n",
      "Epoch 648/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0106 - accuracy: 0.9960 - val_loss: 2.2784 - val_accuracy: 0.7664\n",
      "Epoch 649/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0147 - accuracy: 0.9947 - val_loss: 2.5037 - val_accuracy: 0.7679\n",
      "Epoch 650/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0192 - accuracy: 0.9947 - val_loss: 2.4871 - val_accuracy: 0.7695\n",
      "Epoch 651/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0182 - accuracy: 0.9940 - val_loss: 2.3753 - val_accuracy: 0.7679\n",
      "Epoch 652/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0096 - accuracy: 0.9967 - val_loss: 2.4062 - val_accuracy: 0.7773\n",
      "Epoch 653/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0253 - accuracy: 0.9913 - val_loss: 2.4203 - val_accuracy: 0.7648\n",
      "Epoch 654/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0160 - accuracy: 0.9933 - val_loss: 2.4110 - val_accuracy: 0.7773\n",
      "Epoch 655/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0137 - accuracy: 0.9953 - val_loss: 2.3502 - val_accuracy: 0.7632\n",
      "Epoch 656/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0183 - accuracy: 0.9933 - val_loss: 2.4044 - val_accuracy: 0.7445\n",
      "Epoch 657/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0147 - accuracy: 0.9960 - val_loss: 2.5841 - val_accuracy: 0.7632\n",
      "Epoch 658/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0159 - accuracy: 0.9973 - val_loss: 2.5045 - val_accuracy: 0.7570\n",
      "Epoch 659/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0207 - accuracy: 0.9953 - val_loss: 2.3735 - val_accuracy: 0.7664\n",
      "Epoch 660/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0107 - accuracy: 0.9953 - val_loss: 2.2317 - val_accuracy: 0.7523\n",
      "Epoch 661/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0299 - accuracy: 0.9913 - val_loss: 2.2455 - val_accuracy: 0.7555\n",
      "Epoch 662/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0229 - accuracy: 0.9920 - val_loss: 2.1926 - val_accuracy: 0.7539\n",
      "Epoch 663/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0136 - accuracy: 0.9947 - val_loss: 2.3028 - val_accuracy: 0.7788\n",
      "Epoch 664/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0092 - accuracy: 0.9960 - val_loss: 2.3113 - val_accuracy: 0.7648\n",
      "Epoch 665/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0091 - accuracy: 0.9980 - val_loss: 2.3878 - val_accuracy: 0.7757\n",
      "Epoch 666/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0225 - accuracy: 0.9913 - val_loss: 2.4152 - val_accuracy: 0.7617\n",
      "Epoch 667/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0189 - accuracy: 0.9926 - val_loss: 2.5606 - val_accuracy: 0.7710\n",
      "Epoch 668/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0176 - accuracy: 0.9933 - val_loss: 2.4037 - val_accuracy: 0.7399\n",
      "Epoch 669/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0205 - accuracy: 0.9933 - val_loss: 2.3934 - val_accuracy: 0.7632\n",
      "Epoch 670/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0172 - accuracy: 0.9947 - val_loss: 2.2962 - val_accuracy: 0.7679\n",
      "Epoch 671/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0195 - accuracy: 0.9920 - val_loss: 2.3122 - val_accuracy: 0.7726\n",
      "Epoch 672/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0230 - accuracy: 0.9947 - val_loss: 2.3759 - val_accuracy: 0.7383\n",
      "Epoch 673/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0277 - accuracy: 0.9913 - val_loss: 2.3098 - val_accuracy: 0.7664\n",
      "Epoch 674/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0177 - accuracy: 0.9940 - val_loss: 2.3137 - val_accuracy: 0.7648\n",
      "Epoch 675/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0209 - accuracy: 0.9953 - val_loss: 2.1697 - val_accuracy: 0.7648\n",
      "Epoch 676/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0157 - accuracy: 0.9967 - val_loss: 2.2284 - val_accuracy: 0.7695\n",
      "Epoch 677/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0113 - accuracy: 0.9953 - val_loss: 2.2793 - val_accuracy: 0.7664\n",
      "Epoch 678/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0117 - accuracy: 0.9947 - val_loss: 2.3846 - val_accuracy: 0.7773\n",
      "Epoch 679/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0138 - accuracy: 0.9967 - val_loss: 2.3650 - val_accuracy: 0.7710\n",
      "Epoch 680/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0128 - accuracy: 0.9953 - val_loss: 2.3666 - val_accuracy: 0.7664\n",
      "Epoch 681/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0116 - accuracy: 0.9973 - val_loss: 2.3874 - val_accuracy: 0.7850\n",
      "Epoch 682/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0115 - accuracy: 0.9953 - val_loss: 2.4152 - val_accuracy: 0.7695\n",
      "Epoch 683/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0083 - accuracy: 0.9973 - val_loss: 2.3204 - val_accuracy: 0.7555\n",
      "Epoch 684/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0138 - accuracy: 0.9953 - val_loss: 2.3042 - val_accuracy: 0.7679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 685/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0128 - accuracy: 0.9960 - val_loss: 2.3217 - val_accuracy: 0.7399\n",
      "Epoch 686/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0137 - accuracy: 0.9960 - val_loss: 2.4196 - val_accuracy: 0.7508\n",
      "Epoch 687/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0168 - accuracy: 0.9960 - val_loss: 2.5189 - val_accuracy: 0.7695\n",
      "Epoch 688/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0132 - accuracy: 0.9947 - val_loss: 2.4101 - val_accuracy: 0.7726\n",
      "Epoch 689/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0147 - accuracy: 0.9933 - val_loss: 2.3553 - val_accuracy: 0.7632\n",
      "Epoch 690/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0224 - accuracy: 0.9913 - val_loss: 2.5010 - val_accuracy: 0.7804\n",
      "Epoch 691/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0132 - accuracy: 0.9953 - val_loss: 2.3494 - val_accuracy: 0.7664\n",
      "Epoch 692/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0149 - accuracy: 0.9947 - val_loss: 2.3622 - val_accuracy: 0.7679\n",
      "Epoch 693/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0119 - accuracy: 0.9967 - val_loss: 2.3036 - val_accuracy: 0.7695\n",
      "Epoch 694/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0110 - accuracy: 0.9967 - val_loss: 2.2971 - val_accuracy: 0.7617\n",
      "Epoch 695/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0307 - accuracy: 0.9933 - val_loss: 2.2012 - val_accuracy: 0.7679\n",
      "Epoch 696/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0179 - accuracy: 0.9947 - val_loss: 2.2746 - val_accuracy: 0.7570\n",
      "Epoch 697/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0408 - accuracy: 0.9906 - val_loss: 2.2880 - val_accuracy: 0.7695\n",
      "Epoch 698/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0344 - accuracy: 0.9920 - val_loss: 2.1026 - val_accuracy: 0.7710\n",
      "Epoch 699/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0331 - accuracy: 0.9940 - val_loss: 2.2579 - val_accuracy: 0.7928\n",
      "Epoch 700/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0146 - accuracy: 0.9947 - val_loss: 2.1402 - val_accuracy: 0.7835\n",
      "Epoch 701/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0135 - accuracy: 0.9940 - val_loss: 2.1081 - val_accuracy: 0.7601\n",
      "Epoch 702/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0102 - accuracy: 0.9953 - val_loss: 2.1804 - val_accuracy: 0.7773\n",
      "Epoch 703/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0128 - accuracy: 0.9953 - val_loss: 2.3211 - val_accuracy: 0.7757\n",
      "Epoch 704/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0203 - accuracy: 0.9960 - val_loss: 2.3903 - val_accuracy: 0.7741\n",
      "Epoch 705/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0053 - accuracy: 0.9993 - val_loss: 2.3901 - val_accuracy: 0.7679\n",
      "Epoch 706/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0345 - accuracy: 0.9933 - val_loss: 2.4885 - val_accuracy: 0.7757\n",
      "Epoch 707/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0118 - accuracy: 0.9973 - val_loss: 2.2961 - val_accuracy: 0.7710\n",
      "Epoch 708/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0063 - accuracy: 0.9973 - val_loss: 2.3242 - val_accuracy: 0.7477\n",
      "Epoch 709/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0094 - accuracy: 0.9953 - val_loss: 2.4118 - val_accuracy: 0.7601\n",
      "Epoch 710/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0217 - accuracy: 0.9947 - val_loss: 2.2307 - val_accuracy: 0.7586\n",
      "Epoch 711/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0143 - accuracy: 0.9967 - val_loss: 2.2996 - val_accuracy: 0.7632\n",
      "Epoch 712/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0135 - accuracy: 0.9960 - val_loss: 2.2055 - val_accuracy: 0.7726\n",
      "Epoch 713/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0044 - accuracy: 0.9993 - val_loss: 2.2388 - val_accuracy: 0.7757\n",
      "Epoch 714/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0138 - accuracy: 0.9947 - val_loss: 2.2473 - val_accuracy: 0.7664\n",
      "Epoch 715/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0226 - accuracy: 0.9933 - val_loss: 2.2839 - val_accuracy: 0.7555\n",
      "Epoch 716/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0158 - accuracy: 0.9953 - val_loss: 2.2562 - val_accuracy: 0.7617\n",
      "Epoch 717/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0089 - accuracy: 0.9973 - val_loss: 2.3254 - val_accuracy: 0.7897\n",
      "Epoch 718/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0150 - accuracy: 0.9947 - val_loss: 2.2150 - val_accuracy: 0.7648\n",
      "Epoch 719/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0090 - accuracy: 0.9967 - val_loss: 2.3137 - val_accuracy: 0.7835\n",
      "Epoch 720/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0161 - accuracy: 0.9933 - val_loss: 2.2615 - val_accuracy: 0.7741\n",
      "Epoch 721/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0164 - accuracy: 0.9960 - val_loss: 2.2570 - val_accuracy: 0.7757\n",
      "Epoch 722/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0132 - accuracy: 0.9960 - val_loss: 2.2306 - val_accuracy: 0.7773\n",
      "Epoch 723/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0098 - accuracy: 0.9960 - val_loss: 2.1563 - val_accuracy: 0.7710\n",
      "Epoch 724/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0127 - accuracy: 0.9953 - val_loss: 2.2280 - val_accuracy: 0.7866\n",
      "Epoch 725/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0249 - accuracy: 0.9913 - val_loss: 2.1566 - val_accuracy: 0.7741\n",
      "Epoch 726/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0149 - accuracy: 0.9953 - val_loss: 2.2919 - val_accuracy: 0.7741\n",
      "Epoch 727/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0084 - accuracy: 0.9993 - val_loss: 2.4145 - val_accuracy: 0.7866\n",
      "Epoch 728/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0249 - accuracy: 0.9933 - val_loss: 2.4858 - val_accuracy: 0.7695\n",
      "Epoch 729/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0120 - accuracy: 0.9947 - val_loss: 2.4278 - val_accuracy: 0.7710\n",
      "Epoch 730/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0092 - accuracy: 0.9973 - val_loss: 2.4864 - val_accuracy: 0.7679\n",
      "Epoch 731/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0102 - accuracy: 0.9947 - val_loss: 2.5315 - val_accuracy: 0.7866\n",
      "Epoch 732/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0082 - accuracy: 0.9973 - val_loss: 2.4600 - val_accuracy: 0.7804\n",
      "Epoch 733/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0052 - accuracy: 0.9987 - val_loss: 2.5175 - val_accuracy: 0.7726\n",
      "Epoch 734/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0139 - accuracy: 0.9960 - val_loss: 2.4924 - val_accuracy: 0.7601\n",
      "Epoch 735/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0240 - accuracy: 0.9947 - val_loss: 2.5470 - val_accuracy: 0.7819\n",
      "Epoch 736/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0060 - accuracy: 0.9993 - val_loss: 2.4213 - val_accuracy: 0.7664\n",
      "Epoch 737/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0125 - accuracy: 0.9953 - val_loss: 2.5075 - val_accuracy: 0.7632\n",
      "Epoch 738/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0130 - accuracy: 0.9953 - val_loss: 2.5756 - val_accuracy: 0.7679\n",
      "Epoch 739/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0362 - accuracy: 0.9906 - val_loss: 2.5297 - val_accuracy: 0.7601\n",
      "Epoch 740/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0038 - accuracy: 0.9993 - val_loss: 2.5555 - val_accuracy: 0.7710\n",
      "Epoch 741/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0203 - accuracy: 0.9947 - val_loss: 2.5635 - val_accuracy: 0.7788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 742/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0185 - accuracy: 0.9953 - val_loss: 2.4671 - val_accuracy: 0.7508\n",
      "Epoch 743/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0237 - accuracy: 0.9940 - val_loss: 2.4018 - val_accuracy: 0.7695\n",
      "Epoch 744/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0230 - accuracy: 0.9920 - val_loss: 2.4789 - val_accuracy: 0.7819\n",
      "Epoch 745/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0261 - accuracy: 0.9947 - val_loss: 2.5644 - val_accuracy: 0.7664\n",
      "Epoch 746/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0192 - accuracy: 0.9913 - val_loss: 2.5660 - val_accuracy: 0.7788\n",
      "Epoch 747/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0123 - accuracy: 0.9947 - val_loss: 2.4661 - val_accuracy: 0.7632\n",
      "Epoch 748/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0088 - accuracy: 0.9967 - val_loss: 2.6362 - val_accuracy: 0.7835\n",
      "Epoch 749/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0162 - accuracy: 0.9947 - val_loss: 2.4743 - val_accuracy: 0.7850\n",
      "Epoch 750/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0245 - accuracy: 0.9933 - val_loss: 2.3512 - val_accuracy: 0.7695\n",
      "Epoch 751/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0235 - accuracy: 0.9940 - val_loss: 2.3430 - val_accuracy: 0.7695\n",
      "Epoch 752/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0250 - accuracy: 0.9940 - val_loss: 2.4132 - val_accuracy: 0.7555\n",
      "Epoch 753/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0141 - accuracy: 0.9947 - val_loss: 2.3695 - val_accuracy: 0.7788\n",
      "Epoch 754/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0109 - accuracy: 0.9960 - val_loss: 2.2913 - val_accuracy: 0.7741\n",
      "Epoch 755/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0158 - accuracy: 0.9933 - val_loss: 2.4460 - val_accuracy: 0.7819\n",
      "Epoch 756/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0081 - accuracy: 0.9960 - val_loss: 2.4199 - val_accuracy: 0.7804\n",
      "Epoch 757/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0056 - accuracy: 0.9987 - val_loss: 2.3466 - val_accuracy: 0.7788\n",
      "Epoch 758/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0307 - accuracy: 0.9913 - val_loss: 2.2442 - val_accuracy: 0.7773\n",
      "Epoch 759/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0075 - accuracy: 0.9967 - val_loss: 2.3783 - val_accuracy: 0.7897\n",
      "Epoch 760/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0075 - accuracy: 0.9973 - val_loss: 2.2424 - val_accuracy: 0.7850\n",
      "Epoch 761/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0057 - accuracy: 0.9973 - val_loss: 2.2358 - val_accuracy: 0.7866\n",
      "Epoch 762/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0131 - accuracy: 0.9960 - val_loss: 2.3862 - val_accuracy: 0.7897\n",
      "Epoch 763/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0198 - accuracy: 0.9926 - val_loss: 2.3418 - val_accuracy: 0.7788\n",
      "Epoch 764/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0153 - accuracy: 0.9947 - val_loss: 2.3215 - val_accuracy: 0.7757\n",
      "Epoch 765/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0113 - accuracy: 0.9953 - val_loss: 2.3340 - val_accuracy: 0.7726\n",
      "Epoch 766/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0134 - accuracy: 0.9960 - val_loss: 2.4402 - val_accuracy: 0.7788\n",
      "Epoch 767/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0209 - accuracy: 0.9947 - val_loss: 2.5589 - val_accuracy: 0.7710\n",
      "Epoch 768/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0205 - accuracy: 0.9967 - val_loss: 2.5358 - val_accuracy: 0.7804\n",
      "Epoch 769/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0201 - accuracy: 0.9960 - val_loss: 2.4842 - val_accuracy: 0.7741\n",
      "Epoch 770/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0211 - accuracy: 0.9947 - val_loss: 2.3838 - val_accuracy: 0.7882\n",
      "Epoch 771/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0188 - accuracy: 0.9933 - val_loss: 2.3198 - val_accuracy: 0.7741\n",
      "Epoch 772/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0080 - accuracy: 0.9960 - val_loss: 2.3901 - val_accuracy: 0.7835\n",
      "Epoch 773/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0259 - accuracy: 0.9940 - val_loss: 2.4133 - val_accuracy: 0.7741\n",
      "Epoch 774/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0187 - accuracy: 0.9947 - val_loss: 2.4165 - val_accuracy: 0.7695\n",
      "Epoch 775/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0099 - accuracy: 0.9967 - val_loss: 2.3432 - val_accuracy: 0.7586\n",
      "Epoch 776/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0159 - accuracy: 0.9960 - val_loss: 2.3124 - val_accuracy: 0.7601\n",
      "Epoch 777/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0139 - accuracy: 0.9953 - val_loss: 2.4006 - val_accuracy: 0.7804\n",
      "Epoch 778/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0075 - accuracy: 0.9973 - val_loss: 2.3712 - val_accuracy: 0.7710\n",
      "Epoch 779/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0274 - accuracy: 0.9920 - val_loss: 2.3597 - val_accuracy: 0.7695\n",
      "Epoch 780/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0286 - accuracy: 0.9920 - val_loss: 2.3336 - val_accuracy: 0.7741\n",
      "Epoch 781/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0186 - accuracy: 0.9940 - val_loss: 2.4612 - val_accuracy: 0.7555\n",
      "Epoch 782/1500\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.0244 - accuracy: 0.9906 - val_loss: 2.4492 - val_accuracy: 0.7601\n",
      "Epoch 783/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0139 - accuracy: 0.9953 - val_loss: 2.4831 - val_accuracy: 0.7788\n",
      "Epoch 784/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0114 - accuracy: 0.9960 - val_loss: 2.4528 - val_accuracy: 0.7648\n",
      "Epoch 785/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0112 - accuracy: 0.9940 - val_loss: 2.4097 - val_accuracy: 0.7601\n",
      "Epoch 786/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0031 - accuracy: 0.9993 - val_loss: 2.4883 - val_accuracy: 0.7757\n",
      "Epoch 787/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0087 - accuracy: 0.9980 - val_loss: 2.5818 - val_accuracy: 0.7804\n",
      "Epoch 788/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0126 - accuracy: 0.9947 - val_loss: 2.4318 - val_accuracy: 0.7570\n",
      "Epoch 789/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0062 - accuracy: 0.9980 - val_loss: 2.4387 - val_accuracy: 0.7710\n",
      "Epoch 790/1500\n",
      "38/38 [==============================] - 0s 13ms/step - loss: 0.0057 - accuracy: 0.9987 - val_loss: 2.3919 - val_accuracy: 0.7570\n",
      "Epoch 791/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0124 - accuracy: 0.9953 - val_loss: 2.4369 - val_accuracy: 0.7648\n",
      "Epoch 792/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0146 - accuracy: 0.9973 - val_loss: 2.4668 - val_accuracy: 0.7741\n",
      "Epoch 793/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0110 - accuracy: 0.9953 - val_loss: 2.3763 - val_accuracy: 0.7710\n",
      "Epoch 794/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0163 - accuracy: 0.9940 - val_loss: 2.3764 - val_accuracy: 0.7601\n",
      "Epoch 795/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0081 - accuracy: 0.9960 - val_loss: 2.5120 - val_accuracy: 0.7617\n",
      "Epoch 796/1500\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.0079 - accuracy: 0.9967 - val_loss: 2.6892 - val_accuracy: 0.7710\n",
      "Epoch 797/1500\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.0191 - accuracy: 0.9940 - val_loss: 2.6177 - val_accuracy: 0.7788\n",
      "Epoch 798/1500\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.0076 - accuracy: 0.9980 - val_loss: 2.7310 - val_accuracy: 0.7928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 799/1500\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.0152 - accuracy: 0.9940 - val_loss: 2.5977 - val_accuracy: 0.7819\n",
      "Epoch 800/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0224 - accuracy: 0.9953 - val_loss: 2.4509 - val_accuracy: 0.7648\n",
      "Epoch 801/1500\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.0225 - accuracy: 0.9940 - val_loss: 2.4136 - val_accuracy: 0.7710\n",
      "Epoch 802/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0133 - accuracy: 0.9953 - val_loss: 2.4514 - val_accuracy: 0.7664\n",
      "Epoch 803/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0082 - accuracy: 0.9960 - val_loss: 2.5496 - val_accuracy: 0.7710\n",
      "Epoch 804/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0095 - accuracy: 0.9973 - val_loss: 2.6370 - val_accuracy: 0.7788\n",
      "Epoch 805/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0085 - accuracy: 0.9980 - val_loss: 2.5652 - val_accuracy: 0.7477\n",
      "Epoch 806/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0147 - accuracy: 0.9973 - val_loss: 2.5089 - val_accuracy: 0.7648\n",
      "Epoch 807/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0149 - accuracy: 0.9960 - val_loss: 2.6104 - val_accuracy: 0.7726\n",
      "Epoch 808/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0168 - accuracy: 0.9967 - val_loss: 2.6499 - val_accuracy: 0.7601\n",
      "Epoch 809/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0219 - accuracy: 0.9940 - val_loss: 2.5199 - val_accuracy: 0.7788\n",
      "Epoch 810/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0060 - accuracy: 0.9980 - val_loss: 2.4729 - val_accuracy: 0.7757\n",
      "Epoch 811/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0074 - accuracy: 0.9967 - val_loss: 2.4504 - val_accuracy: 0.7679\n",
      "Epoch 812/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0128 - accuracy: 0.9960 - val_loss: 2.4648 - val_accuracy: 0.7819\n",
      "Epoch 813/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0069 - accuracy: 0.9987 - val_loss: 2.4720 - val_accuracy: 0.7788\n",
      "Epoch 814/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0099 - accuracy: 0.9953 - val_loss: 2.3648 - val_accuracy: 0.7648\n",
      "Epoch 815/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0049 - accuracy: 0.9980 - val_loss: 2.4265 - val_accuracy: 0.7741\n",
      "Epoch 816/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0111 - accuracy: 0.9980 - val_loss: 2.7627 - val_accuracy: 0.7866\n",
      "Epoch 817/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0299 - accuracy: 0.9933 - val_loss: 2.5291 - val_accuracy: 0.7710\n",
      "Epoch 818/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0237 - accuracy: 0.9926 - val_loss: 2.5537 - val_accuracy: 0.7710\n",
      "Epoch 819/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0160 - accuracy: 0.9960 - val_loss: 2.5257 - val_accuracy: 0.7664\n",
      "Epoch 820/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0124 - accuracy: 0.9967 - val_loss: 2.7407 - val_accuracy: 0.7850\n",
      "Epoch 821/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0326 - accuracy: 0.9926 - val_loss: 2.4572 - val_accuracy: 0.7741\n",
      "Epoch 822/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0345 - accuracy: 0.9926 - val_loss: 2.5734 - val_accuracy: 0.7695\n",
      "Epoch 823/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0209 - accuracy: 0.9920 - val_loss: 2.5733 - val_accuracy: 0.7648\n",
      "Epoch 824/1500\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.0238 - accuracy: 0.9940 - val_loss: 2.4374 - val_accuracy: 0.7695\n",
      "Epoch 825/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0296 - accuracy: 0.9920 - val_loss: 2.6098 - val_accuracy: 0.7679\n",
      "Epoch 826/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0212 - accuracy: 0.9926 - val_loss: 2.5919 - val_accuracy: 0.7757\n",
      "Epoch 827/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0144 - accuracy: 0.9967 - val_loss: 2.6416 - val_accuracy: 0.7773\n",
      "Epoch 828/1500\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.0140 - accuracy: 0.9940 - val_loss: 2.6356 - val_accuracy: 0.7866\n",
      "Epoch 829/1500\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.0163 - accuracy: 0.9933 - val_loss: 2.6611 - val_accuracy: 0.7679\n",
      "Epoch 830/1500\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.0219 - accuracy: 0.9913 - val_loss: 2.5455 - val_accuracy: 0.7788\n",
      "Epoch 831/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0126 - accuracy: 0.9953 - val_loss: 2.5826 - val_accuracy: 0.7850\n",
      "Epoch 832/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0086 - accuracy: 0.9967 - val_loss: 2.6191 - val_accuracy: 0.7866\n",
      "Epoch 833/1500\n",
      "38/38 [==============================] - 0s 13ms/step - loss: 0.0140 - accuracy: 0.9953 - val_loss: 2.5605 - val_accuracy: 0.7850\n",
      "Epoch 834/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0075 - accuracy: 0.9987 - val_loss: 2.6567 - val_accuracy: 0.7882\n",
      "Epoch 835/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0078 - accuracy: 0.9987 - val_loss: 2.6121 - val_accuracy: 0.7835\n",
      "Epoch 836/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0065 - accuracy: 0.9987 - val_loss: 2.5144 - val_accuracy: 0.7741\n",
      "Epoch 837/1500\n",
      "38/38 [==============================] - 1s 13ms/step - loss: 0.0047 - accuracy: 0.9987 - val_loss: 2.5810 - val_accuracy: 0.7835\n",
      "Epoch 838/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0032 - accuracy: 0.9987 - val_loss: 2.5830 - val_accuracy: 0.7804\n",
      "Epoch 839/1500\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.0050 - accuracy: 0.9980 - val_loss: 2.5432 - val_accuracy: 0.7835\n",
      "Epoch 840/1500\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.0047 - accuracy: 0.9980 - val_loss: 2.5960 - val_accuracy: 0.7757\n",
      "Epoch 841/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0099 - accuracy: 0.9967 - val_loss: 2.7096 - val_accuracy: 0.7866\n",
      "Epoch 842/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0230 - accuracy: 0.9967 - val_loss: 2.4913 - val_accuracy: 0.7523\n",
      "Epoch 843/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0091 - accuracy: 0.9960 - val_loss: 2.5409 - val_accuracy: 0.7664\n",
      "Epoch 844/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0070 - accuracy: 0.9980 - val_loss: 2.5694 - val_accuracy: 0.7726\n",
      "Epoch 845/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0204 - accuracy: 0.9953 - val_loss: 2.5889 - val_accuracy: 0.7726\n",
      "Epoch 846/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0091 - accuracy: 0.9967 - val_loss: 2.6572 - val_accuracy: 0.7866\n",
      "Epoch 847/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0180 - accuracy: 0.9953 - val_loss: 2.6708 - val_accuracy: 0.7757\n",
      "Epoch 848/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0079 - accuracy: 0.9967 - val_loss: 2.5863 - val_accuracy: 0.7773\n",
      "Epoch 849/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0048 - accuracy: 0.9980 - val_loss: 2.6366 - val_accuracy: 0.7819\n",
      "Epoch 850/1500\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.0090 - accuracy: 0.9973 - val_loss: 2.5867 - val_accuracy: 0.7741\n",
      "Epoch 851/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0224 - accuracy: 0.9973 - val_loss: 2.5195 - val_accuracy: 0.7804\n",
      "Epoch 852/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0086 - accuracy: 0.9973 - val_loss: 2.5773 - val_accuracy: 0.7664\n",
      "Epoch 853/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0245 - accuracy: 0.9933 - val_loss: 2.4154 - val_accuracy: 0.7679\n",
      "Epoch 854/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0080 - accuracy: 0.9967 - val_loss: 2.4924 - val_accuracy: 0.7632\n",
      "Epoch 855/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0343 - accuracy: 0.9906 - val_loss: 2.4986 - val_accuracy: 0.7804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 856/1500\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.0147 - accuracy: 0.9967 - val_loss: 2.3921 - val_accuracy: 0.7788\n",
      "Epoch 857/1500\n",
      "38/38 [==============================] - 1s 13ms/step - loss: 0.0155 - accuracy: 0.9947 - val_loss: 2.4286 - val_accuracy: 0.7773\n",
      "Epoch 858/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0158 - accuracy: 0.9940 - val_loss: 2.3497 - val_accuracy: 0.7866\n",
      "Epoch 859/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0134 - accuracy: 0.9960 - val_loss: 2.3647 - val_accuracy: 0.7788\n",
      "Epoch 860/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0219 - accuracy: 0.9940 - val_loss: 2.4100 - val_accuracy: 0.7741\n",
      "Epoch 861/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0239 - accuracy: 0.9933 - val_loss: 2.3362 - val_accuracy: 0.7773\n",
      "Epoch 862/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0066 - accuracy: 0.9973 - val_loss: 2.4388 - val_accuracy: 0.7866\n",
      "Epoch 863/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0191 - accuracy: 0.9933 - val_loss: 2.2706 - val_accuracy: 0.7788\n",
      "Epoch 864/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0350 - accuracy: 0.9940 - val_loss: 2.5889 - val_accuracy: 0.7866\n",
      "Epoch 865/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0235 - accuracy: 0.9933 - val_loss: 2.3619 - val_accuracy: 0.7679\n",
      "Epoch 866/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0254 - accuracy: 0.9900 - val_loss: 2.2893 - val_accuracy: 0.7586\n",
      "Epoch 867/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0108 - accuracy: 0.9967 - val_loss: 2.3809 - val_accuracy: 0.7897\n",
      "Epoch 868/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0191 - accuracy: 0.9953 - val_loss: 2.4342 - val_accuracy: 0.7882\n",
      "Epoch 869/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0219 - accuracy: 0.9920 - val_loss: 2.3351 - val_accuracy: 0.7835\n",
      "Epoch 870/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0151 - accuracy: 0.9947 - val_loss: 2.3537 - val_accuracy: 0.7804\n",
      "Epoch 871/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0109 - accuracy: 0.9960 - val_loss: 2.2582 - val_accuracy: 0.7741\n",
      "Epoch 872/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0058 - accuracy: 0.9987 - val_loss: 2.3175 - val_accuracy: 0.7850\n",
      "Epoch 873/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0090 - accuracy: 0.9973 - val_loss: 2.3637 - val_accuracy: 0.7819\n",
      "Epoch 874/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0059 - accuracy: 0.9973 - val_loss: 2.3812 - val_accuracy: 0.7866\n",
      "Epoch 875/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0122 - accuracy: 0.9953 - val_loss: 2.4215 - val_accuracy: 0.7866\n",
      "Epoch 876/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0186 - accuracy: 0.9973 - val_loss: 2.3448 - val_accuracy: 0.7757\n",
      "Epoch 877/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0088 - accuracy: 0.9980 - val_loss: 2.5674 - val_accuracy: 0.7850\n",
      "Epoch 878/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0130 - accuracy: 0.9960 - val_loss: 2.5149 - val_accuracy: 0.7804\n",
      "Epoch 879/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0098 - accuracy: 0.9967 - val_loss: 2.5579 - val_accuracy: 0.7741\n",
      "Epoch 880/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0243 - accuracy: 0.9940 - val_loss: 2.4628 - val_accuracy: 0.7726\n",
      "Epoch 881/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0172 - accuracy: 0.9960 - val_loss: 2.5877 - val_accuracy: 0.7897\n",
      "Epoch 882/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0278 - accuracy: 0.9926 - val_loss: 2.3922 - val_accuracy: 0.7850\n",
      "Epoch 883/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0094 - accuracy: 0.9973 - val_loss: 2.3975 - val_accuracy: 0.7788\n",
      "Epoch 884/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0118 - accuracy: 0.9960 - val_loss: 2.5060 - val_accuracy: 0.7850\n",
      "Epoch 885/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0185 - accuracy: 0.9933 - val_loss: 2.6559 - val_accuracy: 0.7773\n",
      "Epoch 886/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0086 - accuracy: 0.9980 - val_loss: 2.6127 - val_accuracy: 0.7648\n",
      "Epoch 887/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0055 - accuracy: 0.9980 - val_loss: 2.4587 - val_accuracy: 0.7632\n",
      "Epoch 888/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0165 - accuracy: 0.9940 - val_loss: 2.5015 - val_accuracy: 0.7819\n",
      "Epoch 889/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0090 - accuracy: 0.9953 - val_loss: 2.3942 - val_accuracy: 0.7664\n",
      "Epoch 890/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0069 - accuracy: 0.9967 - val_loss: 2.4844 - val_accuracy: 0.7710\n",
      "Epoch 891/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0099 - accuracy: 0.9967 - val_loss: 2.4411 - val_accuracy: 0.7726\n",
      "Epoch 892/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0083 - accuracy: 0.9973 - val_loss: 2.3946 - val_accuracy: 0.7835\n",
      "Epoch 893/1500\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.0109 - accuracy: 0.9967 - val_loss: 2.4338 - val_accuracy: 0.7975\n",
      "Epoch 894/1500\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.0196 - accuracy: 0.9947 - val_loss: 2.4696 - val_accuracy: 0.7819\n",
      "Epoch 895/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0125 - accuracy: 0.9940 - val_loss: 2.4357 - val_accuracy: 0.7882\n",
      "Epoch 896/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0172 - accuracy: 0.9933 - val_loss: 2.4373 - val_accuracy: 0.7944\n",
      "Epoch 897/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0215 - accuracy: 0.9947 - val_loss: 2.3326 - val_accuracy: 0.7632\n",
      "Epoch 898/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0175 - accuracy: 0.9953 - val_loss: 2.4902 - val_accuracy: 0.7679\n",
      "Epoch 899/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0061 - accuracy: 0.9973 - val_loss: 2.4760 - val_accuracy: 0.7710\n",
      "Epoch 900/1500\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.0120 - accuracy: 0.9953 - val_loss: 2.5461 - val_accuracy: 0.7788\n",
      "Epoch 901/1500\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.0128 - accuracy: 0.9960 - val_loss: 2.4566 - val_accuracy: 0.7788\n",
      "Epoch 902/1500\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.0073 - accuracy: 0.9973 - val_loss: 2.3444 - val_accuracy: 0.7804\n",
      "Epoch 903/1500\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.0117 - accuracy: 0.9953 - val_loss: 2.5158 - val_accuracy: 0.7757\n",
      "Epoch 904/1500\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.0071 - accuracy: 0.9987 - val_loss: 2.4440 - val_accuracy: 0.7773\n",
      "Epoch 905/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0188 - accuracy: 0.9947 - val_loss: 2.4329 - val_accuracy: 0.7882\n",
      "Epoch 906/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0171 - accuracy: 0.9960 - val_loss: 2.3967 - val_accuracy: 0.7866\n",
      "Epoch 907/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0231 - accuracy: 0.9940 - val_loss: 2.3565 - val_accuracy: 0.7788\n",
      "Epoch 908/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0280 - accuracy: 0.9933 - val_loss: 2.4364 - val_accuracy: 0.7819\n",
      "Epoch 909/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0143 - accuracy: 0.9940 - val_loss: 2.5181 - val_accuracy: 0.7850\n",
      "Epoch 910/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0179 - accuracy: 0.9953 - val_loss: 2.4745 - val_accuracy: 0.7897\n",
      "Epoch 911/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0117 - accuracy: 0.9967 - val_loss: 2.5341 - val_accuracy: 0.7741\n",
      "Epoch 912/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0064 - accuracy: 0.9967 - val_loss: 2.5537 - val_accuracy: 0.7928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 913/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0149 - accuracy: 0.9960 - val_loss: 2.4597 - val_accuracy: 0.7819\n",
      "Epoch 914/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0086 - accuracy: 0.9967 - val_loss: 2.3662 - val_accuracy: 0.7897\n",
      "Epoch 915/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0136 - accuracy: 0.9953 - val_loss: 2.4215 - val_accuracy: 0.7819\n",
      "Epoch 916/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0071 - accuracy: 0.9973 - val_loss: 2.5465 - val_accuracy: 0.7710\n",
      "Epoch 917/1500\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.0198 - accuracy: 0.9953 - val_loss: 2.4763 - val_accuracy: 0.7757\n",
      "Epoch 918/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0068 - accuracy: 0.9973 - val_loss: 2.5614 - val_accuracy: 0.7850\n",
      "Epoch 919/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0088 - accuracy: 0.9967 - val_loss: 2.4308 - val_accuracy: 0.7664\n",
      "Epoch 920/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0146 - accuracy: 0.9973 - val_loss: 2.5320 - val_accuracy: 0.7695\n",
      "Epoch 921/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0109 - accuracy: 0.9947 - val_loss: 2.6012 - val_accuracy: 0.7773\n",
      "Epoch 922/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0074 - accuracy: 0.9960 - val_loss: 2.5512 - val_accuracy: 0.7835\n",
      "Epoch 923/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0145 - accuracy: 0.9933 - val_loss: 2.7778 - val_accuracy: 0.7835\n",
      "Epoch 924/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0205 - accuracy: 0.9933 - val_loss: 2.7123 - val_accuracy: 0.7866\n",
      "Epoch 925/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0119 - accuracy: 0.9960 - val_loss: 2.7654 - val_accuracy: 0.7804\n",
      "Epoch 926/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0105 - accuracy: 0.9960 - val_loss: 2.5482 - val_accuracy: 0.7710\n",
      "Epoch 927/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0086 - accuracy: 0.9980 - val_loss: 2.6044 - val_accuracy: 0.7850\n",
      "Epoch 928/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0061 - accuracy: 0.9967 - val_loss: 2.6556 - val_accuracy: 0.7773\n",
      "Epoch 929/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0110 - accuracy: 0.9967 - val_loss: 2.7680 - val_accuracy: 0.7882\n",
      "Epoch 930/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0085 - accuracy: 0.9980 - val_loss: 2.7543 - val_accuracy: 0.7913\n",
      "Epoch 931/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0148 - accuracy: 0.9960 - val_loss: 2.6927 - val_accuracy: 0.7804\n",
      "Epoch 932/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0034 - accuracy: 0.9993 - val_loss: 2.6562 - val_accuracy: 0.7835\n",
      "Epoch 933/1500\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.0110 - accuracy: 0.9967 - val_loss: 2.7579 - val_accuracy: 0.7882\n",
      "Epoch 934/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0080 - accuracy: 0.9973 - val_loss: 2.7508 - val_accuracy: 0.7819\n",
      "Epoch 935/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0113 - accuracy: 0.9973 - val_loss: 2.4638 - val_accuracy: 0.7757\n",
      "Epoch 936/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0327 - accuracy: 0.9926 - val_loss: 2.7602 - val_accuracy: 0.7788\n",
      "Epoch 937/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0119 - accuracy: 0.9960 - val_loss: 2.6533 - val_accuracy: 0.7773\n",
      "Epoch 938/1500\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.0129 - accuracy: 0.9973 - val_loss: 2.7002 - val_accuracy: 0.7819\n",
      "Epoch 939/1500\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.0103 - accuracy: 0.9980 - val_loss: 2.6276 - val_accuracy: 0.7804\n",
      "Epoch 940/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 2.5855 - val_accuracy: 0.7882\n",
      "Epoch 941/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0065 - accuracy: 0.9967 - val_loss: 2.6451 - val_accuracy: 0.7850\n",
      "Epoch 942/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0152 - accuracy: 0.9980 - val_loss: 2.6682 - val_accuracy: 0.7866\n",
      "Epoch 943/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0067 - accuracy: 0.9967 - val_loss: 2.6066 - val_accuracy: 0.7866\n",
      "Epoch 944/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0123 - accuracy: 0.9960 - val_loss: 2.4879 - val_accuracy: 0.7648\n",
      "Epoch 945/1500\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.0124 - accuracy: 0.9967 - val_loss: 2.6597 - val_accuracy: 0.7819\n",
      "Epoch 946/1500\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.0283 - accuracy: 0.9920 - val_loss: 2.3806 - val_accuracy: 0.7648\n",
      "Epoch 947/1500\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.0105 - accuracy: 0.9960 - val_loss: 2.4960 - val_accuracy: 0.7788\n",
      "Epoch 948/1500\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.0123 - accuracy: 0.9953 - val_loss: 2.5341 - val_accuracy: 0.7850\n",
      "Epoch 949/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0158 - accuracy: 0.9953 - val_loss: 2.5025 - val_accuracy: 0.7710\n",
      "Epoch 950/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0184 - accuracy: 0.9953 - val_loss: 2.6022 - val_accuracy: 0.7773\n",
      "Epoch 951/1500\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.0099 - accuracy: 0.9947 - val_loss: 2.3915 - val_accuracy: 0.7461\n",
      "Epoch 952/1500\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.0081 - accuracy: 0.9960 - val_loss: 2.4524 - val_accuracy: 0.7804\n",
      "Epoch 953/1500\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.0126 - accuracy: 0.9973 - val_loss: 2.5039 - val_accuracy: 0.7757\n",
      "Epoch 954/1500\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.0088 - accuracy: 0.9960 - val_loss: 2.5567 - val_accuracy: 0.7866\n",
      "Epoch 955/1500\n",
      "38/38 [==============================] - 1s 13ms/step - loss: 0.0084 - accuracy: 0.9967 - val_loss: 2.6843 - val_accuracy: 0.7819\n",
      "Epoch 956/1500\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.0153 - accuracy: 0.9973 - val_loss: 2.6327 - val_accuracy: 0.7648\n",
      "Epoch 957/1500\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.0261 - accuracy: 0.9926 - val_loss: 2.5868 - val_accuracy: 0.7664\n",
      "Epoch 958/1500\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.0177 - accuracy: 0.9940 - val_loss: 2.5134 - val_accuracy: 0.7726\n",
      "Epoch 959/1500\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.0172 - accuracy: 0.9973 - val_loss: 2.4739 - val_accuracy: 0.7648\n",
      "Epoch 960/1500\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.0174 - accuracy: 0.9940 - val_loss: 2.5199 - val_accuracy: 0.7710\n",
      "Epoch 961/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0190 - accuracy: 0.9953 - val_loss: 2.3554 - val_accuracy: 0.7664\n",
      "Epoch 962/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0149 - accuracy: 0.9953 - val_loss: 2.5061 - val_accuracy: 0.7804\n",
      "Epoch 963/1500\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.0310 - accuracy: 0.9900 - val_loss: 2.4100 - val_accuracy: 0.7850\n",
      "Epoch 964/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0128 - accuracy: 0.9953 - val_loss: 2.4086 - val_accuracy: 0.7757\n",
      "Epoch 965/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0091 - accuracy: 0.9980 - val_loss: 2.4535 - val_accuracy: 0.7773\n",
      "Epoch 966/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0212 - accuracy: 0.9940 - val_loss: 2.3777 - val_accuracy: 0.7539\n",
      "Epoch 967/1500\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.0219 - accuracy: 0.9940 - val_loss: 2.4597 - val_accuracy: 0.7866\n",
      "Epoch 968/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0162 - accuracy: 0.9947 - val_loss: 2.2988 - val_accuracy: 0.7726\n",
      "Epoch 969/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 1s 15ms/step - loss: 0.0100 - accuracy: 0.9960 - val_loss: 2.3275 - val_accuracy: 0.7695\n",
      "Epoch 970/1500\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.0052 - accuracy: 0.9987 - val_loss: 2.3249 - val_accuracy: 0.7741\n",
      "Epoch 971/1500\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.0219 - accuracy: 0.9953 - val_loss: 2.3283 - val_accuracy: 0.7710\n",
      "Epoch 972/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0075 - accuracy: 0.9967 - val_loss: 2.5450 - val_accuracy: 0.7913\n",
      "Epoch 973/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0157 - accuracy: 0.9947 - val_loss: 2.4740 - val_accuracy: 0.7788\n",
      "Epoch 974/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0030 - accuracy: 0.9980 - val_loss: 2.5017 - val_accuracy: 0.7866\n",
      "Epoch 975/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0112 - accuracy: 0.9960 - val_loss: 2.5658 - val_accuracy: 0.7679\n",
      "Epoch 976/1500\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 2.7067 - val_accuracy: 0.7632\n",
      "Epoch 977/1500\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.0109 - accuracy: 0.9953 - val_loss: 2.5235 - val_accuracy: 0.7804\n",
      "Epoch 978/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0113 - accuracy: 0.9967 - val_loss: 2.5066 - val_accuracy: 0.7726\n",
      "Epoch 979/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0148 - accuracy: 0.9940 - val_loss: 2.5267 - val_accuracy: 0.7788\n",
      "Epoch 980/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0050 - accuracy: 0.9980 - val_loss: 2.5347 - val_accuracy: 0.7586\n",
      "Epoch 981/1500\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.0164 - accuracy: 0.9967 - val_loss: 2.4954 - val_accuracy: 0.7695\n",
      "Epoch 982/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0056 - accuracy: 0.9987 - val_loss: 2.5157 - val_accuracy: 0.7788\n",
      "Epoch 983/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0097 - accuracy: 0.9980 - val_loss: 2.4869 - val_accuracy: 0.7741\n",
      "Epoch 984/1500\n",
      "38/38 [==============================] - 0s 13ms/step - loss: 0.0062 - accuracy: 0.9973 - val_loss: 2.5202 - val_accuracy: 0.7819\n",
      "Epoch 985/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0159 - accuracy: 0.9973 - val_loss: 2.5835 - val_accuracy: 0.7991\n",
      "Epoch 986/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0167 - accuracy: 0.9947 - val_loss: 2.5507 - val_accuracy: 0.7757\n",
      "Epoch 987/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0062 - accuracy: 0.9980 - val_loss: 2.6320 - val_accuracy: 0.7788\n",
      "Epoch 988/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0153 - accuracy: 0.9940 - val_loss: 2.5827 - val_accuracy: 0.7804\n",
      "Epoch 989/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0157 - accuracy: 0.9967 - val_loss: 2.5581 - val_accuracy: 0.7788\n",
      "Epoch 990/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0059 - accuracy: 0.9973 - val_loss: 2.5232 - val_accuracy: 0.7773\n",
      "Epoch 991/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0061 - accuracy: 0.9967 - val_loss: 2.4732 - val_accuracy: 0.7648\n",
      "Epoch 992/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0085 - accuracy: 0.9960 - val_loss: 2.6079 - val_accuracy: 0.7835\n",
      "Epoch 993/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0186 - accuracy: 0.9953 - val_loss: 2.4905 - val_accuracy: 0.7726\n",
      "Epoch 994/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0077 - accuracy: 0.9967 - val_loss: 2.5503 - val_accuracy: 0.7741\n",
      "Epoch 995/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0128 - accuracy: 0.9960 - val_loss: 2.6493 - val_accuracy: 0.7835\n",
      "Epoch 996/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0132 - accuracy: 0.9980 - val_loss: 2.6630 - val_accuracy: 0.7726\n",
      "Epoch 997/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0178 - accuracy: 0.9940 - val_loss: 2.5658 - val_accuracy: 0.7648\n",
      "Epoch 998/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0105 - accuracy: 0.9967 - val_loss: 2.6279 - val_accuracy: 0.7555\n",
      "Epoch 999/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0286 - accuracy: 0.9933 - val_loss: 2.7009 - val_accuracy: 0.7617\n",
      "Epoch 1000/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0278 - accuracy: 0.9960 - val_loss: 2.5837 - val_accuracy: 0.7508\n",
      "Epoch 1001/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0243 - accuracy: 0.9940 - val_loss: 2.6260 - val_accuracy: 0.7788\n",
      "Epoch 1002/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0132 - accuracy: 0.9967 - val_loss: 2.5962 - val_accuracy: 0.7632\n",
      "Epoch 1003/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0268 - accuracy: 0.9953 - val_loss: 2.7256 - val_accuracy: 0.7835\n",
      "Epoch 1004/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0209 - accuracy: 0.9960 - val_loss: 2.5447 - val_accuracy: 0.7726\n",
      "Epoch 1005/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0064 - accuracy: 0.9980 - val_loss: 2.6137 - val_accuracy: 0.7788\n",
      "Epoch 1006/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0167 - accuracy: 0.9953 - val_loss: 2.5159 - val_accuracy: 0.7726\n",
      "Epoch 1007/1500\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.0123 - accuracy: 0.9967 - val_loss: 2.6125 - val_accuracy: 0.7757\n",
      "Epoch 1008/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0191 - accuracy: 0.9953 - val_loss: 2.4915 - val_accuracy: 0.7726\n",
      "Epoch 1009/1500\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.0147 - accuracy: 0.9933 - val_loss: 2.5344 - val_accuracy: 0.7788\n",
      "Epoch 1010/1500\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.0120 - accuracy: 0.9960 - val_loss: 2.5480 - val_accuracy: 0.7819\n",
      "Epoch 1011/1500\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.0125 - accuracy: 0.9953 - val_loss: 2.6224 - val_accuracy: 0.7788\n",
      "Epoch 1012/1500\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.0103 - accuracy: 0.9960 - val_loss: 2.6071 - val_accuracy: 0.7804\n",
      "Epoch 1013/1500\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.0083 - accuracy: 0.9973 - val_loss: 2.4491 - val_accuracy: 0.7850\n",
      "Epoch 1014/1500\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.0057 - accuracy: 0.9987 - val_loss: 2.4697 - val_accuracy: 0.7835\n",
      "Epoch 1015/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0067 - accuracy: 0.9973 - val_loss: 2.4838 - val_accuracy: 0.7788\n",
      "Epoch 1016/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0032 - accuracy: 0.9993 - val_loss: 2.4660 - val_accuracy: 0.7726\n",
      "Epoch 1017/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0033 - accuracy: 0.9987 - val_loss: 2.4862 - val_accuracy: 0.7679\n",
      "Epoch 1018/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0071 - accuracy: 0.9980 - val_loss: 2.4680 - val_accuracy: 0.7679\n",
      "Epoch 1019/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0168 - accuracy: 0.9960 - val_loss: 2.4723 - val_accuracy: 0.7726\n",
      "Epoch 1020/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0158 - accuracy: 0.9940 - val_loss: 2.3413 - val_accuracy: 0.7586\n",
      "Epoch 1021/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0105 - accuracy: 0.9947 - val_loss: 2.4013 - val_accuracy: 0.7710\n",
      "Epoch 1022/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0123 - accuracy: 0.9967 - val_loss: 2.4051 - val_accuracy: 0.7617\n",
      "Epoch 1023/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0102 - accuracy: 0.9967 - val_loss: 2.3512 - val_accuracy: 0.7773\n",
      "Epoch 1024/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0130 - accuracy: 0.9967 - val_loss: 2.4112 - val_accuracy: 0.7757\n",
      "Epoch 1025/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0048 - accuracy: 0.9980 - val_loss: 2.3729 - val_accuracy: 0.7741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1026/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 2.4273 - val_accuracy: 0.7788\n",
      "Epoch 1027/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0094 - accuracy: 0.9967 - val_loss: 2.5422 - val_accuracy: 0.7866\n",
      "Epoch 1028/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0244 - accuracy: 0.9947 - val_loss: 2.2308 - val_accuracy: 0.7757\n",
      "Epoch 1029/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0074 - accuracy: 0.9973 - val_loss: 2.3407 - val_accuracy: 0.7850\n",
      "Epoch 1030/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0054 - accuracy: 0.9980 - val_loss: 2.3726 - val_accuracy: 0.7788\n",
      "Epoch 1031/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0157 - accuracy: 0.9960 - val_loss: 2.4193 - val_accuracy: 0.7664\n",
      "Epoch 1032/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0252 - accuracy: 0.9926 - val_loss: 2.5780 - val_accuracy: 0.7757\n",
      "Epoch 1033/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0164 - accuracy: 0.9940 - val_loss: 2.4798 - val_accuracy: 0.7710\n",
      "Epoch 1034/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0134 - accuracy: 0.9967 - val_loss: 2.6367 - val_accuracy: 0.7710\n",
      "Epoch 1035/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0138 - accuracy: 0.9933 - val_loss: 2.5387 - val_accuracy: 0.7726\n",
      "Epoch 1036/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0119 - accuracy: 0.9973 - val_loss: 2.5425 - val_accuracy: 0.7866\n",
      "Epoch 1037/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0049 - accuracy: 0.9987 - val_loss: 2.4519 - val_accuracy: 0.7586\n",
      "Epoch 1038/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0095 - accuracy: 0.9980 - val_loss: 2.6608 - val_accuracy: 0.7788\n",
      "Epoch 1039/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0120 - accuracy: 0.9973 - val_loss: 2.4889 - val_accuracy: 0.7648\n",
      "Epoch 1040/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.5318 - val_accuracy: 0.7757\n",
      "Epoch 1041/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0107 - accuracy: 0.9967 - val_loss: 2.5150 - val_accuracy: 0.7757\n",
      "Epoch 1042/1500\n",
      "38/38 [==============================] - 0s 13ms/step - loss: 0.0069 - accuracy: 0.9980 - val_loss: 2.5430 - val_accuracy: 0.7617\n",
      "Epoch 1043/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0161 - accuracy: 0.9953 - val_loss: 2.6399 - val_accuracy: 0.7804\n",
      "Epoch 1044/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0148 - accuracy: 0.9953 - val_loss: 2.5395 - val_accuracy: 0.7648\n",
      "Epoch 1045/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0255 - accuracy: 0.9926 - val_loss: 2.6454 - val_accuracy: 0.7835\n",
      "Epoch 1046/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0077 - accuracy: 0.9973 - val_loss: 2.6308 - val_accuracy: 0.7757\n",
      "Epoch 1047/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0063 - accuracy: 0.9973 - val_loss: 2.5725 - val_accuracy: 0.7773\n",
      "Epoch 1048/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 2.5996 - val_accuracy: 0.7679\n",
      "Epoch 1049/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0086 - accuracy: 0.9980 - val_loss: 2.5662 - val_accuracy: 0.7741\n",
      "Epoch 1050/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0241 - accuracy: 0.9953 - val_loss: 2.5721 - val_accuracy: 0.7570\n",
      "Epoch 1051/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0093 - accuracy: 0.9967 - val_loss: 2.5174 - val_accuracy: 0.7819\n",
      "Epoch 1052/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0079 - accuracy: 0.9980 - val_loss: 2.4767 - val_accuracy: 0.7664\n",
      "Epoch 1053/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0041 - accuracy: 0.9980 - val_loss: 2.6330 - val_accuracy: 0.7819\n",
      "Epoch 1054/1500\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.0208 - accuracy: 0.9947 - val_loss: 2.6345 - val_accuracy: 0.7664\n",
      "Epoch 1055/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0106 - accuracy: 0.9967 - val_loss: 2.5292 - val_accuracy: 0.7664\n",
      "Epoch 1056/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0054 - accuracy: 0.9973 - val_loss: 2.6589 - val_accuracy: 0.7757\n",
      "Epoch 1057/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0251 - accuracy: 0.9947 - val_loss: 2.6747 - val_accuracy: 0.7757\n",
      "Epoch 1058/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0121 - accuracy: 0.9960 - val_loss: 2.6624 - val_accuracy: 0.7773\n",
      "Epoch 1059/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0111 - accuracy: 0.9967 - val_loss: 2.4827 - val_accuracy: 0.7804\n",
      "Epoch 1060/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0058 - accuracy: 0.9973 - val_loss: 2.5174 - val_accuracy: 0.7819\n",
      "Epoch 1061/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0446 - accuracy: 0.9913 - val_loss: 2.5448 - val_accuracy: 0.7570\n",
      "Epoch 1062/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0262 - accuracy: 0.9913 - val_loss: 2.6244 - val_accuracy: 0.7726\n",
      "Epoch 1063/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0193 - accuracy: 0.9940 - val_loss: 2.6162 - val_accuracy: 0.7819\n",
      "Epoch 1064/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0188 - accuracy: 0.9953 - val_loss: 2.6561 - val_accuracy: 0.7835\n",
      "Epoch 1065/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0093 - accuracy: 0.9973 - val_loss: 2.7120 - val_accuracy: 0.7804\n",
      "Epoch 1066/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0156 - accuracy: 0.9960 - val_loss: 2.3898 - val_accuracy: 0.7695\n",
      "Epoch 1067/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0220 - accuracy: 0.9953 - val_loss: 2.5971 - val_accuracy: 0.7928\n",
      "Epoch 1068/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0344 - accuracy: 0.9940 - val_loss: 2.3474 - val_accuracy: 0.7586\n",
      "Epoch 1069/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0153 - accuracy: 0.9947 - val_loss: 2.3853 - val_accuracy: 0.7866\n",
      "Epoch 1070/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0053 - accuracy: 0.9987 - val_loss: 2.5354 - val_accuracy: 0.7897\n",
      "Epoch 1071/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0152 - accuracy: 0.9973 - val_loss: 2.5357 - val_accuracy: 0.7850\n",
      "Epoch 1072/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0128 - accuracy: 0.9973 - val_loss: 2.5075 - val_accuracy: 0.7913\n",
      "Epoch 1073/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0063 - accuracy: 0.9987 - val_loss: 2.5342 - val_accuracy: 0.7882\n",
      "Epoch 1074/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0118 - accuracy: 0.9953 - val_loss: 2.4386 - val_accuracy: 0.7757\n",
      "Epoch 1075/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0060 - accuracy: 0.9980 - val_loss: 2.4904 - val_accuracy: 0.7850\n",
      "Epoch 1076/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0059 - accuracy: 0.9973 - val_loss: 2.5959 - val_accuracy: 0.7866\n",
      "Epoch 1077/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0060 - accuracy: 0.9980 - val_loss: 2.5389 - val_accuracy: 0.7804\n",
      "Epoch 1078/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0142 - accuracy: 0.9953 - val_loss: 2.5095 - val_accuracy: 0.7741\n",
      "Epoch 1079/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0103 - accuracy: 0.9960 - val_loss: 2.5621 - val_accuracy: 0.7757\n",
      "Epoch 1080/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0054 - accuracy: 0.9993 - val_loss: 2.5890 - val_accuracy: 0.7695\n",
      "Epoch 1081/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0032 - accuracy: 0.9993 - val_loss: 2.5573 - val_accuracy: 0.7757\n",
      "Epoch 1082/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0037 - accuracy: 0.9980 - val_loss: 2.6491 - val_accuracy: 0.7835\n",
      "Epoch 1083/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0055 - accuracy: 0.9980 - val_loss: 2.5268 - val_accuracy: 0.7866\n",
      "Epoch 1084/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0057 - accuracy: 0.9973 - val_loss: 2.5883 - val_accuracy: 0.7788\n",
      "Epoch 1085/1500\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.0071 - accuracy: 0.9973 - val_loss: 2.5681 - val_accuracy: 0.7882\n",
      "Epoch 1086/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0043 - accuracy: 0.9980 - val_loss: 2.4942 - val_accuracy: 0.7773\n",
      "Epoch 1087/1500\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 2.6736 - val_accuracy: 0.7928\n",
      "Epoch 1088/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0037 - accuracy: 0.9993 - val_loss: 2.6701 - val_accuracy: 0.7850\n",
      "Epoch 1089/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0072 - accuracy: 0.9980 - val_loss: 2.6888 - val_accuracy: 0.7897\n",
      "Epoch 1090/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0040 - accuracy: 0.9993 - val_loss: 2.7069 - val_accuracy: 0.7913\n",
      "Epoch 1091/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0070 - accuracy: 0.9980 - val_loss: 2.6675 - val_accuracy: 0.7835\n",
      "Epoch 1092/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 2.6693 - val_accuracy: 0.7773\n",
      "Epoch 1093/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0116 - accuracy: 0.9967 - val_loss: 2.6880 - val_accuracy: 0.7741\n",
      "Epoch 1094/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0069 - accuracy: 0.9973 - val_loss: 2.7083 - val_accuracy: 0.7788\n",
      "Epoch 1095/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0102 - accuracy: 0.9960 - val_loss: 2.8004 - val_accuracy: 0.7944\n",
      "Epoch 1096/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0122 - accuracy: 0.9967 - val_loss: 2.8348 - val_accuracy: 0.7710\n",
      "Epoch 1097/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0139 - accuracy: 0.9960 - val_loss: 2.7498 - val_accuracy: 0.7710\n",
      "Epoch 1098/1500\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.0102 - accuracy: 0.9973 - val_loss: 2.6746 - val_accuracy: 0.7944\n",
      "Epoch 1099/1500\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.0055 - accuracy: 0.9967 - val_loss: 2.7034 - val_accuracy: 0.7819\n",
      "Epoch 1100/1500\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.0064 - accuracy: 0.9980 - val_loss: 2.6918 - val_accuracy: 0.7773\n",
      "Epoch 1101/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0180 - accuracy: 0.9953 - val_loss: 2.6095 - val_accuracy: 0.7882\n",
      "Epoch 1102/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0066 - accuracy: 0.9967 - val_loss: 2.6486 - val_accuracy: 0.7741\n",
      "Epoch 1103/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0066 - accuracy: 0.9980 - val_loss: 2.7394 - val_accuracy: 0.7835\n",
      "Epoch 1104/1500\n",
      "38/38 [==============================] - 1s 13ms/step - loss: 0.0109 - accuracy: 0.9960 - val_loss: 2.6635 - val_accuracy: 0.7664\n",
      "Epoch 1105/1500\n",
      "38/38 [==============================] - 0s 13ms/step - loss: 0.0057 - accuracy: 0.9993 - val_loss: 2.6067 - val_accuracy: 0.7664\n",
      "Epoch 1106/1500\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.0052 - accuracy: 0.9980 - val_loss: 2.7370 - val_accuracy: 0.7788\n",
      "Epoch 1107/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0071 - accuracy: 0.9980 - val_loss: 2.7555 - val_accuracy: 0.7819\n",
      "Epoch 1108/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0156 - accuracy: 0.9953 - val_loss: 2.8911 - val_accuracy: 0.7788\n",
      "Epoch 1109/1500\n",
      "38/38 [==============================] - 1s 13ms/step - loss: 0.0061 - accuracy: 0.9973 - val_loss: 2.7824 - val_accuracy: 0.7773\n",
      "Epoch 1110/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0083 - accuracy: 0.9980 - val_loss: 2.8159 - val_accuracy: 0.7804\n",
      "Epoch 1111/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.8338 - val_accuracy: 0.7835\n",
      "Epoch 1112/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0051 - accuracy: 0.9980 - val_loss: 2.8155 - val_accuracy: 0.7835\n",
      "Epoch 1113/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0104 - accuracy: 0.9953 - val_loss: 2.7895 - val_accuracy: 0.7819\n",
      "Epoch 1114/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0132 - accuracy: 0.9960 - val_loss: 2.7290 - val_accuracy: 0.7913\n",
      "Epoch 1115/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0038 - accuracy: 0.9987 - val_loss: 2.8285 - val_accuracy: 0.7960\n",
      "Epoch 1116/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0098 - accuracy: 0.9967 - val_loss: 2.8097 - val_accuracy: 0.7866\n",
      "Epoch 1117/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0062 - accuracy: 0.9980 - val_loss: 2.8992 - val_accuracy: 0.7928\n",
      "Epoch 1118/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0034 - accuracy: 0.9993 - val_loss: 2.7798 - val_accuracy: 0.7850\n",
      "Epoch 1119/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0086 - accuracy: 0.9980 - val_loss: 2.7113 - val_accuracy: 0.7773\n",
      "Epoch 1120/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0130 - accuracy: 0.9960 - val_loss: 2.7311 - val_accuracy: 0.7555\n",
      "Epoch 1121/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0053 - accuracy: 0.9993 - val_loss: 2.8845 - val_accuracy: 0.7757\n",
      "Epoch 1122/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0120 - accuracy: 0.9980 - val_loss: 2.9085 - val_accuracy: 0.7741\n",
      "Epoch 1123/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0205 - accuracy: 0.9940 - val_loss: 2.8609 - val_accuracy: 0.7850\n",
      "Epoch 1124/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0251 - accuracy: 0.9960 - val_loss: 3.1217 - val_accuracy: 0.7866\n",
      "Epoch 1125/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0193 - accuracy: 0.9973 - val_loss: 3.0667 - val_accuracy: 0.7991\n",
      "Epoch 1126/1500\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.0195 - accuracy: 0.9940 - val_loss: 2.8574 - val_accuracy: 0.7664\n",
      "Epoch 1127/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0114 - accuracy: 0.9973 - val_loss: 3.0101 - val_accuracy: 0.7726\n",
      "Epoch 1128/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0257 - accuracy: 0.9926 - val_loss: 3.1216 - val_accuracy: 0.7757\n",
      "Epoch 1129/1500\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.0192 - accuracy: 0.9953 - val_loss: 2.8174 - val_accuracy: 0.7632\n",
      "Epoch 1130/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0356 - accuracy: 0.9953 - val_loss: 2.5646 - val_accuracy: 0.7695\n",
      "Epoch 1131/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0053 - accuracy: 0.9980 - val_loss: 2.7070 - val_accuracy: 0.7819\n",
      "Epoch 1132/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0071 - accuracy: 0.9980 - val_loss: 2.6892 - val_accuracy: 0.7726\n",
      "Epoch 1133/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0173 - accuracy: 0.9960 - val_loss: 2.6075 - val_accuracy: 0.7773\n",
      "Epoch 1134/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0044 - accuracy: 0.9980 - val_loss: 2.7209 - val_accuracy: 0.7944\n",
      "Epoch 1135/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0079 - accuracy: 0.9973 - val_loss: 2.6208 - val_accuracy: 0.7819\n",
      "Epoch 1136/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0208 - accuracy: 0.9947 - val_loss: 2.5661 - val_accuracy: 0.7648\n",
      "Epoch 1137/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0059 - accuracy: 0.9980 - val_loss: 2.6530 - val_accuracy: 0.7726\n",
      "Epoch 1138/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0090 - accuracy: 0.9980 - val_loss: 2.8222 - val_accuracy: 0.7866\n",
      "Epoch 1139/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0180 - accuracy: 0.9960 - val_loss: 2.7708 - val_accuracy: 0.7788\n",
      "Epoch 1140/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0183 - accuracy: 0.9933 - val_loss: 2.7877 - val_accuracy: 0.7835\n",
      "Epoch 1141/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0168 - accuracy: 0.9940 - val_loss: 2.8576 - val_accuracy: 0.7679\n",
      "Epoch 1142/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0140 - accuracy: 0.9947 - val_loss: 2.8380 - val_accuracy: 0.7726\n",
      "Epoch 1143/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0122 - accuracy: 0.9967 - val_loss: 2.9010 - val_accuracy: 0.7850\n",
      "Epoch 1144/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0094 - accuracy: 0.9960 - val_loss: 2.7216 - val_accuracy: 0.7788\n",
      "Epoch 1145/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0184 - accuracy: 0.9947 - val_loss: 2.9313 - val_accuracy: 0.7866\n",
      "Epoch 1146/1500\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.0061 - accuracy: 0.9973 - val_loss: 2.9222 - val_accuracy: 0.7819\n",
      "Epoch 1147/1500\n",
      "38/38 [==============================] - 1s 13ms/step - loss: 0.0191 - accuracy: 0.9953 - val_loss: 2.8872 - val_accuracy: 0.7773\n",
      "Epoch 1148/1500\n",
      "38/38 [==============================] - 1s 13ms/step - loss: 0.0077 - accuracy: 0.9973 - val_loss: 2.9040 - val_accuracy: 0.7819\n",
      "Epoch 1149/1500\n",
      "38/38 [==============================] - 1s 13ms/step - loss: 0.0089 - accuracy: 0.9960 - val_loss: 2.9079 - val_accuracy: 0.7632\n",
      "Epoch 1150/1500\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.0164 - accuracy: 0.9953 - val_loss: 2.8135 - val_accuracy: 0.7710\n",
      "Epoch 1151/1500\n",
      "38/38 [==============================] - 1s 13ms/step - loss: 0.0109 - accuracy: 0.9980 - val_loss: 2.8218 - val_accuracy: 0.7773\n",
      "Epoch 1152/1500\n",
      "38/38 [==============================] - 0s 13ms/step - loss: 0.0129 - accuracy: 0.9973 - val_loss: 2.9340 - val_accuracy: 0.7773\n",
      "Epoch 1153/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0047 - accuracy: 0.9987 - val_loss: 2.8827 - val_accuracy: 0.7819\n",
      "Epoch 1154/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0124 - accuracy: 0.9953 - val_loss: 2.7625 - val_accuracy: 0.7788\n",
      "Epoch 1155/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0075 - accuracy: 0.9980 - val_loss: 2.7108 - val_accuracy: 0.7632\n",
      "Epoch 1156/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0030 - accuracy: 0.9987 - val_loss: 2.7102 - val_accuracy: 0.7632\n",
      "Epoch 1157/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0156 - accuracy: 0.9940 - val_loss: 2.6810 - val_accuracy: 0.7601\n",
      "Epoch 1158/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0115 - accuracy: 0.9973 - val_loss: 2.7760 - val_accuracy: 0.7882\n",
      "Epoch 1159/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0201 - accuracy: 0.9967 - val_loss: 2.7080 - val_accuracy: 0.7788\n",
      "Epoch 1160/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0035 - accuracy: 0.9993 - val_loss: 2.7588 - val_accuracy: 0.7819\n",
      "Epoch 1161/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0065 - accuracy: 0.9987 - val_loss: 2.7674 - val_accuracy: 0.7773\n",
      "Epoch 1162/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0048 - accuracy: 0.9973 - val_loss: 2.7327 - val_accuracy: 0.7850\n",
      "Epoch 1163/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0041 - accuracy: 0.9973 - val_loss: 2.8395 - val_accuracy: 0.7897\n",
      "Epoch 1164/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0063 - accuracy: 0.9980 - val_loss: 2.7823 - val_accuracy: 0.7804\n",
      "Epoch 1165/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0114 - accuracy: 0.9967 - val_loss: 2.7701 - val_accuracy: 0.7804\n",
      "Epoch 1166/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 2.7993 - val_accuracy: 0.7773\n",
      "Epoch 1167/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0062 - accuracy: 0.9967 - val_loss: 2.8320 - val_accuracy: 0.7835\n",
      "Epoch 1168/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0057 - accuracy: 0.9980 - val_loss: 2.7918 - val_accuracy: 0.7819\n",
      "Epoch 1169/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0075 - accuracy: 0.9967 - val_loss: 2.7549 - val_accuracy: 0.7679\n",
      "Epoch 1170/1500\n",
      "38/38 [==============================] - 1s 13ms/step - loss: 0.0152 - accuracy: 0.9947 - val_loss: 2.9183 - val_accuracy: 0.7928\n",
      "Epoch 1171/1500\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.0145 - accuracy: 0.9953 - val_loss: 2.6480 - val_accuracy: 0.7788\n",
      "Epoch 1172/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0094 - accuracy: 0.9960 - val_loss: 2.8420 - val_accuracy: 0.7882\n",
      "Epoch 1173/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0158 - accuracy: 0.9960 - val_loss: 2.8508 - val_accuracy: 0.7850\n",
      "Epoch 1174/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0344 - accuracy: 0.9933 - val_loss: 2.7205 - val_accuracy: 0.7773\n",
      "Epoch 1175/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0474 - accuracy: 0.9880 - val_loss: 2.6253 - val_accuracy: 0.7835\n",
      "Epoch 1176/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0276 - accuracy: 0.9926 - val_loss: 2.5343 - val_accuracy: 0.7726\n",
      "Epoch 1177/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0354 - accuracy: 0.9920 - val_loss: 2.5812 - val_accuracy: 0.7773\n",
      "Epoch 1178/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0196 - accuracy: 0.9947 - val_loss: 2.7078 - val_accuracy: 0.7632\n",
      "Epoch 1179/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0243 - accuracy: 0.9920 - val_loss: 2.7505 - val_accuracy: 0.7788\n",
      "Epoch 1180/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0131 - accuracy: 0.9960 - val_loss: 2.6029 - val_accuracy: 0.7757\n",
      "Epoch 1181/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0119 - accuracy: 0.9967 - val_loss: 2.7080 - val_accuracy: 0.7664\n",
      "Epoch 1182/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0095 - accuracy: 0.9987 - val_loss: 2.7789 - val_accuracy: 0.7819\n",
      "Epoch 1183/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0077 - accuracy: 0.9973 - val_loss: 2.7109 - val_accuracy: 0.7944\n",
      "Epoch 1184/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0115 - accuracy: 0.9973 - val_loss: 2.8264 - val_accuracy: 0.7928\n",
      "Epoch 1185/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0046 - accuracy: 0.9967 - val_loss: 2.7791 - val_accuracy: 0.7773\n",
      "Epoch 1186/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 2.7527 - val_accuracy: 0.7679\n",
      "Epoch 1187/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0093 - accuracy: 0.9960 - val_loss: 2.8777 - val_accuracy: 0.7726\n",
      "Epoch 1188/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0050 - accuracy: 0.9980 - val_loss: 2.8972 - val_accuracy: 0.7804\n",
      "Epoch 1189/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0152 - accuracy: 0.9967 - val_loss: 2.7815 - val_accuracy: 0.7648\n",
      "Epoch 1190/1500\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.0158 - accuracy: 0.9960 - val_loss: 2.8472 - val_accuracy: 0.7944\n",
      "Epoch 1191/1500\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.0050 - accuracy: 0.9987 - val_loss: 2.7762 - val_accuracy: 0.7788\n",
      "Epoch 1192/1500\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.0102 - accuracy: 0.9967 - val_loss: 2.8226 - val_accuracy: 0.7835\n",
      "Epoch 1193/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 2.7962 - val_accuracy: 0.7897\n",
      "Epoch 1194/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0066 - accuracy: 0.9980 - val_loss: 2.8268 - val_accuracy: 0.7773\n",
      "Epoch 1195/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0213 - accuracy: 0.9953 - val_loss: 2.6577 - val_accuracy: 0.7679\n",
      "Epoch 1196/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0184 - accuracy: 0.9947 - val_loss: 2.5985 - val_accuracy: 0.7788\n",
      "Epoch 1197/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0073 - accuracy: 0.9980 - val_loss: 2.8049 - val_accuracy: 0.7866\n",
      "Epoch 1198/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0183 - accuracy: 0.9967 - val_loss: 2.7400 - val_accuracy: 0.7866\n",
      "Epoch 1199/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 2.7740 - val_accuracy: 0.7819\n",
      "Epoch 1200/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0085 - accuracy: 0.9987 - val_loss: 2.6991 - val_accuracy: 0.7757\n",
      "Epoch 1201/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0083 - accuracy: 0.9973 - val_loss: 2.6729 - val_accuracy: 0.7804\n",
      "Epoch 1202/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0192 - accuracy: 0.9940 - val_loss: 2.5058 - val_accuracy: 0.7710\n",
      "Epoch 1203/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0111 - accuracy: 0.9933 - val_loss: 2.5317 - val_accuracy: 0.7617\n",
      "Epoch 1204/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0093 - accuracy: 0.9967 - val_loss: 2.5648 - val_accuracy: 0.7882\n",
      "Epoch 1205/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0106 - accuracy: 0.9967 - val_loss: 2.5643 - val_accuracy: 0.7648\n",
      "Epoch 1206/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0068 - accuracy: 0.9973 - val_loss: 2.6780 - val_accuracy: 0.7757\n",
      "Epoch 1207/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0057 - accuracy: 0.9980 - val_loss: 2.6407 - val_accuracy: 0.7726\n",
      "Epoch 1208/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0124 - accuracy: 0.9960 - val_loss: 2.6691 - val_accuracy: 0.7882\n",
      "Epoch 1209/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0096 - accuracy: 0.9967 - val_loss: 2.7121 - val_accuracy: 0.7819\n",
      "Epoch 1210/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0071 - accuracy: 0.9993 - val_loss: 2.8425 - val_accuracy: 0.7866\n",
      "Epoch 1211/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 2.8401 - val_accuracy: 0.7819\n",
      "Epoch 1212/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0149 - accuracy: 0.9953 - val_loss: 2.8497 - val_accuracy: 0.7882\n",
      "Epoch 1213/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0068 - accuracy: 0.9973 - val_loss: 2.7869 - val_accuracy: 0.7710\n",
      "Epoch 1214/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0071 - accuracy: 0.9973 - val_loss: 2.7332 - val_accuracy: 0.7632\n",
      "Epoch 1215/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0075 - accuracy: 0.9980 - val_loss: 2.8004 - val_accuracy: 0.7726\n",
      "Epoch 1216/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0024 - accuracy: 0.9987 - val_loss: 2.8418 - val_accuracy: 0.7726\n",
      "Epoch 1217/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0068 - accuracy: 0.9987 - val_loss: 2.7762 - val_accuracy: 0.7788\n",
      "Epoch 1218/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0046 - accuracy: 0.9980 - val_loss: 2.7519 - val_accuracy: 0.7741\n",
      "Epoch 1219/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0044 - accuracy: 0.9980 - val_loss: 2.7139 - val_accuracy: 0.7726\n",
      "Epoch 1220/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0036 - accuracy: 0.9987 - val_loss: 2.6674 - val_accuracy: 0.7850\n",
      "Epoch 1221/1500\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 2.7423 - val_accuracy: 0.7928\n",
      "Epoch 1222/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 2.7355 - val_accuracy: 0.7788\n",
      "Epoch 1223/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 2.7636 - val_accuracy: 0.7835\n",
      "Epoch 1224/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0016 - accuracy: 0.9987 - val_loss: 2.8027 - val_accuracy: 0.7866\n",
      "Epoch 1225/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0059 - accuracy: 0.9973 - val_loss: 2.8537 - val_accuracy: 0.7975\n",
      "Epoch 1226/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0063 - accuracy: 0.9967 - val_loss: 2.8540 - val_accuracy: 0.7850\n",
      "Epoch 1227/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0193 - accuracy: 0.9933 - val_loss: 2.6923 - val_accuracy: 0.7835\n",
      "Epoch 1228/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 2.7402 - val_accuracy: 0.7804\n",
      "Epoch 1229/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0148 - accuracy: 0.9947 - val_loss: 2.7763 - val_accuracy: 0.7679\n",
      "Epoch 1230/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0130 - accuracy: 0.9960 - val_loss: 3.2159 - val_accuracy: 0.7928\n",
      "Epoch 1231/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0097 - accuracy: 0.9960 - val_loss: 2.8991 - val_accuracy: 0.7773\n",
      "Epoch 1232/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0195 - accuracy: 0.9947 - val_loss: 2.9565 - val_accuracy: 0.7819\n",
      "Epoch 1233/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0173 - accuracy: 0.9967 - val_loss: 2.7434 - val_accuracy: 0.7695\n",
      "Epoch 1234/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0120 - accuracy: 0.9967 - val_loss: 2.8438 - val_accuracy: 0.7804\n",
      "Epoch 1235/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0215 - accuracy: 0.9967 - val_loss: 2.7638 - val_accuracy: 0.7757\n",
      "Epoch 1236/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0178 - accuracy: 0.9947 - val_loss: 2.7860 - val_accuracy: 0.7804\n",
      "Epoch 1237/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0161 - accuracy: 0.9940 - val_loss: 2.9649 - val_accuracy: 0.7726\n",
      "Epoch 1238/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0089 - accuracy: 0.9960 - val_loss: 2.9482 - val_accuracy: 0.7773\n",
      "Epoch 1239/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0053 - accuracy: 0.9980 - val_loss: 2.7455 - val_accuracy: 0.7695\n",
      "Epoch 1240/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0062 - accuracy: 0.9980 - val_loss: 2.6799 - val_accuracy: 0.7741\n",
      "Epoch 1241/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0057 - accuracy: 0.9980 - val_loss: 2.7375 - val_accuracy: 0.7586\n",
      "Epoch 1242/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0322 - accuracy: 0.9953 - val_loss: 2.6003 - val_accuracy: 0.7897\n",
      "Epoch 1243/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0202 - accuracy: 0.9940 - val_loss: 2.6007 - val_accuracy: 0.7726\n",
      "Epoch 1244/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0235 - accuracy: 0.9947 - val_loss: 2.6564 - val_accuracy: 0.7710\n",
      "Epoch 1245/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0097 - accuracy: 0.9980 - val_loss: 2.6352 - val_accuracy: 0.7819\n",
      "Epoch 1246/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0100 - accuracy: 0.9960 - val_loss: 2.7599 - val_accuracy: 0.7913\n",
      "Epoch 1247/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0096 - accuracy: 0.9973 - val_loss: 2.8380 - val_accuracy: 0.7975\n",
      "Epoch 1248/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0121 - accuracy: 0.9953 - val_loss: 2.5553 - val_accuracy: 0.7757\n",
      "Epoch 1249/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0121 - accuracy: 0.9973 - val_loss: 2.5607 - val_accuracy: 0.7882\n",
      "Epoch 1250/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0135 - accuracy: 0.9933 - val_loss: 2.5780 - val_accuracy: 0.7819\n",
      "Epoch 1251/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0112 - accuracy: 0.9973 - val_loss: 2.6441 - val_accuracy: 0.7882\n",
      "Epoch 1252/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0047 - accuracy: 0.9980 - val_loss: 2.7128 - val_accuracy: 0.7866\n",
      "Epoch 1253/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0074 - accuracy: 0.9987 - val_loss: 2.7942 - val_accuracy: 0.7928\n",
      "Epoch 1254/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0068 - accuracy: 0.9973 - val_loss: 2.7261 - val_accuracy: 0.7960\n",
      "Epoch 1255/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0058 - accuracy: 0.9980 - val_loss: 2.6953 - val_accuracy: 0.7835\n",
      "Epoch 1256/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0043 - accuracy: 0.9993 - val_loss: 2.7219 - val_accuracy: 0.7897\n",
      "Epoch 1257/1500\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.0030 - accuracy: 0.9987 - val_loss: 2.7158 - val_accuracy: 0.7850\n",
      "Epoch 1258/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0068 - accuracy: 0.9967 - val_loss: 2.6299 - val_accuracy: 0.7741\n",
      "Epoch 1259/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0270 - accuracy: 0.9933 - val_loss: 2.6391 - val_accuracy: 0.7882\n",
      "Epoch 1260/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0131 - accuracy: 0.9947 - val_loss: 2.6252 - val_accuracy: 0.7913\n",
      "Epoch 1261/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0133 - accuracy: 0.9953 - val_loss: 2.7219 - val_accuracy: 0.7882\n",
      "Epoch 1262/1500\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.0090 - accuracy: 0.9953 - val_loss: 2.6611 - val_accuracy: 0.7866\n",
      "Epoch 1263/1500\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.0107 - accuracy: 0.9960 - val_loss: 2.7155 - val_accuracy: 0.7804\n",
      "Epoch 1264/1500\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.0074 - accuracy: 0.9980 - val_loss: 2.6349 - val_accuracy: 0.7928\n",
      "Epoch 1265/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0034 - accuracy: 0.9987 - val_loss: 2.7127 - val_accuracy: 0.7835\n",
      "Epoch 1266/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0033 - accuracy: 0.9987 - val_loss: 2.7481 - val_accuracy: 0.7866\n",
      "Epoch 1267/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0089 - accuracy: 0.9967 - val_loss: 2.6990 - val_accuracy: 0.7788\n",
      "Epoch 1268/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0048 - accuracy: 0.9973 - val_loss: 2.7721 - val_accuracy: 0.7850\n",
      "Epoch 1269/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0127 - accuracy: 0.9987 - val_loss: 2.6737 - val_accuracy: 0.7819\n",
      "Epoch 1270/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0041 - accuracy: 0.9993 - val_loss: 2.6677 - val_accuracy: 0.7882\n",
      "Epoch 1271/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0025 - accuracy: 0.9987 - val_loss: 2.8648 - val_accuracy: 0.7944\n",
      "Epoch 1272/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0016 - accuracy: 0.9993 - val_loss: 2.9430 - val_accuracy: 0.8022\n",
      "Epoch 1273/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0057 - accuracy: 0.9980 - val_loss: 2.9270 - val_accuracy: 0.7804\n",
      "Epoch 1274/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0095 - accuracy: 0.9967 - val_loss: 2.8267 - val_accuracy: 0.7850\n",
      "Epoch 1275/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0062 - accuracy: 0.9973 - val_loss: 2.7881 - val_accuracy: 0.7804\n",
      "Epoch 1276/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 2.8238 - val_accuracy: 0.7819\n",
      "Epoch 1277/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0053 - accuracy: 0.9980 - val_loss: 2.7446 - val_accuracy: 0.7710\n",
      "Epoch 1278/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0128 - accuracy: 0.9960 - val_loss: 2.8923 - val_accuracy: 0.7679\n",
      "Epoch 1279/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0079 - accuracy: 0.9967 - val_loss: 2.7902 - val_accuracy: 0.7741\n",
      "Epoch 1280/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0279 - accuracy: 0.9933 - val_loss: 2.6651 - val_accuracy: 0.7664\n",
      "Epoch 1281/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0106 - accuracy: 0.9947 - val_loss: 2.7836 - val_accuracy: 0.7835\n",
      "Epoch 1282/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0120 - accuracy: 0.9953 - val_loss: 2.6659 - val_accuracy: 0.7710\n",
      "Epoch 1283/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0206 - accuracy: 0.9967 - val_loss: 2.7065 - val_accuracy: 0.7773\n",
      "Epoch 1284/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0096 - accuracy: 0.9960 - val_loss: 2.6800 - val_accuracy: 0.7882\n",
      "Epoch 1285/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0045 - accuracy: 0.9980 - val_loss: 2.7719 - val_accuracy: 0.7928\n",
      "Epoch 1286/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0190 - accuracy: 0.9953 - val_loss: 2.6922 - val_accuracy: 0.7632\n",
      "Epoch 1287/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0122 - accuracy: 0.9960 - val_loss: 2.7309 - val_accuracy: 0.7773\n",
      "Epoch 1288/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0032 - accuracy: 0.9987 - val_loss: 2.7742 - val_accuracy: 0.7850\n",
      "Epoch 1289/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0192 - accuracy: 0.9947 - val_loss: 2.8014 - val_accuracy: 0.7960\n",
      "Epoch 1290/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0116 - accuracy: 0.9967 - val_loss: 2.8066 - val_accuracy: 0.7757\n",
      "Epoch 1291/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0122 - accuracy: 0.9960 - val_loss: 2.7549 - val_accuracy: 0.7773\n",
      "Epoch 1292/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0285 - accuracy: 0.9947 - val_loss: 2.7366 - val_accuracy: 0.7804\n",
      "Epoch 1293/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0158 - accuracy: 0.9940 - val_loss: 2.7074 - val_accuracy: 0.7804\n",
      "Epoch 1294/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0149 - accuracy: 0.9940 - val_loss: 2.6004 - val_accuracy: 0.7523\n",
      "Epoch 1295/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0088 - accuracy: 0.9967 - val_loss: 2.6673 - val_accuracy: 0.7773\n",
      "Epoch 1296/1500\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.0105 - accuracy: 0.9973 - val_loss: 2.6845 - val_accuracy: 0.7695\n",
      "Epoch 1297/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0122 - accuracy: 0.9953 - val_loss: 2.7191 - val_accuracy: 0.7850\n",
      "Epoch 1298/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0040 - accuracy: 0.9987 - val_loss: 2.7103 - val_accuracy: 0.7788\n",
      "Epoch 1299/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0115 - accuracy: 0.9953 - val_loss: 2.7858 - val_accuracy: 0.7710\n",
      "Epoch 1300/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0197 - accuracy: 0.9926 - val_loss: 2.7072 - val_accuracy: 0.7617\n",
      "Epoch 1301/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0236 - accuracy: 0.9967 - val_loss: 2.8716 - val_accuracy: 0.7664\n",
      "Epoch 1302/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0117 - accuracy: 0.9967 - val_loss: 2.8138 - val_accuracy: 0.7648\n",
      "Epoch 1303/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0126 - accuracy: 0.9960 - val_loss: 2.8630 - val_accuracy: 0.7632\n",
      "Epoch 1304/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0147 - accuracy: 0.9967 - val_loss: 2.7588 - val_accuracy: 0.7648\n",
      "Epoch 1305/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0090 - accuracy: 0.9967 - val_loss: 2.6325 - val_accuracy: 0.7523\n",
      "Epoch 1306/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0101 - accuracy: 0.9960 - val_loss: 2.6226 - val_accuracy: 0.7570\n",
      "Epoch 1307/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 2.6387 - val_accuracy: 0.7601\n",
      "Epoch 1308/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0057 - accuracy: 0.9980 - val_loss: 2.6325 - val_accuracy: 0.7570\n",
      "Epoch 1309/1500\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.0116 - accuracy: 0.9973 - val_loss: 2.7218 - val_accuracy: 0.7741\n",
      "Epoch 1310/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0088 - accuracy: 0.9953 - val_loss: 2.8348 - val_accuracy: 0.7819\n",
      "Epoch 1311/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.9059 - val_accuracy: 0.7835\n",
      "Epoch 1312/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0163 - accuracy: 0.9926 - val_loss: 2.7575 - val_accuracy: 0.7632\n",
      "Epoch 1313/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0057 - accuracy: 0.9973 - val_loss: 2.8677 - val_accuracy: 0.7741\n",
      "Epoch 1314/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0051 - accuracy: 0.9980 - val_loss: 2.9051 - val_accuracy: 0.7741\n",
      "Epoch 1315/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0129 - accuracy: 0.9953 - val_loss: 2.8675 - val_accuracy: 0.7726\n",
      "Epoch 1316/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0053 - accuracy: 0.9987 - val_loss: 2.9594 - val_accuracy: 0.7928\n",
      "Epoch 1317/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0035 - accuracy: 0.9987 - val_loss: 2.9997 - val_accuracy: 0.7804\n",
      "Epoch 1318/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0124 - accuracy: 0.9947 - val_loss: 2.8971 - val_accuracy: 0.7788\n",
      "Epoch 1319/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.0082 - val_accuracy: 0.7850\n",
      "Epoch 1320/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0052 - accuracy: 0.9987 - val_loss: 2.9899 - val_accuracy: 0.7788\n",
      "Epoch 1321/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0020 - accuracy: 0.9987 - val_loss: 3.0301 - val_accuracy: 0.7710\n",
      "Epoch 1322/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0077 - accuracy: 0.9973 - val_loss: 3.1717 - val_accuracy: 0.7726\n",
      "Epoch 1323/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0088 - accuracy: 0.9953 - val_loss: 3.0553 - val_accuracy: 0.7757\n",
      "Epoch 1324/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0110 - accuracy: 0.9973 - val_loss: 2.9317 - val_accuracy: 0.7741\n",
      "Epoch 1325/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 9.2562e-04 - accuracy: 1.0000 - val_loss: 2.8490 - val_accuracy: 0.7804\n",
      "Epoch 1326/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0150 - accuracy: 0.9967 - val_loss: 3.0534 - val_accuracy: 0.7882\n",
      "Epoch 1327/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0104 - accuracy: 0.9980 - val_loss: 3.1218 - val_accuracy: 0.7757\n",
      "Epoch 1328/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0062 - accuracy: 0.9973 - val_loss: 3.0347 - val_accuracy: 0.7695\n",
      "Epoch 1329/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0161 - accuracy: 0.9960 - val_loss: 2.9485 - val_accuracy: 0.7414\n",
      "Epoch 1330/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0120 - accuracy: 0.9947 - val_loss: 3.0229 - val_accuracy: 0.7850\n",
      "Epoch 1331/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0081 - accuracy: 0.9973 - val_loss: 2.9518 - val_accuracy: 0.7788\n",
      "Epoch 1332/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0084 - accuracy: 0.9967 - val_loss: 3.0237 - val_accuracy: 0.7835\n",
      "Epoch 1333/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0207 - accuracy: 0.9947 - val_loss: 2.8684 - val_accuracy: 0.7788\n",
      "Epoch 1334/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0099 - accuracy: 0.9967 - val_loss: 2.7713 - val_accuracy: 0.7850\n",
      "Epoch 1335/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0081 - accuracy: 0.9987 - val_loss: 2.8484 - val_accuracy: 0.7882\n",
      "Epoch 1336/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0260 - accuracy: 0.9940 - val_loss: 2.6837 - val_accuracy: 0.7897\n",
      "Epoch 1337/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0267 - accuracy: 0.9906 - val_loss: 2.7084 - val_accuracy: 0.7882\n",
      "Epoch 1338/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0161 - accuracy: 0.9933 - val_loss: 2.6459 - val_accuracy: 0.7819\n",
      "Epoch 1339/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0326 - accuracy: 0.9940 - val_loss: 2.8941 - val_accuracy: 0.7835\n",
      "Epoch 1340/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0058 - accuracy: 0.9987 - val_loss: 2.8847 - val_accuracy: 0.7819\n",
      "Epoch 1341/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0034 - accuracy: 0.9987 - val_loss: 2.8840 - val_accuracy: 0.7866\n",
      "Epoch 1342/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0092 - accuracy: 0.9967 - val_loss: 2.8773 - val_accuracy: 0.7819\n",
      "Epoch 1343/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0173 - accuracy: 0.9960 - val_loss: 2.6900 - val_accuracy: 0.7928\n",
      "Epoch 1344/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0075 - accuracy: 0.9973 - val_loss: 2.6406 - val_accuracy: 0.7897\n",
      "Epoch 1345/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0055 - accuracy: 0.9987 - val_loss: 2.6409 - val_accuracy: 0.7882\n",
      "Epoch 1346/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0101 - accuracy: 0.9973 - val_loss: 2.6506 - val_accuracy: 0.7710\n",
      "Epoch 1347/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0055 - accuracy: 0.9973 - val_loss: 2.7297 - val_accuracy: 0.7788\n",
      "Epoch 1348/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.7653 - val_accuracy: 0.7850\n",
      "Epoch 1349/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0022 - accuracy: 0.9987 - val_loss: 2.6973 - val_accuracy: 0.7850\n",
      "Epoch 1350/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0014 - accuracy: 0.9993 - val_loss: 2.7677 - val_accuracy: 0.7928\n",
      "Epoch 1351/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0032 - accuracy: 0.9993 - val_loss: 2.7307 - val_accuracy: 0.7819\n",
      "Epoch 1352/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0070 - accuracy: 0.9987 - val_loss: 2.8757 - val_accuracy: 0.7850\n",
      "Epoch 1353/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 2.8424 - val_accuracy: 0.7819\n",
      "Epoch 1354/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0081 - accuracy: 0.9953 - val_loss: 2.7498 - val_accuracy: 0.7773\n",
      "Epoch 1355/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0341 - accuracy: 0.9947 - val_loss: 2.8805 - val_accuracy: 0.7788\n",
      "Epoch 1356/1500\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.0099 - accuracy: 0.9960 - val_loss: 2.9780 - val_accuracy: 0.7804\n",
      "Epoch 1357/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0244 - accuracy: 0.9967 - val_loss: 2.7006 - val_accuracy: 0.7695\n",
      "Epoch 1358/1500\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.0097 - accuracy: 0.9973 - val_loss: 2.7041 - val_accuracy: 0.7632\n",
      "Epoch 1359/1500\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.0120 - accuracy: 0.9967 - val_loss: 2.6928 - val_accuracy: 0.7773\n",
      "Epoch 1360/1500\n",
      "38/38 [==============================] - 0s 13ms/step - loss: 0.0126 - accuracy: 0.9967 - val_loss: 2.5983 - val_accuracy: 0.7632\n",
      "Epoch 1361/1500\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.0137 - accuracy: 0.9967 - val_loss: 2.6933 - val_accuracy: 0.7773\n",
      "Epoch 1362/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 12ms/step - loss: 0.0078 - accuracy: 0.9973 - val_loss: 2.7663 - val_accuracy: 0.7882\n",
      "Epoch 1363/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0103 - accuracy: 0.9947 - val_loss: 2.8263 - val_accuracy: 0.7835\n",
      "Epoch 1364/1500\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.0056 - accuracy: 0.9980 - val_loss: 2.8006 - val_accuracy: 0.7804\n",
      "Epoch 1365/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0049 - accuracy: 0.9980 - val_loss: 2.9577 - val_accuracy: 0.7850\n",
      "Epoch 1366/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0095 - accuracy: 0.9973 - val_loss: 2.8421 - val_accuracy: 0.7741\n",
      "Epoch 1367/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0085 - accuracy: 0.9980 - val_loss: 2.8742 - val_accuracy: 0.7804\n",
      "Epoch 1368/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0101 - accuracy: 0.9973 - val_loss: 2.7554 - val_accuracy: 0.7679\n",
      "Epoch 1369/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0034 - accuracy: 0.9993 - val_loss: 2.8096 - val_accuracy: 0.7757\n",
      "Epoch 1370/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0191 - accuracy: 0.9947 - val_loss: 2.7622 - val_accuracy: 0.7944\n",
      "Epoch 1371/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0097 - accuracy: 0.9953 - val_loss: 2.6840 - val_accuracy: 0.7866\n",
      "Epoch 1372/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0054 - accuracy: 0.9973 - val_loss: 2.7248 - val_accuracy: 0.7804\n",
      "Epoch 1373/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0056 - accuracy: 0.9980 - val_loss: 2.7790 - val_accuracy: 0.7819\n",
      "Epoch 1374/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0062 - accuracy: 0.9980 - val_loss: 2.9654 - val_accuracy: 0.7741\n",
      "Epoch 1375/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0163 - accuracy: 0.9960 - val_loss: 2.7662 - val_accuracy: 0.7788\n",
      "Epoch 1376/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0060 - accuracy: 0.9973 - val_loss: 2.9485 - val_accuracy: 0.7788\n",
      "Epoch 1377/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0097 - accuracy: 0.9980 - val_loss: 2.9259 - val_accuracy: 0.7882\n",
      "Epoch 1378/1500\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.0017 - accuracy: 0.9987 - val_loss: 2.9496 - val_accuracy: 0.7866\n",
      "Epoch 1379/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0110 - accuracy: 0.9960 - val_loss: 2.9653 - val_accuracy: 0.7788\n",
      "Epoch 1380/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0188 - accuracy: 0.9960 - val_loss: 2.8725 - val_accuracy: 0.7679\n",
      "Epoch 1381/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0136 - accuracy: 0.9967 - val_loss: 2.9182 - val_accuracy: 0.7757\n",
      "Epoch 1382/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0099 - accuracy: 0.9980 - val_loss: 2.8759 - val_accuracy: 0.7741\n",
      "Epoch 1383/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0088 - accuracy: 0.9953 - val_loss: 2.9765 - val_accuracy: 0.7835\n",
      "Epoch 1384/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0105 - accuracy: 0.9947 - val_loss: 2.9973 - val_accuracy: 0.7819\n",
      "Epoch 1385/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0168 - accuracy: 0.9960 - val_loss: 2.9991 - val_accuracy: 0.7617\n",
      "Epoch 1386/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0052 - accuracy: 0.9980 - val_loss: 3.0075 - val_accuracy: 0.7632\n",
      "Epoch 1387/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0071 - accuracy: 0.9960 - val_loss: 2.9719 - val_accuracy: 0.7726\n",
      "Epoch 1388/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0097 - accuracy: 0.9967 - val_loss: 2.9622 - val_accuracy: 0.7757\n",
      "Epoch 1389/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0052 - accuracy: 0.9980 - val_loss: 3.1490 - val_accuracy: 0.7882\n",
      "Epoch 1390/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0160 - accuracy: 0.9967 - val_loss: 2.9628 - val_accuracy: 0.7648\n",
      "Epoch 1391/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0037 - accuracy: 0.9973 - val_loss: 3.0896 - val_accuracy: 0.7710\n",
      "Epoch 1392/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0181 - accuracy: 0.9960 - val_loss: 2.9149 - val_accuracy: 0.7788\n",
      "Epoch 1393/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0129 - accuracy: 0.9953 - val_loss: 2.7492 - val_accuracy: 0.7757\n",
      "Epoch 1394/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 2.7385 - val_accuracy: 0.7726\n",
      "Epoch 1395/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0057 - accuracy: 0.9987 - val_loss: 2.8697 - val_accuracy: 0.7882\n",
      "Epoch 1396/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0089 - accuracy: 0.9960 - val_loss: 2.7887 - val_accuracy: 0.7773\n",
      "Epoch 1397/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0108 - accuracy: 0.9973 - val_loss: 2.7318 - val_accuracy: 0.7601\n",
      "Epoch 1398/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0129 - accuracy: 0.9973 - val_loss: 2.7266 - val_accuracy: 0.7648\n",
      "Epoch 1399/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0075 - accuracy: 0.9973 - val_loss: 2.7152 - val_accuracy: 0.7492\n",
      "Epoch 1400/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0152 - accuracy: 0.9967 - val_loss: 2.8826 - val_accuracy: 0.7664\n",
      "Epoch 1401/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0062 - accuracy: 0.9987 - val_loss: 2.8357 - val_accuracy: 0.7648\n",
      "Epoch 1402/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0101 - accuracy: 0.9973 - val_loss: 2.9458 - val_accuracy: 0.7757\n",
      "Epoch 1403/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.8702 - val_accuracy: 0.7695\n",
      "Epoch 1404/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0041 - accuracy: 0.9973 - val_loss: 2.9860 - val_accuracy: 0.7819\n",
      "Epoch 1405/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0059 - accuracy: 0.9987 - val_loss: 2.9572 - val_accuracy: 0.7648\n",
      "Epoch 1406/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0084 - accuracy: 0.9967 - val_loss: 2.8544 - val_accuracy: 0.7648\n",
      "Epoch 1407/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0104 - accuracy: 0.9967 - val_loss: 2.9118 - val_accuracy: 0.7726\n",
      "Epoch 1408/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0083 - accuracy: 0.9973 - val_loss: 2.8518 - val_accuracy: 0.7773\n",
      "Epoch 1409/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 2.9006 - val_accuracy: 0.7710\n",
      "Epoch 1410/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0017 - accuracy: 0.9993 - val_loss: 2.9043 - val_accuracy: 0.7788\n",
      "Epoch 1411/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 8.3767e-04 - accuracy: 1.0000 - val_loss: 2.9112 - val_accuracy: 0.7741\n",
      "Epoch 1412/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0035 - accuracy: 0.9987 - val_loss: 3.0116 - val_accuracy: 0.7710\n",
      "Epoch 1413/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0063 - accuracy: 0.9980 - val_loss: 3.1589 - val_accuracy: 0.7804\n",
      "Epoch 1414/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0108 - accuracy: 0.9967 - val_loss: 3.1505 - val_accuracy: 0.7835\n",
      "Epoch 1415/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0078 - accuracy: 0.9973 - val_loss: 3.0776 - val_accuracy: 0.7819\n",
      "Epoch 1416/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0103 - accuracy: 0.9940 - val_loss: 2.7576 - val_accuracy: 0.7430\n",
      "Epoch 1417/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0106 - accuracy: 0.9973 - val_loss: 2.8838 - val_accuracy: 0.7788\n",
      "Epoch 1418/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0147 - accuracy: 0.9980 - val_loss: 3.0589 - val_accuracy: 0.7819\n",
      "Epoch 1419/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0289 - accuracy: 0.9953 - val_loss: 2.5602 - val_accuracy: 0.7508\n",
      "Epoch 1420/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0194 - accuracy: 0.9953 - val_loss: 2.5913 - val_accuracy: 0.7601\n",
      "Epoch 1421/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0134 - accuracy: 0.9953 - val_loss: 2.8122 - val_accuracy: 0.7741\n",
      "Epoch 1422/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0121 - accuracy: 0.9953 - val_loss: 2.9009 - val_accuracy: 0.7788\n",
      "Epoch 1423/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0129 - accuracy: 0.9973 - val_loss: 2.8708 - val_accuracy: 0.7882\n",
      "Epoch 1424/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0127 - accuracy: 0.9967 - val_loss: 2.7709 - val_accuracy: 0.7710\n",
      "Epoch 1425/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0123 - accuracy: 0.9960 - val_loss: 2.6966 - val_accuracy: 0.7710\n",
      "Epoch 1426/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0047 - accuracy: 0.9973 - val_loss: 2.7174 - val_accuracy: 0.7773\n",
      "Epoch 1427/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0100 - accuracy: 0.9980 - val_loss: 2.8360 - val_accuracy: 0.7819\n",
      "Epoch 1428/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0166 - accuracy: 0.9953 - val_loss: 2.7855 - val_accuracy: 0.7835\n",
      "Epoch 1429/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0134 - accuracy: 0.9947 - val_loss: 2.4668 - val_accuracy: 0.7850\n",
      "Epoch 1430/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0048 - accuracy: 0.9980 - val_loss: 2.5769 - val_accuracy: 0.7850\n",
      "Epoch 1431/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0048 - accuracy: 0.9987 - val_loss: 2.6586 - val_accuracy: 0.7897\n",
      "Epoch 1432/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0222 - accuracy: 0.9960 - val_loss: 2.4632 - val_accuracy: 0.7882\n",
      "Epoch 1433/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0117 - accuracy: 0.9940 - val_loss: 2.5000 - val_accuracy: 0.7866\n",
      "Epoch 1434/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0059 - accuracy: 0.9987 - val_loss: 2.5642 - val_accuracy: 0.7897\n",
      "Epoch 1435/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0047 - accuracy: 0.9980 - val_loss: 2.6953 - val_accuracy: 0.7975\n",
      "Epoch 1436/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0035 - accuracy: 0.9993 - val_loss: 2.6981 - val_accuracy: 0.7850\n",
      "Epoch 1437/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0105 - accuracy: 0.9980 - val_loss: 2.7348 - val_accuracy: 0.7804\n",
      "Epoch 1438/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0048 - accuracy: 0.9987 - val_loss: 2.7755 - val_accuracy: 0.7850\n",
      "Epoch 1439/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0092 - accuracy: 0.9973 - val_loss: 2.5790 - val_accuracy: 0.7679\n",
      "Epoch 1440/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0080 - accuracy: 0.9980 - val_loss: 2.8384 - val_accuracy: 0.7819\n",
      "Epoch 1441/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0082 - accuracy: 0.9980 - val_loss: 2.8798 - val_accuracy: 0.7850\n",
      "Epoch 1442/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0119 - accuracy: 0.9967 - val_loss: 2.7117 - val_accuracy: 0.7960\n",
      "Epoch 1443/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0079 - accuracy: 0.9967 - val_loss: 2.6739 - val_accuracy: 0.7804\n",
      "Epoch 1444/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.9993 - val_loss: 2.6861 - val_accuracy: 0.7835\n",
      "Epoch 1445/1500\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.0082 - accuracy: 0.9980 - val_loss: 2.9393 - val_accuracy: 0.7913\n",
      "Epoch 1446/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0100 - accuracy: 0.9960 - val_loss: 2.8047 - val_accuracy: 0.7866\n",
      "Epoch 1447/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0090 - accuracy: 0.9980 - val_loss: 2.6721 - val_accuracy: 0.7819\n",
      "Epoch 1448/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0040 - accuracy: 0.9993 - val_loss: 2.7113 - val_accuracy: 0.7913\n",
      "Epoch 1449/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 2.8042 - val_accuracy: 0.8022\n",
      "Epoch 1450/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0061 - accuracy: 0.9993 - val_loss: 2.7153 - val_accuracy: 0.7960\n",
      "Epoch 1451/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0175 - accuracy: 0.9947 - val_loss: 2.6395 - val_accuracy: 0.7913\n",
      "Epoch 1452/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0194 - accuracy: 0.9973 - val_loss: 2.7634 - val_accuracy: 0.7804\n",
      "Epoch 1453/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0219 - accuracy: 0.9947 - val_loss: 2.6199 - val_accuracy: 0.7695\n",
      "Epoch 1454/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0167 - accuracy: 0.9926 - val_loss: 3.0403 - val_accuracy: 0.7788\n",
      "Epoch 1455/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0120 - accuracy: 0.9973 - val_loss: 2.8524 - val_accuracy: 0.7741\n",
      "Epoch 1456/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0139 - accuracy: 0.9933 - val_loss: 2.8844 - val_accuracy: 0.7757\n",
      "Epoch 1457/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0110 - accuracy: 0.9953 - val_loss: 3.0007 - val_accuracy: 0.7897\n",
      "Epoch 1458/1500\n",
      "38/38 [==============================] - 0s 13ms/step - loss: 0.0118 - accuracy: 0.9973 - val_loss: 2.9264 - val_accuracy: 0.7850\n",
      "Epoch 1459/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0110 - accuracy: 0.9967 - val_loss: 2.8442 - val_accuracy: 0.7726\n",
      "Epoch 1460/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0079 - accuracy: 0.9973 - val_loss: 2.9098 - val_accuracy: 0.7741\n",
      "Epoch 1461/1500\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.0056 - accuracy: 0.9980 - val_loss: 2.8395 - val_accuracy: 0.7695\n",
      "Epoch 1462/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0031 - accuracy: 0.9993 - val_loss: 2.7980 - val_accuracy: 0.7632\n",
      "Epoch 1463/1500\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 2.8842 - val_accuracy: 0.7664\n",
      "Epoch 1464/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0089 - accuracy: 0.9973 - val_loss: 2.8744 - val_accuracy: 0.7913\n",
      "Epoch 1465/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0030 - accuracy: 0.9993 - val_loss: 2.7755 - val_accuracy: 0.7788\n",
      "Epoch 1466/1500\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.0050 - accuracy: 0.9987 - val_loss: 2.7973 - val_accuracy: 0.7788\n",
      "Epoch 1467/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0228 - accuracy: 0.9980 - val_loss: 2.6732 - val_accuracy: 0.7773\n",
      "Epoch 1468/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0031 - accuracy: 0.9987 - val_loss: 2.6086 - val_accuracy: 0.7773\n",
      "Epoch 1469/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0106 - accuracy: 0.9967 - val_loss: 2.7189 - val_accuracy: 0.7804\n",
      "Epoch 1470/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0044 - accuracy: 0.9980 - val_loss: 2.7361 - val_accuracy: 0.7695\n",
      "Epoch 1471/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0251 - accuracy: 0.9953 - val_loss: 2.8738 - val_accuracy: 0.7741\n",
      "Epoch 1472/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0041 - accuracy: 0.9973 - val_loss: 2.8097 - val_accuracy: 0.7819\n",
      "Epoch 1473/1500\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.0036 - accuracy: 0.9980 - val_loss: 2.7725 - val_accuracy: 0.7601\n",
      "Epoch 1474/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0036 - accuracy: 0.9987 - val_loss: 2.8349 - val_accuracy: 0.7773\n",
      "Epoch 1475/1500\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.0094 - accuracy: 0.9973 - val_loss: 2.8828 - val_accuracy: 0.7710\n",
      "Epoch 1476/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0058 - accuracy: 0.9980 - val_loss: 2.9363 - val_accuracy: 0.7710\n",
      "Epoch 1477/1500\n",
      "38/38 [==============================] - 0s 13ms/step - loss: 0.0024 - accuracy: 0.9987 - val_loss: 2.8888 - val_accuracy: 0.7773\n",
      "Epoch 1478/1500\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.0019 - accuracy: 0.9993 - val_loss: 2.9591 - val_accuracy: 0.7819\n",
      "Epoch 1479/1500\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.0121 - accuracy: 0.9960 - val_loss: 2.9813 - val_accuracy: 0.7866\n",
      "Epoch 1480/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0302 - accuracy: 0.9953 - val_loss: 3.0858 - val_accuracy: 0.7960\n",
      "Epoch 1481/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0233 - accuracy: 0.9926 - val_loss: 2.7350 - val_accuracy: 0.7819\n",
      "Epoch 1482/1500\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.0079 - accuracy: 0.9987 - val_loss: 2.7416 - val_accuracy: 0.7819\n",
      "Epoch 1483/1500\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.0039 - accuracy: 0.9980 - val_loss: 2.7847 - val_accuracy: 0.7788\n",
      "Epoch 1484/1500\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 2.8589 - val_accuracy: 0.7788\n",
      "Epoch 1485/1500\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.0158 - accuracy: 0.9960 - val_loss: 2.9337 - val_accuracy: 0.7866\n",
      "Epoch 1486/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0106 - accuracy: 0.9967 - val_loss: 2.7960 - val_accuracy: 0.7773\n",
      "Epoch 1487/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.7544 - val_accuracy: 0.7773\n",
      "Epoch 1488/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0042 - accuracy: 0.9980 - val_loss: 2.8667 - val_accuracy: 0.7928\n",
      "Epoch 1489/1500\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.0073 - accuracy: 0.9973 - val_loss: 2.7958 - val_accuracy: 0.7850\n",
      "Epoch 1490/1500\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.0031 - accuracy: 0.9987 - val_loss: 2.7752 - val_accuracy: 0.7819\n",
      "Epoch 1491/1500\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.0127 - accuracy: 0.9953 - val_loss: 2.9013 - val_accuracy: 0.7866\n",
      "Epoch 1492/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0056 - accuracy: 0.9987 - val_loss: 2.8862 - val_accuracy: 0.7850\n",
      "Epoch 1493/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0121 - accuracy: 0.9973 - val_loss: 2.7806 - val_accuracy: 0.7679\n",
      "Epoch 1494/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0071 - accuracy: 0.9967 - val_loss: 2.8459 - val_accuracy: 0.7850\n",
      "Epoch 1495/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0059 - accuracy: 0.9987 - val_loss: 2.8738 - val_accuracy: 0.7913\n",
      "Epoch 1496/1500\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.0030 - accuracy: 0.9987 - val_loss: 2.9329 - val_accuracy: 0.7882\n",
      "Epoch 1497/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0103 - accuracy: 0.9973 - val_loss: 3.0546 - val_accuracy: 0.7819\n",
      "Epoch 1498/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 3.0194 - val_accuracy: 0.7835\n",
      "Epoch 1499/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0058 - accuracy: 0.9973 - val_loss: 2.9819 - val_accuracy: 0.7819\n",
      "Epoch 1500/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0200 - accuracy: 0.9960 - val_loss: 2.9818 - val_accuracy: 0.7788\n"
     ]
    }
   ],
   "source": [
    "# Train the CNN\n",
    "#es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "history = model.fit(X_train_reshaped, y_train_onehot, epochs=1500, batch_size=40,\n",
    "                    validation_data=(X_test_reshaped, y_test_onehot))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fad3c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 3ms/step\n",
      "Accuracy: 0.778816199376947\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the performance\n",
    "y_pred = model.predict(X_test_reshaped)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "accuracy = accuracy_score(y_test_encoded, y_pred_classes)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d17f6734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAAsTAAALEwEAmpwYAABQ/klEQVR4nO2dd5wURfbAv282L5klJ8lRoogoCGZBzBEMZ/ZMZzzvzMfPcHp60TvPHM+cTj1FxQAmFAERBSWDsEjOmQ31+6O6Z3pme9LuzM7u8r6fD0x3dXXPm97uelXvvXolxhgURVEUJZJApgVQFEVRaiaqIBRFURRfVEEoiqIovqiCUBRFUXxRBaEoiqL4ogpCURRF8UUVhKIAIvK0iNyVYN2lInJEumVSlEyjCkJRFEXxRRWEotQhRCQ70zIodQdVEEqtwTHt3CAi34vIdhF5QkRaish7IrJVRD4SkSae+seLyBwR2SQik0Wkl+fYQBH51jnvZSA/4ruOFZHvnHOniEi/BGUcIyIzRWSLiCwXkfERx4c719vkHD/PKS8Qkb+IyM8isllEvnDKDhGRYp/7cISzPV5EXhOR50RkC3CeiAwRka+c71gpIv8SkVzP+X1E5EMR2SAiq0XkZhFpJSI7RKTIU2+QiKwVkZxEfrtS91AFodQ2TgGOBLoDxwHvATcDzbHP81UAItIdeBG4xjk2AfifiOQ6jeWbwH+ApsCrznVxzh0IPAn8GigCHgHeFpG8BOTbDvwKaAyMAS4TkROd6+7jyPtPR6YBwHfOeX8G9gMOcmT6HVCe4D05AXjN+c7ngTLgWqAZcCBwOHC5I0MD4CPgfaAN0BX42BizCpgMnO657jnAS8aYkgTlUOoYqiCU2sY/jTGrjTErgM+BqcaYmcaYXcB/gYFOvTOAd40xHzoN3J+BAmwDPBTIAf5ujCkxxrwGTPN8xyXAI8aYqcaYMmPMM8Bu57yYGGMmG2N+MMaUG2O+xyqpkc7hM4GPjDEvOt+73hjznYgEgAuAq40xK5zvnGKM2Z3gPfnKGPOm8507jTEzjDFfG2NKjTFLsQrOleFYYJUx5i/GmF3GmK3GmKnOsWeAswFEJAsYh1Wiyl6KKgiltrHas73TZ7++s90G+Nk9YIwpB5YDbZ1jK0x4psqfPdv7ANc7JppNIrIJaO+cFxMROUBEJjmmmc3ApdiePM41Fvmc1gxr4vI7lgjLI2ToLiLviMgqx+z0xwRkAHgL6C0inbCjtM3GmG8qKZNSB1AFodRVfsE29ACIiGAbxxXASqCtU+bSwbO9HLjbGNPY86/QGPNiAt/7AvA20N4Y0wh4GHC/ZznQxeecdcCuKMe2A4We35GFNU95iUzJ/BAwF+hmjGmINcF5ZejsJ7gzCnsFO4o4Bx097PWoglDqKq8AY0TkcMfJej3WTDQF+AooBa4SkRwRORkY4jn3MeBSZzQgIlLPcT43SOB7GwAbjDG7RGQI1qzk8jxwhIicLiLZIlIkIgOc0c2TwF9FpI2IZInIgY7PYz6Q73x/DnArEM8X0gDYAmwTkZ7AZZ5j7wCtReQaEckTkQYicoDn+LPAecDxqILY61EFodRJjDHzsD3hf2J76McBxxlj9hhj9gAnYxvCDVh/xRuec6cDFwP/AjYCC526iXA5cIeIbAVuxyoq97rLgGOwymoD1kHd3zn8W+AHrC9kA/AnIGCM2exc83Hs6Gc7EBbV5MNvsYppK1bZveyRYSvWfHQcsApYABzqOf4l1jn+rTHGa3ZT9kJEFwxSFMWLiHwCvGCMeTzTsiiZRRWEoihBRGR/4EOsD2VrpuVRMouamBRFAUBEnsHOkbhGlYMCOoJQFEVRoqAjCEVRFMWXOpPYq1mzZqZjx46ZFkNRFKVWMWPGjHXGmMi5NUAdUhAdO3Zk+vTpmRZDURSlViEiUcOZ1cSkKIqi+KIKQlEURfFFFYSiKIriS53xQfhRUlJCcXExu3btyrQoaSc/P5927dqRk6NruyiKkhrqtIIoLi6mQYMGdOzYkfDEnXULYwzr16+nuLiYTp06ZVocRVHqCGkzMYnIkyKyRkRmRzkuIvKAiCwUu4TkIM+xc0VkgfPv3MrKsGvXLoqKiuq0cgAQEYqKivaKkZKiKNVHOn0QTwOjYhwfDXRz/l2CzWGPiDQF/gAcgE3B/AfxrDOcLHVdObjsLb9TUZTqI20KwhjzGTZtcTROAJ41lq+BxiLSGjga+NAYs8EYsxGbOCyWolEUpQZgjOGNb4vZuiv5Jaxnr9jM9KWxmovM89Z3K1i4Zhv/m/ULL09bRmlZaMnwpeu2M2nemoSus3lHCW99t4Kpi9fzffGmSsmyfXcpr80oJt2pkjLpg2hL+FKJxU5ZtPIKiMgl2NEHHTp08KuScTZt2sQLL7zA5ZdfntR5xxxzDC+88AKNGzdOj2A1nB17Snnvh1WcPKhtjR0drdm6iyF3f8xBXYqYvnQj8+8ezTUvzWTqkg2s3GzNfXee0IdzDuzIsvU7+HnDdg7uFj5h9cbXv+elacv56LqRdG1hV0stLze8/m0xJwxoS2627cO9P3sli9Zu56wDOtC4MDfsGmXlhtdnFHPSoLbkZIX3+Wav2ExZuaF/+8bBst2lZfS49X1uGt2Tlg3zOXFg+Ou1q6SMd79fycmD2vLZgnW0bVwQlM1l844S+t8xkZtG9+ThTxdxxaFdyc/J4tY3Z3PyoLb89fQBYfVfnraM7bvLeO7rn1m8bnuwfOm9Yzj0z5NZ4ilrkJ/ND+OPDjvfGMPfPlrAM1OWsnlnSbDOntJyTnt4CrOKN3N0n5aM3rc1jQpymL96Kw9OWsgxfVvTsCCH/JwsTh/cjnZNgovz8fSXSxj/vx956rz9+ecnC/h22SYA3rj8ILJEyApI8P4W5mZx9UvfhclUUmbIyRK27Czl7gk/hf2mrxatZ9xjX/PmFcNYuWkno/u2ZvmGHRz+l0/Z41Esbn2AWcs3ccKDX4YdO65/G47v34aLn7WTgK88tCv/mrQwePy3r84C4MnzBnNYz5akmrQm6xORjsA7xph9fY69A9xrjPnC2f8Y+D1wCJBvjLnLKb8N2GmM+XOs7xo8eLCJnEn9008/0atXrxT8ksqzdOlSjj32WGbPDnfFlJaWkp2dWv1cld87ZdE62jcppH3TwviVq4H97vyQ9dv38MblBzGoQ2wL48xlGynIzaJnq4YJX/+e937i45/W8NF1IzHG8PzUZbw8bTk/rNjMD+OP4pdNu5i6ZD23vzWHT64fSefm9Xn888U0b5DHCQNsg/rBnFX8+j8zgtd8+ZKhnPHo12HfU5CTxU93jqLjje8C8N/LD2JghybsLrWN8HWvzAqr375pAcs37AzuL713DMYYutw8gXLPqzq0c1OeuWAI78xaiQjB6wzrWsSXC9dz9tAOHNuvDWMdeebfNZoLn5nGwA5NeODjBWHfefXh3RjRvRmPf76Elg3zeXrK0gr3KyBQbuCqw7rywCcLaZCXzdbdpXHv87VHdKdeXhZ3vftT3LpeRMBtmh4+ez8ufW5GhTqPnLMfP6/fzh8nzE3omg3yszllUDvf3+elab1cNmzfE1aWmxWo0LBHY2T35nw6f21CdV1aNMhjzdbdSZ3jpXvL+ky8dmSlzhWRGcaYwb7HMqggHgEmu+v8isg8rHI4BDjEGPNrv3rRqKkKYuzYsbz11lv06NGDnJwc8vPzadKkCXPnzmX+/PmceOKJLF++nF27dnH11VdzySWXAKHUIdu2bWP06NEMHz6cKVOm0LZtW9566y0KCgoqfFdVfq/bgLm9mWQoLSvnne9XMm3pBr5bvol3rzoYYwxvz/qFeau28u/JiwCYdssRNG8QWi1zw/Y9TFu6gaP7tOKUh6bQrUV97j2lH+Xlhs43TwjWy88JMPfO0cH9Bau3cuTfPuPDa0ewfOMOLnh6elD2QXd+yEUHd+LyQ7oy4YeVXP78t4zo3pwnzh1MTlaAsnLDhc9MY/I8+wK3apjPg2cN4pSHpkT9fbcf25s73vkxuH/ywLZ8sXAdVx3ejVvf9I3BCCOZxiWS3q0b8uPKLZU6d29g3JAOvPjNsph1DuvZgk/mJmb+qa0M6tCYNy4fVqlzYymITJqY3gauFJGXsA7pzcaYlSLyAfBHj2P6KOCmqn7Z//1vDj/+ktoXrXebhvzhuD4x69x7773Mnj2b7777jsmTJzNmzBhmz54dDEd98sknadq0KTt37mT//ffnlFNOoaioKOwaCxYs4MUXX+Sxxx7j9NNP5/XXX+fss89O6W9JhC8WrKN7y/osXLuNTs3qkR0I8NPKLcxdtSWsF3fU3z6lRYN8vli4Luz8GT9vZNS+rQCYung9Fz0zna27S/n7GQOY8fNGZvy8kXtO7kvXWyaEnberpJwpC9fRID+Hvu0a8fePbA/45WnLefyLJcF6//x4ARu27+G+9+fRtnFB0CTw2fy1jLxvEqu37uboPi2DygFg1ZZdMZUDEKYcAN6YuQIgIeUAVFo5AGHKoX+7Rswq3lzpa9UUnrlgCAM7NKbf+ImVOv/wni342Gnw4ymHX4/oTM/WDeIqiHq5WTz6q8Gc9fjUSslUkJPFLWN6JfxM3H9qP/JzsvjNizMrHLvzxH25LeI67/xmOMf+8wvfa3VtUZ/S8vR09NOmIETkRexooJmIFGMjk3IAjDEPAxOw6/MuBHYA5zvHNojIndi1eQHuMMbUbO9VEgwZMiRsrsIDDzzAf//7XwCWL1/OggULKiiITp06MWDAAAD2228/li5dmjJ51mzZxYI12yqU/2/WL/zmxZm8ePFQ9pSVc+l/ZrCzpCysTrTe7fzV25i/uuI195SVc8K/vmDDjj1hZpRrXv4uuH37W3Pwe9bPdF7cerlZbN9j5XAbape/fDg/uB1pL/7F8QlM+GFVxYvXEp6/eChzVmzm9rfmMG918uv5eE0nNx/Tkz9OmEtBTlaFv2uiXDKiM49+tjjh+kf0asnIHs05uGszAgFh6b1j+HbZRnbsLmPuqi3kZgfYU1oe1xx18YjONCrM4Y1vQ3//pfeO4YkvlnCno8y7tajPuQd15NT92vHxT/FHDy//+kD2bduIUX1a8f6cis/IP8YOCHumbhrdk3veC3WKPvntSHaXlJObHWBA+8Z8s8Q2Wfed2o92TQo487GpvH7ZgSxdt4NT9msXPM9VENcd2Z2/Os9v+yYFLL13DMP/9AnFG+170qdNQz66bgTLN+7k/Kds0/jZDYcyd9UWDuxSRL3c9DTlaVMQxphxcY4b4Ioox54EnkylPPF6+tVFvXr1gtuTJ0/mo48+4quvvqKwsJBDDjnEdy5DXl7ILJOVlcXOnTsr1ImFMYb3Z6/iqD6tyAoIlz8/g3q52dx/Wn/GPvp1mNOw443vMqZfaz5xXqpxj30d7bJJmz6e+nJJ3B7wf74OJZZ84tzBXPbct2E9cFc5ABXsxMniVTaJMOf/jubBSQuDJjOX4/u34e1Zv4SVXTi8E094RjexeP6iA/hu+Sbu/2Ae953aj7zsALOWb+bJL8PPr5+XzQGdi3j1sgN9e99eB+bNx/Tk3vfm8tVNh3PW41M5pm9rrjuyOyc++CX187Kpl2df/aL6uRRv3Mm4Ie158ZtQbMgH14ygfn42M5dtpGNRPbbsLOHZr37m/Tmr+M1hXfnnJwu54tCutG1cwMmD2tLXkcc9dkzfVvz7rP2Cpsvxx/Xm3IMqTlh1/UvDuzUDCFMQtxzTi88WrCU7IDx1/hC27irhne9XckCnpgztXBSmINx7fvrgdvQdP5Ffj+zCqU5DPLBDYwAePWc/1m7bTU5WgK8Xr+eNb1cwbkh7Js1dy75tGwFw0qC2vD9nFd/cfDgL1mzj0udmsHVXKQ3zQxkKXDPsr0d2Cf6+lg3yCQSE+XeFTKHGmODvdc/Zb5+mYTK/8usDyckSBnZowsUHd+a1b4sZ4QQyvHjxUA6+bxJgw9i7tmhA1xYNgud2KCqkQ1F6fYZ1eiZ1TaBBgwZs3erf29u8eTNNmjShsLCQuXPn8vXX0RvjSPaUllNaVk6h86Jv311KWblh4pxVHNytOQW5WcG6B97zCau2WMUz985RwV70jaN7hikHl3e/X5mwHMkw04kSSZRWjfKZftsRlTZFADx1/v6s2bKL37/+Q1j5E+cO5rCeLbj+lVkVRiLRqJeXTZfm4dE8S+45BhHhgXEDWbZ+ByPun8SBnYtokB/+ah3brzXvfL+SU/drx/2n9mPr7tLg7xrYoTHDujbjikO7BuuP3rc1C9du4zMfZ6e3scrPCbCrpJz+7Rtz7ZHdad4gjzP2b09+ThaXjOgCwEfXhZyXb1x2EADlxlBSWs4BnYsY/Y/POb5/Ww7q0izYo+3RyjZEbRuHfF0HdW0W3L7+qB4AnHtQRwBevfRAyssNQzo1pU3jAkY7pkSX84YlNsM/NzvAgrtH8/zXP3PW0H24eETnYChng/wcxg2pGK04onsoMqxBfk7wb+LSpnFBBd/a6YPbV4i0Aji6T6tg3RYN85l68+G8NqOYkd2b8+R5g8OioLwEAhUj7RKJvhvSKaQwCnKzOGfoPsH99k0Luf/UfozsER759vH1I1nkM+pPB6og0kxRURHDhg1j3333paCggJYtQ6Foo0aN4uGHH6ZXr1706NGDoUOHVjh/555S/KyLC9dspbTc0K9dYwAWrd3G6s27uORtG+1x2n7tWL11N18sWBtmsnHD5QD2u+ujlPzGeCQS1XHD0T3o06Yh5z01LVjWu3VDqhpDcWiPFjz+ecgMctLAthzRqyWH97J/hz+d2q+Cgrj8kC4c1KUZS9ZvZ8O2PfRr34hy5yaeOLAtm3eW8OqMYrIDEtYIdCgq5N6T+3JE75as3LSLv3+0gOuO7M6I7s3pVFSPAzoXcfYBHRARGubncNkhXXho8iIKcrKIJDc7wLMXDMEYw9QlGwhENDbDuhYxf/U2iurlMnfVVp4+b3+yAhJssKPhNmQBJNhoextPP5t4IuzfMdTQeRvxh84a5Fc9JjlZgTCFEq+hffaCIWH7qQyLLszN5lcHdgTwDSNt27iATs3qVShPFacNbl+hrEvz+hU6KumizqxJXVOjmKqKO5Gma4v6FOZmY4zhp5VbKS23ZpfWjQpYv303e0rLWb1sMRe/nZ7efzyuPrwbJWXlFcwvYBsgdygeyaAOjRm9b2t+ddA+rNu2h2H3fhI8xyXauS6vXXogT09ZSq/WDblsZBduf3s2z329jA5NC/nsd4cG48vdENNIOt74LrnZAWbediQvTVvO+Qd19O0R1kRWb9nF5HlrOGP/1MwD+nrxegQ4oHNR3LqZpiqRd0qImhrFpCTBwjXb6NeuMbtLy4PKAWDl5uT8EZWlf/vGzFq+KerxEwa0oVOzejQpzA2bNOTSpDCHjTtKmH7rEQy+6yPG9G3N0C5FHN2nJS0a5AM25BSsHdvLv84cyJUvhPdsR+/bivdmW1PZ4I5NGezpwd51Yl/uOrFvmOyRZgcv/xg7gL5tG1EvL5sLh9euZIctG+anTDkADK0FisGlf7tGwQmJSnpQBVHL2JbA5KR08OblB9HpJht+Om5IB24Z04vnvv6Zf3y0gJ0lZTQpzEVEuHhEZ96YuYKfIhzY3952JGCH/9F6fFkBYck9x1QoP7ZfG2av2MLDn4ZGJ7uSjLyJZXZwJ74ptYu3rhyeaRHqPLpgUC1i+YYd/LIp9SOGrCjmlKGdQ71ybwP7x5P2pX5eNpeO7MIFwzsC0LAg5DhtVBDqd5w/rGPw/ERsw9Hq3Ti6p69iufPECnMwFUVJEaogaiA795RSWlbO9ojRwsYdlQ/rLKqXG/XYn07pF9x+8EzrVDy4WzNevHgoh3oiKE5ycvZ4G/Abju7J4j8eE6ZkHhg7kNuO7c3iPx7D7cf2rrTMfvzrzIG8feUw7j6pL7cd25uzD6iZObgUpS6gJqYaxM6SMn7ZuJPte6pmRlp492i63vIeELLVu0nf/OpmZwV4/PPFLF67nTInaKF+XjYiwhPn7h+Movrr6f3582n9K1wj0qHbomF+2mz5x/ZrE9yubf4CRaltqIKoASzfsANjICdLqqwcnjh3MNlZAU4c0IY3v/uFkd2b897sVcEsnxcO78TvRvXgiwXryAoI2U75hKsOptwYXppmJ0u5YXTexl9EyKodwT2KoqQAVRBpJl667w3b9wRNRy2dKB6X5x5/iFPOOpeCgvDJOQ3yc6Lm3Hfj+/8+diB/OrUfKzfZKI9yY5h31yhyAgECAQnWcwkEhADCyYPasmrzrrBJW4qi7J2oDyLNbNq0iX//+99Rjxdv3BHcjuycP//EQ+zySasREMLy83duVp+2jQto2zhcweRlZwVNS2XlhrzsrLjx/YW52fz26B5hM7EVRdk70RFEmrnxxhtZtGgRAwYM4Mgjj6RFixa88sor7N69m5NOOolTLr6WHTu287vLzmf96lXsLinhkqtvYP26taxZvYqLTj+Oxk2LeOKV/wWvGRCh0JOcq15eFvXzs1njE/3jmpbyovggFEVRorH3KIj3boRVP8Svlwyt+sLoe2NW8ab7njhxIq+99hrffPMNO/eUctrJJ9Gx75ds3LCe5i1b8+jzr7GntJytWzbToGEjnnvsQR5/5X8M37czc34JJbnLjnAExAofbVY/lxuO7sGYvq2r9lsVRdnr0G5lNTJx4kQmTpxI/wEDGDRoEHN++okVPy+ha8/efP35JP50x218O3UKbVs0CzsvKyDs26YRfdo0pFn9vODM4/p58fW7iHDFoV3pmMZ8MYqi1E32nhFEnJ5+dWCM4aabbuLAMWcA1ueQnRWgpKyclyZ8yueTJvKv++9m4axvOP2Sa8LOtb4DoY0nu2bHZvWqnMxOURQlGjqCSDPedN9HH300Tz75JDu221S9q1b+wqrVq1mzaiX5BQUce/IZnHvpb5j1nc07VFivPs1yo69GFvAsrK4oipJq9p4RRIbwpvsePXo0Z555JueccBRgFcAf//EIy5Yu5m93304gECA7O4eHH7ZRT2eccz4nn3Asbdq0YdKkSZn8GYqi7IVouu9qxhjDDytir6rWrUV9FqzZRn5OFt1bNohZ10tN/L2KotRsYqX7VhNTNbMjzhKXHZoWBlNbqPFIUZRMogqiGjHGsGht7KUCGxfmBh3PqVwZS1EUJVnqvA/Cu3B4puVYvy16Ntb6ednBBchDCiK56yuKoqSSOj2CyM/PZ/369TWi8dy2u5Rfoqz+1rGoHh2b1SM7YP8chXlZNK2XS/smBb71IzHGsH79evLz8+NXVhRFSZA6PYJo164dxcXFrF27NtOisH13KRt3+CfYY1NeMCWGl62rEr9+fn4+7dq1q6R0iqIoFanTCiInJ4dOnWrGmgG/evIbPpvvr6g+uGYEPVolHq2kKIpSHdRpE1NNoazcVFAO+TmhW69z3RRFqYmogqgGZvvMe5h68xEM72pzLjUqzKlwXFEUJdPUaRNTTaHMx0neqCCHJ8/bn2UbdgST7ymKotQkdARRDcxctim47TUn5WYHwhb+URRFqUnoCCJNfF+8iZnLNnHuQR1Zv203AJ//7lAKc7PYVRo9AZ+iKEpNIa0KQkRGAf8AsoDHjTH3RhzfB3gSaA5sAM42xhQ7x8oAd4WfZcaY49Mpa6o5/l9fAjC6byv+PXkRAO2bFsY6RVEUpUaRNgUhIlnAg8CRQDEwTUTeNsb86Kn2Z+BZY8wzInIYcA9wjnNspzFmQLrkqy7+8sH8TIugKIpSKdLpgxgCLDTGLDbG7AFeAk6IqNMb+MTZnuRzvNazeWeUyXGKoig1nHQqiLbAcs9+sVPmZRZwsrN9EtBARIqc/XwRmS4iX4vIiX5fICKXOHWm14TZ0l7chXzWbN2VYUkURVEqR6ajmH4LjBSRmcBIYAXg5sPex8lRfibwdxHpEnmyMeZRY8xgY8zg5s2bV5vQiVCQkwXAys2qIBRFqZ2k00m9Amjv2W/nlAUxxvyCM4IQkfrAKcaYTc6xFc7nYhGZDAwEFqVR3pRSkJvFtt2lqiAURam1pHMEMQ3oJiKdRCQXGAu87a0gIs1ExJXhJmxEEyLSRETy3DrAMMDr3K7xFOZmZVoERVGUKpE2BWGMKQWuBD4AfgJeMcbMEZE7RMQNWT0EmCci84GWwN1OeS9guojMwjqv742IfqrxuCYmRVGU2kpa50EYYyYAEyLKbvdsvwa85nPeFKBvOmVLNwU6glAUpZaTaSd1ncWbXmPftg356LoRmRNGURSlEmiqjTSwq6QsbP+hs/bTWdSKotQ6dASRBnre9n7Yfv081cOKotQ+VEFUAznZepsVRal9aMtVDeT6rDetKIpS09GWqxrIydI1RRVFqX2ogkgDHYsKOb5/m+C+iCoIRVFqH6og0kBJmSE7S7juyO7U0/kQiqLUUjS8JoX8vH47v2zaRVm5ITsgXHV4N646vFumxVIURakUqiBSyMj7JwPQrH4u2eqYVhSllqOtWBpYt20POQH1OyiKUrtRBZEmTKYFUBRFqSKqINLEs1/9nGkRFEVRqoQqiDRxRK+WmRZBURSlSqiCSCEjuttlT28+pieP/Wq/DEujKIpSNTSKKYVkCfRr14hLRlRYPltRFKXWoSOIFFJabsjS6CVFUeoIqiBSSGmZnSCnKIpSF1ATU4pYvWUXXy1en2kxFEVRUoYqiBTw8KeLuPe9uZkWQ1EUJaWoiSkFqHJQFKUuogpCURRF8UUVRIrp365RpkVQFEVJCaogUszwbs0yLYKiKEpKUAWRYi47pGumRVAURUkJqiBSTP08DQxTFKVuoAoihdxzct9Mi6AoipIyVEGkkGb18zItgqIoSspQBZFC6uVlZVoERVGUlJFWBSEio0RknogsFJEbfY7vIyIfi8j3IjJZRNp5jp0rIgucf+emU86qMHvF5uC2+h8URalLpE1BiEgW8CAwGugNjBOR3hHV/gw8a4zpB9wB3OOc2xT4A3AAMAT4g4g0SZesVeGy52cEtwtzVUEoilJ3SOcIYgiw0Biz2BizB3gJOCGiTm/gE2d7kuf40cCHxpgNxpiNwIfAqDTKWmkKc0JKoXOzehmURFEUJbWkU0G0BZZ79oudMi+zgJOd7ZOABiJSlOC5iMglIjJdRKavXbs2ZYInQ6HjdyjIySKgqb4VRalDZNpJ/VtgpIjMBEYCK4CyRE82xjxqjBlsjBncvHnzdMkYk3qOWWlnScJiK4qi1ArSaTRfAbT37LdzyoIYY37BGUGISH3gFGPMJhFZARwSce7kNMpaaQpzNXJJUZS6SUIjCBF5Q0TGiEgyI45pQDcR6SQiucBY4O2I6zbzXPMm4Eln+wPgKBFp4jinj3LKahxu5NKgDo0zK4iiKEqKSbTB/zdwJrBARO4VkR7xTjDGlAJXYhv2n4BXjDFzROQOETneqXYIME9E5gMtgbudczcAd2KVzDTgDqesRrF5ZwlbdpXSID+bp84fkmlxFEVRUooYYxKvLNIIGAfcgnUiPwY8Z4wpSY94iTN48GAzffr0av3Ojje+C0Dv1g2ZcPXB1frdiqIoqUBEZhhjBvsdS9hk5EQXnQdcBMwE/gEMwoag7tXk5WTa168oipJ6EnJSi8h/gR7Af4DjjDErnUMvi0j1dttrIPnZ6qhWFKXukWgU0wPGmEl+B6INTfYmcrJ1BKEoSt0j0Zatt4g0dnec6KLL0yNS7eOz+ZmZpKcoipJOElUQFxtjNrk7TvqLi9MikaIoilIjSFRBZIlIMI+Ek4gvNz0i1T6m33pEpkVQFEVJOYn6IN7HOqQfcfZ/7ZTt1QQELjq4sy4UpChKnSRRBfF7rFK4zNn/EHg8LRLVEq5/ZRblBr4v3pRpURRFUdJCQgrCGFMOPOT8U4DXvy0GYOayTZkVRFEUJU0kOg+iG3Yxn95AvltujOmcJrlqDQHRFN+KotRNEnVSP4UdPZQChwLPAs+lS6jahC4BoShKXSVRBVFgjPkYm7vpZ2PMeGBM+sSq2Uz4YWVwWxcJUhSlrpKok3q3k5Z7gYhciV3XoX76xKrZXP78t8FtNTEpilJXSXQEcTVQCFwF7AecDZybLqFqE1k6glAUpY4SdwThTIo7wxjzW2AbcH7apapF6AhCUZS6StwRhDGmDBheDbLUSm4d0yvTIiiKoqSFRH0QM0XkbeBVYLtbaIx5Iy1S1SKO698m0yIoiqKkhUQVRD6wHjjMU2aAvU5BeFfgO++gjuqDUBSlzpLoTGr1OziUG+924su1Koqi1DYSnUn9FHbEEIYx5oKUS1TD6X17KEdhWbkqCEVR6i6Jmpje8WznAycBv6RenJrP7tLy4HaeLjWqKEodJlET0+vefRF5EfgiLRLVIsYNaZ9pERRFUdJGZRdT7ga0SKUgtZFuLRtkWgRFUZS0kagPYivhPohV2DUi9lqO6t0y0yIoiqKklURNTNpVBp74Yklw+/5T+2dQEkVRlPSTkIlJRE4SkUae/cYicmLapKqh3PnOjwCM6tOKRoU5GZZGURQlvSTqg/iDMWazu2OM2QT8IS0S1QLKdP6Doih7AYkqCL96iYbI1jm27y7NtAiKoihpJ1EFMV1E/ioiXZx/fwVmxDtJREaJyDwRWSgiN/oc7yAik0Rkpoh8LyLHOOUdRWSniHzn/Hs4uZ+VXqYsWp9pERRFUdJOoqOA3wC3AS9jo5k+BK6IdYKTJvxB4EigGJgmIm8bY370VLsVeMUY85CI9AYmAB2dY4uMMQMSlE9RFEVJMYlGMW0HKowA4jAEWGiMWQwgIi8BJwBeBWGAhs52I2r47GwRMAYePHNQpkVRFEVJO4lGMX0oIo09+01E5IM4p7UFlnv2i50yL+OBs0WkGDt6+I3nWCfH9PSpiByciJzpYvPOEob/6RMCIhzYuYgx/VpnUhxFUZRqIVEfRDMncgkAY8xGUjOTehzwtDGmHXAM8B9n7euVQAdjzEDgOuAFEWkYebKIXCIi00Vk+tq1a1Mgjj8zft5A8cadlJUburSol7bvURRFqUkkqiDKRaSDuyMiHfHJ7hrBCsCbrKidU+blQuAVAGPMV9hEgM2MMbuNMeud8hnAIqB75BcYYx41xgw2xgxu3rx5gj8lebIDodtUkKMJ+hRF2TtI1El9C/CFiHwKCHAwcEmcc6YB3USkE1YxjAXOjKizDDgceFpEemEVxFoRaQ5sMMaUiUhnbO6nxQnKmnJWb9kV3N5VUh6jpqIoSt0hUSf1+yIyGKsUZgJvAjvjnFMqIlcCHwBZwJPGmDkicgcw3RjzNnA98JiIXIsdkZxnjDEiMgK4Q0RKgHLgUmPMhsr9xKpzw2vfB7dnLt+YKTEURVGqlUST9V0EXI01E30HDAW+InwJ0goYYyZgnc/ests92z8Cw3zOex14PbK8JtCkMDfTIiiKolQLifogrgb2B342xhwKDAQ2pUuomkxuVmUzpCuKotQuEm3tdhljdgGISJ4xZi7QI31i1Vx0HWpFUfYWEnVSFzvzIN4EPhSRjcDP6RKqJhG57rQuQ60oyt5Cok7qk5zN8SIyCTvr+f20SVWD+OuH88L2dQShKMreQtIZWY0xn6ZDkBqHMXBfZxpkj8PrR88OSOZkUhRFqUbU4+rHlH/Cy2fDzg1cuvXBYPEFwzpx7yn9MiiYoihK9bHXrukQk4m3Bjd3G7tyXL3cLG4/rjesXwQzvoD9zs2UdIqiKNWCKgiXHRtg/vuQW7/CodOzJtE1sAFKD4VHRsCebaogFEWp86iCcPnfVfDT/yoU50kJ9+U8Znc+bm2VA0B5OQTUQqcoSt1FWziA7et8lUMFNnkie43mZFIUpW6jCgLg22cSqyee22XK0iOLoihKDUFNTADrFgBwV8lZNJMtbDUF3JDzSsV6P74V2i5XBaEoSt1GFQRQtmoOX5b15fGyMcGyuaY9T+T+JfpJamJSFKWOoyYmYOfGVaw0RWFlH5fvF/uk+e/Dmp/SKJWiKEpmUQUBZJkSSgitFFeQk8W7Vw1n/QG/g4aRy2g7vH4h/HtoNUmoKIpS/aiCALIoo8RjbZty42H0adOIotG3wHU/hjun/di+Ps0SKoqiVD+qIIBAeUmYgmhSL2JRoBsWRT954cdwf2dY8FGapFMURckMqiAAKQ83MVUgK8YqcsXT7efyqakVSlEUJcNoFJMxZJlSSslm7P7tGbRPk4p1AjGUxw7XvKRpwBVFqVuogigrAWCPyeamY3rRqCCnYh2JoSC+ecR+6joRiqLUMdTEVG4VRClZ5GVHuR2xRhBBVEEoilK3UAVRtgeAErLJyYpyO+JFMYFOnFMUpc6hCqKs1H5INlnRVouTBFaRUxOToih1DFUQBY15rM+zTJQDq3ghVRCKotQtVEFk5bAiryvbsxpX7TrG2H/37gMznk6FZIqiKBlFFQSwu7Sc3OxEHNExmPIAvH8j7NoE79/sX6e8DP57KayaXbXvUhRFqQZUQQB7SsvJzYrjZzhifPwLTX3YfhY29T++fhHMehFe1eVKFUWp+eg8CKCkrJzcaCGuLsOvhZ2b4IdXYcuK2HWjKQg3XFbXklAUpRagIwhgd2lZfAUBcOT/wbF/j1+voClsWQklu0JlW1dD6W67vX1tpeRUFEWpTtKqIERklIjME5GFInKjz/EOIjJJRGaKyPcicozn2E3OefNE5Oh0yrl5Z4n/DGo/Agncsgat4K894YXTQmV/6Q7PHGe392xLXkhFUZRqJm0KQkSygAeB0UBvYJyI9I6odivwijFmIDAW+Ldzbm9nvw8wCvi3c720sGH7HppGZnCNhleMoVf418lvZD+XfBZevmNd8sIpipJ+ystgfCOY9MdMS2LZtcXK8/XDGRUjnSOIIcBCY8xiY8we4CXghIg6BmjobDcCfnG2TwBeMsbsNsYsARY610sL23aV0iA/wRGEd1Z1vWb+daZG/FFL91Sss2k53NfFOq4VKC+HB4fC7NczLYmyN7Jnu/2c8q/MyuGybY39jGxLqpl0Koi2wHLPfrFT5mU8cLaIFAMTgN8kcS4icomITBeR6WvXVt6uX24g2iTqCnjzMu3cGL/+7Ddg2uMVy9+42I4oZv7H7n/3Asx5M0Eh6iDlJbD2JxsGrNQcdm6E/10DJTur7zu/eQwWVvP6KqWOvzA7QUtCunFN2SazAS2ZdlKPA542xrQDjgH+I5JI4iOLMeZRY8xgY8zg5s2bV1oIg0FIUEN4xet3evz6r50PH9xUsXzZV+H7b14WCn/dsAR+fCsxeTJJyS77MpenIA+Vm6pEU5akhh/fgo1Lq36dyffCjKdg5nNVv1aiTPgtPHdK6q63fhH89E542cznYMeG0H7JDvuZlZe6760M896DdQtCkY4Zfh/SqSBWAO09++2cMi8XAq8AGGO+AvKBZgmemzLKTWK+Z4ujSNofAK36hh/KLkiNQA8Ng1d+lZprpZPJ99iXec4bVb9WdfSU9myHFTPS/z01gVd+BQ8fXPXrlNtcZdXSUK2ZC9vSEOH34BB4+azw73nrCnj2BFi30Ja5IyR3BLFjA6yek3pZ4vHiWPjXYCieZvf9QuI3LLEm6mognQpiGtBNRDqJSC7W6fx2RJ1lwOEAItILqyDWOvXGikieiHQCugHfpEtQ++wnOoJI1BaVKD7XK9ke+5Td2+wD7e0BVYZdm4PrYVSKnc73795aNTnA8yKksSH676Xw2GF1fw1xtzHfvSV110r5c499/rauDu3/+wDbOLrs3JjYnKHt6+37sDtKdKCr5Fzc+7Lqe/jXfnbbHUFk59vPRw+Bhw6K/92x2LGh8or1zcvsp1+W6AcGwN/3rbRYyZA2BWGMKQWuBD4AfsJGK80RkTtE5Hin2vXAxSIyC3gROM9Y5mBHFj8C7wNXGJPOLqZJ3AdRE7inLdzdCu7rFHJmVYZ7O8BLZ6ZOrqpQHSOIX2baz7oeZuxtEKscBJFGhX1vBxv+vXZeqGzXptD2nzrChBtiX2PnJrsm/N2t7HsRC7exLt1V8Zg7gnBNTJt+jn2teGxeYd/PL/6W+Dl+yqQu+yCMMROMMd2NMV2MMXc7ZbcbY952tn80xgwzxvQ3xgwwxkz0nHu3c14PY8x76ZSz3FSig1QdQ+5HD4lfp6q99wUT7cNcFd69rmrnQ8iPkc77Kil0/M1734Yhbl1V9WsBrJxlr7fqh6pfyzsq3PKL7cmOb1S5CDG3B1uVEcR/L4W/9Aztf3AL3NUytO9VEJH88Jp/+bMn2vfD7flHw+t7+L/G9rMkQkG8eTk8PcZuZ+XAj5GGDofd2+x9nPl8ePkHt9jy8Y1g8ae2zH0ufopyLT/cibReYo2gxjeC+ROjH08BmXZS1wiMMQQSfgHcek5DFvCEx6Z6GO72eL/6t30Ypj1RsU681e6WfmFtrc66F3z4B/jygYjv+baSAjq/NxWLJS3/2rlWGntMwVQnKZB3+pP20/0bVRW3UZqXgr5QmSesOjs/NIpwQziXfA4vnBG78XnjEvj+VY/CrsKzPetF2LoS3r3e7n/1r/BevCkPPZ8ViNJhWDzJ3vt4JlK/MNHIEcR3ngY/Oy96r3+LE4X/xV/Dy7/yhMa6zvwsp13wC3GPRqlPpJgps8/rf06GRZ9UPP7CaTD5T4l/R5KogsAZQSRa2VUC7ouTXcWoB5HwnsNH/1exjhsF5ddT93vJ186DKf+0269fBIsnwzbH1vvl3+HD2yKFSFLoOCz5zGa0TWY0UB3hrcERRAoURMBJY+aacxZ+BHP+G71+WQk8czx8dn/Vv9vLnh0w8VY7kty8AibdE95o5uTD2rl22+0IvDgW5r9vfQDR+P5leOMigg10Kjo/fuHeYBtBv8YRKj5D5WXh70ikf2HD4tjnGwOf3Bldxqzc0JyISCKfH2Mq/j3dOq6CKEtCQfg9P7s2w8fjYdHH8PI5/udNTt/kPk3Whx1BSGVfgKwqxk1vWAKvXRDaj+ydxGtky0thc7ENjWveE9bMgVcvgN2b4YBLQyOc8ko6o+d/AG0GQf0kwojfuMT2GIddZdOOgG281s2DLodF/x3pxp0Fn4pRSnA04sjthmX2Ocm//vz3Ycmn9l/bwVDUFRq396/rx8KPoVn3iufMfs12BsrLrdN16efQun/o+NZV8PaV4ee4PphlX1v5ex9PVFIxgvDi16Ne8S10TCDiyhgbfTTrxVBZ5HPz0llw3AOwbIptrCNHC798C+vmR/+O7PxwBVFeHgpxFM+Iee670KQjfHJX+PmBLFj5fSgCav0CWD4N2g6yiT7zGkD7oVCvKHTOnh0wbwK8c62/TF/+w5GlLDWj3yRQBYF97hLXDxEmpsNurZoNPl6IaDwnY3mpnYG8Zys0bBueaba8DLKcP/G2NdGV2fa1Nrlgw9bh5aW74YXToUUfuHxKqHz1HKuMorF1Zeh8sL3bvzlZVsZvtjd89WwbJrx2nn3RqhJNlSipzKYbHEFEXGvxp7aRadYtPKuvN0XLf06E3AZwc7HnxIiGeOcm23tsso9tcJ47GXLqwYUfQE4hFHWx4ZrLHNPcgokhB693ZPD8qeHyeSO4XhpnPy+YCC162qihJh1tpyVSrlgvyNZVVu6SHVBYBPkNo9dd5+Nv+OpfMORi//p7tlrTTiDHTqT0Kgeo2Ote8yM8cUT074/3nGXnhvs1TBlBQ4t7D7avs8EdflO2JACPRCi7J46AUffa9WIA2u0PF3kmAn5wU2KLjJmy+D6XFKMKAvsKJOyDiDQx7X+h7f08uH9aZGNHnJDM8lL7EkHFNOTlpaGG7Ikjw495RybvXGM/x3saltI9ocZvg0dJrfoBHh4Oh9wU3miEaVkBjI0MKd1jTStepj4C7/8eTnkCXr8Q+p2R2AiidHdiJr1o9SSi158spXvs/QwEQiaEyGs96/zWvIZwkxOrXrLTmnq87IkTXPDQMNhSbBvvJ49yrrPd3nuA3y6wYaEu6xeEtmPN8L+/c8Wyp8dA0062Z33behtG6RJ8TCLej/JyOyrNzoO/9AiVt+gNl0dMAvXiyh9JrJnaf+1lP8e9VPFYpEkpHvE6BxIIr1O6yz43gUDonXFHYH6mymgj/s2ezsC6BeHHNiYYMWXKoyuI0j1pmQWuPgig3JgkBtA+NdMRI+7iNg4uxdPD92M1duUlIQURSSw7/J4dcFfzisNnCEU8RU44+/LvoW33O58/1V7H6wTftsYqB4DlU+3n9y8TN5xy7rtwVwvbm47FzOdtPb+GwzUVVEZBlJfZ3/KBs1qg+xuj9UjdWPvl39gQzKVfJPd9W5wGJfLv7xLLf+A3cz8W5SUhs8ufu0UcdEcQEU3F6xfY+xzJmh+T+26XRHrG3oAQl2TnAsXzP/34VvjzcU87eO08u53IyPO7KDPOw5zykX6RBEe05WXR/SPx5k5VElUQJGtiCp4V2gy+PAJXpSiqJRquScEl1kNbXlZJBeE8bNPdqCm/myPh5bNesj2j8Y1C/o7NPrM9vekfksnv487X8Isa2rzCfm/xDPjxTVsW2UsDG0oKIb/N+EZW0X3+V7sdK2bdVQSuozVoropjsnDza7kzY6MRnJAWu1oQv5DIVLAzosF1n6+3r7T36MVxNrzUNe34Kar/a2rDgAHWxrD3e3ntwvh1snye5YUfJnZ9l0Qa48jG9se3rMmvKlaCMAe987fetgbuaQ/LpiZ4ERNdkS5I8j4kiJqYsLmYkjYxRcs+3tRnCJ9KVkX0oGP1hstKQqaQSPwUxNr50Lx7qPHz9o7f+z30PpEwxfjdC57rGfj+Ff/vCmSH5PTKG29lvmjXimTxJPs5/YlQgxYrpVdZiXX6Akx7MtTr+2i8XTnQj2DDkoTTdsnn8PWDzvZnFY9H65msmRv/2tWV9TZSAc6bEL6/3SeFvSmDF8+Aei1ge4ITOTcuiV/nP1ECAJIhWZOUS7IjwFjs3mJToXQamfxs91eiLFf8wc2J5YZLEh1BYMNcE+65tR4AQy+HUz1zEpIdftSrfGJBa47xMPne6HXLS6Ggif8xv2yZb1xkP4OJ88pC15n6MDw1KjSHYsEHUObpxZbtjh6q6HWOe3u+fnHd8QhkwdRH7Ujks/vDJz1993xIZgnYiU2f3W8VgteZWV4SijKJNAlEM1mUe+7F53/xDPVj/O2fOTb2b5nxlHUIT3+KMMXjplmIRWS0W7pYEWeOTKxZ6Ykqh0RJRXhytEiheCSSuTkZfnwr9rsbjfU+I2OAjlF8O1VEFQSAScJJHQjAqHtstIdL4gloLalck3rJpzG+p8SGU/rhl2Jjzw6bvGzeuxWv47JsCr5sXBpKfBaJ1+bql+YgGvMnVgyL3LoK3rsB/tHf+ki++mf49X925Atk2XDbT+6yk9pePS9UZ+HH8M0j/t/5v6tC2xuXhmY2e0c+H99hw0uryjvXWofwO9eEfufPX1Zh4mIaiNezj5b/qDI0SiLst7qJZZq6PkEzWiR+CnS/80LbByTQUXBJ5d/BgyoIknVS+5Hk2R2HVenbEmb94uQmq5XshOdPgbd/E7+uH/OjzAL2jix+jqJgvOzYYG2qL5xmzT6xiPRjuBOTJCuk6CJTq3tnvlb47o3WP7F+kVVCbtRNNFNAqnqWrhKuzKgqk6RylJDOYI9E6B8jL1ms0Us0P19l6DfWfrbcF3LrJX5emta5VwVBkmGufgT9EglcY/xm+8evDp4/JXpP2Y+SHalZQyAWUx6IX+e+TqH4/ci4+QqpRaLcc2+9WDOcIzFl8Lc+8M9B4eXRUmd/7DPzvTKky+mcbrwjs6rSfVTqrpUs4zfDoTdHPx5NQVwwMX66m2QIKhuJ3Z50ODC03WYQnJ+edHWqIHBGEFXpvEQzMV0/P7qJpyYSGcFSE4gMI514a/j+53/GN0TWL2VJIvg5/Vd8G9uZOL5RYteO1dNMxvRWF2gRuTw9MPLGxM4dneJ0JS6x5thEG4mLpHYE4SobCf7nz6lPwZFOypDCppBbmDoZvOKk5aq1DBtMUiUN4V/coCWc/35o/7KvQl+oJEZ5GTxzXPLnLf86fp1o3xfJ4smVu1YknQ+Jfiwy+CCV9D6hYtlht8GvMrhqYfMe4fuS5R/G6kezyLkaleTaiAWBokX8QfQRhARSqyAiJ5tGo7AIWvRK3fdGYa9XEMZprKtk/YzlpPbmMGrp02tSYrPsK/8QUS+pVLh+DuKP70jNtcdUMfIolmlyyCXRj53w74plOQWxFVY6OM5jXoy8FyLRQ8cjqWqCTJdG7eD0/8BFjt8nVl61qOHkcUYQrQckLk92QfgCTbH8HtW0drYqiFQkq4w8+azXosfTZ4qcJBxeNYlEJjbN/yDdQqTmMt7cTJVhwFnh+826h7aHXgZjI/IUgZ19nFcf9o/IdZTMbPKuPrmNuh5ZsSweXnNrhXuRhKkm2R77sTEmQPY+Hto5q8rFWo862ox5kdg+iCOT6FzkFpLUPJtqYK9XEOWOhqiSkzryj9ntSDhifGi/3xnQY4ynQgZMTIfdGr9OKjj4+uTqF6XAXBAZlpsMLfpU/fsTRbLgiCo4td1nNM9JhucdOUkAeh4Dgy8IP8e1TQ+KSBXdM84cDS9+DefZlQjzzasfvr//xZDrlMVraL0kOtJwibwn4L9+fKzv9yqI+p7FjsRxJtdr7u8bya1fsSwah93m0Q9SI0zRe72CSIm+jjcP4uRHYdwLseukm1j21VSS7JyQyxIIe00nyaTcToRYaasDWTD8Gvh1HJNZNNxev9vomLLQ/Y78dHHrelOA377BZoNNlFQ9O+4o1h3NjPkzXOTMaJdA4g1/KsJhvRNdE7mud1Lob+eHfot7v29YCAf4mPkSNQXl1ofB5xPWInUe6V83ciSZRlRBuAvDVWVR6mQf2FipstNFOnsj3kmDyaraVNtSxyXh7M3KC+8NpoITHox+zG0As/Oj14lG2/1Cs8bdZWY3LPYoBjf6JeKVzvGJbkk2LDNVCkIEbl0Do+/zyOIJ6wwk2BxVJazUDaVNdlZ25ES0YGh7HJkLmyV2ffc31XPqdxhqfUS3rIZmjkM/OOpzvrthG/vZdr/EvqMS7PUKojwlDWeSjeK+J8OlKcztkhBpVBDeuRPJjiCicUmMGeKxKGiceN1Admpj2MG+tNHs8+53JetkbdwBfvW2JxTWa1qKVAwRz2KOjyklWfyyqAIcfnvy18rOC1cEbgehVd/o51wZkcFYAnDVd/5RWOe+U7EMbMj59fNDjuho2Qy88wu8RK5DEbzPUd79DgfCb761a6yclYA5zpWrSUe4/OuQ7yInP5Qq3lXU7le27GNH4CN/H//6lWSvVxAuKZkolwyt+toHqO9p/sdPjrI8Y2WpLntmdh6clYJEcm0GVO68ZBRUdl7y9uy4359lF9/xPeY8J37271h0PsTa793Z1sOuDh0LRCgI99Md1Xlt4Jd/DRf65ODyw+sIjqbQGnUIbZ/zZvxr+r0njdrDcf+Ak3zWjnZp0iniOll2/QrXF+MlWrLMBi3tP/d+RRtBnPUq7HtqxXJ3MaagDHFGELn1Q2a8lgn4ubxKuEWv8FGbq8zyfebbtOyT+k6OV6y0XbmW4I4gUhPFlORFirqEeizug9aqHxzzZ+gXRXH4Mfq+itESx0emk4hQEO5Qu36rxL/Hj3ZDQtuBHLvMaYcDKtZr2gXOeN72pk572oY8XuBEH109Cw5NkRM9GQVxwfvxF2RKlkAgvgyJjCACOXDpl1YZuI5tt6Hwnh85gnBNFK4S8k6gatEL2kekrI7scbs9ea9pqmnnKH8fzzPV5dCKh9sM9DknAhGbfyiaT+SEBys2gJH3t3V/OPEhOG9CAksAe5YN9SOvAfRKxIGfRPaEaJ0Qb9RZrDkgborvoLKvvginvV5BBH0Q6ZhJXZlrtOoXfflFL+2HhrYP+HXFMMbIqJW+EamA97/I9kzPn0DKHrgj/mAbJG/vs8NB9t+lX9gXr9uRdt3m/c61dlawvd2RN6RGhnh/C2/IZvMecIjP7N1EGjY/3IiseKOSRHwQB14Brfa1it8NCXUbNcmCQefaRjFy5DD4Aug0Ak57ynY+jvJZ9MlLp4NtDx5g0K9C5op2HkUSyA7/+7T36QD4UWHUmsRz1vUIq7wGnm0bYW/UlftbW/aBfYbbMNYBZ9ocZ25Dm9cIhl9XMWrMPTeWD6LL4XbdcD/cjlewTxjxvLlzTrwdtqCC8/z+4dfaqLNgnRh+npMesWZLd1RYjTmr9noFERxBVKmRrMq5kSt2xTAF5Tawn6Pvq5h7JbfQ5pePRr0iq3xcGraxNtyiLtFtyYVF/uVeDrw89OC6tndvA9miF1zwXtpSAVTA+8J2i7Iam5fmPUINpIvfokSJ4E01HotERhB+DZh3rYvjH7CNYqRjt7ApnPs/576/X/nZttn5oU5HZA/eXXcgrtmyCmbNs1+3ystl7POh59dNMZ6dB+e/G+6kdd+RQ2+yHZbh14RfN2hiiiFbfkO4+OOK5dn5FTtekX/rgWc5+dY8k2Ldnn+s+RixAgHaD7FhxX6KJs3s9QrCG3Zc9atUglZO+GGnEc6lYlyr32n24Tvg16GGwTsyOPdt//PcnC3eXpi38T/4uvD6w539RNKS9znJmojGbw7Z3r0jiESXU4zFPklkv/W+sGe9CgddFX68wGeyWrIjwGi9S/d37xPF0Rn8vigP29ArQtt+zlJXaXgb7GCPOFUp5F3ZTCisNlJBBJ9R5zPSj3bJ5Ih6KcJVTLE6LlnZ9lkcGiVVdmXulzsaCMuXlYRZOSffyjT4/FBZ5L2JNYJwcRWk21ZUA6og3FF7plINt98fblgM+54SLhDAjRFLdkaaC37/szUzRCM4Qch5GEfcAL9bAjcsggYRvgfXbJDXKJTrpnEHKkUgAKc+abdTMREumsnHz2kX2dhHKrkWveDKGXDjsujnxCOandt9ybseYf+myeL9+3rNDy5+IxTX1BjX9p4A3hXujPE8B/tUrAehMMvIsO1oo+FkJo35ceCV9tltsk/8utFwR1QNWid+jp9JMJkMzl4OibJeeCKhxO0G2+eqr48TPU3s9UuOGlKQi6mq1Cvyf6nyPVEal0yumB8+Xkhn5AsZCERP93DWazZlRedDrKOzcQcbZ1/ZtSH2PcU6wKOFDSbDEeP913Bo2Da0JvKAs2wDEvnC5kdGuhhoFplhN8m/vtujzmtozR1+Pft6ccxzl34JD0eMjOLNA3CVnfd7TnkM1s5NLry3AuKzbeyCNa0HVFy/xB1ZdBphHcOuL+ma2faYO+u4XovQORd/Ep6XrFJiSsgJX1kO/I31r+xzUOLnuGuMhAsTkikZoinyROeaxHuuUoyOIFLhpHapUrhZnOiKyjpOIbGhfn5Da8Kq39w+9B2HV33GZsdhiU9+Arg8yuLt0V6ecZ4okPzG1u4bORqIzInldy8qE2Rw+rN2RrT375XMBLhWnsR73Y62CiMewRGE5znLrZfaiVLeEUQg4L+4lTePU8dhoee+cXsbftq8u40+OuVxOPsN+9vSOJkrKQKB5JQDhJaX9XZ2Ep0oF5VKmJgywF4/ggiFuVZBQ+Q1tDmIXDNRZQjaRlNot62q2SyQZVNHLP08NfLEI9r8AT/Oet2aPnLqQcn26A7i7DyrPIJx7AkoiKy88NQKLkN+bRdgEqmYQnvfU6M7+8/9H6z8vmL56c/aWdEDz/Y/L5Jyn5FKyvGMICJpuS+snp1Yoj/3N3U9PLmvH/Unq2BqEq5TvPvRnsJKhrZHeycTTXVezaR1BCEio0RknogsFJEK8YQi8jcR+c75N19ENnmOlXmORfG+Vp2sgNCrdUOa1quCDVfENg6JTIiJRpfD7JB82FUVy+OFKnrpeDCMilwMvQpKpxrzvgS/76AEzFrdjgjdd/CYeXxetHhpFSJfWm+iRS/BWH+fl3zMX6LbxjuNgIOurFje+4TElQP4jyBSTYeh1j7vNzvXnTuTyjXVIxl6qX3maxLuCMJrsq3qCKIyTuoMkDa1JSJZwIPAkUAxME1E3jbG/OjWMcZc66n/G8BrR9lpjBmQLvlcGhfm8t7VMRKsVRf1iuCGBRXLz0liuUyA87wTnzzmgsriNkrthkDxN5W/TqKc6LN2QSR+MfGuEvBbx/eg38Cku516Ptdzr7HvKda57tfbh+j5jiA1TuJ49DnZLizknaOQUoz1ZVw/1/+wq3xTFjFVwxl8AUx/EnqOsZ9+0UNJK4hoI4jqWd8hWdI5ghgCLDTGLDbG7AFeAnyWtgoyDvBJaK9kFLfhbdbdhuplmvGbbUy8iztqc23cfsnpRv4ODv6ts+NnYorw/7j7kQv0xIpc8fOThCUxTAE9RtnfX8HJXkUSNUW6frDqWlM90xz7N3u/ux5hP8NWwaukkzpIxHPYqQZ0Un1Ip+GrLeCN0ywGfKdgisg+QCfgE09xvohMB0qBe40xb/qcdwlwCUCHDpUMyazLSAx7cqIEI2ecvsTvl8KfOlZBqCT4/dL4dToOs/Mw3FBMPwUB0Kit/fQLb0xkdi147oXPa+NXdumXULIz9jVrEz1G2XudasVXG6lseh03NLhhu/DyAy6tskjpoKZ4RsYCrxkTNnbdxxizQkQ6A5+IyA/GmEXek4wxjwKPAgwePDjzq2vUNFybabRGMxHcWb9uYrSCJtZeWl4SPeooVRQ0Sayet8GKFjU16DwbdttjtM/BKBFkkaY546MgXIe2X08yr37FRXJqO6ocHCrZ+ep7mn0vXX9O8HIZDbSPSjoVxArAuxpLO6fMj7HAFd4CY8wK53OxiEzG+icWVTxVicqBVwIGBl9Y+Wv0PR22/BI+M/WyKVA8Lbmoo6py3oSQszAeJz4cvkAOWMXhN/kMfCLIorysbvSO1+586Rep9c2MfcGuTqbUbKSS/j2R6M9hDSSdCmIa0E1EOmEVw1jgzMhKItITaAJ85SlrAuwwxuwWkWbAMOC+yHOVOOTk29nTVSErG0b8NryseffqD0X0i8ePxoBxyV07aohxxH4w9YTntUn1veg5Jn6dVNPnZDtJ8tBbqv+7ay0pMN/WAtLmpDbGlAJXAh8APwGvGGPmiMgdInK8p+pY4CVjwt7OXsB0EZkFTML6IH5EUdJBpJO6aSdAKqZFiOWDqM3k1beOf9c+rsSnsiOIWkZan3RjzARgQkTZ7RH7433OmwLEWGJKUVKIm5+n13H2M7cejN9UsZ7fCELZS0mRzyC7oIppUtKLPumK0rSzXfs3J06qDFUQikvH4fD9S/7zbpLhpuLUyJMm9vpcTIoCxFcOEMoeq6YY5fgHbBRftOSXiZKVXWPTbIAqCEWJzZXTQ9u9joeTHrUT75S9m+y86o3iyxA1V3UpSk2gWTerFBq0so7J/mdkWiJFqTZUQShKPFQpKHspamJSFEVRfFEFoSiKoviiCkJRFEXxRRWEoiiK4osqCEVRFMUXVRCKoiiKL6ogFEVRFF9UQSiKoii+iKkj6WpFZC3wcxUu0QxYlyJx0kFNlw9qvow1XT5QGVNBTZcPapaM+xhjfFepqjMKoqqIyHRjzOBMyxGNmi4f1HwZa7p8oDKmgpouH9QOGUFNTIqiKEoUVEEoiqIovqiCCPFopgWIQ02XD2q+jDVdPlAZU0FNlw9qh4zqg1AURVH80RGEoiiK4osqCEVRFMWXvV5BiMgoEZknIgtF5MYMytFeRCaJyI8iMkdErnbKm4rIhyKywPls4pSLiDzgyP29iAyqJjmzRGSmiLzj7HcSkamOHC+LSK5TnufsL3SOd6wm+RqLyGsiMldEfhKRA2vSPRSRa52/72wReVFE8jN9D0XkSRFZIyKzPWVJ3zMROdepv0BEzq0GGe93/s7fi8h/RaSx59hNjozzRORoT3la3nc/+TzHrhcRIyLNnP2M3MNKYYzZa/8BWcAioDOQC8wCemdIltbAIGe7ATAf6A3cB9zolN8I/MnZPgZ4DxBgKDC1muS8DngBeMfZfwUY62w/DFzmbF8OPOxsjwVerib5ngEucrZzgcY15R4CbYElQIHn3p2X6XsIjAAGAbM9ZUndM6ApsNj5bOJsN0mzjEcB2c72nzwy9nbe5Tygk/OOZ6XzffeTzylvD3yAncTbLJP3sFK/K5Nfnul/wIHAB579m4CbMi2XI8tbwJHAPKC1U9YamOdsPwKM89QP1kujTO2Aj4HDgHecB3yd5yUN3k/npTjQ2c526kma5WvkNMASUV4j7iFWQSx3GoBs5x4eXRPuIdAxovFN6p4B44BHPOVh9dIhY8Sxk4Dnne2w99i9j+l+3/3kA14D+gNLCSmIjN3DZP/t7SYm94V1KXbKMopjShgITAVaGmNWOodWAS2d7UzI/nfgd0C5s18EbDLGlPrIEJTPOb7ZqZ9OOgFrgaccM9jjIlKPGnIPjTErgD8Dy4CV2Hsyg5p1D12SvWeZfpcuwPbKiSFLtcooIicAK4wxsyIO1Qj5EmFvVxA1DhGpD7wOXGOM2eI9Zmy3IiNxySJyLLDGGDMjE9+fINnYYf5DxpiBwHaseSRIhu9hE+AErCJrA9QDRmVClmTI5D1LBBG5BSgFns+0LC4iUgjcDNyeaVmqwt6uIFZgbYQu7ZyyjCAiOVjl8Lwx5g2neLWItHaOtwbWOOXVLfsw4HgRWQq8hDUz/QNoLCLZPjIE5XOONwLWp1E+sD2uYmPMVGf/NazCqCn38AhgiTFmrTGmBHgDe19r0j10SfaeZeRdEpHzgGOBsxxFVlNk7ILtCMxy3pl2wLci0qqGyJcQe7uCmAZ0c6JIcrGOwLczIYiICPAE8JMx5q+eQ28DbjTDuVjfhFv+KyciYiiw2WMSSDnGmJuMMe2MMR2x9+kTY8xZwCTg1CjyuXKf6tRPay/UGLMKWC4iPZyiw4EfqSH3EGtaGioihc7f25WvxtxDD8nesw+Ao0SkiTNSOsopSxsiMgpr8jzeGLMjQvaxThRYJ6Ab8A3V+L4bY34wxrQwxnR03plibBDKKmrQPYxLJh0gNeEfNqJgPja64ZYMyjEcO4z/HvjO+XcM1ub8MbAA+Aho6tQX4EFH7h+AwdUo6yGEopg6Y1++hcCrQJ5Tnu/sL3SOd64m2QYA0537+CY2GqTG3EPg/4C5wGzgP9hIm4zeQ+BFrE+kBNuQXViZe4b1Ayx0/p1fDTIuxNrs3fflYU/9WxwZ5wGjPeVped/95Is4vpSQkzoj97Ay/zTVhqIoiuLL3m5iUhRFUaKgCkJRFEXxRRWEoiiK4osqCEVRFMUXVRCKoiiKL6ogFKUGICKHiJMhV1FqCqogFEVRFF9UQShKEojI2SLyjYh8JyKPiF0fY5uI/E3sOg8fi0hzp+4AEfnas16Bu6ZCVxH5SERmici3ItLFuXx9Ca1l8bwz21pRMoYqCEVJEBHpBZwBDDPGDADKgLOwSfemG2P6AJ8Cf3BOeRb4vTGmH3bGrFv+PPCgMaY/cBB2Bi7YDL7XYNcz6IzN06QoGSM7fhVFURwOB/YDpjmd+wJsErty4GWnznPAGyLSCGhsjPnUKX8GeFVEGgBtjTH/BTDG7AJwrveNMabY2f8Ou77AF2n/VYoSBVUQipI4AjxjjLkprFDktoh6lc1fs9uzXYa+n0qGUROToiTOx8CpItICgus274N9j9xsrGcCXxhjNgMbReRgp/wc4FNjzFagWEROdK6R56wdoCg1Du2hKEqCGGN+FJFbgYkiEsBm7rwCuzDREOfYGqyfAmya7IcdBbAYON8pPwd4RETucK5xWjX+DEVJGM3mqihVRES2GWPqZ1oORUk1amJSFEVRfNERhKIoiuKLjiAURVEUX1RBKIqiKL6oglAURVF8UQWhKIqi+KIKQlEURfHl/wF7m7nFOXgNmwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71748165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c637edb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.90      0.87       532\n",
      "           1       0.28      0.19      0.23       110\n",
      "\n",
      "    accuracy                           0.78       642\n",
      "   macro avg       0.56      0.55      0.55       642\n",
      "weighted avg       0.75      0.78      0.76       642\n",
      "\n",
      "Predict   0         1         \n",
      "Actual\n",
      "0         479       53        \n",
      "\n",
      "1         89        21        \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overall Statistics : \n",
      "\n",
      "95% CI                                                            (0.74671,0.81092)\n",
      "ACC Macro                                                         0.77882\n",
      "ARI                                                               0.07363\n",
      "AUNP                                                              0.54564\n",
      "AUNU                                                              0.54564\n",
      "Bangdiwala B                                                      0.7408\n",
      "Bennett S                                                         0.55763\n",
      "CBA                                                               0.51711\n",
      "CSI                                                               0.10919\n",
      "Chi-Squared                                                       7.44832\n",
      "Chi-Squared DF                                                    1\n",
      "Conditional Entropy                                               0.50816\n",
      "Cramer V                                                          0.10771\n",
      "Cross Entropy                                                     0.68047\n",
      "F1 Macro                                                          0.54958\n",
      "F1 Micro                                                          0.77882\n",
      "FNR Macro                                                         0.45436\n",
      "FNR Micro                                                         0.22118\n",
      "FPR Macro                                                         0.45436\n",
      "FPR Micro                                                         0.22118\n",
      "Gwet AC1                                                          0.70683\n",
      "Hamming Loss                                                      0.22118\n",
      "Joint Entropy                                                     1.16892\n",
      "KL Divergence                                                     0.01971\n",
      "Kappa                                                             0.1049\n",
      "Kappa 95% CI                                                      (-0.02503,0.23483)\n",
      "Kappa No Prevalence                                               0.55763\n",
      "Kappa Standard Error                                              0.06629\n",
      "Kappa Unbiased                                                    0.09917\n",
      "Krippendorff Alpha                                                0.09987\n",
      "Lambda A                                                          0.0\n",
      "Lambda B                                                          0.0\n",
      "Mutual Information                                                0.00743\n",
      "NIR                                                               0.82866\n",
      "Overall ACC                                                       0.77882\n",
      "Overall CEN                                                       0.57879\n",
      "Overall J                                                         (0.90017,0.45009)\n",
      "Overall MCC                                                       0.10771\n",
      "Overall MCEN                                                      0.46824\n",
      "Overall RACC                                                      0.75289\n",
      "Overall RACCU                                                     0.75447\n",
      "P-Value                                                           0.99951\n",
      "PPV Macro                                                         0.56355\n",
      "PPV Micro                                                         0.77882\n",
      "Pearson C                                                         0.10709\n",
      "Phi-Squared                                                       0.0116\n",
      "RCI                                                               0.01124\n",
      "RR                                                                321.0\n",
      "Reference Entropy                                                 0.66076\n",
      "Response Entropy                                                  0.51559\n",
      "SOA1(Landis & Koch)                                               Slight\n",
      "SOA2(Fleiss)                                                      Poor\n",
      "SOA3(Altman)                                                      Poor\n",
      "SOA4(Cicchetti)                                                   Poor\n",
      "SOA5(Cramer)                                                      Weak\n",
      "SOA6(Matthews)                                                    Negligible\n",
      "SOA7(Lambda A)                                                    None\n",
      "SOA8(Lambda B)                                                    None\n",
      "SOA9(Krippendorff Alpha)                                          Low\n",
      "SOA10(Pearson C)                                                  Weak\n",
      "Scott PI                                                          0.09917\n",
      "Standard Error                                                    0.01638\n",
      "TNR Macro                                                         0.54564\n",
      "TNR Micro                                                         0.77882\n",
      "TPR Macro                                                         0.54564\n",
      "TPR Micro                                                         0.77882\n",
      "Zero-one Loss                                                     142\n",
      "\n",
      "Class Statistics :\n",
      "\n",
      "Classes                                                           0             1             \n",
      "ACC(Accuracy)                                                     0.77882       0.77882       \n",
      "AGF(Adjusted F-score)                                             0.47932       0.41771       \n",
      "AGM(Adjusted geometric mean)                                      0.38188       0.63473       \n",
      "AM(Difference between automatic and manual classification)        36            -36           \n",
      "AUC(Area under the ROC curve)                                     0.54564       0.54564       \n",
      "AUCI(AUC value interpretation)                                    Poor          Poor          \n",
      "AUPR(Area under the PR curve)                                     0.87184       0.23735       \n",
      "BB(Braun-Blanquet similarity)                                     0.84331       0.19091       \n",
      "BCD(Bray-Curtis dissimilarity)                                    0.02804       0.02804       \n",
      "BM(Informedness or bookmaker informedness)                        0.09129       0.09129       \n",
      "CEN(Confusion entropy)                                            0.50432       1.02405       \n",
      "DOR(Diagnostic odds ratio)                                        2.1325        2.1325        \n",
      "DP(Discriminant power)                                            0.18133       0.18133       \n",
      "DPI(Discriminant power interpretation)                            Poor          Poor          \n",
      "ERR(Error rate)                                                   0.22118       0.22118       \n",
      "F0.5(F0.5 score)                                                  0.85414       0.25862       \n",
      "F1(F1 score - harmonic mean of precision and sensitivity)         0.87091       0.22826       \n",
      "F2(F2 score)                                                      0.88835       0.20428       \n",
      "FDR(False discovery rate)                                         0.15669       0.71622       \n",
      "FN(False negative/miss/type 2 error)                              53            89            \n",
      "FNR(Miss rate or false negative rate)                             0.09962       0.80909       \n",
      "FOR(False omission rate)                                          0.71622       0.15669       \n",
      "FP(False positive/type 1 error/false alarm)                       89            53            \n",
      "FPR(Fall-out or false positive rate)                              0.80909       0.09962       \n",
      "G(G-measure geometric mean of precision and sensitivity)          0.87138       0.23276       \n",
      "GI(Gini index)                                                    0.09129       0.09129       \n",
      "GM(G-mean geometric mean of specificity and sensitivity)          0.4146        0.4146        \n",
      "HD(Hamming distance)                                              142           142           \n",
      "IBA(Index of balanced accuracy)                                   0.29384       0.04994       \n",
      "ICSI(Individual classification success index)                     0.74369       -0.52531      \n",
      "IS(Information score)                                             0.02528       0.72793       \n",
      "J(Jaccard index)                                                  0.77134       0.12883       \n",
      "LS(Lift score)                                                    1.01768       1.65627       \n",
      "MCC(Matthews correlation coefficient)                             0.10771       0.10771       \n",
      "MCCI(Matthews correlation coefficient interpretation)             Negligible    Negligible    \n",
      "MCEN(Modified confusion entropy)                                  0.7047        1.00368       \n",
      "MK(Markedness)                                                    0.12709       0.12709       \n",
      "N(Condition negative)                                             110           532           \n",
      "NLR(Negative likelihood ratio)                                    0.52184       0.89861       \n",
      "NLRI(Negative likelihood ratio interpretation)                    Negligible    Negligible    \n",
      "NPV(Negative predictive value)                                    0.28378       0.84331       \n",
      "OC(Overlap coefficient)                                           0.90038       0.28378       \n",
      "OOC(Otsuka-Ochiai coefficient)                                    0.87138       0.23276       \n",
      "OP(Optimized precision)                                           0.1287        0.1287        \n",
      "P(Condition positive or support)                                  532           110           \n",
      "PLR(Positive likelihood ratio)                                    1.11282       1.9163        \n",
      "PLRI(Positive likelihood ratio interpretation)                    Poor          Poor          \n",
      "POP(Population)                                                   642           642           \n",
      "PPV(Precision or positive predictive value)                       0.84331       0.28378       \n",
      "PRE(Prevalence)                                                   0.82866       0.17134       \n",
      "Q(Yule Q - coefficient of colligation)                            0.36153       0.36153       \n",
      "QI(Yule Q interpretation)                                         Weak          Weak          \n",
      "RACC(Random accuracy)                                             0.73315       0.01975       \n",
      "RACCU(Random accuracy unbiased)                                   0.73393       0.02054       \n",
      "TN(True negative/correct rejection)                               21            479           \n",
      "TNR(Specificity or true negative rate)                            0.19091       0.90038       \n",
      "TON(Test outcome negative)                                        74            568           \n",
      "TOP(Test outcome positive)                                        568           74            \n",
      "TP(True positive/hit)                                             479           21            \n",
      "TPR(Sensitivity, recall, hit rate, or true positive rate)         0.90038       0.19091       \n",
      "Y(Youden index)                                                   0.09129       0.09129       \n",
      "dInd(Distance index)                                              0.8152        0.8152        \n",
      "sInd(Similarity index)                                            0.42357       0.42357       \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pycm import ConfusionMatrix\n",
    "\n",
    "\n",
    "print(\"Report : \", classification_report(y_test_encoded, y_pred_classes))\n",
    "\n",
    "print(ConfusionMatrix(actual_vector=list(y_test_encoded),predict_vector=list(y_pred_classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3483e9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.778816199376947\n",
      "Precision:  0.7474409054309016\n",
      "Recall:  0.778816199376947\n",
      "F1-score:  0.760798024946745\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.90      0.87       532\n",
      "           1       0.28      0.19      0.23       110\n",
      "\n",
      "    accuracy                           0.78       642\n",
      "   macro avg       0.56      0.55      0.55       642\n",
      "weighted avg       0.75      0.78      0.76       642\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import plot_confusion_matrix, classification_report\n",
    "import warnings\n",
    "\n",
    "print(\"Accuracy: \", accuracy_score(y_test_encoded, y_pred_classes))\n",
    "print(\"Precision: \", precision_score(y_test_encoded, y_pred_classes, average='weighted'))\n",
    "print(\"Recall: \", recall_score(y_test_encoded, y_pred_classes, average='weighted'))\n",
    "print(\"F1-score: \", f1_score(y_test_encoded, y_pred_classes, average='weighted'))\n",
    "\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test_encoded, y_pred_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc46798",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
