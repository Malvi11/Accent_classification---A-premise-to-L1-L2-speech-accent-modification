{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "960c61fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9814adcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mfcc_1</th>\n",
       "      <th>mfcc_2</th>\n",
       "      <th>mfcc_3</th>\n",
       "      <th>mfcc_4</th>\n",
       "      <th>mfcc_5</th>\n",
       "      <th>mfcc_6</th>\n",
       "      <th>mfcc_7</th>\n",
       "      <th>mfcc_8</th>\n",
       "      <th>mfcc_9</th>\n",
       "      <th>mfcc_10</th>\n",
       "      <th>mfcc_11</th>\n",
       "      <th>mfcc_12</th>\n",
       "      <th>mfcc_13</th>\n",
       "      <th>English Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-351.79230</td>\n",
       "      <td>147.745390</td>\n",
       "      <td>19.917744</td>\n",
       "      <td>31.775644</td>\n",
       "      <td>23.516031</td>\n",
       "      <td>2.070087</td>\n",
       "      <td>9.844380</td>\n",
       "      <td>0.265172</td>\n",
       "      <td>-2.338450</td>\n",
       "      <td>-1.322878</td>\n",
       "      <td>-9.483175</td>\n",
       "      <td>-1.679585</td>\n",
       "      <td>-0.177087</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-410.52670</td>\n",
       "      <td>125.953590</td>\n",
       "      <td>-20.461075</td>\n",
       "      <td>17.156311</td>\n",
       "      <td>-6.669661</td>\n",
       "      <td>15.239104</td>\n",
       "      <td>-16.752926</td>\n",
       "      <td>-3.614888</td>\n",
       "      <td>-5.258536</td>\n",
       "      <td>-7.771095</td>\n",
       "      <td>-2.448791</td>\n",
       "      <td>-5.192124</td>\n",
       "      <td>-2.269287</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-342.62964</td>\n",
       "      <td>78.433655</td>\n",
       "      <td>12.540177</td>\n",
       "      <td>31.937393</td>\n",
       "      <td>-2.213818</td>\n",
       "      <td>15.747808</td>\n",
       "      <td>-39.245610</td>\n",
       "      <td>-5.218530</td>\n",
       "      <td>-16.471539</td>\n",
       "      <td>-5.059716</td>\n",
       "      <td>-14.047500</td>\n",
       "      <td>-2.351587</td>\n",
       "      <td>-14.914782</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-331.50244</td>\n",
       "      <td>108.531410</td>\n",
       "      <td>-21.552880</td>\n",
       "      <td>42.042065</td>\n",
       "      <td>-4.467168</td>\n",
       "      <td>9.407474</td>\n",
       "      <td>1.117538</td>\n",
       "      <td>-26.776285</td>\n",
       "      <td>-9.033010</td>\n",
       "      <td>-18.285458</td>\n",
       "      <td>5.542378</td>\n",
       "      <td>1.801108</td>\n",
       "      <td>-12.343457</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-306.30480</td>\n",
       "      <td>105.473820</td>\n",
       "      <td>-2.033697</td>\n",
       "      <td>33.645050</td>\n",
       "      <td>19.767216</td>\n",
       "      <td>14.690701</td>\n",
       "      <td>-7.823933</td>\n",
       "      <td>16.233910</td>\n",
       "      <td>1.511278</td>\n",
       "      <td>-1.097624</td>\n",
       "      <td>-4.256559</td>\n",
       "      <td>5.822567</td>\n",
       "      <td>-5.417769</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2133</th>\n",
       "      <td>-367.42440</td>\n",
       "      <td>153.012450</td>\n",
       "      <td>-6.412210</td>\n",
       "      <td>19.019106</td>\n",
       "      <td>17.933186</td>\n",
       "      <td>-5.957310</td>\n",
       "      <td>-0.477651</td>\n",
       "      <td>-18.703012</td>\n",
       "      <td>-15.582651</td>\n",
       "      <td>-1.840943</td>\n",
       "      <td>-12.552829</td>\n",
       "      <td>-8.802483</td>\n",
       "      <td>-3.864208</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2134</th>\n",
       "      <td>-321.66678</td>\n",
       "      <td>128.274500</td>\n",
       "      <td>-3.335473</td>\n",
       "      <td>28.203968</td>\n",
       "      <td>15.083783</td>\n",
       "      <td>16.396720</td>\n",
       "      <td>4.090911</td>\n",
       "      <td>10.306094</td>\n",
       "      <td>2.037651</td>\n",
       "      <td>0.225633</td>\n",
       "      <td>1.150143</td>\n",
       "      <td>1.580174</td>\n",
       "      <td>-2.241047</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2135</th>\n",
       "      <td>-253.21036</td>\n",
       "      <td>93.182236</td>\n",
       "      <td>9.850489</td>\n",
       "      <td>38.595917</td>\n",
       "      <td>-14.542635</td>\n",
       "      <td>16.471262</td>\n",
       "      <td>-13.102000</td>\n",
       "      <td>20.879627</td>\n",
       "      <td>-8.502631</td>\n",
       "      <td>6.002625</td>\n",
       "      <td>12.753398</td>\n",
       "      <td>2.869624</td>\n",
       "      <td>-1.761060</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2136</th>\n",
       "      <td>-322.13104</td>\n",
       "      <td>150.674900</td>\n",
       "      <td>-11.696100</td>\n",
       "      <td>24.301128</td>\n",
       "      <td>10.992788</td>\n",
       "      <td>-7.354234</td>\n",
       "      <td>20.903921</td>\n",
       "      <td>-4.221878</td>\n",
       "      <td>-11.789002</td>\n",
       "      <td>8.365523</td>\n",
       "      <td>-4.948959</td>\n",
       "      <td>-10.440193</td>\n",
       "      <td>-3.944272</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2137</th>\n",
       "      <td>-273.39096</td>\n",
       "      <td>95.479520</td>\n",
       "      <td>-0.170104</td>\n",
       "      <td>45.088196</td>\n",
       "      <td>8.184654</td>\n",
       "      <td>13.003067</td>\n",
       "      <td>-2.578697</td>\n",
       "      <td>4.493932</td>\n",
       "      <td>0.366728</td>\n",
       "      <td>5.716188</td>\n",
       "      <td>3.348301</td>\n",
       "      <td>-2.878420</td>\n",
       "      <td>5.174947</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2138 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         mfcc_1      mfcc_2     mfcc_3     mfcc_4     mfcc_5     mfcc_6  \\\n",
       "0    -351.79230  147.745390  19.917744  31.775644  23.516031   2.070087   \n",
       "1    -410.52670  125.953590 -20.461075  17.156311  -6.669661  15.239104   \n",
       "2    -342.62964   78.433655  12.540177  31.937393  -2.213818  15.747808   \n",
       "3    -331.50244  108.531410 -21.552880  42.042065  -4.467168   9.407474   \n",
       "4    -306.30480  105.473820  -2.033697  33.645050  19.767216  14.690701   \n",
       "...         ...         ...        ...        ...        ...        ...   \n",
       "2133 -367.42440  153.012450  -6.412210  19.019106  17.933186  -5.957310   \n",
       "2134 -321.66678  128.274500  -3.335473  28.203968  15.083783  16.396720   \n",
       "2135 -253.21036   93.182236   9.850489  38.595917 -14.542635  16.471262   \n",
       "2136 -322.13104  150.674900 -11.696100  24.301128  10.992788  -7.354234   \n",
       "2137 -273.39096   95.479520  -0.170104  45.088196   8.184654  13.003067   \n",
       "\n",
       "         mfcc_7     mfcc_8     mfcc_9    mfcc_10    mfcc_11    mfcc_12  \\\n",
       "0      9.844380   0.265172  -2.338450  -1.322878  -9.483175  -1.679585   \n",
       "1    -16.752926  -3.614888  -5.258536  -7.771095  -2.448791  -5.192124   \n",
       "2    -39.245610  -5.218530 -16.471539  -5.059716 -14.047500  -2.351587   \n",
       "3      1.117538 -26.776285  -9.033010 -18.285458   5.542378   1.801108   \n",
       "4     -7.823933  16.233910   1.511278  -1.097624  -4.256559   5.822567   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "2133  -0.477651 -18.703012 -15.582651  -1.840943 -12.552829  -8.802483   \n",
       "2134   4.090911  10.306094   2.037651   0.225633   1.150143   1.580174   \n",
       "2135 -13.102000  20.879627  -8.502631   6.002625  12.753398   2.869624   \n",
       "2136  20.903921  -4.221878 -11.789002   8.365523  -4.948959 -10.440193   \n",
       "2137  -2.578697   4.493932   0.366728   5.716188   3.348301  -2.878420   \n",
       "\n",
       "        mfcc_13  English Type  \n",
       "0     -0.177087             0  \n",
       "1     -2.269287             0  \n",
       "2    -14.914782             0  \n",
       "3    -12.343457             1  \n",
       "4     -5.417769             0  \n",
       "...         ...           ...  \n",
       "2133  -3.864208             1  \n",
       "2134  -2.241047             0  \n",
       "2135  -1.761060             0  \n",
       "2136  -3.944272             0  \n",
       "2137   5.174947             0  \n",
       "\n",
       "[2138 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the features from the CSV file\n",
    "df = pd.read_csv(r'Original_Features6.csv')\n",
    "df=df.drop(['rolloff','zero_crossing_rate','chroma_stft','spectral_centroid','spectral_bandwidth'],axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d99f810",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,0:13]\n",
    "y = df.iloc[:,13]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "101a0a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1710, 13) (1710,)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(X_train.shape,y_train.shape)\n",
    "\n",
    "# scale data\n",
    "t = MinMaxScaler()\n",
    "t.fit(X_train)\n",
    "X_train = t.transform(X_train)\n",
    "X_test = t.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2516a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the input features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "889ff4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "43/43 [==============================] - 1s 10ms/step - loss: 1.1292 - val_loss: 1.0364\n",
      "Epoch 2/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.9368 - val_loss: 0.8959\n",
      "Epoch 3/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.8315 - val_loss: 0.8216\n",
      "Epoch 4/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.7718 - val_loss: 0.7755\n",
      "Epoch 5/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.7339 - val_loss: 0.7451\n",
      "Epoch 6/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.7082 - val_loss: 0.7232\n",
      "Epoch 7/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6890 - val_loss: 0.7064\n",
      "Epoch 8/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6739 - val_loss: 0.6928\n",
      "Epoch 9/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6615 - val_loss: 0.6814\n",
      "Epoch 10/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6512 - val_loss: 0.6720\n",
      "Epoch 11/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6427 - val_loss: 0.6641\n",
      "Epoch 12/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6356 - val_loss: 0.6574\n",
      "Epoch 13/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6297 - val_loss: 0.6519\n",
      "Epoch 14/1500\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.6247 - val_loss: 0.6471\n",
      "Epoch 15/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6204 - val_loss: 0.6429\n",
      "Epoch 16/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6167 - val_loss: 0.6393\n",
      "Epoch 17/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6135 - val_loss: 0.6362\n",
      "Epoch 18/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6107 - val_loss: 0.6334\n",
      "Epoch 19/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6083 - val_loss: 0.6310\n",
      "Epoch 20/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6062 - val_loss: 0.6288\n",
      "Epoch 21/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6043 - val_loss: 0.6269\n",
      "Epoch 22/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6027 - val_loss: 0.6252\n",
      "Epoch 23/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6013 - val_loss: 0.6237\n",
      "Epoch 24/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6000 - val_loss: 0.6224\n",
      "Epoch 25/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5988 - val_loss: 0.6212\n",
      "Epoch 26/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5978 - val_loss: 0.6201\n",
      "Epoch 27/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5969 - val_loss: 0.6192\n",
      "Epoch 28/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5961 - val_loss: 0.6183\n",
      "Epoch 29/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5953 - val_loss: 0.6176\n",
      "Epoch 30/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5947 - val_loss: 0.6169\n",
      "Epoch 31/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5941 - val_loss: 0.6162\n",
      "Epoch 32/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5935 - val_loss: 0.6157\n",
      "Epoch 33/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5930 - val_loss: 0.6151\n",
      "Epoch 34/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5926 - val_loss: 0.6147\n",
      "Epoch 35/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5921 - val_loss: 0.6142\n",
      "Epoch 36/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5918 - val_loss: 0.6138\n",
      "Epoch 37/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5914 - val_loss: 0.6135\n",
      "Epoch 38/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5911 - val_loss: 0.6131\n",
      "Epoch 39/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5908 - val_loss: 0.6128\n",
      "Epoch 40/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5905 - val_loss: 0.6125\n",
      "Epoch 41/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5902 - val_loss: 0.6123\n",
      "Epoch 42/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5900 - val_loss: 0.6120\n",
      "Epoch 43/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5898 - val_loss: 0.6118\n",
      "Epoch 44/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5896 - val_loss: 0.6116\n",
      "Epoch 45/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5894 - val_loss: 0.6114\n",
      "Epoch 46/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5892 - val_loss: 0.6112\n",
      "Epoch 47/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5890 - val_loss: 0.6110\n",
      "Epoch 48/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5889 - val_loss: 0.6109\n",
      "Epoch 49/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5887 - val_loss: 0.6107\n",
      "Epoch 50/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5886 - val_loss: 0.6105\n",
      "Epoch 51/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5884 - val_loss: 0.6104\n",
      "Epoch 52/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5883 - val_loss: 0.6103\n",
      "Epoch 53/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5882 - val_loss: 0.6102\n",
      "Epoch 54/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5881 - val_loss: 0.6101\n",
      "Epoch 55/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5880 - val_loss: 0.6099\n",
      "Epoch 56/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5879 - val_loss: 0.6098\n",
      "Epoch 57/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5878 - val_loss: 0.6097\n",
      "Epoch 58/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5877 - val_loss: 0.6096\n",
      "Epoch 59/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5876 - val_loss: 0.6095\n",
      "Epoch 60/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5875 - val_loss: 0.6095\n",
      "Epoch 61/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5874 - val_loss: 0.6094\n",
      "Epoch 62/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5874 - val_loss: 0.6093\n",
      "Epoch 63/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5873 - val_loss: 0.6092\n",
      "Epoch 64/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5872 - val_loss: 0.6091\n",
      "Epoch 65/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5872 - val_loss: 0.6091\n",
      "Epoch 66/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5871 - val_loss: 0.6090\n",
      "Epoch 67/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5870 - val_loss: 0.6089\n",
      "Epoch 68/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5870 - val_loss: 0.6089\n",
      "Epoch 69/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5869 - val_loss: 0.6088\n",
      "Epoch 70/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5869 - val_loss: 0.6088\n",
      "Epoch 71/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5868 - val_loss: 0.6087\n",
      "Epoch 72/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5868 - val_loss: 0.6087\n",
      "Epoch 73/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5867 - val_loss: 0.6086\n",
      "Epoch 74/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5867 - val_loss: 0.6085\n",
      "Epoch 75/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5866 - val_loss: 0.6085\n",
      "Epoch 76/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5866 - val_loss: 0.6085\n",
      "Epoch 77/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5865 - val_loss: 0.6084\n",
      "Epoch 78/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5865 - val_loss: 0.6084\n",
      "Epoch 79/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5865 - val_loss: 0.6083\n",
      "Epoch 80/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5864 - val_loss: 0.6083\n",
      "Epoch 81/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5864 - val_loss: 0.6082\n",
      "Epoch 82/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5864 - val_loss: 0.6082\n",
      "Epoch 83/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5863 - val_loss: 0.6082\n",
      "Epoch 84/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5863 - val_loss: 0.6082\n",
      "Epoch 85/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5863 - val_loss: 0.6081\n",
      "Epoch 86/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5862 - val_loss: 0.6082\n",
      "Epoch 87/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5862 - val_loss: 0.6081\n",
      "Epoch 88/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5862 - val_loss: 0.6080\n",
      "Epoch 89/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5861 - val_loss: 0.6080\n",
      "Epoch 90/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5861 - val_loss: 0.6080\n",
      "Epoch 91/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5861 - val_loss: 0.6080\n",
      "Epoch 92/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5861 - val_loss: 0.6079\n",
      "Epoch 93/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5860 - val_loss: 0.6080\n",
      "Epoch 94/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5860 - val_loss: 0.6079\n",
      "Epoch 95/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5860 - val_loss: 0.6079\n",
      "Epoch 96/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5860 - val_loss: 0.6078\n",
      "Epoch 97/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5860 - val_loss: 0.6079\n",
      "Epoch 98/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5859 - val_loss: 0.6078\n",
      "Epoch 99/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5859 - val_loss: 0.6078\n",
      "Epoch 100/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5859 - val_loss: 0.6078\n",
      "Epoch 101/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5859 - val_loss: 0.6078\n",
      "Epoch 102/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5859 - val_loss: 0.6077\n",
      "Epoch 103/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5858 - val_loss: 0.6077\n",
      "Epoch 104/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5858 - val_loss: 0.6077\n",
      "Epoch 105/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5858 - val_loss: 0.6077\n",
      "Epoch 106/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5858 - val_loss: 0.6077\n",
      "Epoch 107/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5858 - val_loss: 0.6076\n",
      "Epoch 108/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5858 - val_loss: 0.6076\n",
      "Epoch 109/1500\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.5857 - val_loss: 0.6076\n",
      "Epoch 110/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5857 - val_loss: 0.6076\n",
      "Epoch 111/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5857 - val_loss: 0.6076\n",
      "Epoch 112/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5857 - val_loss: 0.6076\n",
      "Epoch 113/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5857 - val_loss: 0.6076\n",
      "Epoch 114/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5857 - val_loss: 0.6075\n",
      "Epoch 115/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5857 - val_loss: 0.6076\n",
      "Epoch 116/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5856 - val_loss: 0.6075\n",
      "Epoch 117/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5856 - val_loss: 0.6075\n",
      "Epoch 118/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5856 - val_loss: 0.6075\n",
      "Epoch 119/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5856 - val_loss: 0.6075\n",
      "Epoch 120/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5856 - val_loss: 0.6075\n",
      "Epoch 121/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5856 - val_loss: 0.6075\n",
      "Epoch 122/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5856 - val_loss: 0.6075\n",
      "Epoch 123/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5856 - val_loss: 0.6075\n",
      "Epoch 124/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5856 - val_loss: 0.6074\n",
      "Epoch 125/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5855 - val_loss: 0.6074\n",
      "Epoch 126/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5855 - val_loss: 0.6074\n",
      "Epoch 127/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5855 - val_loss: 0.6074\n",
      "Epoch 128/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5855 - val_loss: 0.6074\n",
      "Epoch 129/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5855 - val_loss: 0.6074\n",
      "Epoch 130/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5855 - val_loss: 0.6074\n",
      "Epoch 131/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5855 - val_loss: 0.6073\n",
      "Epoch 132/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5855 - val_loss: 0.6074\n",
      "Epoch 133/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5855 - val_loss: 0.6073\n",
      "Epoch 134/1500\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.5855 - val_loss: 0.6074\n",
      "Epoch 135/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5854 - val_loss: 0.6073\n",
      "Epoch 136/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5854 - val_loss: 0.6073\n",
      "Epoch 137/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5854 - val_loss: 0.6073\n",
      "Epoch 138/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5854 - val_loss: 0.6073\n",
      "Epoch 139/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5854 - val_loss: 0.6073\n",
      "Epoch 140/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5854 - val_loss: 0.6073\n",
      "Epoch 141/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5854 - val_loss: 0.6073\n",
      "Epoch 142/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5854 - val_loss: 0.6072\n",
      "Epoch 143/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5854 - val_loss: 0.6072\n",
      "Epoch 144/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5854 - val_loss: 0.6072\n",
      "Epoch 145/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5854 - val_loss: 0.6073\n",
      "Epoch 146/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5854 - val_loss: 0.6072\n",
      "Epoch 147/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5854 - val_loss: 0.6072\n",
      "Epoch 148/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5853 - val_loss: 0.6072\n",
      "Epoch 149/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5853 - val_loss: 0.6072\n",
      "Epoch 150/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5853 - val_loss: 0.6072\n",
      "Epoch 151/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5853 - val_loss: 0.6072\n",
      "Epoch 152/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5853 - val_loss: 0.6072\n",
      "Epoch 153/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5853 - val_loss: 0.6072\n",
      "Epoch 154/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5853 - val_loss: 0.6072\n",
      "Epoch 155/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5853 - val_loss: 0.6072\n",
      "Epoch 156/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5853 - val_loss: 0.6072\n",
      "Epoch 157/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5853 - val_loss: 0.6072\n",
      "Epoch 158/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5853 - val_loss: 0.6071\n",
      "Epoch 159/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5853 - val_loss: 0.6072\n",
      "Epoch 160/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5853 - val_loss: 0.6071\n",
      "Epoch 161/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5853 - val_loss: 0.6071\n",
      "Epoch 162/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5852 - val_loss: 0.6071\n",
      "Epoch 163/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5852 - val_loss: 0.6072\n",
      "Epoch 164/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5852 - val_loss: 0.6071\n",
      "Epoch 165/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5852 - val_loss: 0.6071\n",
      "Epoch 166/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5852 - val_loss: 0.6071\n",
      "Epoch 167/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5852 - val_loss: 0.6071\n",
      "Epoch 168/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5852 - val_loss: 0.6071\n",
      "Epoch 169/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5852 - val_loss: 0.6071\n",
      "Epoch 170/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5852 - val_loss: 0.6071\n",
      "Epoch 171/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5852 - val_loss: 0.6070\n",
      "Epoch 172/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5852 - val_loss: 0.6071\n",
      "Epoch 173/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5852 - val_loss: 0.6070\n",
      "Epoch 174/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5852 - val_loss: 0.6070\n",
      "Epoch 175/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5852 - val_loss: 0.6070\n",
      "Epoch 176/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5852 - val_loss: 0.6070\n",
      "Epoch 177/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5852 - val_loss: 0.6070\n",
      "Epoch 178/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5852 - val_loss: 0.6070\n",
      "Epoch 179/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5851 - val_loss: 0.6070\n",
      "Epoch 180/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5851 - val_loss: 0.6070\n",
      "Epoch 181/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5851 - val_loss: 0.6070\n",
      "Epoch 182/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5851 - val_loss: 0.6070\n",
      "Epoch 183/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5851 - val_loss: 0.6070\n",
      "Epoch 184/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5851 - val_loss: 0.6070\n",
      "Epoch 185/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5851 - val_loss: 0.6070\n",
      "Epoch 186/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5851 - val_loss: 0.6070\n",
      "Epoch 187/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5851 - val_loss: 0.6070\n",
      "Epoch 188/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5851 - val_loss: 0.6070\n",
      "Epoch 189/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5851 - val_loss: 0.6070\n",
      "Epoch 190/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5851 - val_loss: 0.6070\n",
      "Epoch 191/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5851 - val_loss: 0.6070\n",
      "Epoch 192/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5851 - val_loss: 0.6070\n",
      "Epoch 193/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5851 - val_loss: 0.6069\n",
      "Epoch 194/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5851 - val_loss: 0.6069\n",
      "Epoch 195/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5851 - val_loss: 0.6070\n",
      "Epoch 196/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5851 - val_loss: 0.6069\n",
      "Epoch 197/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5851 - val_loss: 0.6070\n",
      "Epoch 198/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5851 - val_loss: 0.6069\n",
      "Epoch 199/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5851 - val_loss: 0.6069\n",
      "Epoch 200/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5850 - val_loss: 0.6069\n",
      "Epoch 201/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5850 - val_loss: 0.6069\n",
      "Epoch 202/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5850 - val_loss: 0.6069\n",
      "Epoch 203/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5850 - val_loss: 0.6069\n",
      "Epoch 204/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5850 - val_loss: 0.6069\n",
      "Epoch 205/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5850 - val_loss: 0.6069\n",
      "Epoch 206/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5850 - val_loss: 0.6069\n",
      "Epoch 207/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5850 - val_loss: 0.6069\n",
      "Epoch 208/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5850 - val_loss: 0.6069\n",
      "Epoch 209/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5850 - val_loss: 0.6069\n",
      "Epoch 210/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5850 - val_loss: 0.6069\n",
      "Epoch 211/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5850 - val_loss: 0.6069\n",
      "Epoch 212/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5850 - val_loss: 0.6068\n",
      "Epoch 213/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5850 - val_loss: 0.6069\n",
      "Epoch 214/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5850 - val_loss: 0.6069\n",
      "Epoch 215/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5850 - val_loss: 0.6069\n",
      "Epoch 216/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5850 - val_loss: 0.6069\n",
      "Epoch 217/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5850 - val_loss: 0.6069\n",
      "Epoch 218/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5850 - val_loss: 0.6068\n",
      "Epoch 219/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5850 - val_loss: 0.6069\n",
      "Epoch 220/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5850 - val_loss: 0.6069\n",
      "Epoch 221/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5850 - val_loss: 0.6069\n",
      "Epoch 222/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5850 - val_loss: 0.6069\n",
      "Epoch 223/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5850 - val_loss: 0.6068\n",
      "Epoch 224/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5850 - val_loss: 0.6068\n",
      "Epoch 225/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5850 - val_loss: 0.6068\n",
      "Epoch 226/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5850 - val_loss: 0.6068\n",
      "Epoch 227/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5850 - val_loss: 0.6068\n",
      "Epoch 228/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5850 - val_loss: 0.6068\n",
      "Epoch 229/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5850 - val_loss: 0.6068\n",
      "Epoch 230/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5850 - val_loss: 0.6068\n",
      "Epoch 231/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5850 - val_loss: 0.6068\n",
      "Epoch 232/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5850 - val_loss: 0.6068\n",
      "Epoch 233/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5850 - val_loss: 0.6068\n",
      "Epoch 234/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5850 - val_loss: 0.6068\n",
      "Epoch 235/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5850 - val_loss: 0.6068\n",
      "Epoch 236/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5850 - val_loss: 0.6068\n",
      "Epoch 237/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5850 - val_loss: 0.6068\n",
      "Epoch 238/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5850 - val_loss: 0.6068\n",
      "Epoch 239/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5850 - val_loss: 0.6068\n",
      "Epoch 240/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5849 - val_loss: 0.6068\n",
      "Epoch 241/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5849 - val_loss: 0.6068\n",
      "Epoch 242/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5849 - val_loss: 0.6068\n",
      "Epoch 243/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5850 - val_loss: 0.6068\n",
      "Epoch 244/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5849 - val_loss: 0.6068\n",
      "Epoch 245/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5849 - val_loss: 0.6068\n",
      "Epoch 246/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5849 - val_loss: 0.6068\n",
      "Epoch 247/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5850 - val_loss: 0.6068\n",
      "Epoch 248/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5849 - val_loss: 0.6067\n",
      "Epoch 249/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5849 - val_loss: 0.6068\n",
      "Epoch 250/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5849 - val_loss: 0.6068\n",
      "Epoch 251/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5849 - val_loss: 0.6067\n",
      "Epoch 252/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5849 - val_loss: 0.6068\n",
      "Epoch 253/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5849 - val_loss: 0.6068\n",
      "Epoch 254/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5849 - val_loss: 0.6068\n",
      "Epoch 255/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5849 - val_loss: 0.6068\n",
      "Epoch 256/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5849 - val_loss: 0.6068\n",
      "Epoch 257/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5849 - val_loss: 0.6067\n",
      "Epoch 258/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5849 - val_loss: 0.6068\n",
      "Epoch 259/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5849 - val_loss: 0.6067\n",
      "Epoch 260/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5849 - val_loss: 0.6067\n",
      "Epoch 261/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5849 - val_loss: 0.6068\n",
      "Epoch 262/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5849 - val_loss: 0.6068\n",
      "Epoch 263/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5849 - val_loss: 0.6067\n",
      "Epoch 264/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5849 - val_loss: 0.6067\n",
      "Epoch 265/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5849 - val_loss: 0.6067\n",
      "Epoch 266/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5849 - val_loss: 0.6067\n",
      "Epoch 267/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5849 - val_loss: 0.6068\n",
      "Epoch 268/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5849 - val_loss: 0.6067\n",
      "Epoch 269/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5849 - val_loss: 0.6067\n",
      "Epoch 270/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5849 - val_loss: 0.6067\n",
      "Epoch 271/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5849 - val_loss: 0.6068\n",
      "Epoch 272/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5849 - val_loss: 0.6067\n",
      "Epoch 273/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5849 - val_loss: 0.6067\n",
      "Epoch 274/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5849 - val_loss: 0.6067\n",
      "Epoch 275/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5849 - val_loss: 0.6067\n",
      "Epoch 276/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5849 - val_loss: 0.6067\n",
      "Epoch 277/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5849 - val_loss: 0.6067\n",
      "Epoch 278/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5849 - val_loss: 0.6067\n",
      "Epoch 279/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5849 - val_loss: 0.6067\n",
      "Epoch 280/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5849 - val_loss: 0.6067\n",
      "Epoch 281/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5849 - val_loss: 0.6067\n",
      "Epoch 282/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5849 - val_loss: 0.6067\n",
      "Epoch 283/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5849 - val_loss: 0.6067\n",
      "Epoch 284/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5849 - val_loss: 0.6067\n",
      "Epoch 285/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5849 - val_loss: 0.6067\n",
      "Epoch 286/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5849 - val_loss: 0.6067\n",
      "Epoch 287/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5849 - val_loss: 0.6067\n",
      "Epoch 288/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5849 - val_loss: 0.6067\n",
      "Epoch 289/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5848 - val_loss: 0.6067\n",
      "Epoch 290/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5848 - val_loss: 0.6067\n",
      "Epoch 291/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5849 - val_loss: 0.6066\n",
      "Epoch 292/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5849 - val_loss: 0.6067\n",
      "Epoch 293/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5849 - val_loss: 0.6067\n",
      "Epoch 294/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5848 - val_loss: 0.6067\n",
      "Epoch 295/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5849 - val_loss: 0.6067\n",
      "Epoch 296/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5849 - val_loss: 0.6066\n",
      "Epoch 297/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5848 - val_loss: 0.6066\n",
      "Epoch 298/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5848 - val_loss: 0.6066\n",
      "Epoch 299/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5848 - val_loss: 0.6066\n",
      "Epoch 300/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5848 - val_loss: 0.6067\n",
      "Epoch 301/1500\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.5848 - val_loss: 0.6066\n",
      "Epoch 302/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5848 - val_loss: 0.6067\n",
      "Epoch 303/1500\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.5848 - val_loss: 0.6067\n",
      "Epoch 304/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5848 - val_loss: 0.6067\n",
      "Epoch 305/1500\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.5848 - val_loss: 0.6067\n",
      "Epoch 306/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5848 - val_loss: 0.6067\n",
      "Epoch 307/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5848 - val_loss: 0.6067\n",
      "Epoch 308/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5848 - val_loss: 0.6067\n",
      "Epoch 309/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5848 - val_loss: 0.6067\n",
      "Epoch 310/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5848 - val_loss: 0.6066\n",
      "Epoch 311/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5848 - val_loss: 0.6067\n",
      "Epoch 312/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5848 - val_loss: 0.6066\n",
      "Epoch 313/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5848 - val_loss: 0.6066\n",
      "Epoch 314/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5848 - val_loss: 0.6066\n",
      "Epoch 315/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5848 - val_loss: 0.6066\n",
      "Epoch 316/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5848 - val_loss: 0.6066\n",
      "Epoch 317/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5848 - val_loss: 0.6066\n",
      "Epoch 318/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5848 - val_loss: 0.6066\n",
      "Epoch 319/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5848 - val_loss: 0.6066\n",
      "Epoch 320/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5848 - val_loss: 0.6066\n",
      "Epoch 321/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5848 - val_loss: 0.6066\n",
      "Epoch 322/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5848 - val_loss: 0.6066\n",
      "Epoch 323/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5848 - val_loss: 0.6066\n",
      "Epoch 324/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5848 - val_loss: 0.6066\n",
      "Epoch 325/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5848 - val_loss: 0.6066\n",
      "Epoch 326/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5848 - val_loss: 0.6066\n",
      "Epoch 327/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5848 - val_loss: 0.6067\n",
      "Epoch 328/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5848 - val_loss: 0.6067\n",
      "Epoch 329/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5848 - val_loss: 0.6066\n",
      "Epoch 330/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5848 - val_loss: 0.6066\n",
      "Epoch 331/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5848 - val_loss: 0.6066\n",
      "Epoch 332/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5848 - val_loss: 0.6066\n",
      "Epoch 333/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5848 - val_loss: 0.6066\n",
      "Epoch 334/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5848 - val_loss: 0.6066\n",
      "Epoch 335/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5848 - val_loss: 0.6066\n",
      "Epoch 336/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5848 - val_loss: 0.6066\n",
      "Epoch 337/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5848 - val_loss: 0.6066\n",
      "Epoch 338/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5848 - val_loss: 0.6066\n",
      "Epoch 339/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5848 - val_loss: 0.6066\n",
      "Epoch 340/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5848 - val_loss: 0.6066\n",
      "Epoch 341/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5848 - val_loss: 0.6066\n",
      "Epoch 342/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5848 - val_loss: 0.6066\n",
      "Epoch 343/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5848 - val_loss: 0.6066\n",
      "Epoch 344/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5848 - val_loss: 0.6066\n",
      "Epoch 345/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5848 - val_loss: 0.6066\n",
      "Epoch 346/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5848 - val_loss: 0.6066\n",
      "Epoch 347/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5848 - val_loss: 0.6066\n",
      "Epoch 348/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5848 - val_loss: 0.6066\n",
      "Epoch 349/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5848 - val_loss: 0.6066\n",
      "Epoch 350/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5848 - val_loss: 0.6066\n",
      "Epoch 351/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5848 - val_loss: 0.6066\n",
      "Epoch 352/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5848 - val_loss: 0.6066\n",
      "Epoch 353/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5848 - val_loss: 0.6066\n",
      "Epoch 354/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5848 - val_loss: 0.6066\n",
      "Epoch 355/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5848 - val_loss: 0.6066\n",
      "Epoch 356/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5848 - val_loss: 0.6066\n",
      "Epoch 357/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5848 - val_loss: 0.6066\n",
      "Epoch 358/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5848 - val_loss: 0.6066\n",
      "Epoch 359/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6066\n",
      "Epoch 360/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5848 - val_loss: 0.6066\n",
      "Epoch 361/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5848 - val_loss: 0.6066\n",
      "Epoch 362/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5848 - val_loss: 0.6066\n",
      "Epoch 363/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5848 - val_loss: 0.6066\n",
      "Epoch 364/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5848 - val_loss: 0.6065\n",
      "Epoch 365/1500\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.5848 - val_loss: 0.6066\n",
      "Epoch 366/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5848 - val_loss: 0.6066\n",
      "Epoch 367/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5848 - val_loss: 0.6066\n",
      "Epoch 368/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5848 - val_loss: 0.6066\n",
      "Epoch 369/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5848 - val_loss: 0.6066\n",
      "Epoch 370/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5848 - val_loss: 0.6066\n",
      "Epoch 371/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5848 - val_loss: 0.6066\n",
      "Epoch 372/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5848 - val_loss: 0.6066\n",
      "Epoch 373/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5848 - val_loss: 0.6066\n",
      "Epoch 374/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6066\n",
      "Epoch 375/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 376/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5847 - val_loss: 0.6066\n",
      "Epoch 377/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5848 - val_loss: 0.6066\n",
      "Epoch 378/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 379/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 380/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5847 - val_loss: 0.6066\n",
      "Epoch 381/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6066\n",
      "Epoch 382/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6066\n",
      "Epoch 383/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 384/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6066\n",
      "Epoch 385/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 386/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 387/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6066\n",
      "Epoch 388/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 389/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 390/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 391/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6066\n",
      "Epoch 392/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6066\n",
      "Epoch 393/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6066\n",
      "Epoch 394/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 395/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 396/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6066\n",
      "Epoch 397/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 398/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6066\n",
      "Epoch 399/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5847 - val_loss: 0.6066\n",
      "Epoch 400/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 401/1500\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 402/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 403/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 404/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 405/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 406/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 407/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 408/1500\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 409/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 410/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 411/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6066\n",
      "Epoch 412/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 413/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 414/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 415/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 416/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 417/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 418/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6066\n",
      "Epoch 419/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 420/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 421/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 422/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 423/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 424/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 425/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 426/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 427/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 428/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 429/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 430/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 431/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 432/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 433/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 434/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 435/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 436/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 437/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 438/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 439/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 440/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 441/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 442/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 443/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 444/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 445/1500\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 446/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 447/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 448/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 449/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 450/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 451/1500\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 452/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 453/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 454/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 455/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 456/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 457/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 458/1500\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 459/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 460/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 461/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 462/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 463/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 464/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 465/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 466/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 467/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 468/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 469/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 470/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 471/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5847 - val_loss: 0.6064\n",
      "Epoch 472/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5847 - val_loss: 0.6064\n",
      "Epoch 473/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6064\n",
      "Epoch 474/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5847 - val_loss: 0.6064\n",
      "Epoch 475/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6064\n",
      "Epoch 476/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6064\n",
      "Epoch 477/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 478/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6064\n",
      "Epoch 479/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6064\n",
      "Epoch 480/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6064\n",
      "Epoch 481/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6064\n",
      "Epoch 482/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6064\n",
      "Epoch 483/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 484/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 485/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6064\n",
      "Epoch 486/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6064\n",
      "Epoch 487/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 488/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5847 - val_loss: 0.6064\n",
      "Epoch 489/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6064\n",
      "Epoch 490/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5847 - val_loss: 0.6064\n",
      "Epoch 491/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6064\n",
      "Epoch 492/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5847 - val_loss: 0.6064\n",
      "Epoch 493/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 494/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 495/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5847 - val_loss: 0.6064\n",
      "Epoch 496/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 497/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5847 - val_loss: 0.6064\n",
      "Epoch 498/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6064\n",
      "Epoch 499/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 500/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5847 - val_loss: 0.6065\n",
      "Epoch 501/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5847 - val_loss: 0.6064\n",
      "Epoch 502/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5847 - val_loss: 0.6064\n",
      "Epoch 503/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5847 - val_loss: 0.6064\n",
      "Epoch 504/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5847 - val_loss: 0.6064\n",
      "Epoch 505/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 506/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 507/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6064\n",
      "Epoch 508/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5847 - val_loss: 0.6064\n",
      "Epoch 509/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6064\n",
      "Epoch 510/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5847 - val_loss: 0.6064\n",
      "Epoch 511/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 512/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 513/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 514/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 515/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 516/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5847 - val_loss: 0.6064\n",
      "Epoch 517/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 518/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5847 - val_loss: 0.6064\n",
      "Epoch 519/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 520/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 521/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 522/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 523/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 524/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 525/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 526/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 527/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 528/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 529/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 530/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 531/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 532/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 533/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 534/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 535/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 536/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 537/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 538/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 539/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 540/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 541/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 542/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 543/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 544/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 545/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 546/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 547/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 548/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 549/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 550/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 551/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 552/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 553/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 554/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 555/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 556/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 557/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 558/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 559/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 560/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 561/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 562/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 563/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 564/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 565/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 566/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 567/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 568/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 569/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 570/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 571/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 572/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 573/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 574/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 575/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 576/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 577/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 578/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 579/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 580/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 581/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 582/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 583/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 584/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 585/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 586/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 587/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 588/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 589/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 590/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 591/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 592/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 593/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 594/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 595/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 596/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 597/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 598/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 599/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 600/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 601/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 602/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 603/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 604/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 605/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 606/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 607/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 608/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 609/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 610/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 611/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 612/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 613/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 614/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 615/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 616/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 617/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 618/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 619/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 620/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 621/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 622/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 623/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 624/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 625/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 626/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 627/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 628/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 629/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 630/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 631/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 632/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 633/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 634/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 635/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 636/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 637/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 638/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 639/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 640/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 641/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 642/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 643/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 644/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 645/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 646/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 647/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 648/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 649/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 650/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 651/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 652/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 653/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 654/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 655/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 656/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 657/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 658/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 659/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 660/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 661/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 662/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 663/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 664/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 665/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 666/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 667/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 668/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 669/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 670/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 671/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 672/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 673/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 674/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 675/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 676/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 677/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 678/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 679/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 680/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 681/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 682/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 683/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 684/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 685/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 686/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 687/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 688/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 689/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 690/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 691/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 692/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 693/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 694/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 695/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 696/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 697/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 698/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 699/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 700/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 701/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 702/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 703/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 704/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 705/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 706/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 707/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 708/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 709/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 710/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6064\n",
      "Epoch 711/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 712/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 713/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 714/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 715/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 716/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 717/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 718/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 719/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 720/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 721/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 722/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 723/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 724/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 725/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 726/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 727/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 728/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 729/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 730/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 731/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 732/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 733/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 734/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6064\n",
      "Epoch 735/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 736/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 737/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 738/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 739/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 740/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 741/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 742/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 743/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 744/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 745/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 746/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 747/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 748/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 749/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 750/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 751/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 752/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 753/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 754/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 755/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 756/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 757/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 758/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 759/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 760/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 761/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 762/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 763/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 764/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 765/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5846 - val_loss: 0.6063\n",
      "Epoch 766/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 767/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 768/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 769/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 770/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 771/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 772/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 773/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 774/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 775/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 776/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 777/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 778/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 779/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 780/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 781/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 782/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 783/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 784/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 785/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 786/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 787/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 788/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 789/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 790/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 791/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 792/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 793/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 794/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 795/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 796/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 797/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 798/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 799/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 800/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 801/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 802/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 803/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 804/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 805/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 806/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 807/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 808/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 809/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 810/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 811/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 812/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 813/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 814/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 815/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 816/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 817/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 818/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 819/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 820/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 821/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 822/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 823/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 824/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 825/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 826/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 827/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 828/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 829/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 830/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 831/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 832/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 833/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 834/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 835/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 836/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 837/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 838/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 839/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 840/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 841/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 842/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 843/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 844/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 845/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 846/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 847/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 848/1500\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 849/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 850/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 851/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 852/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 853/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 854/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 855/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 856/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 857/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 858/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 859/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 860/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 861/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 862/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 863/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 864/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 865/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 866/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 867/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 868/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 869/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 870/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 871/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 872/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 873/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 874/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 875/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 876/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 877/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 878/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 879/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 880/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 881/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 882/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 883/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 884/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 885/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 886/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 887/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 888/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 889/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 890/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 891/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 892/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 893/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 894/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 895/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 896/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 897/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 898/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 899/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 900/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 901/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 902/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 903/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 904/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 905/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 906/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 907/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 908/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 909/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 910/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 911/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 912/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 913/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 914/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 915/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 916/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 917/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 918/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 919/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 920/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 921/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 922/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 923/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 924/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 925/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 926/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 927/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 928/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 929/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 930/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 931/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 932/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 933/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 934/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 935/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 936/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 937/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 938/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 939/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 940/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 941/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 942/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 943/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 944/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 945/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 946/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 947/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 948/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6062\n",
      "Epoch 949/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6062\n",
      "Epoch 950/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 951/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 952/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 953/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 954/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 955/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 956/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 957/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 958/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 959/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 960/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 961/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 962/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 963/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 964/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 965/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 966/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 967/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 968/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 969/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 970/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 971/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 972/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 973/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 974/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 975/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 976/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 977/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 978/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 979/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 980/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 981/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 982/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 983/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 984/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 985/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 986/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6062\n",
      "Epoch 987/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 988/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 989/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 990/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 991/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 992/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 993/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 994/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 995/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 996/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 997/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 998/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 999/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1000/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1001/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1002/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1003/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1004/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1005/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1006/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1007/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1008/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1009/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1010/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6062\n",
      "Epoch 1011/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6062\n",
      "Epoch 1012/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1013/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1014/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1015/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1016/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1017/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1018/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1019/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1020/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1021/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1022/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1023/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1024/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6062\n",
      "Epoch 1025/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1026/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6062\n",
      "Epoch 1027/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1028/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1029/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1030/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1031/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6062\n",
      "Epoch 1032/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1033/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1034/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1035/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1036/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1037/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1038/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1039/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6062\n",
      "Epoch 1040/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6062\n",
      "Epoch 1041/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1042/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1043/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1044/1500\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1045/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6062\n",
      "Epoch 1046/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6062\n",
      "Epoch 1047/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1048/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1049/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1050/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1051/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1052/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1053/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1054/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1055/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1056/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6062\n",
      "Epoch 1057/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1058/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1059/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1060/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1061/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6062\n",
      "Epoch 1062/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1063/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1064/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1065/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1066/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6062\n",
      "Epoch 1067/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1068/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1069/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1070/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6062\n",
      "Epoch 1071/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6062\n",
      "Epoch 1072/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6062\n",
      "Epoch 1073/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1074/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6062\n",
      "Epoch 1075/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1076/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1077/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6062\n",
      "Epoch 1078/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6062\n",
      "Epoch 1079/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1080/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6062\n",
      "Epoch 1081/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1082/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1083/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1084/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6062\n",
      "Epoch 1085/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1086/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6062\n",
      "Epoch 1087/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6062\n",
      "Epoch 1088/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1089/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6062\n",
      "Epoch 1090/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6062\n",
      "Epoch 1091/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1092/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1093/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1094/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1095/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6062\n",
      "Epoch 1096/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6062\n",
      "Epoch 1097/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1098/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1099/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1100/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1101/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1102/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1103/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1104/1500\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1105/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1106/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1107/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1108/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6062\n",
      "Epoch 1109/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1110/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1111/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1112/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1113/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6062\n",
      "Epoch 1114/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1115/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1116/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1117/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1118/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6062\n",
      "Epoch 1119/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1120/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6062\n",
      "Epoch 1121/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1122/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1123/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1124/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1125/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1126/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1127/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1128/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1129/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1130/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1131/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1132/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1133/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6062\n",
      "Epoch 1134/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1135/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1136/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1137/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1138/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1139/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1140/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1141/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1142/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1143/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1144/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1145/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6062\n",
      "Epoch 1146/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1147/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6062\n",
      "Epoch 1148/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1149/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1150/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6062\n",
      "Epoch 1151/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1152/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6062\n",
      "Epoch 1153/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1154/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1155/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1156/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6062\n",
      "Epoch 1157/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1158/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1159/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1160/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6062\n",
      "Epoch 1161/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1162/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1163/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6062\n",
      "Epoch 1164/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1165/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1166/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1167/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6062\n",
      "Epoch 1168/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1169/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1170/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1171/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1172/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1173/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6062\n",
      "Epoch 1174/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6062\n",
      "Epoch 1175/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1176/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1177/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1178/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1179/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6062\n",
      "Epoch 1180/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1181/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6062\n",
      "Epoch 1182/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1183/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1184/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1185/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1186/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1187/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6062\n",
      "Epoch 1188/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1189/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1190/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1191/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1192/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1193/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1194/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1195/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1196/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1197/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1198/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6062\n",
      "Epoch 1199/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1200/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6062\n",
      "Epoch 1201/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6062\n",
      "Epoch 1202/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1203/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1204/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6062\n",
      "Epoch 1205/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1206/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1207/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1208/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1209/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1210/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1211/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1212/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1213/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1214/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1215/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1216/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1217/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6062\n",
      "Epoch 1218/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1219/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1220/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1221/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1222/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6062\n",
      "Epoch 1223/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1224/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1225/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1226/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1227/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6062\n",
      "Epoch 1228/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1229/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6062\n",
      "Epoch 1230/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6062\n",
      "Epoch 1231/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1232/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1233/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6062\n",
      "Epoch 1234/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1235/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1236/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1237/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6062\n",
      "Epoch 1238/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6062\n",
      "Epoch 1239/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1240/1500\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1241/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1242/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1243/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1244/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1245/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1246/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1247/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1248/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1249/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1250/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1251/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1252/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1253/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1254/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1255/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1256/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1257/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1258/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1259/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1260/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6062\n",
      "Epoch 1261/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1262/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1263/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1264/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1265/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1266/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6062\n",
      "Epoch 1267/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1268/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1269/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1270/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6062\n",
      "Epoch 1271/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1272/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1273/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1274/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1275/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6062\n",
      "Epoch 1276/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1277/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1278/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1279/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1280/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1281/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1282/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6062\n",
      "Epoch 1283/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1284/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1285/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1286/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1287/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1288/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6062\n",
      "Epoch 1289/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1290/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6062\n",
      "Epoch 1291/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1292/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1293/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1294/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1295/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1296/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1297/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1298/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6062\n",
      "Epoch 1299/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1300/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1301/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1302/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1303/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6062\n",
      "Epoch 1304/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6062\n",
      "Epoch 1305/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1306/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1307/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1308/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6062\n",
      "Epoch 1309/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1310/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1311/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1312/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6062\n",
      "Epoch 1313/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1314/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6062\n",
      "Epoch 1315/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1316/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1317/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6062\n",
      "Epoch 1318/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1319/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1320/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1321/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1322/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1323/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1324/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1325/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1326/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1327/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1328/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1329/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1330/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1331/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1332/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1333/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1334/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1335/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6062\n",
      "Epoch 1336/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1337/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1338/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6062\n",
      "Epoch 1339/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1340/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1341/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1342/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1343/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1344/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1345/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1346/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1347/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1348/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1349/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1350/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1351/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1352/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6062\n",
      "Epoch 1353/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1354/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1355/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6062\n",
      "Epoch 1356/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6062\n",
      "Epoch 1357/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1358/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1359/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1360/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1361/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6062\n",
      "Epoch 1362/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1363/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1364/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1365/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1366/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1367/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6062\n",
      "Epoch 1368/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6062\n",
      "Epoch 1369/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1370/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1371/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1372/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6062\n",
      "Epoch 1373/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1374/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1375/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1376/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1377/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1378/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1379/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1380/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1381/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6062\n",
      "Epoch 1382/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1383/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1384/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1385/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1386/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1387/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1388/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1389/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1390/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6062\n",
      "Epoch 1391/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6062\n",
      "Epoch 1392/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1393/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1394/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1395/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1396/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1397/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1398/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5845 - val_loss: 0.6063\n",
      "Epoch 1399/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1400/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1401/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1402/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1403/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1404/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6062\n",
      "Epoch 1405/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1406/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1407/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1408/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1409/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1410/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1411/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1412/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1413/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1414/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1415/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1416/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1417/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1418/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1419/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1420/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1421/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1422/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1423/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1424/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1425/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1426/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1427/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6062\n",
      "Epoch 1428/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1429/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1430/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1431/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1432/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1433/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1434/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1435/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1436/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1437/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1438/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1439/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1440/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1441/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1442/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1443/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1444/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1445/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1446/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1447/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1448/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1449/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1450/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1451/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6062\n",
      "Epoch 1452/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1453/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1454/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1455/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1456/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1457/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1458/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1459/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1460/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1461/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1462/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1463/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1464/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1465/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1466/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1467/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1468/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1469/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1470/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1471/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1472/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1473/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1474/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1475/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1476/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1477/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1478/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1479/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1480/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6062\n",
      "Epoch 1481/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1482/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1483/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1484/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1485/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1486/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1487/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1488/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1489/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1490/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1491/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1492/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1493/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1494/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1495/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6062\n",
      "Epoch 1496/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1497/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1498/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1499/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "Epoch 1500/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.6063\n",
      "54/54 [==============================] - 0s 2ms/step\n",
      "14/14 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Define the autoencoder architecture\n",
    "input_dim = X_train_scaled.shape[1]\n",
    "encoding_dim = 64\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "encoder = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "decoder = Dense(input_dim, activation='sigmoid')(encoder)\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the autoencoder\n",
    "autoencoder.fit(X_train_scaled, X_train_scaled, epochs=1500, batch_size=40,\n",
    "                validation_data=(X_test_scaled, X_test_scaled))\n",
    "\n",
    "# Extract the encoded representations\n",
    "encoder = Model(inputs=input_layer, outputs=encoder)\n",
    "X_train_encoded = encoder.predict(X_train_scaled)\n",
    "X_test_encoded = encoder.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "968e24a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8177570093457944\n",
      "Precision:  0.6687265263341776\n",
      "Recall:  0.8177570093457944\n",
      "F1-score:  0.7357710881003291\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90       350\n",
      "           1       0.00      0.00      0.00        78\n",
      "\n",
      "    accuracy                           0.82       428\n",
      "   macro avg       0.41      0.50      0.45       428\n",
      "weighted avg       0.67      0.82      0.74       428\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Train a classifier\n",
    "from sklearn.svm import SVC\n",
    "clf = SVC()\n",
    "clf.fit(X_train_encoded, y_train)\n",
    "\n",
    "# Evaluate the performance\n",
    "y_pred = clf.predict(X_test_encoded)\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision: \", precision_score(y_test, y_pred, average='weighted'))\n",
    "print(\"Recall: \", recall_score(y_test, y_pred, average='weighted'))\n",
    "print(\"F1-score: \", f1_score(y_test, y_pred, average='weighted'))\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import plot_confusion_matrix, classification_report\n",
    "import warnings\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "859c689c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 79.67%\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "model = XGBClassifier()\n",
    "history = model.fit(X_train_encoded, y_train)\n",
    "#print(model)\n",
    "\n",
    "y_pred = model.predict(X_test_encoded)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fe7a26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7967289719626168\n",
      "Precision:  0.7340326059228682\n",
      "Recall:  0.7967289719626168\n",
      "F1-score:  0.7515847145850859\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.88       350\n",
      "           1       0.32      0.10      0.16        78\n",
      "\n",
      "    accuracy                           0.80       428\n",
      "   macro avg       0.57      0.53      0.52       428\n",
      "weighted avg       0.73      0.80      0.75       428\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import plot_confusion_matrix, classification_report\n",
    "import warnings\n",
    "\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision: \", precision_score(y_test, y_pred, average='weighted'))\n",
    "print(\"Recall: \", recall_score(y_test, y_pred, average='weighted'))\n",
    "print(\"F1-score: \", f1_score(y_test, y_pred, average='weighted'))\n",
    "\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a25a5f",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70ed4e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9405b9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,0:13]\n",
    "y = df.iloc[:,13]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca662d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the accent labels to integers\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Convert the accent labels to one-hot vectors\n",
    "num_classes = len(np.unique(y_train_encoded))\n",
    "y_train_onehot = to_categorical(y_train_encoded, num_classes)\n",
    "y_test_onehot = to_categorical(y_test_encoded, num_classes)\n",
    "\n",
    "# Reshape the input features for the CNN\n",
    "n_timesteps, n_features = X_train.shape[1], 1\n",
    "X_train_reshaped = X_train.values.reshape((X_train.shape[0], n_timesteps, n_features))\n",
    "X_test_reshaped = X_test.values.reshape((X_test.shape[0], n_timesteps, n_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16bed7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN architecture\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(n_timesteps, n_features)))\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99978040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "38/38 [==============================] - 2s 16ms/step - loss: 1.5150 - accuracy: 0.7239 - val_loss: 0.5518 - val_accuracy: 0.8131\n",
      "Epoch 2/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.5925 - accuracy: 0.7821 - val_loss: 0.5011 - val_accuracy: 0.8084\n",
      "Epoch 3/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.5175 - accuracy: 0.7955 - val_loss: 0.4847 - val_accuracy: 0.8100\n",
      "Epoch 4/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4785 - accuracy: 0.8162 - val_loss: 0.4934 - val_accuracy: 0.7913\n",
      "Epoch 5/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4742 - accuracy: 0.8155 - val_loss: 0.5019 - val_accuracy: 0.8100\n",
      "Epoch 6/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4428 - accuracy: 0.8262 - val_loss: 0.4797 - val_accuracy: 0.8100\n",
      "Epoch 7/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4453 - accuracy: 0.8235 - val_loss: 0.4782 - val_accuracy: 0.8115\n",
      "Epoch 8/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4544 - accuracy: 0.8282 - val_loss: 0.4608 - val_accuracy: 0.8131\n",
      "Epoch 9/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4530 - accuracy: 0.8229 - val_loss: 0.4757 - val_accuracy: 0.8022\n",
      "Epoch 10/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4356 - accuracy: 0.8269 - val_loss: 0.4740 - val_accuracy: 0.8100\n",
      "Epoch 11/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4340 - accuracy: 0.8269 - val_loss: 0.4684 - val_accuracy: 0.8053\n",
      "Epoch 12/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4219 - accuracy: 0.8302 - val_loss: 0.4681 - val_accuracy: 0.8131\n",
      "Epoch 13/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4403 - accuracy: 0.8309 - val_loss: 0.4624 - val_accuracy: 0.8115\n",
      "Epoch 14/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4193 - accuracy: 0.8356 - val_loss: 0.4685 - val_accuracy: 0.8084\n",
      "Epoch 15/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4275 - accuracy: 0.8282 - val_loss: 0.4694 - val_accuracy: 0.8069\n",
      "Epoch 16/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4305 - accuracy: 0.8316 - val_loss: 0.4630 - val_accuracy: 0.8115\n",
      "Epoch 17/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4218 - accuracy: 0.8275 - val_loss: 0.4674 - val_accuracy: 0.8115\n",
      "Epoch 18/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4246 - accuracy: 0.8295 - val_loss: 0.4772 - val_accuracy: 0.8037\n",
      "Epoch 19/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4240 - accuracy: 0.8329 - val_loss: 0.4681 - val_accuracy: 0.8100\n",
      "Epoch 20/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4276 - accuracy: 0.8342 - val_loss: 0.4772 - val_accuracy: 0.8115\n",
      "Epoch 21/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4213 - accuracy: 0.8316 - val_loss: 0.4872 - val_accuracy: 0.8100\n",
      "Epoch 22/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4187 - accuracy: 0.8349 - val_loss: 0.4742 - val_accuracy: 0.8084\n",
      "Epoch 23/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.4213 - accuracy: 0.8316 - val_loss: 0.4651 - val_accuracy: 0.8146\n",
      "Epoch 24/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4104 - accuracy: 0.8349 - val_loss: 0.4738 - val_accuracy: 0.8115\n",
      "Epoch 25/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.4097 - accuracy: 0.8275 - val_loss: 0.4624 - val_accuracy: 0.8084\n",
      "Epoch 26/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.4092 - accuracy: 0.8342 - val_loss: 0.4623 - val_accuracy: 0.8178\n",
      "Epoch 27/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4076 - accuracy: 0.8376 - val_loss: 0.4618 - val_accuracy: 0.8131\n",
      "Epoch 28/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4070 - accuracy: 0.8356 - val_loss: 0.4693 - val_accuracy: 0.8069\n",
      "Epoch 29/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3942 - accuracy: 0.8409 - val_loss: 0.4718 - val_accuracy: 0.8131\n",
      "Epoch 30/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.4024 - accuracy: 0.8362 - val_loss: 0.4724 - val_accuracy: 0.8115\n",
      "Epoch 31/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3931 - accuracy: 0.8382 - val_loss: 0.4809 - val_accuracy: 0.8131\n",
      "Epoch 32/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.4091 - accuracy: 0.8309 - val_loss: 0.4716 - val_accuracy: 0.8131\n",
      "Epoch 33/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3978 - accuracy: 0.8349 - val_loss: 0.4717 - val_accuracy: 0.8146\n",
      "Epoch 34/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3911 - accuracy: 0.8396 - val_loss: 0.4739 - val_accuracy: 0.8146\n",
      "Epoch 35/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3972 - accuracy: 0.8382 - val_loss: 0.4703 - val_accuracy: 0.8100\n",
      "Epoch 36/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3897 - accuracy: 0.8369 - val_loss: 0.4777 - val_accuracy: 0.8100\n",
      "Epoch 37/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4000 - accuracy: 0.8289 - val_loss: 0.4751 - val_accuracy: 0.8146\n",
      "Epoch 38/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3893 - accuracy: 0.8402 - val_loss: 0.4758 - val_accuracy: 0.8131\n",
      "Epoch 39/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3867 - accuracy: 0.8409 - val_loss: 0.4782 - val_accuracy: 0.8162\n",
      "Epoch 40/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3948 - accuracy: 0.8316 - val_loss: 0.4786 - val_accuracy: 0.8084\n",
      "Epoch 41/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3867 - accuracy: 0.8349 - val_loss: 0.4813 - val_accuracy: 0.8006\n",
      "Epoch 42/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3813 - accuracy: 0.8429 - val_loss: 0.4772 - val_accuracy: 0.8053\n",
      "Epoch 43/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3807 - accuracy: 0.8429 - val_loss: 0.4700 - val_accuracy: 0.8084\n",
      "Epoch 44/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3740 - accuracy: 0.8422 - val_loss: 0.4723 - val_accuracy: 0.8069\n",
      "Epoch 45/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3720 - accuracy: 0.8429 - val_loss: 0.4826 - val_accuracy: 0.8115\n",
      "Epoch 46/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3831 - accuracy: 0.8409 - val_loss: 0.4773 - val_accuracy: 0.8084\n",
      "Epoch 47/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3684 - accuracy: 0.8463 - val_loss: 0.4813 - val_accuracy: 0.8100\n",
      "Epoch 48/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3729 - accuracy: 0.8476 - val_loss: 0.4917 - val_accuracy: 0.7913\n",
      "Epoch 49/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3694 - accuracy: 0.8489 - val_loss: 0.4828 - val_accuracy: 0.8084\n",
      "Epoch 50/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3713 - accuracy: 0.8422 - val_loss: 0.4804 - val_accuracy: 0.8084\n",
      "Epoch 51/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3688 - accuracy: 0.8456 - val_loss: 0.4824 - val_accuracy: 0.8084\n",
      "Epoch 52/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3634 - accuracy: 0.8402 - val_loss: 0.4801 - val_accuracy: 0.8037\n",
      "Epoch 53/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3684 - accuracy: 0.8443 - val_loss: 0.4859 - val_accuracy: 0.8053\n",
      "Epoch 54/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3507 - accuracy: 0.8483 - val_loss: 0.4953 - val_accuracy: 0.7866\n",
      "Epoch 55/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3570 - accuracy: 0.8516 - val_loss: 0.4843 - val_accuracy: 0.7991\n",
      "Epoch 56/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3707 - accuracy: 0.8402 - val_loss: 0.4846 - val_accuracy: 0.8069\n",
      "Epoch 57/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3621 - accuracy: 0.8449 - val_loss: 0.5156 - val_accuracy: 0.8100\n",
      "Epoch 58/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3538 - accuracy: 0.8543 - val_loss: 0.4944 - val_accuracy: 0.8069\n",
      "Epoch 59/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3529 - accuracy: 0.8463 - val_loss: 0.5089 - val_accuracy: 0.8037\n",
      "Epoch 60/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3448 - accuracy: 0.8516 - val_loss: 0.4983 - val_accuracy: 0.8053\n",
      "Epoch 61/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3487 - accuracy: 0.8496 - val_loss: 0.5002 - val_accuracy: 0.7928\n",
      "Epoch 62/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3462 - accuracy: 0.8483 - val_loss: 0.5043 - val_accuracy: 0.8084\n",
      "Epoch 63/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3459 - accuracy: 0.8496 - val_loss: 0.5024 - val_accuracy: 0.7944\n",
      "Epoch 64/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3522 - accuracy: 0.8436 - val_loss: 0.5091 - val_accuracy: 0.8053\n",
      "Epoch 65/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3532 - accuracy: 0.8503 - val_loss: 0.4974 - val_accuracy: 0.7975\n",
      "Epoch 66/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3504 - accuracy: 0.8509 - val_loss: 0.5065 - val_accuracy: 0.7788\n",
      "Epoch 67/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3378 - accuracy: 0.8536 - val_loss: 0.5043 - val_accuracy: 0.8022\n",
      "Epoch 68/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3455 - accuracy: 0.8496 - val_loss: 0.5176 - val_accuracy: 0.7975\n",
      "Epoch 69/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3432 - accuracy: 0.8516 - val_loss: 0.5094 - val_accuracy: 0.8084\n",
      "Epoch 70/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3315 - accuracy: 0.8623 - val_loss: 0.5023 - val_accuracy: 0.7975\n",
      "Epoch 71/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3311 - accuracy: 0.8590 - val_loss: 0.5067 - val_accuracy: 0.7975\n",
      "Epoch 72/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3429 - accuracy: 0.8523 - val_loss: 0.5169 - val_accuracy: 0.7991\n",
      "Epoch 73/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3336 - accuracy: 0.8549 - val_loss: 0.5199 - val_accuracy: 0.7850\n",
      "Epoch 74/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3189 - accuracy: 0.8650 - val_loss: 0.5209 - val_accuracy: 0.7928\n",
      "Epoch 75/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3245 - accuracy: 0.8690 - val_loss: 0.5224 - val_accuracy: 0.7960\n",
      "Epoch 76/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3244 - accuracy: 0.8590 - val_loss: 0.5433 - val_accuracy: 0.8022\n",
      "Epoch 77/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3275 - accuracy: 0.8583 - val_loss: 0.5371 - val_accuracy: 0.7757\n",
      "Epoch 78/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3200 - accuracy: 0.8636 - val_loss: 0.5436 - val_accuracy: 0.7975\n",
      "Epoch 79/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3363 - accuracy: 0.8503 - val_loss: 0.5220 - val_accuracy: 0.8069\n",
      "Epoch 80/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3147 - accuracy: 0.8623 - val_loss: 0.5413 - val_accuracy: 0.7882\n",
      "Epoch 81/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3452 - accuracy: 0.8489 - val_loss: 0.5229 - val_accuracy: 0.8006\n",
      "Epoch 82/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3189 - accuracy: 0.8543 - val_loss: 0.5331 - val_accuracy: 0.7928\n",
      "Epoch 83/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3244 - accuracy: 0.8656 - val_loss: 0.5370 - val_accuracy: 0.7835\n",
      "Epoch 84/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3117 - accuracy: 0.8596 - val_loss: 0.5293 - val_accuracy: 0.7804\n",
      "Epoch 85/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3225 - accuracy: 0.8583 - val_loss: 0.5421 - val_accuracy: 0.7897\n",
      "Epoch 86/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3312 - accuracy: 0.8556 - val_loss: 0.5404 - val_accuracy: 0.7804\n",
      "Epoch 87/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3257 - accuracy: 0.8549 - val_loss: 0.5539 - val_accuracy: 0.7850\n",
      "Epoch 88/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3146 - accuracy: 0.8656 - val_loss: 0.5477 - val_accuracy: 0.7944\n",
      "Epoch 89/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3216 - accuracy: 0.8697 - val_loss: 0.5368 - val_accuracy: 0.7866\n",
      "Epoch 90/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3227 - accuracy: 0.8549 - val_loss: 0.5456 - val_accuracy: 0.7975\n",
      "Epoch 91/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2996 - accuracy: 0.8730 - val_loss: 0.5568 - val_accuracy: 0.7804\n",
      "Epoch 92/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3253 - accuracy: 0.8556 - val_loss: 0.5686 - val_accuracy: 0.7960\n",
      "Epoch 93/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3112 - accuracy: 0.8670 - val_loss: 0.5343 - val_accuracy: 0.7804\n",
      "Epoch 94/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3057 - accuracy: 0.8616 - val_loss: 0.5626 - val_accuracy: 0.7695\n",
      "Epoch 95/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3169 - accuracy: 0.8643 - val_loss: 0.5650 - val_accuracy: 0.7850\n",
      "Epoch 96/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.3123 - accuracy: 0.8717 - val_loss: 0.5612 - val_accuracy: 0.7804\n",
      "Epoch 97/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3194 - accuracy: 0.8610 - val_loss: 0.5552 - val_accuracy: 0.7897\n",
      "Epoch 98/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2981 - accuracy: 0.8670 - val_loss: 0.5692 - val_accuracy: 0.7819\n",
      "Epoch 99/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3074 - accuracy: 0.8683 - val_loss: 0.5768 - val_accuracy: 0.7835\n",
      "Epoch 100/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3013 - accuracy: 0.8730 - val_loss: 0.5722 - val_accuracy: 0.7866\n",
      "Epoch 101/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3037 - accuracy: 0.8670 - val_loss: 0.5828 - val_accuracy: 0.7882\n",
      "Epoch 102/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2809 - accuracy: 0.8783 - val_loss: 0.6036 - val_accuracy: 0.7804\n",
      "Epoch 103/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2970 - accuracy: 0.8676 - val_loss: 0.6123 - val_accuracy: 0.7850\n",
      "Epoch 104/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2984 - accuracy: 0.8703 - val_loss: 0.5773 - val_accuracy: 0.7773\n",
      "Epoch 105/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2827 - accuracy: 0.8737 - val_loss: 0.5905 - val_accuracy: 0.7882\n",
      "Epoch 106/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3022 - accuracy: 0.8790 - val_loss: 0.5888 - val_accuracy: 0.7679\n",
      "Epoch 107/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2916 - accuracy: 0.8697 - val_loss: 0.5892 - val_accuracy: 0.7757\n",
      "Epoch 108/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2881 - accuracy: 0.8770 - val_loss: 0.6128 - val_accuracy: 0.7773\n",
      "Epoch 109/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2682 - accuracy: 0.8857 - val_loss: 0.5861 - val_accuracy: 0.7835\n",
      "Epoch 110/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2897 - accuracy: 0.8783 - val_loss: 0.5943 - val_accuracy: 0.7850\n",
      "Epoch 111/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2809 - accuracy: 0.8770 - val_loss: 0.6046 - val_accuracy: 0.7632\n",
      "Epoch 112/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2918 - accuracy: 0.8797 - val_loss: 0.6133 - val_accuracy: 0.7664\n",
      "Epoch 113/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2835 - accuracy: 0.8797 - val_loss: 0.6210 - val_accuracy: 0.7648\n",
      "Epoch 114/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2811 - accuracy: 0.8837 - val_loss: 0.6142 - val_accuracy: 0.7835\n",
      "Epoch 115/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2933 - accuracy: 0.8683 - val_loss: 0.5726 - val_accuracy: 0.7804\n",
      "Epoch 116/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2829 - accuracy: 0.8750 - val_loss: 0.6213 - val_accuracy: 0.7819\n",
      "Epoch 117/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2953 - accuracy: 0.8697 - val_loss: 0.6106 - val_accuracy: 0.7866\n",
      "Epoch 118/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2832 - accuracy: 0.8817 - val_loss: 0.6034 - val_accuracy: 0.7773\n",
      "Epoch 119/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2818 - accuracy: 0.8770 - val_loss: 0.6118 - val_accuracy: 0.7648\n",
      "Epoch 120/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2810 - accuracy: 0.8703 - val_loss: 0.6044 - val_accuracy: 0.7866\n",
      "Epoch 121/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2888 - accuracy: 0.8717 - val_loss: 0.6054 - val_accuracy: 0.7523\n",
      "Epoch 122/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2612 - accuracy: 0.8917 - val_loss: 0.6396 - val_accuracy: 0.7819\n",
      "Epoch 123/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2678 - accuracy: 0.8850 - val_loss: 0.6336 - val_accuracy: 0.7913\n",
      "Epoch 124/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2692 - accuracy: 0.8844 - val_loss: 0.6448 - val_accuracy: 0.7804\n",
      "Epoch 125/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2638 - accuracy: 0.8857 - val_loss: 0.6320 - val_accuracy: 0.7804\n",
      "Epoch 126/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2612 - accuracy: 0.8917 - val_loss: 0.6634 - val_accuracy: 0.7788\n",
      "Epoch 127/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2674 - accuracy: 0.8857 - val_loss: 0.6332 - val_accuracy: 0.7773\n",
      "Epoch 128/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2607 - accuracy: 0.8904 - val_loss: 0.6406 - val_accuracy: 0.7804\n",
      "Epoch 129/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2529 - accuracy: 0.8850 - val_loss: 0.6896 - val_accuracy: 0.7835\n",
      "Epoch 130/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2598 - accuracy: 0.8924 - val_loss: 0.6375 - val_accuracy: 0.7679\n",
      "Epoch 131/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2572 - accuracy: 0.8964 - val_loss: 0.6562 - val_accuracy: 0.7788\n",
      "Epoch 132/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2499 - accuracy: 0.8910 - val_loss: 0.6677 - val_accuracy: 0.7835\n",
      "Epoch 133/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2559 - accuracy: 0.8937 - val_loss: 0.6530 - val_accuracy: 0.7866\n",
      "Epoch 134/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2565 - accuracy: 0.8897 - val_loss: 0.6796 - val_accuracy: 0.7788\n",
      "Epoch 135/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2559 - accuracy: 0.8830 - val_loss: 0.6884 - val_accuracy: 0.7850\n",
      "Epoch 136/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2431 - accuracy: 0.8951 - val_loss: 0.6893 - val_accuracy: 0.7835\n",
      "Epoch 137/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2656 - accuracy: 0.8810 - val_loss: 0.6627 - val_accuracy: 0.7819\n",
      "Epoch 138/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2474 - accuracy: 0.8944 - val_loss: 0.6988 - val_accuracy: 0.7695\n",
      "Epoch 139/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2567 - accuracy: 0.8937 - val_loss: 0.6808 - val_accuracy: 0.7664\n",
      "Epoch 140/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2303 - accuracy: 0.8997 - val_loss: 0.6953 - val_accuracy: 0.7804\n",
      "Epoch 141/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2582 - accuracy: 0.8844 - val_loss: 0.6830 - val_accuracy: 0.7648\n",
      "Epoch 142/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2633 - accuracy: 0.8837 - val_loss: 0.6761 - val_accuracy: 0.7866\n",
      "Epoch 143/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2368 - accuracy: 0.8984 - val_loss: 0.6881 - val_accuracy: 0.7928\n",
      "Epoch 144/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2544 - accuracy: 0.8897 - val_loss: 0.6753 - val_accuracy: 0.7866\n",
      "Epoch 145/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2373 - accuracy: 0.8884 - val_loss: 0.7279 - val_accuracy: 0.7882\n",
      "Epoch 146/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2397 - accuracy: 0.8937 - val_loss: 0.7204 - val_accuracy: 0.7726\n",
      "Epoch 147/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2590 - accuracy: 0.8930 - val_loss: 0.7084 - val_accuracy: 0.7726\n",
      "Epoch 148/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2282 - accuracy: 0.9017 - val_loss: 0.7334 - val_accuracy: 0.7632\n",
      "Epoch 149/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2358 - accuracy: 0.8917 - val_loss: 0.7107 - val_accuracy: 0.7741\n",
      "Epoch 150/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2541 - accuracy: 0.8904 - val_loss: 0.7026 - val_accuracy: 0.7710\n",
      "Epoch 151/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2387 - accuracy: 0.8930 - val_loss: 0.7125 - val_accuracy: 0.7773\n",
      "Epoch 152/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2365 - accuracy: 0.9017 - val_loss: 0.7289 - val_accuracy: 0.7850\n",
      "Epoch 153/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2420 - accuracy: 0.8904 - val_loss: 0.7052 - val_accuracy: 0.7664\n",
      "Epoch 154/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2335 - accuracy: 0.8984 - val_loss: 0.7244 - val_accuracy: 0.7710\n",
      "Epoch 155/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2247 - accuracy: 0.9051 - val_loss: 0.6997 - val_accuracy: 0.7586\n",
      "Epoch 156/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2533 - accuracy: 0.8971 - val_loss: 0.7145 - val_accuracy: 0.7664\n",
      "Epoch 157/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2468 - accuracy: 0.8944 - val_loss: 0.7338 - val_accuracy: 0.7710\n",
      "Epoch 158/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2370 - accuracy: 0.8997 - val_loss: 0.7445 - val_accuracy: 0.7773\n",
      "Epoch 159/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2357 - accuracy: 0.8924 - val_loss: 0.7056 - val_accuracy: 0.7741\n",
      "Epoch 160/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2343 - accuracy: 0.8964 - val_loss: 0.7343 - val_accuracy: 0.7695\n",
      "Epoch 161/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2284 - accuracy: 0.8977 - val_loss: 0.7185 - val_accuracy: 0.7586\n",
      "Epoch 162/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2201 - accuracy: 0.9017 - val_loss: 0.7225 - val_accuracy: 0.7586\n",
      "Epoch 163/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2240 - accuracy: 0.8997 - val_loss: 0.7270 - val_accuracy: 0.7695\n",
      "Epoch 164/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2224 - accuracy: 0.8997 - val_loss: 0.7307 - val_accuracy: 0.7913\n",
      "Epoch 165/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.2293 - accuracy: 0.9037 - val_loss: 0.7759 - val_accuracy: 0.7773\n",
      "Epoch 166/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2308 - accuracy: 0.8971 - val_loss: 0.7397 - val_accuracy: 0.7648\n",
      "Epoch 167/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2369 - accuracy: 0.8997 - val_loss: 0.7686 - val_accuracy: 0.7461\n",
      "Epoch 168/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2056 - accuracy: 0.9071 - val_loss: 0.7468 - val_accuracy: 0.7773\n",
      "Epoch 169/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2230 - accuracy: 0.9031 - val_loss: 0.7397 - val_accuracy: 0.7445\n",
      "Epoch 170/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2176 - accuracy: 0.9057 - val_loss: 0.7535 - val_accuracy: 0.7788\n",
      "Epoch 171/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2137 - accuracy: 0.9011 - val_loss: 0.7873 - val_accuracy: 0.7679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2258 - accuracy: 0.9037 - val_loss: 0.7470 - val_accuracy: 0.7679\n",
      "Epoch 173/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2079 - accuracy: 0.9118 - val_loss: 0.8054 - val_accuracy: 0.7695\n",
      "Epoch 174/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2073 - accuracy: 0.9111 - val_loss: 0.7728 - val_accuracy: 0.7726\n",
      "Epoch 175/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2219 - accuracy: 0.9057 - val_loss: 0.8012 - val_accuracy: 0.7648\n",
      "Epoch 176/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2177 - accuracy: 0.9124 - val_loss: 0.7693 - val_accuracy: 0.7710\n",
      "Epoch 177/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2201 - accuracy: 0.9078 - val_loss: 0.7337 - val_accuracy: 0.7757\n",
      "Epoch 178/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2219 - accuracy: 0.9078 - val_loss: 0.7520 - val_accuracy: 0.7601\n",
      "Epoch 179/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2252 - accuracy: 0.9044 - val_loss: 0.7408 - val_accuracy: 0.7741\n",
      "Epoch 180/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2174 - accuracy: 0.9171 - val_loss: 0.7561 - val_accuracy: 0.7819\n",
      "Epoch 181/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2005 - accuracy: 0.9091 - val_loss: 0.7748 - val_accuracy: 0.7695\n",
      "Epoch 182/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2218 - accuracy: 0.9084 - val_loss: 0.7284 - val_accuracy: 0.7679\n",
      "Epoch 183/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2256 - accuracy: 0.9078 - val_loss: 0.7731 - val_accuracy: 0.7788\n",
      "Epoch 184/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2252 - accuracy: 0.8964 - val_loss: 0.7416 - val_accuracy: 0.7741\n",
      "Epoch 185/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2181 - accuracy: 0.9057 - val_loss: 0.7812 - val_accuracy: 0.7726\n",
      "Epoch 186/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2077 - accuracy: 0.9044 - val_loss: 0.7507 - val_accuracy: 0.7788\n",
      "Epoch 187/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1988 - accuracy: 0.9124 - val_loss: 0.7913 - val_accuracy: 0.7773\n",
      "Epoch 188/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2113 - accuracy: 0.9057 - val_loss: 0.7822 - val_accuracy: 0.7804\n",
      "Epoch 189/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2009 - accuracy: 0.9184 - val_loss: 0.7665 - val_accuracy: 0.7726\n",
      "Epoch 190/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2067 - accuracy: 0.9037 - val_loss: 0.7655 - val_accuracy: 0.7757\n",
      "Epoch 191/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2344 - accuracy: 0.8937 - val_loss: 0.7764 - val_accuracy: 0.7819\n",
      "Epoch 192/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2013 - accuracy: 0.9064 - val_loss: 0.7906 - val_accuracy: 0.7555\n",
      "Epoch 193/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1974 - accuracy: 0.9151 - val_loss: 0.7886 - val_accuracy: 0.7648\n",
      "Epoch 194/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1908 - accuracy: 0.9184 - val_loss: 0.7946 - val_accuracy: 0.7741\n",
      "Epoch 195/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1979 - accuracy: 0.9151 - val_loss: 0.7989 - val_accuracy: 0.7648\n",
      "Epoch 196/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1959 - accuracy: 0.9118 - val_loss: 0.8257 - val_accuracy: 0.7617\n",
      "Epoch 197/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1926 - accuracy: 0.9198 - val_loss: 0.8242 - val_accuracy: 0.7773\n",
      "Epoch 198/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1788 - accuracy: 0.9251 - val_loss: 0.8634 - val_accuracy: 0.7601\n",
      "Epoch 199/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2003 - accuracy: 0.9211 - val_loss: 0.7970 - val_accuracy: 0.7679\n",
      "Epoch 200/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1870 - accuracy: 0.9265 - val_loss: 0.8649 - val_accuracy: 0.7835\n",
      "Epoch 201/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2019 - accuracy: 0.9098 - val_loss: 0.8557 - val_accuracy: 0.7773\n",
      "Epoch 202/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2025 - accuracy: 0.9178 - val_loss: 0.8871 - val_accuracy: 0.7819\n",
      "Epoch 203/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1923 - accuracy: 0.9238 - val_loss: 0.8695 - val_accuracy: 0.7726\n",
      "Epoch 204/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1962 - accuracy: 0.9124 - val_loss: 0.8494 - val_accuracy: 0.7617\n",
      "Epoch 205/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2156 - accuracy: 0.9138 - val_loss: 0.8610 - val_accuracy: 0.7819\n",
      "Epoch 206/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1954 - accuracy: 0.9191 - val_loss: 0.8569 - val_accuracy: 0.7710\n",
      "Epoch 207/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1962 - accuracy: 0.9104 - val_loss: 0.8453 - val_accuracy: 0.7788\n",
      "Epoch 208/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1797 - accuracy: 0.9231 - val_loss: 0.8616 - val_accuracy: 0.7757\n",
      "Epoch 209/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1923 - accuracy: 0.9164 - val_loss: 0.8670 - val_accuracy: 0.7757\n",
      "Epoch 210/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1947 - accuracy: 0.9191 - val_loss: 0.8626 - val_accuracy: 0.7773\n",
      "Epoch 211/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1806 - accuracy: 0.9225 - val_loss: 0.8438 - val_accuracy: 0.7819\n",
      "Epoch 212/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1957 - accuracy: 0.9178 - val_loss: 0.8837 - val_accuracy: 0.7710\n",
      "Epoch 213/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2085 - accuracy: 0.9064 - val_loss: 0.9027 - val_accuracy: 0.7695\n",
      "Epoch 214/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2194 - accuracy: 0.9031 - val_loss: 0.8601 - val_accuracy: 0.7695\n",
      "Epoch 215/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1936 - accuracy: 0.9205 - val_loss: 0.8733 - val_accuracy: 0.7695\n",
      "Epoch 216/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1782 - accuracy: 0.9271 - val_loss: 0.8630 - val_accuracy: 0.7679\n",
      "Epoch 217/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1907 - accuracy: 0.9218 - val_loss: 0.8677 - val_accuracy: 0.7757\n",
      "Epoch 218/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2077 - accuracy: 0.9084 - val_loss: 0.8650 - val_accuracy: 0.7726\n",
      "Epoch 219/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1886 - accuracy: 0.9198 - val_loss: 0.8262 - val_accuracy: 0.7850\n",
      "Epoch 220/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1916 - accuracy: 0.9151 - val_loss: 0.8383 - val_accuracy: 0.7710\n",
      "Epoch 221/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1794 - accuracy: 0.9311 - val_loss: 0.8650 - val_accuracy: 0.7757\n",
      "Epoch 222/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1804 - accuracy: 0.9318 - val_loss: 0.8564 - val_accuracy: 0.7648\n",
      "Epoch 223/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1778 - accuracy: 0.9191 - val_loss: 0.8675 - val_accuracy: 0.7804\n",
      "Epoch 224/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1872 - accuracy: 0.9285 - val_loss: 0.8829 - val_accuracy: 0.7632\n",
      "Epoch 225/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1823 - accuracy: 0.9171 - val_loss: 0.9250 - val_accuracy: 0.7835\n",
      "Epoch 226/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1691 - accuracy: 0.9265 - val_loss: 0.8698 - val_accuracy: 0.7710\n",
      "Epoch 227/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1835 - accuracy: 0.9238 - val_loss: 0.9266 - val_accuracy: 0.7741\n",
      "Epoch 228/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1849 - accuracy: 0.9171 - val_loss: 0.9263 - val_accuracy: 0.7601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2002 - accuracy: 0.9144 - val_loss: 0.9059 - val_accuracy: 0.7726\n",
      "Epoch 230/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1686 - accuracy: 0.9305 - val_loss: 0.9083 - val_accuracy: 0.7804\n",
      "Epoch 231/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1708 - accuracy: 0.9291 - val_loss: 0.9171 - val_accuracy: 0.7695\n",
      "Epoch 232/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1802 - accuracy: 0.9231 - val_loss: 1.0000 - val_accuracy: 0.7804\n",
      "Epoch 233/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1821 - accuracy: 0.9265 - val_loss: 0.9096 - val_accuracy: 0.7368\n",
      "Epoch 234/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1523 - accuracy: 0.9358 - val_loss: 0.9403 - val_accuracy: 0.7726\n",
      "Epoch 235/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1648 - accuracy: 0.9271 - val_loss: 0.9725 - val_accuracy: 0.7726\n",
      "Epoch 236/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1763 - accuracy: 0.9245 - val_loss: 0.9804 - val_accuracy: 0.7850\n",
      "Epoch 237/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1845 - accuracy: 0.9238 - val_loss: 0.9102 - val_accuracy: 0.7601\n",
      "Epoch 238/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1726 - accuracy: 0.9245 - val_loss: 0.9665 - val_accuracy: 0.7882\n",
      "Epoch 239/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1732 - accuracy: 0.9298 - val_loss: 0.9206 - val_accuracy: 0.7804\n",
      "Epoch 240/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1796 - accuracy: 0.9271 - val_loss: 0.9434 - val_accuracy: 0.7850\n",
      "Epoch 241/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1975 - accuracy: 0.9171 - val_loss: 0.8978 - val_accuracy: 0.7695\n",
      "Epoch 242/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1938 - accuracy: 0.9164 - val_loss: 0.9312 - val_accuracy: 0.7648\n",
      "Epoch 243/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1689 - accuracy: 0.9305 - val_loss: 0.8933 - val_accuracy: 0.7773\n",
      "Epoch 244/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1860 - accuracy: 0.9231 - val_loss: 0.9089 - val_accuracy: 0.7648\n",
      "Epoch 245/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1699 - accuracy: 0.9258 - val_loss: 0.9400 - val_accuracy: 0.7757\n",
      "Epoch 246/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1596 - accuracy: 0.9238 - val_loss: 0.9679 - val_accuracy: 0.7773\n",
      "Epoch 247/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1748 - accuracy: 0.9291 - val_loss: 0.9401 - val_accuracy: 0.7695\n",
      "Epoch 248/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1961 - accuracy: 0.9198 - val_loss: 0.8898 - val_accuracy: 0.7664\n",
      "Epoch 249/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1898 - accuracy: 0.9184 - val_loss: 0.9177 - val_accuracy: 0.7492\n",
      "Epoch 250/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1683 - accuracy: 0.9278 - val_loss: 0.9576 - val_accuracy: 0.7617\n",
      "Epoch 251/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1935 - accuracy: 0.9278 - val_loss: 0.9136 - val_accuracy: 0.7757\n",
      "Epoch 252/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1748 - accuracy: 0.9198 - val_loss: 0.9602 - val_accuracy: 0.7741\n",
      "Epoch 253/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1661 - accuracy: 0.9345 - val_loss: 0.9168 - val_accuracy: 0.7523\n",
      "Epoch 254/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1528 - accuracy: 0.9365 - val_loss: 0.9689 - val_accuracy: 0.7414\n",
      "Epoch 255/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1637 - accuracy: 0.9238 - val_loss: 0.9535 - val_accuracy: 0.7586\n",
      "Epoch 256/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1645 - accuracy: 0.9412 - val_loss: 0.9545 - val_accuracy: 0.7461\n",
      "Epoch 257/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1803 - accuracy: 0.9265 - val_loss: 0.9552 - val_accuracy: 0.7523\n",
      "Epoch 258/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1551 - accuracy: 0.9358 - val_loss: 0.9683 - val_accuracy: 0.7617\n",
      "Epoch 259/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1524 - accuracy: 0.9338 - val_loss: 0.9251 - val_accuracy: 0.7648\n",
      "Epoch 260/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1640 - accuracy: 0.9245 - val_loss: 0.9479 - val_accuracy: 0.7664\n",
      "Epoch 261/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1634 - accuracy: 0.9365 - val_loss: 0.9367 - val_accuracy: 0.7679\n",
      "Epoch 262/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1600 - accuracy: 0.9439 - val_loss: 0.9877 - val_accuracy: 0.7804\n",
      "Epoch 263/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1609 - accuracy: 0.9385 - val_loss: 0.9413 - val_accuracy: 0.7383\n",
      "Epoch 264/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1723 - accuracy: 0.9345 - val_loss: 0.9716 - val_accuracy: 0.7741\n",
      "Epoch 265/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1719 - accuracy: 0.9352 - val_loss: 0.9633 - val_accuracy: 0.7695\n",
      "Epoch 266/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1418 - accuracy: 0.9398 - val_loss: 1.0149 - val_accuracy: 0.7523\n",
      "Epoch 267/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1604 - accuracy: 0.9332 - val_loss: 0.9901 - val_accuracy: 0.7570\n",
      "Epoch 268/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1470 - accuracy: 0.9392 - val_loss: 1.0257 - val_accuracy: 0.7570\n",
      "Epoch 269/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1643 - accuracy: 0.9338 - val_loss: 1.0228 - val_accuracy: 0.7601\n",
      "Epoch 270/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1725 - accuracy: 0.9311 - val_loss: 1.0225 - val_accuracy: 0.7617\n",
      "Epoch 271/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1924 - accuracy: 0.9225 - val_loss: 1.0261 - val_accuracy: 0.7586\n",
      "Epoch 272/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1704 - accuracy: 0.9285 - val_loss: 0.9974 - val_accuracy: 0.7586\n",
      "Epoch 273/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1778 - accuracy: 0.9298 - val_loss: 1.0316 - val_accuracy: 0.7804\n",
      "Epoch 274/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1680 - accuracy: 0.9245 - val_loss: 0.9586 - val_accuracy: 0.7555\n",
      "Epoch 275/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1636 - accuracy: 0.9352 - val_loss: 0.9606 - val_accuracy: 0.7788\n",
      "Epoch 276/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1796 - accuracy: 0.9251 - val_loss: 0.9506 - val_accuracy: 0.7679\n",
      "Epoch 277/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1544 - accuracy: 0.9345 - val_loss: 1.0123 - val_accuracy: 0.7741\n",
      "Epoch 278/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1464 - accuracy: 0.9392 - val_loss: 1.0105 - val_accuracy: 0.7492\n",
      "Epoch 279/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1630 - accuracy: 0.9325 - val_loss: 1.0134 - val_accuracy: 0.7570\n",
      "Epoch 280/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1669 - accuracy: 0.9338 - val_loss: 0.9583 - val_accuracy: 0.7773\n",
      "Epoch 281/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1579 - accuracy: 0.9338 - val_loss: 0.9991 - val_accuracy: 0.7679\n",
      "Epoch 282/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1591 - accuracy: 0.9298 - val_loss: 0.9929 - val_accuracy: 0.7539\n",
      "Epoch 283/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1671 - accuracy: 0.9265 - val_loss: 0.9725 - val_accuracy: 0.7445\n",
      "Epoch 284/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1499 - accuracy: 0.9372 - val_loss: 1.0259 - val_accuracy: 0.7601\n",
      "Epoch 285/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1493 - accuracy: 0.9472 - val_loss: 1.0251 - val_accuracy: 0.7586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1733 - accuracy: 0.9231 - val_loss: 1.0318 - val_accuracy: 0.7710\n",
      "Epoch 287/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1717 - accuracy: 0.9291 - val_loss: 1.0243 - val_accuracy: 0.7632\n",
      "Epoch 288/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1800 - accuracy: 0.9305 - val_loss: 1.0191 - val_accuracy: 0.7664\n",
      "Epoch 289/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1602 - accuracy: 0.9332 - val_loss: 0.9946 - val_accuracy: 0.7710\n",
      "Epoch 290/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1629 - accuracy: 0.9258 - val_loss: 1.0406 - val_accuracy: 0.7741\n",
      "Epoch 291/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1710 - accuracy: 0.9231 - val_loss: 0.9955 - val_accuracy: 0.7741\n",
      "Epoch 292/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1617 - accuracy: 0.9352 - val_loss: 1.0410 - val_accuracy: 0.7695\n",
      "Epoch 293/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1702 - accuracy: 0.9278 - val_loss: 1.0022 - val_accuracy: 0.7586\n",
      "Epoch 294/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1667 - accuracy: 0.9271 - val_loss: 0.9915 - val_accuracy: 0.7695\n",
      "Epoch 295/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1621 - accuracy: 0.9358 - val_loss: 1.0229 - val_accuracy: 0.7788\n",
      "Epoch 296/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1559 - accuracy: 0.9405 - val_loss: 0.9947 - val_accuracy: 0.7679\n",
      "Epoch 297/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1564 - accuracy: 0.9352 - val_loss: 1.0259 - val_accuracy: 0.7664\n",
      "Epoch 298/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1453 - accuracy: 0.9372 - val_loss: 1.0711 - val_accuracy: 0.7664\n",
      "Epoch 299/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1465 - accuracy: 0.9445 - val_loss: 0.9994 - val_accuracy: 0.7695\n",
      "Epoch 300/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1416 - accuracy: 0.9365 - val_loss: 1.0427 - val_accuracy: 0.7741\n",
      "Epoch 301/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1448 - accuracy: 0.9398 - val_loss: 1.0043 - val_accuracy: 0.7679\n",
      "Epoch 302/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1615 - accuracy: 0.9291 - val_loss: 1.0407 - val_accuracy: 0.7788\n",
      "Epoch 303/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1600 - accuracy: 0.9345 - val_loss: 1.0114 - val_accuracy: 0.7586\n",
      "Epoch 304/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.1678 - accuracy: 0.9345 - val_loss: 1.0199 - val_accuracy: 0.7508\n",
      "Epoch 305/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1547 - accuracy: 0.9432 - val_loss: 1.0237 - val_accuracy: 0.7726\n",
      "Epoch 306/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1423 - accuracy: 0.9432 - val_loss: 1.0172 - val_accuracy: 0.7664\n",
      "Epoch 307/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1539 - accuracy: 0.9385 - val_loss: 1.0407 - val_accuracy: 0.7819\n",
      "Epoch 308/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.1505 - accuracy: 0.9372 - val_loss: 1.0795 - val_accuracy: 0.7726\n",
      "Epoch 309/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1567 - accuracy: 0.9345 - val_loss: 1.1421 - val_accuracy: 0.7726\n",
      "Epoch 310/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1445 - accuracy: 0.9392 - val_loss: 1.0982 - val_accuracy: 0.7710\n",
      "Epoch 311/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1552 - accuracy: 0.9372 - val_loss: 1.0309 - val_accuracy: 0.7710\n",
      "Epoch 312/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1488 - accuracy: 0.9398 - val_loss: 1.0388 - val_accuracy: 0.7679\n",
      "Epoch 313/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1677 - accuracy: 0.9191 - val_loss: 1.0112 - val_accuracy: 0.7617\n",
      "Epoch 314/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1513 - accuracy: 0.9452 - val_loss: 1.0748 - val_accuracy: 0.7710\n",
      "Epoch 315/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1448 - accuracy: 0.9432 - val_loss: 1.0719 - val_accuracy: 0.7788\n",
      "Epoch 316/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1499 - accuracy: 0.9459 - val_loss: 1.0323 - val_accuracy: 0.7866\n",
      "Epoch 317/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1658 - accuracy: 0.9352 - val_loss: 1.0082 - val_accuracy: 0.7757\n",
      "Epoch 318/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1539 - accuracy: 0.9332 - val_loss: 1.0343 - val_accuracy: 0.7492\n",
      "Epoch 319/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1479 - accuracy: 0.9352 - val_loss: 1.0509 - val_accuracy: 0.7648\n",
      "Epoch 320/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1737 - accuracy: 0.9258 - val_loss: 1.0314 - val_accuracy: 0.7664\n",
      "Epoch 321/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1437 - accuracy: 0.9365 - val_loss: 1.0816 - val_accuracy: 0.7632\n",
      "Epoch 322/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1399 - accuracy: 0.9398 - val_loss: 1.0658 - val_accuracy: 0.7741\n",
      "Epoch 323/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1548 - accuracy: 0.9378 - val_loss: 1.0654 - val_accuracy: 0.7710\n",
      "Epoch 324/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1620 - accuracy: 0.9305 - val_loss: 1.0392 - val_accuracy: 0.7679\n",
      "Epoch 325/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1486 - accuracy: 0.9365 - val_loss: 1.0784 - val_accuracy: 0.7882\n",
      "Epoch 326/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1513 - accuracy: 0.9358 - val_loss: 1.0048 - val_accuracy: 0.7570\n",
      "Epoch 327/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1340 - accuracy: 0.9445 - val_loss: 1.0243 - val_accuracy: 0.7773\n",
      "Epoch 328/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1470 - accuracy: 0.9311 - val_loss: 1.0359 - val_accuracy: 0.7679\n",
      "Epoch 329/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1308 - accuracy: 0.9492 - val_loss: 1.1241 - val_accuracy: 0.7617\n",
      "Epoch 330/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1412 - accuracy: 0.9465 - val_loss: 1.1321 - val_accuracy: 0.7679\n",
      "Epoch 331/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1690 - accuracy: 0.9445 - val_loss: 1.0740 - val_accuracy: 0.7648\n",
      "Epoch 332/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.1644 - accuracy: 0.9311 - val_loss: 1.0772 - val_accuracy: 0.7664\n",
      "Epoch 333/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.1549 - accuracy: 0.9325 - val_loss: 1.1082 - val_accuracy: 0.7819\n",
      "Epoch 334/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1407 - accuracy: 0.9452 - val_loss: 1.0964 - val_accuracy: 0.7710\n",
      "Epoch 335/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1353 - accuracy: 0.9425 - val_loss: 1.0916 - val_accuracy: 0.7710\n",
      "Epoch 336/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1464 - accuracy: 0.9412 - val_loss: 1.0939 - val_accuracy: 0.7617\n",
      "Epoch 337/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1323 - accuracy: 0.9485 - val_loss: 1.1180 - val_accuracy: 0.7788\n",
      "Epoch 338/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.1589 - accuracy: 0.9425 - val_loss: 1.1081 - val_accuracy: 0.7726\n",
      "Epoch 339/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.1398 - accuracy: 0.9445 - val_loss: 1.1451 - val_accuracy: 0.7664\n",
      "Epoch 340/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.1476 - accuracy: 0.9485 - val_loss: 1.1418 - val_accuracy: 0.7601\n",
      "Epoch 341/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1339 - accuracy: 0.9492 - val_loss: 1.1054 - val_accuracy: 0.7570\n",
      "Epoch 342/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1346 - accuracy: 0.9479 - val_loss: 1.1014 - val_accuracy: 0.7601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1635 - accuracy: 0.9285 - val_loss: 1.1150 - val_accuracy: 0.7617\n",
      "Epoch 344/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1587 - accuracy: 0.9325 - val_loss: 1.1315 - val_accuracy: 0.7632\n",
      "Epoch 345/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1544 - accuracy: 0.9372 - val_loss: 1.0786 - val_accuracy: 0.7679\n",
      "Epoch 346/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1470 - accuracy: 0.9398 - val_loss: 1.1127 - val_accuracy: 0.7710\n",
      "Epoch 347/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1430 - accuracy: 0.9385 - val_loss: 1.1391 - val_accuracy: 0.7679\n",
      "Epoch 348/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1489 - accuracy: 0.9398 - val_loss: 1.0763 - val_accuracy: 0.7648\n",
      "Epoch 349/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1392 - accuracy: 0.9418 - val_loss: 1.1024 - val_accuracy: 0.7726\n",
      "Epoch 350/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1271 - accuracy: 0.9452 - val_loss: 1.1623 - val_accuracy: 0.7757\n",
      "Epoch 351/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1646 - accuracy: 0.9432 - val_loss: 1.1306 - val_accuracy: 0.7601\n",
      "Epoch 352/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1437 - accuracy: 0.9405 - val_loss: 1.1233 - val_accuracy: 0.7695\n",
      "Epoch 353/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1427 - accuracy: 0.9452 - val_loss: 1.0741 - val_accuracy: 0.7664\n",
      "Epoch 354/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1425 - accuracy: 0.9479 - val_loss: 1.0859 - val_accuracy: 0.7617\n",
      "Epoch 355/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1446 - accuracy: 0.9418 - val_loss: 1.1141 - val_accuracy: 0.7648\n",
      "Epoch 356/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1328 - accuracy: 0.9479 - val_loss: 1.0676 - val_accuracy: 0.7679\n",
      "Epoch 357/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1332 - accuracy: 0.9465 - val_loss: 1.0720 - val_accuracy: 0.7632\n",
      "Epoch 358/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1313 - accuracy: 0.9499 - val_loss: 1.1215 - val_accuracy: 0.7617\n",
      "Epoch 359/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1375 - accuracy: 0.9465 - val_loss: 1.1294 - val_accuracy: 0.7570\n",
      "Epoch 360/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1198 - accuracy: 0.9532 - val_loss: 1.1234 - val_accuracy: 0.7508\n",
      "Epoch 361/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1378 - accuracy: 0.9398 - val_loss: 1.1250 - val_accuracy: 0.7695\n",
      "Epoch 362/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1157 - accuracy: 0.9485 - val_loss: 1.1441 - val_accuracy: 0.7757\n",
      "Epoch 363/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1604 - accuracy: 0.9412 - val_loss: 1.0904 - val_accuracy: 0.7679\n",
      "Epoch 364/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1423 - accuracy: 0.9432 - val_loss: 1.0826 - val_accuracy: 0.7445\n",
      "Epoch 365/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1289 - accuracy: 0.9485 - val_loss: 1.1232 - val_accuracy: 0.7586\n",
      "Epoch 366/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1507 - accuracy: 0.9392 - val_loss: 1.1212 - val_accuracy: 0.7523\n",
      "Epoch 367/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1484 - accuracy: 0.9392 - val_loss: 1.1294 - val_accuracy: 0.7679\n",
      "Epoch 368/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1420 - accuracy: 0.9418 - val_loss: 1.1417 - val_accuracy: 0.7664\n",
      "Epoch 369/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1281 - accuracy: 0.9479 - val_loss: 1.1025 - val_accuracy: 0.7664\n",
      "Epoch 370/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1624 - accuracy: 0.9385 - val_loss: 1.1379 - val_accuracy: 0.7835\n",
      "Epoch 371/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1366 - accuracy: 0.9459 - val_loss: 1.1236 - val_accuracy: 0.7788\n",
      "Epoch 372/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1410 - accuracy: 0.9445 - val_loss: 1.1322 - val_accuracy: 0.7695\n",
      "Epoch 373/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1374 - accuracy: 0.9439 - val_loss: 1.0859 - val_accuracy: 0.7757\n",
      "Epoch 374/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1573 - accuracy: 0.9358 - val_loss: 1.0976 - val_accuracy: 0.7741\n",
      "Epoch 375/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1487 - accuracy: 0.9325 - val_loss: 1.0721 - val_accuracy: 0.7741\n",
      "Epoch 376/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1615 - accuracy: 0.9398 - val_loss: 1.0522 - val_accuracy: 0.7679\n",
      "Epoch 377/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1375 - accuracy: 0.9392 - val_loss: 1.0572 - val_accuracy: 0.7710\n",
      "Epoch 378/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1245 - accuracy: 0.9485 - val_loss: 1.0876 - val_accuracy: 0.7617\n",
      "Epoch 379/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1306 - accuracy: 0.9472 - val_loss: 1.0840 - val_accuracy: 0.7601\n",
      "Epoch 380/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1418 - accuracy: 0.9445 - val_loss: 1.1376 - val_accuracy: 0.7679\n",
      "Epoch 381/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1459 - accuracy: 0.9412 - val_loss: 1.1122 - val_accuracy: 0.7819\n",
      "Epoch 382/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1448 - accuracy: 0.9432 - val_loss: 1.0692 - val_accuracy: 0.7757\n",
      "Epoch 383/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1362 - accuracy: 0.9439 - val_loss: 1.1329 - val_accuracy: 0.7819\n",
      "Epoch 384/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1155 - accuracy: 0.9545 - val_loss: 1.1135 - val_accuracy: 0.7664\n",
      "Epoch 385/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1047 - accuracy: 0.9572 - val_loss: 1.1960 - val_accuracy: 0.7726\n",
      "Epoch 386/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1315 - accuracy: 0.9432 - val_loss: 1.1617 - val_accuracy: 0.7570\n",
      "Epoch 387/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1497 - accuracy: 0.9452 - val_loss: 1.1393 - val_accuracy: 0.7601\n",
      "Epoch 388/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1184 - accuracy: 0.9492 - val_loss: 1.1891 - val_accuracy: 0.7695\n",
      "Epoch 389/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1521 - accuracy: 0.9365 - val_loss: 1.1655 - val_accuracy: 0.7788\n",
      "Epoch 390/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1445 - accuracy: 0.9378 - val_loss: 1.1474 - val_accuracy: 0.7601\n",
      "Epoch 391/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1455 - accuracy: 0.9425 - val_loss: 1.1057 - val_accuracy: 0.7773\n",
      "Epoch 392/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1385 - accuracy: 0.9418 - val_loss: 1.1205 - val_accuracy: 0.7788\n",
      "Epoch 393/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1349 - accuracy: 0.9445 - val_loss: 1.1012 - val_accuracy: 0.7586\n",
      "Epoch 394/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1334 - accuracy: 0.9479 - val_loss: 1.1615 - val_accuracy: 0.7695\n",
      "Epoch 395/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1365 - accuracy: 0.9432 - val_loss: 1.0941 - val_accuracy: 0.7773\n",
      "Epoch 396/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1263 - accuracy: 0.9512 - val_loss: 1.1354 - val_accuracy: 0.7664\n",
      "Epoch 397/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1229 - accuracy: 0.9525 - val_loss: 1.1511 - val_accuracy: 0.7726\n",
      "Epoch 398/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1363 - accuracy: 0.9445 - val_loss: 1.1246 - val_accuracy: 0.7601\n",
      "Epoch 399/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1322 - accuracy: 0.9398 - val_loss: 1.1557 - val_accuracy: 0.7664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1132 - accuracy: 0.9519 - val_loss: 1.1501 - val_accuracy: 0.7570\n",
      "Epoch 401/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1097 - accuracy: 0.9532 - val_loss: 1.1884 - val_accuracy: 0.7664\n",
      "Epoch 402/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1357 - accuracy: 0.9512 - val_loss: 1.1497 - val_accuracy: 0.7741\n",
      "Epoch 403/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1248 - accuracy: 0.9499 - val_loss: 1.1770 - val_accuracy: 0.7819\n",
      "Epoch 404/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1216 - accuracy: 0.9512 - val_loss: 1.1937 - val_accuracy: 0.7804\n",
      "Epoch 405/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1400 - accuracy: 0.9439 - val_loss: 1.2167 - val_accuracy: 0.7710\n",
      "Epoch 406/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1286 - accuracy: 0.9519 - val_loss: 1.2002 - val_accuracy: 0.7679\n",
      "Epoch 407/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1043 - accuracy: 0.9539 - val_loss: 1.1891 - val_accuracy: 0.7773\n",
      "Epoch 408/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1296 - accuracy: 0.9439 - val_loss: 1.1986 - val_accuracy: 0.7788\n",
      "Epoch 409/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1333 - accuracy: 0.9459 - val_loss: 1.1512 - val_accuracy: 0.7664\n",
      "Epoch 410/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1229 - accuracy: 0.9539 - val_loss: 1.2193 - val_accuracy: 0.7726\n",
      "Epoch 411/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1152 - accuracy: 0.9532 - val_loss: 1.2607 - val_accuracy: 0.7850\n",
      "Epoch 412/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1184 - accuracy: 0.9572 - val_loss: 1.1922 - val_accuracy: 0.7804\n",
      "Epoch 413/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1304 - accuracy: 0.9492 - val_loss: 1.2139 - val_accuracy: 0.7788\n",
      "Epoch 414/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1336 - accuracy: 0.9472 - val_loss: 1.1964 - val_accuracy: 0.7710\n",
      "Epoch 415/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1596 - accuracy: 0.9365 - val_loss: 1.1748 - val_accuracy: 0.7679\n",
      "Epoch 416/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1460 - accuracy: 0.9412 - val_loss: 1.1309 - val_accuracy: 0.7679\n",
      "Epoch 417/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1404 - accuracy: 0.9425 - val_loss: 1.1639 - val_accuracy: 0.7741\n",
      "Epoch 418/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1363 - accuracy: 0.9372 - val_loss: 1.1935 - val_accuracy: 0.7882\n",
      "Epoch 419/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1419 - accuracy: 0.9452 - val_loss: 1.1629 - val_accuracy: 0.7632\n",
      "Epoch 420/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1213 - accuracy: 0.9472 - val_loss: 1.2222 - val_accuracy: 0.7648\n",
      "Epoch 421/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1442 - accuracy: 0.9425 - val_loss: 1.2298 - val_accuracy: 0.7850\n",
      "Epoch 422/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1182 - accuracy: 0.9566 - val_loss: 1.1952 - val_accuracy: 0.7788\n",
      "Epoch 423/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1239 - accuracy: 0.9539 - val_loss: 1.2152 - val_accuracy: 0.7850\n",
      "Epoch 424/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1106 - accuracy: 0.9586 - val_loss: 1.1868 - val_accuracy: 0.7726\n",
      "Epoch 425/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1349 - accuracy: 0.9492 - val_loss: 1.2373 - val_accuracy: 0.7788\n",
      "Epoch 426/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1137 - accuracy: 0.9579 - val_loss: 1.1892 - val_accuracy: 0.7788\n",
      "Epoch 427/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1340 - accuracy: 0.9472 - val_loss: 1.1608 - val_accuracy: 0.7850\n",
      "Epoch 428/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1199 - accuracy: 0.9492 - val_loss: 1.1370 - val_accuracy: 0.7679\n",
      "Epoch 429/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1159 - accuracy: 0.9572 - val_loss: 1.1649 - val_accuracy: 0.7773\n",
      "Epoch 430/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1191 - accuracy: 0.9566 - val_loss: 1.1893 - val_accuracy: 0.7695\n",
      "Epoch 431/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1304 - accuracy: 0.9505 - val_loss: 1.1931 - val_accuracy: 0.7679\n",
      "Epoch 432/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1162 - accuracy: 0.9499 - val_loss: 1.2029 - val_accuracy: 0.7570\n",
      "Epoch 433/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1230 - accuracy: 0.9539 - val_loss: 1.2449 - val_accuracy: 0.7695\n",
      "Epoch 434/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1226 - accuracy: 0.9512 - val_loss: 1.2507 - val_accuracy: 0.7726\n",
      "Epoch 435/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1303 - accuracy: 0.9525 - val_loss: 1.2747 - val_accuracy: 0.7882\n",
      "Epoch 436/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1485 - accuracy: 0.9405 - val_loss: 1.1472 - val_accuracy: 0.7773\n",
      "Epoch 437/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1327 - accuracy: 0.9452 - val_loss: 1.1961 - val_accuracy: 0.7648\n",
      "Epoch 438/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1201 - accuracy: 0.9499 - val_loss: 1.1708 - val_accuracy: 0.7710\n",
      "Epoch 439/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1310 - accuracy: 0.9472 - val_loss: 1.2333 - val_accuracy: 0.7773\n",
      "Epoch 440/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1176 - accuracy: 0.9572 - val_loss: 1.2926 - val_accuracy: 0.7804\n",
      "Epoch 441/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1263 - accuracy: 0.9425 - val_loss: 1.2201 - val_accuracy: 0.7586\n",
      "Epoch 442/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1216 - accuracy: 0.9525 - val_loss: 1.2206 - val_accuracy: 0.7664\n",
      "Epoch 443/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1259 - accuracy: 0.9472 - val_loss: 1.2501 - val_accuracy: 0.7850\n",
      "Epoch 444/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1144 - accuracy: 0.9572 - val_loss: 1.2479 - val_accuracy: 0.7882\n",
      "Epoch 445/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1356 - accuracy: 0.9479 - val_loss: 1.2380 - val_accuracy: 0.7788\n",
      "Epoch 446/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1321 - accuracy: 0.9499 - val_loss: 1.2818 - val_accuracy: 0.7866\n",
      "Epoch 447/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1207 - accuracy: 0.9485 - val_loss: 1.3037 - val_accuracy: 0.7695\n",
      "Epoch 448/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1226 - accuracy: 0.9459 - val_loss: 1.2670 - val_accuracy: 0.7617\n",
      "Epoch 449/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1241 - accuracy: 0.9479 - val_loss: 1.2590 - val_accuracy: 0.7757\n",
      "Epoch 450/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1229 - accuracy: 0.9525 - val_loss: 1.1638 - val_accuracy: 0.7570\n",
      "Epoch 451/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1282 - accuracy: 0.9445 - val_loss: 1.1668 - val_accuracy: 0.7819\n",
      "Epoch 452/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1117 - accuracy: 0.9586 - val_loss: 1.2303 - val_accuracy: 0.7757\n",
      "Epoch 453/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1239 - accuracy: 0.9539 - val_loss: 1.2112 - val_accuracy: 0.7679\n",
      "Epoch 454/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1154 - accuracy: 0.9532 - val_loss: 1.2431 - val_accuracy: 0.7819\n",
      "Epoch 455/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1041 - accuracy: 0.9592 - val_loss: 1.2441 - val_accuracy: 0.7710\n",
      "Epoch 456/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1094 - accuracy: 0.9592 - val_loss: 1.3033 - val_accuracy: 0.7757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1082 - accuracy: 0.9566 - val_loss: 1.2408 - val_accuracy: 0.7741\n",
      "Epoch 458/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1092 - accuracy: 0.9572 - val_loss: 1.2536 - val_accuracy: 0.7757\n",
      "Epoch 459/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1035 - accuracy: 0.9592 - val_loss: 1.2325 - val_accuracy: 0.7648\n",
      "Epoch 460/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0950 - accuracy: 0.9632 - val_loss: 1.2197 - val_accuracy: 0.7710\n",
      "Epoch 461/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1102 - accuracy: 0.9599 - val_loss: 1.2731 - val_accuracy: 0.7710\n",
      "Epoch 462/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1159 - accuracy: 0.9519 - val_loss: 1.2504 - val_accuracy: 0.7757\n",
      "Epoch 463/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1057 - accuracy: 0.9566 - val_loss: 1.3103 - val_accuracy: 0.7788\n",
      "Epoch 464/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1241 - accuracy: 0.9499 - val_loss: 1.2134 - val_accuracy: 0.7632\n",
      "Epoch 465/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1428 - accuracy: 0.9432 - val_loss: 1.2465 - val_accuracy: 0.7726\n",
      "Epoch 466/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1356 - accuracy: 0.9439 - val_loss: 1.2332 - val_accuracy: 0.7819\n",
      "Epoch 467/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1302 - accuracy: 0.9519 - val_loss: 1.1292 - val_accuracy: 0.7586\n",
      "Epoch 468/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1045 - accuracy: 0.9606 - val_loss: 1.2023 - val_accuracy: 0.7679\n",
      "Epoch 469/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1037 - accuracy: 0.9639 - val_loss: 1.1606 - val_accuracy: 0.7695\n",
      "Epoch 470/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1025 - accuracy: 0.9599 - val_loss: 1.1893 - val_accuracy: 0.7632\n",
      "Epoch 471/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1050 - accuracy: 0.9539 - val_loss: 1.2237 - val_accuracy: 0.7710\n",
      "Epoch 472/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1039 - accuracy: 0.9586 - val_loss: 1.2924 - val_accuracy: 0.7648\n",
      "Epoch 473/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1217 - accuracy: 0.9559 - val_loss: 1.1812 - val_accuracy: 0.7492\n",
      "Epoch 474/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1231 - accuracy: 0.9559 - val_loss: 1.1846 - val_accuracy: 0.7664\n",
      "Epoch 475/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1369 - accuracy: 0.9485 - val_loss: 1.1979 - val_accuracy: 0.7695\n",
      "Epoch 476/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1326 - accuracy: 0.9418 - val_loss: 1.2232 - val_accuracy: 0.7726\n",
      "Epoch 477/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1213 - accuracy: 0.9519 - val_loss: 1.1865 - val_accuracy: 0.7866\n",
      "Epoch 478/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1089 - accuracy: 0.9559 - val_loss: 1.2494 - val_accuracy: 0.7835\n",
      "Epoch 479/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0994 - accuracy: 0.9586 - val_loss: 1.2175 - val_accuracy: 0.7788\n",
      "Epoch 480/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1329 - accuracy: 0.9452 - val_loss: 1.2783 - val_accuracy: 0.7819\n",
      "Epoch 481/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1384 - accuracy: 0.9492 - val_loss: 1.2300 - val_accuracy: 0.7601\n",
      "Epoch 482/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1108 - accuracy: 0.9532 - val_loss: 1.1980 - val_accuracy: 0.7664\n",
      "Epoch 483/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1112 - accuracy: 0.9519 - val_loss: 1.2252 - val_accuracy: 0.7617\n",
      "Epoch 484/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1388 - accuracy: 0.9405 - val_loss: 1.2317 - val_accuracy: 0.7757\n",
      "Epoch 485/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1125 - accuracy: 0.9586 - val_loss: 1.2837 - val_accuracy: 0.7632\n",
      "Epoch 486/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1343 - accuracy: 0.9425 - val_loss: 1.3453 - val_accuracy: 0.7757\n",
      "Epoch 487/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1221 - accuracy: 0.9532 - val_loss: 1.2407 - val_accuracy: 0.7601\n",
      "Epoch 488/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1191 - accuracy: 0.9552 - val_loss: 1.2358 - val_accuracy: 0.7679\n",
      "Epoch 489/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1119 - accuracy: 0.9566 - val_loss: 1.2707 - val_accuracy: 0.7726\n",
      "Epoch 490/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1283 - accuracy: 0.9505 - val_loss: 1.2552 - val_accuracy: 0.7757\n",
      "Epoch 491/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1101 - accuracy: 0.9579 - val_loss: 1.2604 - val_accuracy: 0.7850\n",
      "Epoch 492/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1129 - accuracy: 0.9552 - val_loss: 1.2638 - val_accuracy: 0.7710\n",
      "Epoch 493/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1045 - accuracy: 0.9639 - val_loss: 1.2517 - val_accuracy: 0.7477\n",
      "Epoch 494/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1275 - accuracy: 0.9472 - val_loss: 1.2618 - val_accuracy: 0.7648\n",
      "Epoch 495/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1091 - accuracy: 0.9512 - val_loss: 1.2294 - val_accuracy: 0.7866\n",
      "Epoch 496/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1041 - accuracy: 0.9599 - val_loss: 1.3057 - val_accuracy: 0.7710\n",
      "Epoch 497/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1134 - accuracy: 0.9592 - val_loss: 1.2629 - val_accuracy: 0.7679\n",
      "Epoch 498/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1232 - accuracy: 0.9512 - val_loss: 1.2606 - val_accuracy: 0.7508\n",
      "Epoch 499/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1260 - accuracy: 0.9512 - val_loss: 1.2562 - val_accuracy: 0.7523\n",
      "Epoch 500/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0966 - accuracy: 0.9612 - val_loss: 1.2341 - val_accuracy: 0.7648\n",
      "Epoch 501/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1238 - accuracy: 0.9505 - val_loss: 1.2368 - val_accuracy: 0.7788\n",
      "Epoch 502/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1281 - accuracy: 0.9519 - val_loss: 1.2450 - val_accuracy: 0.7648\n",
      "Epoch 503/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1150 - accuracy: 0.9566 - val_loss: 1.2774 - val_accuracy: 0.7617\n",
      "Epoch 504/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1103 - accuracy: 0.9559 - val_loss: 1.2646 - val_accuracy: 0.7757\n",
      "Epoch 505/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1202 - accuracy: 0.9479 - val_loss: 1.2680 - val_accuracy: 0.7757\n",
      "Epoch 506/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1179 - accuracy: 0.9559 - val_loss: 1.3119 - val_accuracy: 0.7664\n",
      "Epoch 507/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0979 - accuracy: 0.9612 - val_loss: 1.3242 - val_accuracy: 0.7695\n",
      "Epoch 508/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1384 - accuracy: 0.9445 - val_loss: 1.3124 - val_accuracy: 0.7741\n",
      "Epoch 509/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1146 - accuracy: 0.9525 - val_loss: 1.2982 - val_accuracy: 0.7539\n",
      "Epoch 510/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1034 - accuracy: 0.9579 - val_loss: 1.3192 - val_accuracy: 0.7741\n",
      "Epoch 511/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1064 - accuracy: 0.9539 - val_loss: 1.2863 - val_accuracy: 0.7788\n",
      "Epoch 512/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1065 - accuracy: 0.9612 - val_loss: 1.3358 - val_accuracy: 0.7679\n",
      "Epoch 513/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0978 - accuracy: 0.9639 - val_loss: 1.3341 - val_accuracy: 0.7726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 514/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1058 - accuracy: 0.9659 - val_loss: 1.3046 - val_accuracy: 0.7679\n",
      "Epoch 515/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1037 - accuracy: 0.9619 - val_loss: 1.2784 - val_accuracy: 0.7757\n",
      "Epoch 516/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1115 - accuracy: 0.9492 - val_loss: 1.3244 - val_accuracy: 0.7695\n",
      "Epoch 517/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1284 - accuracy: 0.9492 - val_loss: 1.2454 - val_accuracy: 0.7695\n",
      "Epoch 518/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1191 - accuracy: 0.9465 - val_loss: 1.2528 - val_accuracy: 0.7726\n",
      "Epoch 519/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1160 - accuracy: 0.9525 - val_loss: 1.3073 - val_accuracy: 0.7586\n",
      "Epoch 520/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1086 - accuracy: 0.9532 - val_loss: 1.3026 - val_accuracy: 0.7679\n",
      "Epoch 521/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1070 - accuracy: 0.9619 - val_loss: 1.3630 - val_accuracy: 0.7726\n",
      "Epoch 522/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1081 - accuracy: 0.9632 - val_loss: 1.3255 - val_accuracy: 0.7632\n",
      "Epoch 523/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1078 - accuracy: 0.9606 - val_loss: 1.3657 - val_accuracy: 0.7648\n",
      "Epoch 524/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1108 - accuracy: 0.9566 - val_loss: 1.2808 - val_accuracy: 0.7695\n",
      "Epoch 525/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1222 - accuracy: 0.9559 - val_loss: 1.3006 - val_accuracy: 0.7788\n",
      "Epoch 526/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1096 - accuracy: 0.9599 - val_loss: 1.2704 - val_accuracy: 0.7819\n",
      "Epoch 527/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1246 - accuracy: 0.9485 - val_loss: 1.3207 - val_accuracy: 0.7773\n",
      "Epoch 528/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1153 - accuracy: 0.9539 - val_loss: 1.2625 - val_accuracy: 0.7617\n",
      "Epoch 529/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1012 - accuracy: 0.9606 - val_loss: 1.2508 - val_accuracy: 0.7679\n",
      "Epoch 530/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1185 - accuracy: 0.9552 - val_loss: 1.2764 - val_accuracy: 0.7632\n",
      "Epoch 531/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1052 - accuracy: 0.9626 - val_loss: 1.2912 - val_accuracy: 0.7773\n",
      "Epoch 532/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1033 - accuracy: 0.9646 - val_loss: 1.2841 - val_accuracy: 0.7648\n",
      "Epoch 533/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0930 - accuracy: 0.9672 - val_loss: 1.3169 - val_accuracy: 0.7695\n",
      "Epoch 534/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1131 - accuracy: 0.9532 - val_loss: 1.2817 - val_accuracy: 0.7819\n",
      "Epoch 535/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1035 - accuracy: 0.9632 - val_loss: 1.3022 - val_accuracy: 0.7741\n",
      "Epoch 536/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1102 - accuracy: 0.9579 - val_loss: 1.2807 - val_accuracy: 0.7648\n",
      "Epoch 537/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1069 - accuracy: 0.9592 - val_loss: 1.2604 - val_accuracy: 0.7710\n",
      "Epoch 538/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1498 - accuracy: 0.9459 - val_loss: 1.3146 - val_accuracy: 0.7586\n",
      "Epoch 539/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1107 - accuracy: 0.9579 - val_loss: 1.2636 - val_accuracy: 0.7695\n",
      "Epoch 540/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0967 - accuracy: 0.9639 - val_loss: 1.2895 - val_accuracy: 0.7570\n",
      "Epoch 541/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1027 - accuracy: 0.9619 - val_loss: 1.3404 - val_accuracy: 0.7617\n",
      "Epoch 542/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0946 - accuracy: 0.9619 - val_loss: 1.3378 - val_accuracy: 0.7664\n",
      "Epoch 543/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1093 - accuracy: 0.9552 - val_loss: 1.3125 - val_accuracy: 0.7679\n",
      "Epoch 544/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1079 - accuracy: 0.9619 - val_loss: 1.3328 - val_accuracy: 0.7679\n",
      "Epoch 545/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1047 - accuracy: 0.9599 - val_loss: 1.3041 - val_accuracy: 0.7648\n",
      "Epoch 546/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1292 - accuracy: 0.9485 - val_loss: 1.2837 - val_accuracy: 0.7679\n",
      "Epoch 547/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1273 - accuracy: 0.9539 - val_loss: 1.3006 - val_accuracy: 0.7804\n",
      "Epoch 548/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1176 - accuracy: 0.9599 - val_loss: 1.3322 - val_accuracy: 0.7866\n",
      "Epoch 549/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1050 - accuracy: 0.9612 - val_loss: 1.2644 - val_accuracy: 0.7679\n",
      "Epoch 550/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0857 - accuracy: 0.9659 - val_loss: 1.2779 - val_accuracy: 0.7679\n",
      "Epoch 551/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0891 - accuracy: 0.9659 - val_loss: 1.3063 - val_accuracy: 0.7741\n",
      "Epoch 552/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1298 - accuracy: 0.9499 - val_loss: 1.2187 - val_accuracy: 0.7632\n",
      "Epoch 553/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1458 - accuracy: 0.9392 - val_loss: 1.2333 - val_accuracy: 0.7788\n",
      "Epoch 554/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1028 - accuracy: 0.9639 - val_loss: 1.2573 - val_accuracy: 0.7679\n",
      "Epoch 555/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1106 - accuracy: 0.9519 - val_loss: 1.2898 - val_accuracy: 0.7757\n",
      "Epoch 556/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0976 - accuracy: 0.9579 - val_loss: 1.3062 - val_accuracy: 0.7773\n",
      "Epoch 557/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1100 - accuracy: 0.9505 - val_loss: 1.2953 - val_accuracy: 0.7695\n",
      "Epoch 558/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1233 - accuracy: 0.9525 - val_loss: 1.3202 - val_accuracy: 0.7695\n",
      "Epoch 559/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1237 - accuracy: 0.9539 - val_loss: 1.2935 - val_accuracy: 0.7788\n",
      "Epoch 560/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0974 - accuracy: 0.9619 - val_loss: 1.2388 - val_accuracy: 0.7632\n",
      "Epoch 561/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1110 - accuracy: 0.9566 - val_loss: 1.2264 - val_accuracy: 0.7710\n",
      "Epoch 562/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0978 - accuracy: 0.9632 - val_loss: 1.3218 - val_accuracy: 0.7804\n",
      "Epoch 563/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0993 - accuracy: 0.9659 - val_loss: 1.3095 - val_accuracy: 0.7710\n",
      "Epoch 564/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1070 - accuracy: 0.9499 - val_loss: 1.3035 - val_accuracy: 0.7773\n",
      "Epoch 565/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1091 - accuracy: 0.9592 - val_loss: 1.3144 - val_accuracy: 0.7695\n",
      "Epoch 566/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0986 - accuracy: 0.9666 - val_loss: 1.3879 - val_accuracy: 0.7664\n",
      "Epoch 567/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0807 - accuracy: 0.9693 - val_loss: 1.3163 - val_accuracy: 0.7539\n",
      "Epoch 568/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1313 - accuracy: 0.9485 - val_loss: 1.3177 - val_accuracy: 0.7664\n",
      "Epoch 569/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1309 - accuracy: 0.9452 - val_loss: 1.2724 - val_accuracy: 0.7773\n",
      "Epoch 570/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1081 - accuracy: 0.9592 - val_loss: 1.2837 - val_accuracy: 0.7757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 571/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1157 - accuracy: 0.9559 - val_loss: 1.3147 - val_accuracy: 0.7850\n",
      "Epoch 572/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1115 - accuracy: 0.9579 - val_loss: 1.3061 - val_accuracy: 0.7741\n",
      "Epoch 573/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1219 - accuracy: 0.9472 - val_loss: 1.2792 - val_accuracy: 0.7679\n",
      "Epoch 574/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0961 - accuracy: 0.9646 - val_loss: 1.3330 - val_accuracy: 0.7773\n",
      "Epoch 575/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1156 - accuracy: 0.9532 - val_loss: 1.2802 - val_accuracy: 0.7773\n",
      "Epoch 576/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1450 - accuracy: 0.9499 - val_loss: 1.2599 - val_accuracy: 0.7726\n",
      "Epoch 577/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1088 - accuracy: 0.9552 - val_loss: 1.3183 - val_accuracy: 0.7773\n",
      "Epoch 578/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1114 - accuracy: 0.9586 - val_loss: 1.2631 - val_accuracy: 0.7726\n",
      "Epoch 579/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0846 - accuracy: 0.9619 - val_loss: 1.3188 - val_accuracy: 0.7741\n",
      "Epoch 580/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1122 - accuracy: 0.9519 - val_loss: 1.3190 - val_accuracy: 0.7679\n",
      "Epoch 581/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1041 - accuracy: 0.9612 - val_loss: 1.3576 - val_accuracy: 0.7850\n",
      "Epoch 582/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1155 - accuracy: 0.9572 - val_loss: 1.3699 - val_accuracy: 0.7726\n",
      "Epoch 583/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1165 - accuracy: 0.9599 - val_loss: 1.2795 - val_accuracy: 0.7804\n",
      "Epoch 584/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0942 - accuracy: 0.9572 - val_loss: 1.3258 - val_accuracy: 0.7695\n",
      "Epoch 585/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0973 - accuracy: 0.9666 - val_loss: 1.3696 - val_accuracy: 0.7679\n",
      "Epoch 586/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1045 - accuracy: 0.9606 - val_loss: 1.3341 - val_accuracy: 0.7695\n",
      "Epoch 587/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1112 - accuracy: 0.9539 - val_loss: 1.3538 - val_accuracy: 0.7757\n",
      "Epoch 588/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0962 - accuracy: 0.9632 - val_loss: 1.3283 - val_accuracy: 0.7757\n",
      "Epoch 589/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0866 - accuracy: 0.9679 - val_loss: 1.3804 - val_accuracy: 0.7866\n",
      "Epoch 590/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0911 - accuracy: 0.9646 - val_loss: 1.3489 - val_accuracy: 0.7850\n",
      "Epoch 591/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0851 - accuracy: 0.9646 - val_loss: 1.3813 - val_accuracy: 0.7975\n",
      "Epoch 592/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1103 - accuracy: 0.9606 - val_loss: 1.3468 - val_accuracy: 0.7835\n",
      "Epoch 593/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1030 - accuracy: 0.9612 - val_loss: 1.3080 - val_accuracy: 0.7757\n",
      "Epoch 594/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1337 - accuracy: 0.9479 - val_loss: 1.2862 - val_accuracy: 0.7757\n",
      "Epoch 595/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1042 - accuracy: 0.9606 - val_loss: 1.3512 - val_accuracy: 0.7695\n",
      "Epoch 596/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0843 - accuracy: 0.9672 - val_loss: 1.3811 - val_accuracy: 0.7788\n",
      "Epoch 597/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0901 - accuracy: 0.9586 - val_loss: 1.3882 - val_accuracy: 0.7804\n",
      "Epoch 598/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1092 - accuracy: 0.9532 - val_loss: 1.3788 - val_accuracy: 0.7788\n",
      "Epoch 599/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0888 - accuracy: 0.9686 - val_loss: 1.3810 - val_accuracy: 0.7695\n",
      "Epoch 600/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0848 - accuracy: 0.9672 - val_loss: 1.4340 - val_accuracy: 0.7835\n",
      "Epoch 601/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1080 - accuracy: 0.9619 - val_loss: 1.3795 - val_accuracy: 0.7757\n",
      "Epoch 602/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1047 - accuracy: 0.9592 - val_loss: 1.3370 - val_accuracy: 0.7741\n",
      "Epoch 603/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0915 - accuracy: 0.9632 - val_loss: 1.4082 - val_accuracy: 0.7757\n",
      "Epoch 604/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0932 - accuracy: 0.9679 - val_loss: 1.4375 - val_accuracy: 0.7882\n",
      "Epoch 605/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1034 - accuracy: 0.9592 - val_loss: 1.3366 - val_accuracy: 0.7850\n",
      "Epoch 606/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1112 - accuracy: 0.9599 - val_loss: 1.2925 - val_accuracy: 0.7819\n",
      "Epoch 607/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0910 - accuracy: 0.9612 - val_loss: 1.4447 - val_accuracy: 0.7773\n",
      "Epoch 608/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0955 - accuracy: 0.9626 - val_loss: 1.3417 - val_accuracy: 0.7819\n",
      "Epoch 609/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1072 - accuracy: 0.9539 - val_loss: 1.3700 - val_accuracy: 0.7757\n",
      "Epoch 610/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1074 - accuracy: 0.9606 - val_loss: 1.3738 - val_accuracy: 0.7695\n",
      "Epoch 611/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1118 - accuracy: 0.9612 - val_loss: 1.3694 - val_accuracy: 0.7819\n",
      "Epoch 612/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0972 - accuracy: 0.9632 - val_loss: 1.3611 - val_accuracy: 0.7788\n",
      "Epoch 613/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1129 - accuracy: 0.9586 - val_loss: 1.3301 - val_accuracy: 0.7695\n",
      "Epoch 614/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1255 - accuracy: 0.9545 - val_loss: 1.3309 - val_accuracy: 0.7788\n",
      "Epoch 615/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1145 - accuracy: 0.9545 - val_loss: 1.2917 - val_accuracy: 0.7726\n",
      "Epoch 616/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0945 - accuracy: 0.9672 - val_loss: 1.3486 - val_accuracy: 0.7788\n",
      "Epoch 617/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1065 - accuracy: 0.9612 - val_loss: 1.3074 - val_accuracy: 0.7804\n",
      "Epoch 618/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0905 - accuracy: 0.9679 - val_loss: 1.3565 - val_accuracy: 0.7819\n",
      "Epoch 619/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1095 - accuracy: 0.9552 - val_loss: 1.3289 - val_accuracy: 0.7804\n",
      "Epoch 620/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1108 - accuracy: 0.9559 - val_loss: 1.3376 - val_accuracy: 0.7804\n",
      "Epoch 621/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1043 - accuracy: 0.9626 - val_loss: 1.3063 - val_accuracy: 0.7773\n",
      "Epoch 622/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1013 - accuracy: 0.9586 - val_loss: 1.3449 - val_accuracy: 0.7835\n",
      "Epoch 623/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0952 - accuracy: 0.9659 - val_loss: 1.3448 - val_accuracy: 0.7741\n",
      "Epoch 624/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0977 - accuracy: 0.9592 - val_loss: 1.3899 - val_accuracy: 0.7695\n",
      "Epoch 625/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1030 - accuracy: 0.9659 - val_loss: 1.4039 - val_accuracy: 0.7882\n",
      "Epoch 626/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0974 - accuracy: 0.9586 - val_loss: 1.4057 - val_accuracy: 0.7804\n",
      "Epoch 627/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0953 - accuracy: 0.9626 - val_loss: 1.4282 - val_accuracy: 0.7601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 628/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1097 - accuracy: 0.9599 - val_loss: 1.4402 - val_accuracy: 0.7819\n",
      "Epoch 629/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1109 - accuracy: 0.9619 - val_loss: 1.3907 - val_accuracy: 0.7804\n",
      "Epoch 630/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1045 - accuracy: 0.9572 - val_loss: 1.3126 - val_accuracy: 0.7679\n",
      "Epoch 631/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1261 - accuracy: 0.9525 - val_loss: 1.3203 - val_accuracy: 0.7773\n",
      "Epoch 632/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0968 - accuracy: 0.9626 - val_loss: 1.3499 - val_accuracy: 0.7850\n",
      "Epoch 633/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1002 - accuracy: 0.9606 - val_loss: 1.3875 - val_accuracy: 0.7819\n",
      "Epoch 634/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1034 - accuracy: 0.9566 - val_loss: 1.3048 - val_accuracy: 0.7726\n",
      "Epoch 635/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1075 - accuracy: 0.9579 - val_loss: 1.3734 - val_accuracy: 0.7850\n",
      "Epoch 636/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0969 - accuracy: 0.9626 - val_loss: 1.3408 - val_accuracy: 0.7804\n",
      "Epoch 637/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1037 - accuracy: 0.9606 - val_loss: 1.3531 - val_accuracy: 0.7819\n",
      "Epoch 638/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1049 - accuracy: 0.9566 - val_loss: 1.3477 - val_accuracy: 0.7773\n",
      "Epoch 639/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1062 - accuracy: 0.9619 - val_loss: 1.3205 - val_accuracy: 0.7788\n",
      "Epoch 640/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0988 - accuracy: 0.9572 - val_loss: 1.2790 - val_accuracy: 0.7741\n",
      "Epoch 641/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0952 - accuracy: 0.9626 - val_loss: 1.3816 - val_accuracy: 0.7664\n",
      "Epoch 642/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0850 - accuracy: 0.9693 - val_loss: 1.3898 - val_accuracy: 0.7773\n",
      "Epoch 643/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1190 - accuracy: 0.9559 - val_loss: 1.3919 - val_accuracy: 0.7710\n",
      "Epoch 644/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0983 - accuracy: 0.9612 - val_loss: 1.3147 - val_accuracy: 0.7741\n",
      "Epoch 645/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0993 - accuracy: 0.9646 - val_loss: 1.3470 - val_accuracy: 0.7710\n",
      "Epoch 646/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1086 - accuracy: 0.9586 - val_loss: 1.3169 - val_accuracy: 0.7648\n",
      "Epoch 647/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1014 - accuracy: 0.9612 - val_loss: 1.3861 - val_accuracy: 0.7804\n",
      "Epoch 648/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0920 - accuracy: 0.9646 - val_loss: 1.4188 - val_accuracy: 0.7757\n",
      "Epoch 649/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0890 - accuracy: 0.9699 - val_loss: 1.4719 - val_accuracy: 0.7741\n",
      "Epoch 650/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1024 - accuracy: 0.9539 - val_loss: 1.4460 - val_accuracy: 0.7757\n",
      "Epoch 651/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0828 - accuracy: 0.9646 - val_loss: 1.3688 - val_accuracy: 0.7773\n",
      "Epoch 652/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0859 - accuracy: 0.9686 - val_loss: 1.3755 - val_accuracy: 0.7679\n",
      "Epoch 653/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1217 - accuracy: 0.9619 - val_loss: 1.3585 - val_accuracy: 0.7757\n",
      "Epoch 654/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0871 - accuracy: 0.9659 - val_loss: 1.3914 - val_accuracy: 0.7757\n",
      "Epoch 655/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0800 - accuracy: 0.9713 - val_loss: 1.4197 - val_accuracy: 0.7819\n",
      "Epoch 656/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0716 - accuracy: 0.9726 - val_loss: 1.4777 - val_accuracy: 0.7757\n",
      "Epoch 657/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0788 - accuracy: 0.9672 - val_loss: 1.4543 - val_accuracy: 0.7695\n",
      "Epoch 658/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0807 - accuracy: 0.9693 - val_loss: 1.4424 - val_accuracy: 0.7695\n",
      "Epoch 659/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0829 - accuracy: 0.9686 - val_loss: 1.4295 - val_accuracy: 0.7788\n",
      "Epoch 660/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0972 - accuracy: 0.9579 - val_loss: 1.4592 - val_accuracy: 0.7835\n",
      "Epoch 661/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0936 - accuracy: 0.9646 - val_loss: 1.3772 - val_accuracy: 0.7804\n",
      "Epoch 662/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1031 - accuracy: 0.9599 - val_loss: 1.3854 - val_accuracy: 0.7773\n",
      "Epoch 663/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0948 - accuracy: 0.9632 - val_loss: 1.4157 - val_accuracy: 0.7835\n",
      "Epoch 664/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0934 - accuracy: 0.9659 - val_loss: 1.4616 - val_accuracy: 0.7819\n",
      "Epoch 665/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0960 - accuracy: 0.9612 - val_loss: 1.3620 - val_accuracy: 0.7882\n",
      "Epoch 666/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1029 - accuracy: 0.9592 - val_loss: 1.3538 - val_accuracy: 0.7788\n",
      "Epoch 667/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1023 - accuracy: 0.9619 - val_loss: 1.4408 - val_accuracy: 0.7804\n",
      "Epoch 668/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1057 - accuracy: 0.9572 - val_loss: 1.4041 - val_accuracy: 0.7882\n",
      "Epoch 669/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1116 - accuracy: 0.9572 - val_loss: 1.3665 - val_accuracy: 0.7850\n",
      "Epoch 670/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0912 - accuracy: 0.9652 - val_loss: 1.4323 - val_accuracy: 0.7835\n",
      "Epoch 671/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1047 - accuracy: 0.9639 - val_loss: 1.4047 - val_accuracy: 0.7601\n",
      "Epoch 672/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1120 - accuracy: 0.9579 - val_loss: 1.4148 - val_accuracy: 0.7819\n",
      "Epoch 673/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1042 - accuracy: 0.9686 - val_loss: 1.3893 - val_accuracy: 0.7788\n",
      "Epoch 674/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1070 - accuracy: 0.9592 - val_loss: 1.4003 - val_accuracy: 0.7850\n",
      "Epoch 675/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1124 - accuracy: 0.9566 - val_loss: 1.3708 - val_accuracy: 0.7882\n",
      "Epoch 676/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0917 - accuracy: 0.9646 - val_loss: 1.4402 - val_accuracy: 0.7850\n",
      "Epoch 677/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0994 - accuracy: 0.9686 - val_loss: 1.4062 - val_accuracy: 0.7866\n",
      "Epoch 678/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0757 - accuracy: 0.9686 - val_loss: 1.4451 - val_accuracy: 0.7664\n",
      "Epoch 679/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1154 - accuracy: 0.9572 - val_loss: 1.4369 - val_accuracy: 0.7757\n",
      "Epoch 680/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0919 - accuracy: 0.9639 - val_loss: 1.3997 - val_accuracy: 0.7804\n",
      "Epoch 681/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0917 - accuracy: 0.9686 - val_loss: 1.4175 - val_accuracy: 0.7866\n",
      "Epoch 682/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0786 - accuracy: 0.9719 - val_loss: 1.4006 - val_accuracy: 0.7835\n",
      "Epoch 683/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0877 - accuracy: 0.9686 - val_loss: 1.4229 - val_accuracy: 0.7850\n",
      "Epoch 684/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1005 - accuracy: 0.9646 - val_loss: 1.4706 - val_accuracy: 0.7835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 685/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0996 - accuracy: 0.9586 - val_loss: 1.4132 - val_accuracy: 0.7741\n",
      "Epoch 686/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0703 - accuracy: 0.9739 - val_loss: 1.5104 - val_accuracy: 0.7757\n",
      "Epoch 687/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1063 - accuracy: 0.9566 - val_loss: 1.4653 - val_accuracy: 0.7850\n",
      "Epoch 688/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0833 - accuracy: 0.9672 - val_loss: 1.4026 - val_accuracy: 0.7773\n",
      "Epoch 689/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0883 - accuracy: 0.9679 - val_loss: 1.4291 - val_accuracy: 0.7913\n",
      "Epoch 690/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1030 - accuracy: 0.9619 - val_loss: 1.4008 - val_accuracy: 0.7804\n",
      "Epoch 691/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1084 - accuracy: 0.9566 - val_loss: 1.4223 - val_accuracy: 0.7804\n",
      "Epoch 692/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0949 - accuracy: 0.9632 - val_loss: 1.4389 - val_accuracy: 0.7788\n",
      "Epoch 693/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1135 - accuracy: 0.9626 - val_loss: 1.3474 - val_accuracy: 0.7648\n",
      "Epoch 694/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1058 - accuracy: 0.9592 - val_loss: 1.4603 - val_accuracy: 0.7695\n",
      "Epoch 695/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1038 - accuracy: 0.9619 - val_loss: 1.3939 - val_accuracy: 0.7679\n",
      "Epoch 696/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0851 - accuracy: 0.9679 - val_loss: 1.3799 - val_accuracy: 0.7679\n",
      "Epoch 697/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0959 - accuracy: 0.9639 - val_loss: 1.4126 - val_accuracy: 0.7726\n",
      "Epoch 698/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1188 - accuracy: 0.9606 - val_loss: 1.3828 - val_accuracy: 0.7710\n",
      "Epoch 699/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1148 - accuracy: 0.9505 - val_loss: 1.4448 - val_accuracy: 0.7726\n",
      "Epoch 700/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0995 - accuracy: 0.9579 - val_loss: 1.3674 - val_accuracy: 0.7695\n",
      "Epoch 701/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0798 - accuracy: 0.9686 - val_loss: 1.4479 - val_accuracy: 0.7632\n",
      "Epoch 702/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0856 - accuracy: 0.9632 - val_loss: 1.4389 - val_accuracy: 0.7664\n",
      "Epoch 703/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1126 - accuracy: 0.9632 - val_loss: 1.4130 - val_accuracy: 0.7710\n",
      "Epoch 704/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0879 - accuracy: 0.9639 - val_loss: 1.3695 - val_accuracy: 0.7741\n",
      "Epoch 705/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0910 - accuracy: 0.9545 - val_loss: 1.4082 - val_accuracy: 0.7788\n",
      "Epoch 706/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0822 - accuracy: 0.9632 - val_loss: 1.4763 - val_accuracy: 0.7913\n",
      "Epoch 707/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0866 - accuracy: 0.9652 - val_loss: 1.4243 - val_accuracy: 0.7726\n",
      "Epoch 708/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1108 - accuracy: 0.9586 - val_loss: 1.4746 - val_accuracy: 0.7819\n",
      "Epoch 709/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0930 - accuracy: 0.9652 - val_loss: 1.5290 - val_accuracy: 0.7757\n",
      "Epoch 710/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1075 - accuracy: 0.9612 - val_loss: 1.4567 - val_accuracy: 0.7866\n",
      "Epoch 711/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1022 - accuracy: 0.9606 - val_loss: 1.4159 - val_accuracy: 0.7741\n",
      "Epoch 712/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0970 - accuracy: 0.9652 - val_loss: 1.4398 - val_accuracy: 0.7757\n",
      "Epoch 713/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0784 - accuracy: 0.9713 - val_loss: 1.4461 - val_accuracy: 0.7757\n",
      "Epoch 714/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1026 - accuracy: 0.9619 - val_loss: 1.4001 - val_accuracy: 0.7819\n",
      "Epoch 715/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0859 - accuracy: 0.9639 - val_loss: 1.3964 - val_accuracy: 0.7788\n",
      "Epoch 716/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0977 - accuracy: 0.9639 - val_loss: 1.5260 - val_accuracy: 0.7897\n",
      "Epoch 717/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0899 - accuracy: 0.9592 - val_loss: 1.4750 - val_accuracy: 0.7757\n",
      "Epoch 718/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0915 - accuracy: 0.9652 - val_loss: 1.4404 - val_accuracy: 0.7726\n",
      "Epoch 719/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1200 - accuracy: 0.9512 - val_loss: 1.4771 - val_accuracy: 0.7804\n",
      "Epoch 720/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0860 - accuracy: 0.9639 - val_loss: 1.4953 - val_accuracy: 0.7757\n",
      "Epoch 721/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1069 - accuracy: 0.9566 - val_loss: 1.3928 - val_accuracy: 0.7695\n",
      "Epoch 722/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0941 - accuracy: 0.9659 - val_loss: 1.4209 - val_accuracy: 0.7835\n",
      "Epoch 723/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0976 - accuracy: 0.9612 - val_loss: 1.3917 - val_accuracy: 0.7850\n",
      "Epoch 724/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0961 - accuracy: 0.9606 - val_loss: 1.4646 - val_accuracy: 0.7928\n",
      "Epoch 725/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1279 - accuracy: 0.9566 - val_loss: 1.4290 - val_accuracy: 0.7757\n",
      "Epoch 726/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1095 - accuracy: 0.9612 - val_loss: 1.4241 - val_accuracy: 0.7850\n",
      "Epoch 727/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0953 - accuracy: 0.9552 - val_loss: 1.4013 - val_accuracy: 0.7882\n",
      "Epoch 728/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0961 - accuracy: 0.9706 - val_loss: 1.4076 - val_accuracy: 0.7773\n",
      "Epoch 729/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0995 - accuracy: 0.9619 - val_loss: 1.4432 - val_accuracy: 0.7741\n",
      "Epoch 730/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1191 - accuracy: 0.9632 - val_loss: 1.3858 - val_accuracy: 0.7804\n",
      "Epoch 731/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0900 - accuracy: 0.9619 - val_loss: 1.4416 - val_accuracy: 0.7835\n",
      "Epoch 732/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0899 - accuracy: 0.9639 - val_loss: 1.4240 - val_accuracy: 0.7819\n",
      "Epoch 733/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1110 - accuracy: 0.9592 - val_loss: 1.3397 - val_accuracy: 0.7819\n",
      "Epoch 734/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1085 - accuracy: 0.9579 - val_loss: 1.4186 - val_accuracy: 0.7913\n",
      "Epoch 735/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0925 - accuracy: 0.9652 - val_loss: 1.3977 - val_accuracy: 0.7850\n",
      "Epoch 736/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0951 - accuracy: 0.9666 - val_loss: 1.3902 - val_accuracy: 0.7850\n",
      "Epoch 737/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0982 - accuracy: 0.9672 - val_loss: 1.4511 - val_accuracy: 0.7850\n",
      "Epoch 738/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0788 - accuracy: 0.9646 - val_loss: 1.4525 - val_accuracy: 0.7866\n",
      "Epoch 739/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0860 - accuracy: 0.9679 - val_loss: 1.3860 - val_accuracy: 0.7819\n",
      "Epoch 740/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0877 - accuracy: 0.9679 - val_loss: 1.4476 - val_accuracy: 0.7788\n",
      "Epoch 741/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1180 - accuracy: 0.9505 - val_loss: 1.4372 - val_accuracy: 0.7741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 742/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0985 - accuracy: 0.9592 - val_loss: 1.4201 - val_accuracy: 0.7757\n",
      "Epoch 743/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1063 - accuracy: 0.9626 - val_loss: 1.4435 - val_accuracy: 0.7788\n",
      "Epoch 744/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0838 - accuracy: 0.9693 - val_loss: 1.4205 - val_accuracy: 0.7726\n",
      "Epoch 745/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0815 - accuracy: 0.9672 - val_loss: 1.4966 - val_accuracy: 0.7819\n",
      "Epoch 746/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0956 - accuracy: 0.9619 - val_loss: 1.4702 - val_accuracy: 0.7804\n",
      "Epoch 747/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1020 - accuracy: 0.9619 - val_loss: 1.4285 - val_accuracy: 0.7819\n",
      "Epoch 748/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0985 - accuracy: 0.9646 - val_loss: 1.4147 - val_accuracy: 0.7819\n",
      "Epoch 749/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0923 - accuracy: 0.9659 - val_loss: 1.4682 - val_accuracy: 0.7788\n",
      "Epoch 750/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1047 - accuracy: 0.9612 - val_loss: 1.4966 - val_accuracy: 0.7882\n",
      "Epoch 751/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0999 - accuracy: 0.9659 - val_loss: 1.4343 - val_accuracy: 0.7819\n",
      "Epoch 752/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0998 - accuracy: 0.9592 - val_loss: 1.4230 - val_accuracy: 0.7804\n",
      "Epoch 753/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0856 - accuracy: 0.9719 - val_loss: 1.5398 - val_accuracy: 0.7882\n",
      "Epoch 754/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0935 - accuracy: 0.9632 - val_loss: 1.4781 - val_accuracy: 0.7757\n",
      "Epoch 755/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1044 - accuracy: 0.9646 - val_loss: 1.4532 - val_accuracy: 0.7773\n",
      "Epoch 756/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0996 - accuracy: 0.9606 - val_loss: 1.4406 - val_accuracy: 0.7850\n",
      "Epoch 757/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0986 - accuracy: 0.9626 - val_loss: 1.4216 - val_accuracy: 0.7773\n",
      "Epoch 758/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0915 - accuracy: 0.9632 - val_loss: 1.4845 - val_accuracy: 0.7850\n",
      "Epoch 759/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0859 - accuracy: 0.9713 - val_loss: 1.4492 - val_accuracy: 0.7757\n",
      "Epoch 760/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0966 - accuracy: 0.9652 - val_loss: 1.4077 - val_accuracy: 0.7710\n",
      "Epoch 761/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0861 - accuracy: 0.9646 - val_loss: 1.4256 - val_accuracy: 0.7695\n",
      "Epoch 762/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0845 - accuracy: 0.9599 - val_loss: 1.4548 - val_accuracy: 0.7866\n",
      "Epoch 763/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0978 - accuracy: 0.9646 - val_loss: 1.4302 - val_accuracy: 0.7913\n",
      "Epoch 764/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0810 - accuracy: 0.9699 - val_loss: 1.4704 - val_accuracy: 0.7804\n",
      "Epoch 765/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0796 - accuracy: 0.9666 - val_loss: 1.5191 - val_accuracy: 0.7850\n",
      "Epoch 766/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0917 - accuracy: 0.9686 - val_loss: 1.4861 - val_accuracy: 0.7835\n",
      "Epoch 767/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0849 - accuracy: 0.9652 - val_loss: 1.3778 - val_accuracy: 0.7757\n",
      "Epoch 768/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0737 - accuracy: 0.9679 - val_loss: 1.4214 - val_accuracy: 0.7773\n",
      "Epoch 769/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0813 - accuracy: 0.9719 - val_loss: 1.5078 - val_accuracy: 0.7897\n",
      "Epoch 770/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0797 - accuracy: 0.9686 - val_loss: 1.5012 - val_accuracy: 0.7710\n",
      "Epoch 771/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0911 - accuracy: 0.9679 - val_loss: 1.4909 - val_accuracy: 0.7570\n",
      "Epoch 772/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0857 - accuracy: 0.9706 - val_loss: 1.4966 - val_accuracy: 0.7850\n",
      "Epoch 773/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0899 - accuracy: 0.9626 - val_loss: 1.4340 - val_accuracy: 0.7741\n",
      "Epoch 774/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0848 - accuracy: 0.9666 - val_loss: 1.4628 - val_accuracy: 0.7804\n",
      "Epoch 775/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0788 - accuracy: 0.9733 - val_loss: 1.4044 - val_accuracy: 0.7741\n",
      "Epoch 776/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1028 - accuracy: 0.9599 - val_loss: 1.4178 - val_accuracy: 0.7819\n",
      "Epoch 777/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0816 - accuracy: 0.9612 - val_loss: 1.5071 - val_accuracy: 0.7741\n",
      "Epoch 778/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0923 - accuracy: 0.9666 - val_loss: 1.4782 - val_accuracy: 0.7710\n",
      "Epoch 779/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1027 - accuracy: 0.9606 - val_loss: 1.5055 - val_accuracy: 0.7773\n",
      "Epoch 780/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1114 - accuracy: 0.9545 - val_loss: 1.5196 - val_accuracy: 0.7804\n",
      "Epoch 781/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0947 - accuracy: 0.9666 - val_loss: 1.4260 - val_accuracy: 0.7679\n",
      "Epoch 782/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0851 - accuracy: 0.9672 - val_loss: 1.3764 - val_accuracy: 0.7788\n",
      "Epoch 783/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1010 - accuracy: 0.9626 - val_loss: 1.4436 - val_accuracy: 0.7835\n",
      "Epoch 784/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0908 - accuracy: 0.9672 - val_loss: 1.4088 - val_accuracy: 0.7757\n",
      "Epoch 785/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1022 - accuracy: 0.9599 - val_loss: 1.4689 - val_accuracy: 0.7726\n",
      "Epoch 786/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0900 - accuracy: 0.9666 - val_loss: 1.5045 - val_accuracy: 0.7804\n",
      "Epoch 787/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1101 - accuracy: 0.9545 - val_loss: 1.5218 - val_accuracy: 0.7773\n",
      "Epoch 788/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0991 - accuracy: 0.9659 - val_loss: 1.4445 - val_accuracy: 0.7726\n",
      "Epoch 789/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0808 - accuracy: 0.9679 - val_loss: 1.4461 - val_accuracy: 0.7850\n",
      "Epoch 790/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0789 - accuracy: 0.9699 - val_loss: 1.5287 - val_accuracy: 0.7710\n",
      "Epoch 791/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1016 - accuracy: 0.9672 - val_loss: 1.5056 - val_accuracy: 0.7679\n",
      "Epoch 792/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1018 - accuracy: 0.9566 - val_loss: 1.4636 - val_accuracy: 0.7804\n",
      "Epoch 793/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0946 - accuracy: 0.9646 - val_loss: 1.4940 - val_accuracy: 0.7835\n",
      "Epoch 794/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0740 - accuracy: 0.9699 - val_loss: 1.5062 - val_accuracy: 0.7773\n",
      "Epoch 795/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0846 - accuracy: 0.9672 - val_loss: 1.4684 - val_accuracy: 0.7882\n",
      "Epoch 796/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0786 - accuracy: 0.9746 - val_loss: 1.4848 - val_accuracy: 0.7882\n",
      "Epoch 797/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0891 - accuracy: 0.9699 - val_loss: 1.4761 - val_accuracy: 0.7804\n",
      "Epoch 798/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0986 - accuracy: 0.9619 - val_loss: 1.5274 - val_accuracy: 0.7710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 799/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0839 - accuracy: 0.9659 - val_loss: 1.4716 - val_accuracy: 0.7741\n",
      "Epoch 800/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0888 - accuracy: 0.9672 - val_loss: 1.4372 - val_accuracy: 0.7679\n",
      "Epoch 801/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0780 - accuracy: 0.9666 - val_loss: 1.5177 - val_accuracy: 0.7679\n",
      "Epoch 802/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0903 - accuracy: 0.9666 - val_loss: 1.5355 - val_accuracy: 0.7773\n",
      "Epoch 803/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0629 - accuracy: 0.9746 - val_loss: 1.5648 - val_accuracy: 0.7648\n",
      "Epoch 804/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0803 - accuracy: 0.9686 - val_loss: 1.5723 - val_accuracy: 0.7773\n",
      "Epoch 805/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0679 - accuracy: 0.9779 - val_loss: 1.5576 - val_accuracy: 0.7695\n",
      "Epoch 806/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0831 - accuracy: 0.9706 - val_loss: 1.5220 - val_accuracy: 0.7773\n",
      "Epoch 807/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0735 - accuracy: 0.9739 - val_loss: 1.5415 - val_accuracy: 0.7664\n",
      "Epoch 808/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0803 - accuracy: 0.9753 - val_loss: 1.5205 - val_accuracy: 0.7773\n",
      "Epoch 809/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0639 - accuracy: 0.9753 - val_loss: 1.5401 - val_accuracy: 0.7710\n",
      "Epoch 810/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0806 - accuracy: 0.9719 - val_loss: 1.4773 - val_accuracy: 0.7664\n",
      "Epoch 811/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0659 - accuracy: 0.9753 - val_loss: 1.5182 - val_accuracy: 0.7695\n",
      "Epoch 812/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0658 - accuracy: 0.9746 - val_loss: 1.5687 - val_accuracy: 0.7726\n",
      "Epoch 813/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0815 - accuracy: 0.9672 - val_loss: 1.5052 - val_accuracy: 0.7835\n",
      "Epoch 814/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0769 - accuracy: 0.9666 - val_loss: 1.4650 - val_accuracy: 0.7788\n",
      "Epoch 815/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0946 - accuracy: 0.9726 - val_loss: 1.5575 - val_accuracy: 0.7897\n",
      "Epoch 816/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0889 - accuracy: 0.9699 - val_loss: 1.4881 - val_accuracy: 0.7664\n",
      "Epoch 817/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0904 - accuracy: 0.9706 - val_loss: 1.5195 - val_accuracy: 0.7835\n",
      "Epoch 818/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1237 - accuracy: 0.9512 - val_loss: 1.4100 - val_accuracy: 0.7960\n",
      "Epoch 819/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0897 - accuracy: 0.9619 - val_loss: 1.4709 - val_accuracy: 0.7679\n",
      "Epoch 820/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1295 - accuracy: 0.9626 - val_loss: 1.4980 - val_accuracy: 0.7773\n",
      "Epoch 821/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0913 - accuracy: 0.9639 - val_loss: 1.5027 - val_accuracy: 0.7773\n",
      "Epoch 822/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0836 - accuracy: 0.9693 - val_loss: 1.5452 - val_accuracy: 0.7757\n",
      "Epoch 823/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0833 - accuracy: 0.9606 - val_loss: 1.5793 - val_accuracy: 0.7741\n",
      "Epoch 824/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0957 - accuracy: 0.9552 - val_loss: 1.5418 - val_accuracy: 0.7710\n",
      "Epoch 825/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0959 - accuracy: 0.9672 - val_loss: 1.4677 - val_accuracy: 0.7804\n",
      "Epoch 826/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0897 - accuracy: 0.9666 - val_loss: 1.4645 - val_accuracy: 0.7850\n",
      "Epoch 827/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0806 - accuracy: 0.9672 - val_loss: 1.5188 - val_accuracy: 0.7741\n",
      "Epoch 828/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0765 - accuracy: 0.9672 - val_loss: 1.5344 - val_accuracy: 0.7710\n",
      "Epoch 829/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0898 - accuracy: 0.9666 - val_loss: 1.5050 - val_accuracy: 0.7866\n",
      "Epoch 830/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0861 - accuracy: 0.9666 - val_loss: 1.5392 - val_accuracy: 0.7835\n",
      "Epoch 831/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0892 - accuracy: 0.9639 - val_loss: 1.5230 - val_accuracy: 0.7835\n",
      "Epoch 832/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0742 - accuracy: 0.9699 - val_loss: 1.5590 - val_accuracy: 0.7757\n",
      "Epoch 833/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0892 - accuracy: 0.9652 - val_loss: 1.5375 - val_accuracy: 0.7850\n",
      "Epoch 834/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0955 - accuracy: 0.9646 - val_loss: 1.5378 - val_accuracy: 0.7928\n",
      "Epoch 835/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1007 - accuracy: 0.9666 - val_loss: 1.4726 - val_accuracy: 0.7804\n",
      "Epoch 836/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0758 - accuracy: 0.9686 - val_loss: 1.5640 - val_accuracy: 0.7866\n",
      "Epoch 837/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0748 - accuracy: 0.9726 - val_loss: 1.4707 - val_accuracy: 0.7741\n",
      "Epoch 838/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1078 - accuracy: 0.9612 - val_loss: 1.4496 - val_accuracy: 0.7835\n",
      "Epoch 839/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1025 - accuracy: 0.9619 - val_loss: 1.4469 - val_accuracy: 0.7726\n",
      "Epoch 840/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0905 - accuracy: 0.9659 - val_loss: 1.4871 - val_accuracy: 0.7679\n",
      "Epoch 841/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0792 - accuracy: 0.9706 - val_loss: 1.5771 - val_accuracy: 0.7773\n",
      "Epoch 842/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0960 - accuracy: 0.9612 - val_loss: 1.4942 - val_accuracy: 0.7788\n",
      "Epoch 843/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0796 - accuracy: 0.9706 - val_loss: 1.5387 - val_accuracy: 0.7757\n",
      "Epoch 844/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1016 - accuracy: 0.9659 - val_loss: 1.5060 - val_accuracy: 0.7695\n",
      "Epoch 845/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1006 - accuracy: 0.9592 - val_loss: 1.5445 - val_accuracy: 0.7788\n",
      "Epoch 846/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0873 - accuracy: 0.9672 - val_loss: 1.4486 - val_accuracy: 0.7617\n",
      "Epoch 847/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0744 - accuracy: 0.9672 - val_loss: 1.4898 - val_accuracy: 0.7741\n",
      "Epoch 848/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0807 - accuracy: 0.9733 - val_loss: 1.4692 - val_accuracy: 0.7773\n",
      "Epoch 849/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0813 - accuracy: 0.9693 - val_loss: 1.5271 - val_accuracy: 0.7757\n",
      "Epoch 850/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0827 - accuracy: 0.9693 - val_loss: 1.5361 - val_accuracy: 0.7757\n",
      "Epoch 851/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0844 - accuracy: 0.9666 - val_loss: 1.5130 - val_accuracy: 0.7695\n",
      "Epoch 852/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0907 - accuracy: 0.9659 - val_loss: 1.5434 - val_accuracy: 0.7835\n",
      "Epoch 853/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1051 - accuracy: 0.9639 - val_loss: 1.5513 - val_accuracy: 0.7757\n",
      "Epoch 854/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0838 - accuracy: 0.9652 - val_loss: 1.5415 - val_accuracy: 0.7695\n",
      "Epoch 855/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0966 - accuracy: 0.9652 - val_loss: 1.5281 - val_accuracy: 0.7804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 856/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0852 - accuracy: 0.9686 - val_loss: 1.5407 - val_accuracy: 0.7741\n",
      "Epoch 857/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0946 - accuracy: 0.9686 - val_loss: 1.4972 - val_accuracy: 0.7835\n",
      "Epoch 858/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0958 - accuracy: 0.9619 - val_loss: 1.4867 - val_accuracy: 0.7788\n",
      "Epoch 859/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0961 - accuracy: 0.9646 - val_loss: 1.5719 - val_accuracy: 0.7882\n",
      "Epoch 860/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1088 - accuracy: 0.9639 - val_loss: 1.5622 - val_accuracy: 0.7850\n",
      "Epoch 861/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0929 - accuracy: 0.9686 - val_loss: 1.4098 - val_accuracy: 0.7804\n",
      "Epoch 862/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0899 - accuracy: 0.9646 - val_loss: 1.4966 - val_accuracy: 0.7804\n",
      "Epoch 863/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0654 - accuracy: 0.9739 - val_loss: 1.4220 - val_accuracy: 0.7726\n",
      "Epoch 864/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0765 - accuracy: 0.9706 - val_loss: 1.5043 - val_accuracy: 0.7804\n",
      "Epoch 865/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0857 - accuracy: 0.9706 - val_loss: 1.5539 - val_accuracy: 0.7882\n",
      "Epoch 866/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0992 - accuracy: 0.9626 - val_loss: 1.4739 - val_accuracy: 0.7741\n",
      "Epoch 867/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0903 - accuracy: 0.9659 - val_loss: 1.5153 - val_accuracy: 0.7741\n",
      "Epoch 868/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1058 - accuracy: 0.9586 - val_loss: 1.4883 - val_accuracy: 0.7804\n",
      "Epoch 869/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0821 - accuracy: 0.9659 - val_loss: 1.4569 - val_accuracy: 0.7726\n",
      "Epoch 870/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0645 - accuracy: 0.9766 - val_loss: 1.4963 - val_accuracy: 0.7804\n",
      "Epoch 871/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0722 - accuracy: 0.9779 - val_loss: 1.4958 - val_accuracy: 0.7773\n",
      "Epoch 872/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0902 - accuracy: 0.9606 - val_loss: 1.4702 - val_accuracy: 0.7648\n",
      "Epoch 873/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0942 - accuracy: 0.9666 - val_loss: 1.4339 - val_accuracy: 0.7710\n",
      "Epoch 874/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1001 - accuracy: 0.9612 - val_loss: 1.4158 - val_accuracy: 0.7695\n",
      "Epoch 875/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0758 - accuracy: 0.9699 - val_loss: 1.5129 - val_accuracy: 0.7882\n",
      "Epoch 876/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1105 - accuracy: 0.9592 - val_loss: 1.4442 - val_accuracy: 0.7679\n",
      "Epoch 877/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0849 - accuracy: 0.9632 - val_loss: 1.5268 - val_accuracy: 0.7850\n",
      "Epoch 878/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0766 - accuracy: 0.9679 - val_loss: 1.5077 - val_accuracy: 0.7695\n",
      "Epoch 879/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0633 - accuracy: 0.9739 - val_loss: 1.4806 - val_accuracy: 0.7710\n",
      "Epoch 880/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0780 - accuracy: 0.9699 - val_loss: 1.5137 - val_accuracy: 0.7788\n",
      "Epoch 881/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0796 - accuracy: 0.9686 - val_loss: 1.4911 - val_accuracy: 0.7741\n",
      "Epoch 882/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0743 - accuracy: 0.9706 - val_loss: 1.5025 - val_accuracy: 0.7804\n",
      "Epoch 883/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0735 - accuracy: 0.9746 - val_loss: 1.4700 - val_accuracy: 0.7773\n",
      "Epoch 884/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0739 - accuracy: 0.9733 - val_loss: 1.5054 - val_accuracy: 0.7695\n",
      "Epoch 885/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0993 - accuracy: 0.9686 - val_loss: 1.4216 - val_accuracy: 0.7835\n",
      "Epoch 886/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0869 - accuracy: 0.9686 - val_loss: 1.4525 - val_accuracy: 0.7726\n",
      "Epoch 887/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0794 - accuracy: 0.9679 - val_loss: 1.4588 - val_accuracy: 0.7632\n",
      "Epoch 888/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0848 - accuracy: 0.9746 - val_loss: 1.4443 - val_accuracy: 0.7726\n",
      "Epoch 889/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0870 - accuracy: 0.9646 - val_loss: 1.4931 - val_accuracy: 0.7710\n",
      "Epoch 890/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0790 - accuracy: 0.9679 - val_loss: 1.4882 - val_accuracy: 0.7679\n",
      "Epoch 891/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1004 - accuracy: 0.9592 - val_loss: 1.5020 - val_accuracy: 0.7757\n",
      "Epoch 892/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0962 - accuracy: 0.9652 - val_loss: 1.4893 - val_accuracy: 0.7695\n",
      "Epoch 893/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0911 - accuracy: 0.9706 - val_loss: 1.5102 - val_accuracy: 0.7757\n",
      "Epoch 894/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0985 - accuracy: 0.9659 - val_loss: 1.4696 - val_accuracy: 0.7773\n",
      "Epoch 895/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0904 - accuracy: 0.9646 - val_loss: 1.4845 - val_accuracy: 0.7601\n",
      "Epoch 896/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0933 - accuracy: 0.9713 - val_loss: 1.5154 - val_accuracy: 0.7741\n",
      "Epoch 897/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1037 - accuracy: 0.9592 - val_loss: 1.4740 - val_accuracy: 0.7788\n",
      "Epoch 898/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1019 - accuracy: 0.9626 - val_loss: 1.4877 - val_accuracy: 0.7788\n",
      "Epoch 899/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1013 - accuracy: 0.9652 - val_loss: 1.5835 - val_accuracy: 0.7804\n",
      "Epoch 900/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0973 - accuracy: 0.9626 - val_loss: 1.6098 - val_accuracy: 0.7710\n",
      "Epoch 901/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1021 - accuracy: 0.9626 - val_loss: 1.5118 - val_accuracy: 0.7741\n",
      "Epoch 902/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1117 - accuracy: 0.9572 - val_loss: 1.5047 - val_accuracy: 0.7882\n",
      "Epoch 903/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0906 - accuracy: 0.9632 - val_loss: 1.5018 - val_accuracy: 0.7897\n",
      "Epoch 904/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0756 - accuracy: 0.9733 - val_loss: 1.4418 - val_accuracy: 0.7695\n",
      "Epoch 905/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0748 - accuracy: 0.9693 - val_loss: 1.4990 - val_accuracy: 0.7835\n",
      "Epoch 906/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0731 - accuracy: 0.9733 - val_loss: 1.5451 - val_accuracy: 0.7757\n",
      "Epoch 907/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0920 - accuracy: 0.9679 - val_loss: 1.4974 - val_accuracy: 0.7788\n",
      "Epoch 908/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0948 - accuracy: 0.9619 - val_loss: 1.4411 - val_accuracy: 0.7804\n",
      "Epoch 909/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0664 - accuracy: 0.9806 - val_loss: 1.4236 - val_accuracy: 0.7679\n",
      "Epoch 910/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0807 - accuracy: 0.9719 - val_loss: 1.4838 - val_accuracy: 0.7804\n",
      "Epoch 911/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0763 - accuracy: 0.9739 - val_loss: 1.5322 - val_accuracy: 0.7757\n",
      "Epoch 912/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0898 - accuracy: 0.9659 - val_loss: 1.4746 - val_accuracy: 0.7710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 913/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0688 - accuracy: 0.9686 - val_loss: 1.5581 - val_accuracy: 0.7679\n",
      "Epoch 914/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0805 - accuracy: 0.9639 - val_loss: 1.5363 - val_accuracy: 0.7726\n",
      "Epoch 915/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0697 - accuracy: 0.9733 - val_loss: 1.5861 - val_accuracy: 0.7835\n",
      "Epoch 916/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0801 - accuracy: 0.9739 - val_loss: 1.5629 - val_accuracy: 0.7850\n",
      "Epoch 917/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0832 - accuracy: 0.9686 - val_loss: 1.5348 - val_accuracy: 0.7850\n",
      "Epoch 918/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0765 - accuracy: 0.9739 - val_loss: 1.5232 - val_accuracy: 0.7835\n",
      "Epoch 919/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0733 - accuracy: 0.9679 - val_loss: 1.5695 - val_accuracy: 0.7741\n",
      "Epoch 920/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0774 - accuracy: 0.9699 - val_loss: 1.5317 - val_accuracy: 0.7601\n",
      "Epoch 921/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0949 - accuracy: 0.9606 - val_loss: 1.5552 - val_accuracy: 0.7773\n",
      "Epoch 922/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0938 - accuracy: 0.9626 - val_loss: 1.4396 - val_accuracy: 0.7726\n",
      "Epoch 923/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1136 - accuracy: 0.9606 - val_loss: 1.4316 - val_accuracy: 0.7679\n",
      "Epoch 924/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0730 - accuracy: 0.9706 - val_loss: 1.4821 - val_accuracy: 0.7773\n",
      "Epoch 925/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0891 - accuracy: 0.9632 - val_loss: 1.5288 - val_accuracy: 0.7835\n",
      "Epoch 926/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0865 - accuracy: 0.9606 - val_loss: 1.4422 - val_accuracy: 0.7804\n",
      "Epoch 927/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0723 - accuracy: 0.9686 - val_loss: 1.5415 - val_accuracy: 0.7882\n",
      "Epoch 928/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1067 - accuracy: 0.9532 - val_loss: 1.4450 - val_accuracy: 0.7741\n",
      "Epoch 929/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0611 - accuracy: 0.9793 - val_loss: 1.5360 - val_accuracy: 0.7726\n",
      "Epoch 930/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0706 - accuracy: 0.9739 - val_loss: 1.5522 - val_accuracy: 0.7710\n",
      "Epoch 931/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0781 - accuracy: 0.9713 - val_loss: 1.5801 - val_accuracy: 0.7773\n",
      "Epoch 932/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0835 - accuracy: 0.9659 - val_loss: 1.5508 - val_accuracy: 0.7773\n",
      "Epoch 933/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0881 - accuracy: 0.9699 - val_loss: 1.4837 - val_accuracy: 0.7757\n",
      "Epoch 934/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0948 - accuracy: 0.9659 - val_loss: 1.5001 - val_accuracy: 0.7850\n",
      "Epoch 935/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0927 - accuracy: 0.9592 - val_loss: 1.4500 - val_accuracy: 0.7664\n",
      "Epoch 936/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0759 - accuracy: 0.9726 - val_loss: 1.4258 - val_accuracy: 0.7710\n",
      "Epoch 937/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1023 - accuracy: 0.9579 - val_loss: 1.5212 - val_accuracy: 0.7850\n",
      "Epoch 938/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0940 - accuracy: 0.9659 - val_loss: 1.4422 - val_accuracy: 0.7695\n",
      "Epoch 939/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0921 - accuracy: 0.9659 - val_loss: 1.4624 - val_accuracy: 0.7835\n",
      "Epoch 940/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0914 - accuracy: 0.9612 - val_loss: 1.4823 - val_accuracy: 0.7850\n",
      "Epoch 941/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1096 - accuracy: 0.9666 - val_loss: 1.5137 - val_accuracy: 0.7850\n",
      "Epoch 942/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0861 - accuracy: 0.9679 - val_loss: 1.5238 - val_accuracy: 0.7819\n",
      "Epoch 943/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0926 - accuracy: 0.9626 - val_loss: 1.4930 - val_accuracy: 0.7866\n",
      "Epoch 944/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0821 - accuracy: 0.9733 - val_loss: 1.4720 - val_accuracy: 0.7773\n",
      "Epoch 945/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0834 - accuracy: 0.9739 - val_loss: 1.4338 - val_accuracy: 0.7757\n",
      "Epoch 946/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0726 - accuracy: 0.9746 - val_loss: 1.4875 - val_accuracy: 0.7617\n",
      "Epoch 947/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0974 - accuracy: 0.9646 - val_loss: 1.4827 - val_accuracy: 0.7882\n",
      "Epoch 948/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0861 - accuracy: 0.9693 - val_loss: 1.4331 - val_accuracy: 0.7804\n",
      "Epoch 949/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0937 - accuracy: 0.9646 - val_loss: 1.4208 - val_accuracy: 0.7788\n",
      "Epoch 950/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0764 - accuracy: 0.9679 - val_loss: 1.4337 - val_accuracy: 0.7788\n",
      "Epoch 951/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0651 - accuracy: 0.9759 - val_loss: 1.5362 - val_accuracy: 0.7804\n",
      "Epoch 952/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0761 - accuracy: 0.9679 - val_loss: 1.5378 - val_accuracy: 0.7788\n",
      "Epoch 953/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0605 - accuracy: 0.9759 - val_loss: 1.5099 - val_accuracy: 0.7788\n",
      "Epoch 954/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0778 - accuracy: 0.9693 - val_loss: 1.4401 - val_accuracy: 0.7773\n",
      "Epoch 955/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0798 - accuracy: 0.9706 - val_loss: 1.5379 - val_accuracy: 0.7882\n",
      "Epoch 956/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0771 - accuracy: 0.9719 - val_loss: 1.5038 - val_accuracy: 0.7835\n",
      "Epoch 957/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0831 - accuracy: 0.9659 - val_loss: 1.4968 - val_accuracy: 0.7928\n",
      "Epoch 958/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0664 - accuracy: 0.9759 - val_loss: 1.4742 - val_accuracy: 0.7788\n",
      "Epoch 959/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1144 - accuracy: 0.9559 - val_loss: 1.5194 - val_accuracy: 0.7773\n",
      "Epoch 960/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0844 - accuracy: 0.9672 - val_loss: 1.5314 - val_accuracy: 0.7773\n",
      "Epoch 961/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0934 - accuracy: 0.9679 - val_loss: 1.4877 - val_accuracy: 0.7835\n",
      "Epoch 962/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0729 - accuracy: 0.9713 - val_loss: 1.5144 - val_accuracy: 0.7788\n",
      "Epoch 963/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0860 - accuracy: 0.9652 - val_loss: 1.5624 - val_accuracy: 0.7897\n",
      "Epoch 964/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0779 - accuracy: 0.9699 - val_loss: 1.5262 - val_accuracy: 0.7850\n",
      "Epoch 965/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0874 - accuracy: 0.9672 - val_loss: 1.5368 - val_accuracy: 0.7850\n",
      "Epoch 966/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0716 - accuracy: 0.9733 - val_loss: 1.5353 - val_accuracy: 0.7804\n",
      "Epoch 967/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0635 - accuracy: 0.9793 - val_loss: 1.5749 - val_accuracy: 0.7850\n",
      "Epoch 968/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0732 - accuracy: 0.9713 - val_loss: 1.5494 - val_accuracy: 0.7882\n",
      "Epoch 969/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0780 - accuracy: 0.9719 - val_loss: 1.4899 - val_accuracy: 0.7788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 970/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0865 - accuracy: 0.9733 - val_loss: 1.5218 - val_accuracy: 0.7928\n",
      "Epoch 971/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0801 - accuracy: 0.9652 - val_loss: 1.4813 - val_accuracy: 0.7773\n",
      "Epoch 972/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0736 - accuracy: 0.9679 - val_loss: 1.5657 - val_accuracy: 0.7788\n",
      "Epoch 973/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1035 - accuracy: 0.9612 - val_loss: 1.5416 - val_accuracy: 0.7928\n",
      "Epoch 974/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0678 - accuracy: 0.9713 - val_loss: 1.4674 - val_accuracy: 0.7664\n",
      "Epoch 975/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1033 - accuracy: 0.9626 - val_loss: 1.4913 - val_accuracy: 0.7710\n",
      "Epoch 976/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0734 - accuracy: 0.9726 - val_loss: 1.5524 - val_accuracy: 0.7835\n",
      "Epoch 977/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0767 - accuracy: 0.9733 - val_loss: 1.4896 - val_accuracy: 0.7819\n",
      "Epoch 978/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0831 - accuracy: 0.9706 - val_loss: 1.4878 - val_accuracy: 0.7835\n",
      "Epoch 979/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0801 - accuracy: 0.9726 - val_loss: 1.5428 - val_accuracy: 0.7944\n",
      "Epoch 980/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0889 - accuracy: 0.9726 - val_loss: 1.5789 - val_accuracy: 0.7944\n",
      "Epoch 981/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0828 - accuracy: 0.9713 - val_loss: 1.5776 - val_accuracy: 0.7757\n",
      "Epoch 982/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0698 - accuracy: 0.9773 - val_loss: 1.6087 - val_accuracy: 0.7960\n",
      "Epoch 983/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0878 - accuracy: 0.9679 - val_loss: 1.5077 - val_accuracy: 0.7788\n",
      "Epoch 984/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0652 - accuracy: 0.9766 - val_loss: 1.5033 - val_accuracy: 0.7804\n",
      "Epoch 985/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0777 - accuracy: 0.9739 - val_loss: 1.5285 - val_accuracy: 0.7819\n",
      "Epoch 986/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0752 - accuracy: 0.9719 - val_loss: 1.6640 - val_accuracy: 0.7850\n",
      "Epoch 987/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0896 - accuracy: 0.9659 - val_loss: 1.7155 - val_accuracy: 0.7819\n",
      "Epoch 988/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0981 - accuracy: 0.9666 - val_loss: 1.5643 - val_accuracy: 0.7788\n",
      "Epoch 989/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0727 - accuracy: 0.9733 - val_loss: 1.5691 - val_accuracy: 0.7788\n",
      "Epoch 990/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0708 - accuracy: 0.9733 - val_loss: 1.5661 - val_accuracy: 0.7788\n",
      "Epoch 991/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0700 - accuracy: 0.9733 - val_loss: 1.5993 - val_accuracy: 0.7850\n",
      "Epoch 992/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0762 - accuracy: 0.9713 - val_loss: 1.6194 - val_accuracy: 0.7804\n",
      "Epoch 993/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0823 - accuracy: 0.9713 - val_loss: 1.5401 - val_accuracy: 0.7726\n",
      "Epoch 994/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0826 - accuracy: 0.9693 - val_loss: 1.5173 - val_accuracy: 0.7804\n",
      "Epoch 995/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0841 - accuracy: 0.9719 - val_loss: 1.5605 - val_accuracy: 0.7804\n",
      "Epoch 996/1500\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.0722 - accuracy: 0.9719 - val_loss: 1.5141 - val_accuracy: 0.7788\n",
      "Epoch 997/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0760 - accuracy: 0.9699 - val_loss: 1.5722 - val_accuracy: 0.7741\n",
      "Epoch 998/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0707 - accuracy: 0.9699 - val_loss: 1.5651 - val_accuracy: 0.7757\n",
      "Epoch 999/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0654 - accuracy: 0.9719 - val_loss: 1.6204 - val_accuracy: 0.7913\n",
      "Epoch 1000/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0843 - accuracy: 0.9672 - val_loss: 1.5530 - val_accuracy: 0.7757\n",
      "Epoch 1001/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0791 - accuracy: 0.9699 - val_loss: 1.5534 - val_accuracy: 0.7850\n",
      "Epoch 1002/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0801 - accuracy: 0.9706 - val_loss: 1.5215 - val_accuracy: 0.7835\n",
      "Epoch 1003/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0572 - accuracy: 0.9773 - val_loss: 1.5947 - val_accuracy: 0.7804\n",
      "Epoch 1004/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0817 - accuracy: 0.9672 - val_loss: 1.5765 - val_accuracy: 0.7741\n",
      "Epoch 1005/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0862 - accuracy: 0.9666 - val_loss: 1.6060 - val_accuracy: 0.7773\n",
      "Epoch 1006/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0934 - accuracy: 0.9619 - val_loss: 1.5006 - val_accuracy: 0.7726\n",
      "Epoch 1007/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0894 - accuracy: 0.9686 - val_loss: 1.5395 - val_accuracy: 0.7788\n",
      "Epoch 1008/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0986 - accuracy: 0.9639 - val_loss: 1.4615 - val_accuracy: 0.7679\n",
      "Epoch 1009/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1172 - accuracy: 0.9552 - val_loss: 1.5077 - val_accuracy: 0.7866\n",
      "Epoch 1010/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0689 - accuracy: 0.9786 - val_loss: 1.6193 - val_accuracy: 0.7804\n",
      "Epoch 1011/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0984 - accuracy: 0.9606 - val_loss: 1.5362 - val_accuracy: 0.7726\n",
      "Epoch 1012/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0834 - accuracy: 0.9713 - val_loss: 1.5470 - val_accuracy: 0.7804\n",
      "Epoch 1013/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0887 - accuracy: 0.9659 - val_loss: 1.5050 - val_accuracy: 0.7882\n",
      "Epoch 1014/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0724 - accuracy: 0.9726 - val_loss: 1.5272 - val_accuracy: 0.7741\n",
      "Epoch 1015/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0742 - accuracy: 0.9733 - val_loss: 1.5720 - val_accuracy: 0.7850\n",
      "Epoch 1016/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0881 - accuracy: 0.9713 - val_loss: 1.5284 - val_accuracy: 0.7804\n",
      "Epoch 1017/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0666 - accuracy: 0.9739 - val_loss: 1.5724 - val_accuracy: 0.7726\n",
      "Epoch 1018/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0832 - accuracy: 0.9719 - val_loss: 1.5307 - val_accuracy: 0.7788\n",
      "Epoch 1019/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0825 - accuracy: 0.9679 - val_loss: 1.5333 - val_accuracy: 0.7741\n",
      "Epoch 1020/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1020 - accuracy: 0.9612 - val_loss: 1.5695 - val_accuracy: 0.7741\n",
      "Epoch 1021/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0880 - accuracy: 0.9659 - val_loss: 1.5241 - val_accuracy: 0.7819\n",
      "Epoch 1022/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0969 - accuracy: 0.9679 - val_loss: 1.6283 - val_accuracy: 0.7835\n",
      "Epoch 1023/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0899 - accuracy: 0.9619 - val_loss: 1.5811 - val_accuracy: 0.7835\n",
      "Epoch 1024/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0842 - accuracy: 0.9733 - val_loss: 1.4742 - val_accuracy: 0.7819\n",
      "Epoch 1025/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0633 - accuracy: 0.9799 - val_loss: 1.5750 - val_accuracy: 0.7804\n",
      "Epoch 1026/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0603 - accuracy: 0.9806 - val_loss: 1.5438 - val_accuracy: 0.7788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1027/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0695 - accuracy: 0.9733 - val_loss: 1.5856 - val_accuracy: 0.7882\n",
      "Epoch 1028/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0787 - accuracy: 0.9739 - val_loss: 1.5970 - val_accuracy: 0.7866\n",
      "Epoch 1029/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0843 - accuracy: 0.9706 - val_loss: 1.5589 - val_accuracy: 0.7741\n",
      "Epoch 1030/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0804 - accuracy: 0.9659 - val_loss: 1.5779 - val_accuracy: 0.7788\n",
      "Epoch 1031/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0899 - accuracy: 0.9693 - val_loss: 1.5565 - val_accuracy: 0.7695\n",
      "Epoch 1032/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0757 - accuracy: 0.9739 - val_loss: 1.5148 - val_accuracy: 0.7695\n",
      "Epoch 1033/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0967 - accuracy: 0.9626 - val_loss: 1.5435 - val_accuracy: 0.7679\n",
      "Epoch 1034/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0764 - accuracy: 0.9739 - val_loss: 1.5968 - val_accuracy: 0.7757\n",
      "Epoch 1035/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0785 - accuracy: 0.9659 - val_loss: 1.6077 - val_accuracy: 0.7632\n",
      "Epoch 1036/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0824 - accuracy: 0.9646 - val_loss: 1.5358 - val_accuracy: 0.7819\n",
      "Epoch 1037/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0636 - accuracy: 0.9773 - val_loss: 1.5456 - val_accuracy: 0.7773\n",
      "Epoch 1038/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0916 - accuracy: 0.9652 - val_loss: 1.5915 - val_accuracy: 0.7741\n",
      "Epoch 1039/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0732 - accuracy: 0.9719 - val_loss: 1.5004 - val_accuracy: 0.7835\n",
      "Epoch 1040/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0766 - accuracy: 0.9739 - val_loss: 1.4950 - val_accuracy: 0.7773\n",
      "Epoch 1041/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0650 - accuracy: 0.9759 - val_loss: 1.5862 - val_accuracy: 0.7850\n",
      "Epoch 1042/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1086 - accuracy: 0.9626 - val_loss: 1.5478 - val_accuracy: 0.7757\n",
      "Epoch 1043/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0847 - accuracy: 0.9666 - val_loss: 1.5471 - val_accuracy: 0.7679\n",
      "Epoch 1044/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0783 - accuracy: 0.9693 - val_loss: 1.6184 - val_accuracy: 0.7804\n",
      "Epoch 1045/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0782 - accuracy: 0.9666 - val_loss: 1.5804 - val_accuracy: 0.7710\n",
      "Epoch 1046/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0805 - accuracy: 0.9759 - val_loss: 1.5823 - val_accuracy: 0.7819\n",
      "Epoch 1047/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0770 - accuracy: 0.9726 - val_loss: 1.5964 - val_accuracy: 0.7804\n",
      "Epoch 1048/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0744 - accuracy: 0.9739 - val_loss: 1.5521 - val_accuracy: 0.7850\n",
      "Epoch 1049/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0784 - accuracy: 0.9693 - val_loss: 1.5351 - val_accuracy: 0.7710\n",
      "Epoch 1050/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0801 - accuracy: 0.9739 - val_loss: 1.6226 - val_accuracy: 0.7819\n",
      "Epoch 1051/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0624 - accuracy: 0.9779 - val_loss: 1.5999 - val_accuracy: 0.7835\n",
      "Epoch 1052/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0649 - accuracy: 0.9753 - val_loss: 1.6299 - val_accuracy: 0.7726\n",
      "Epoch 1053/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0588 - accuracy: 0.9813 - val_loss: 1.6720 - val_accuracy: 0.7850\n",
      "Epoch 1054/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0729 - accuracy: 0.9766 - val_loss: 1.6451 - val_accuracy: 0.7679\n",
      "Epoch 1055/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0571 - accuracy: 0.9779 - val_loss: 1.6691 - val_accuracy: 0.7866\n",
      "Epoch 1056/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0642 - accuracy: 0.9786 - val_loss: 1.6029 - val_accuracy: 0.7726\n",
      "Epoch 1057/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0590 - accuracy: 0.9773 - val_loss: 1.6108 - val_accuracy: 0.7741\n",
      "Epoch 1058/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0722 - accuracy: 0.9733 - val_loss: 1.5747 - val_accuracy: 0.7850\n",
      "Epoch 1059/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0884 - accuracy: 0.9632 - val_loss: 1.5261 - val_accuracy: 0.7804\n",
      "Epoch 1060/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0782 - accuracy: 0.9686 - val_loss: 1.6952 - val_accuracy: 0.7913\n",
      "Epoch 1061/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1067 - accuracy: 0.9606 - val_loss: 1.5465 - val_accuracy: 0.7866\n",
      "Epoch 1062/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1034 - accuracy: 0.9612 - val_loss: 1.5153 - val_accuracy: 0.7882\n",
      "Epoch 1063/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0955 - accuracy: 0.9646 - val_loss: 1.5316 - val_accuracy: 0.7897\n",
      "Epoch 1064/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0748 - accuracy: 0.9706 - val_loss: 1.5407 - val_accuracy: 0.7726\n",
      "Epoch 1065/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0972 - accuracy: 0.9659 - val_loss: 1.5166 - val_accuracy: 0.7695\n",
      "Epoch 1066/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0983 - accuracy: 0.9679 - val_loss: 1.5560 - val_accuracy: 0.7804\n",
      "Epoch 1067/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0846 - accuracy: 0.9612 - val_loss: 1.5561 - val_accuracy: 0.7835\n",
      "Epoch 1068/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0908 - accuracy: 0.9666 - val_loss: 1.6234 - val_accuracy: 0.7804\n",
      "Epoch 1069/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0564 - accuracy: 0.9773 - val_loss: 1.6560 - val_accuracy: 0.7897\n",
      "Epoch 1070/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0896 - accuracy: 0.9672 - val_loss: 1.6245 - val_accuracy: 0.7835\n",
      "Epoch 1071/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0964 - accuracy: 0.9646 - val_loss: 1.5351 - val_accuracy: 0.7850\n",
      "Epoch 1072/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0784 - accuracy: 0.9713 - val_loss: 1.5586 - val_accuracy: 0.7882\n",
      "Epoch 1073/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0689 - accuracy: 0.9713 - val_loss: 1.5968 - val_accuracy: 0.7804\n",
      "Epoch 1074/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0974 - accuracy: 0.9659 - val_loss: 1.6299 - val_accuracy: 0.7741\n",
      "Epoch 1075/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0796 - accuracy: 0.9713 - val_loss: 1.5738 - val_accuracy: 0.7882\n",
      "Epoch 1076/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0822 - accuracy: 0.9713 - val_loss: 1.5363 - val_accuracy: 0.7819\n",
      "Epoch 1077/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0717 - accuracy: 0.9746 - val_loss: 1.5175 - val_accuracy: 0.7788\n",
      "Epoch 1078/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0753 - accuracy: 0.9786 - val_loss: 1.6148 - val_accuracy: 0.7835\n",
      "Epoch 1079/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0873 - accuracy: 0.9672 - val_loss: 1.6289 - val_accuracy: 0.7835\n",
      "Epoch 1080/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0583 - accuracy: 0.9826 - val_loss: 1.6183 - val_accuracy: 0.7819\n",
      "Epoch 1081/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1027 - accuracy: 0.9646 - val_loss: 1.5403 - val_accuracy: 0.7726\n",
      "Epoch 1082/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0660 - accuracy: 0.9746 - val_loss: 1.6949 - val_accuracy: 0.7850\n",
      "Epoch 1083/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0682 - accuracy: 0.9773 - val_loss: 1.6355 - val_accuracy: 0.7788\n",
      "Epoch 1084/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0824 - accuracy: 0.9652 - val_loss: 1.6485 - val_accuracy: 0.7819\n",
      "Epoch 1085/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0765 - accuracy: 0.9706 - val_loss: 1.6239 - val_accuracy: 0.7788\n",
      "Epoch 1086/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0998 - accuracy: 0.9652 - val_loss: 1.6210 - val_accuracy: 0.7835\n",
      "Epoch 1087/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0771 - accuracy: 0.9706 - val_loss: 1.6515 - val_accuracy: 0.7788\n",
      "Epoch 1088/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0840 - accuracy: 0.9652 - val_loss: 1.6364 - val_accuracy: 0.7804\n",
      "Epoch 1089/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0544 - accuracy: 0.9799 - val_loss: 1.6079 - val_accuracy: 0.7726\n",
      "Epoch 1090/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0841 - accuracy: 0.9639 - val_loss: 1.5513 - val_accuracy: 0.7850\n",
      "Epoch 1091/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0861 - accuracy: 0.9713 - val_loss: 1.5676 - val_accuracy: 0.7804\n",
      "Epoch 1092/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0682 - accuracy: 0.9759 - val_loss: 1.5018 - val_accuracy: 0.7757\n",
      "Epoch 1093/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0804 - accuracy: 0.9679 - val_loss: 1.5295 - val_accuracy: 0.7788\n",
      "Epoch 1094/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0856 - accuracy: 0.9666 - val_loss: 1.5719 - val_accuracy: 0.7928\n",
      "Epoch 1095/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0564 - accuracy: 0.9793 - val_loss: 1.6134 - val_accuracy: 0.7819\n",
      "Epoch 1096/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0605 - accuracy: 0.9773 - val_loss: 1.6148 - val_accuracy: 0.7695\n",
      "Epoch 1097/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0673 - accuracy: 0.9746 - val_loss: 1.6485 - val_accuracy: 0.7741\n",
      "Epoch 1098/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0686 - accuracy: 0.9766 - val_loss: 1.6294 - val_accuracy: 0.7819\n",
      "Epoch 1099/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0811 - accuracy: 0.9693 - val_loss: 1.5818 - val_accuracy: 0.7788\n",
      "Epoch 1100/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0833 - accuracy: 0.9646 - val_loss: 1.5377 - val_accuracy: 0.7804\n",
      "Epoch 1101/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0806 - accuracy: 0.9672 - val_loss: 1.6130 - val_accuracy: 0.7866\n",
      "Epoch 1102/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0775 - accuracy: 0.9733 - val_loss: 1.6011 - val_accuracy: 0.7850\n",
      "Epoch 1103/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0679 - accuracy: 0.9746 - val_loss: 1.5951 - val_accuracy: 0.7835\n",
      "Epoch 1104/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0737 - accuracy: 0.9693 - val_loss: 1.6267 - val_accuracy: 0.7788\n",
      "Epoch 1105/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0618 - accuracy: 0.9746 - val_loss: 1.6102 - val_accuracy: 0.7804\n",
      "Epoch 1106/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0749 - accuracy: 0.9699 - val_loss: 1.6043 - val_accuracy: 0.7773\n",
      "Epoch 1107/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0708 - accuracy: 0.9759 - val_loss: 1.6605 - val_accuracy: 0.7897\n",
      "Epoch 1108/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0752 - accuracy: 0.9693 - val_loss: 1.5864 - val_accuracy: 0.7866\n",
      "Epoch 1109/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0839 - accuracy: 0.9679 - val_loss: 1.6347 - val_accuracy: 0.7897\n",
      "Epoch 1110/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0740 - accuracy: 0.9713 - val_loss: 1.5758 - val_accuracy: 0.7679\n",
      "Epoch 1111/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0744 - accuracy: 0.9739 - val_loss: 1.6599 - val_accuracy: 0.7757\n",
      "Epoch 1112/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0819 - accuracy: 0.9713 - val_loss: 1.6516 - val_accuracy: 0.7773\n",
      "Epoch 1113/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0595 - accuracy: 0.9786 - val_loss: 1.6448 - val_accuracy: 0.7819\n",
      "Epoch 1114/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0511 - accuracy: 0.9773 - val_loss: 1.6034 - val_accuracy: 0.7819\n",
      "Epoch 1115/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0794 - accuracy: 0.9719 - val_loss: 1.6379 - val_accuracy: 0.7897\n",
      "Epoch 1116/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0819 - accuracy: 0.9679 - val_loss: 1.6020 - val_accuracy: 0.7726\n",
      "Epoch 1117/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0606 - accuracy: 0.9759 - val_loss: 1.7032 - val_accuracy: 0.7850\n",
      "Epoch 1118/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0736 - accuracy: 0.9733 - val_loss: 1.6813 - val_accuracy: 0.7897\n",
      "Epoch 1119/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0585 - accuracy: 0.9793 - val_loss: 1.6355 - val_accuracy: 0.7726\n",
      "Epoch 1120/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0820 - accuracy: 0.9706 - val_loss: 1.6239 - val_accuracy: 0.7788\n",
      "Epoch 1121/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0781 - accuracy: 0.9739 - val_loss: 1.7231 - val_accuracy: 0.7757\n",
      "Epoch 1122/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0844 - accuracy: 0.9713 - val_loss: 1.6643 - val_accuracy: 0.7804\n",
      "Epoch 1123/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0720 - accuracy: 0.9753 - val_loss: 1.6353 - val_accuracy: 0.7850\n",
      "Epoch 1124/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0849 - accuracy: 0.9706 - val_loss: 1.6866 - val_accuracy: 0.7819\n",
      "Epoch 1125/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0891 - accuracy: 0.9646 - val_loss: 1.6125 - val_accuracy: 0.7679\n",
      "Epoch 1126/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0754 - accuracy: 0.9753 - val_loss: 1.6190 - val_accuracy: 0.7757\n",
      "Epoch 1127/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0599 - accuracy: 0.9779 - val_loss: 1.7254 - val_accuracy: 0.7804\n",
      "Epoch 1128/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0667 - accuracy: 0.9719 - val_loss: 1.6250 - val_accuracy: 0.7757\n",
      "Epoch 1129/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0788 - accuracy: 0.9713 - val_loss: 1.6336 - val_accuracy: 0.7679\n",
      "Epoch 1130/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0846 - accuracy: 0.9686 - val_loss: 1.6221 - val_accuracy: 0.7850\n",
      "Epoch 1131/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0763 - accuracy: 0.9773 - val_loss: 1.5842 - val_accuracy: 0.7819\n",
      "Epoch 1132/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0752 - accuracy: 0.9706 - val_loss: 1.6415 - val_accuracy: 0.7866\n",
      "Epoch 1133/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0573 - accuracy: 0.9746 - val_loss: 1.6464 - val_accuracy: 0.7819\n",
      "Epoch 1134/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0845 - accuracy: 0.9666 - val_loss: 1.6568 - val_accuracy: 0.7773\n",
      "Epoch 1135/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1293 - accuracy: 0.9612 - val_loss: 1.6257 - val_accuracy: 0.7819\n",
      "Epoch 1136/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0878 - accuracy: 0.9693 - val_loss: 1.6304 - val_accuracy: 0.7804\n",
      "Epoch 1137/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0823 - accuracy: 0.9693 - val_loss: 1.5758 - val_accuracy: 0.7773\n",
      "Epoch 1138/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0919 - accuracy: 0.9632 - val_loss: 1.6245 - val_accuracy: 0.7788\n",
      "Epoch 1139/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1032 - accuracy: 0.9713 - val_loss: 1.5852 - val_accuracy: 0.7773\n",
      "Epoch 1140/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0955 - accuracy: 0.9659 - val_loss: 1.6507 - val_accuracy: 0.7773\n",
      "Epoch 1141/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0702 - accuracy: 0.9713 - val_loss: 1.6244 - val_accuracy: 0.7804\n",
      "Epoch 1142/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0855 - accuracy: 0.9706 - val_loss: 1.6340 - val_accuracy: 0.7710\n",
      "Epoch 1143/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0853 - accuracy: 0.9679 - val_loss: 1.6753 - val_accuracy: 0.7788\n",
      "Epoch 1144/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0695 - accuracy: 0.9753 - val_loss: 1.6788 - val_accuracy: 0.7835\n",
      "Epoch 1145/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0810 - accuracy: 0.9713 - val_loss: 1.5960 - val_accuracy: 0.7866\n",
      "Epoch 1146/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0580 - accuracy: 0.9759 - val_loss: 1.6390 - val_accuracy: 0.7710\n",
      "Epoch 1147/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0694 - accuracy: 0.9739 - val_loss: 1.5918 - val_accuracy: 0.7664\n",
      "Epoch 1148/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0741 - accuracy: 0.9753 - val_loss: 1.6528 - val_accuracy: 0.7866\n",
      "Epoch 1149/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0901 - accuracy: 0.9672 - val_loss: 1.5997 - val_accuracy: 0.7819\n",
      "Epoch 1150/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0727 - accuracy: 0.9699 - val_loss: 1.6200 - val_accuracy: 0.7773\n",
      "Epoch 1151/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0829 - accuracy: 0.9666 - val_loss: 1.6023 - val_accuracy: 0.7773\n",
      "Epoch 1152/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0684 - accuracy: 0.9766 - val_loss: 1.6199 - val_accuracy: 0.7664\n",
      "Epoch 1153/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0676 - accuracy: 0.9799 - val_loss: 1.6022 - val_accuracy: 0.7835\n",
      "Epoch 1154/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0680 - accuracy: 0.9786 - val_loss: 1.5882 - val_accuracy: 0.7850\n",
      "Epoch 1155/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0758 - accuracy: 0.9733 - val_loss: 1.6524 - val_accuracy: 0.7928\n",
      "Epoch 1156/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0812 - accuracy: 0.9699 - val_loss: 1.5637 - val_accuracy: 0.7757\n",
      "Epoch 1157/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0638 - accuracy: 0.9793 - val_loss: 1.6096 - val_accuracy: 0.7850\n",
      "Epoch 1158/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0742 - accuracy: 0.9719 - val_loss: 1.5890 - val_accuracy: 0.7741\n",
      "Epoch 1159/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0761 - accuracy: 0.9739 - val_loss: 1.6145 - val_accuracy: 0.7741\n",
      "Epoch 1160/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0814 - accuracy: 0.9733 - val_loss: 1.6542 - val_accuracy: 0.7788\n",
      "Epoch 1161/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0991 - accuracy: 0.9592 - val_loss: 1.6000 - val_accuracy: 0.7710\n",
      "Epoch 1162/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0872 - accuracy: 0.9659 - val_loss: 1.6246 - val_accuracy: 0.7866\n",
      "Epoch 1163/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0974 - accuracy: 0.9619 - val_loss: 1.6412 - val_accuracy: 0.7741\n",
      "Epoch 1164/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0669 - accuracy: 0.9726 - val_loss: 1.6749 - val_accuracy: 0.7741\n",
      "Epoch 1165/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0854 - accuracy: 0.9686 - val_loss: 1.6416 - val_accuracy: 0.7741\n",
      "Epoch 1166/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0744 - accuracy: 0.9726 - val_loss: 1.6181 - val_accuracy: 0.7819\n",
      "Epoch 1167/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0858 - accuracy: 0.9699 - val_loss: 1.6442 - val_accuracy: 0.7741\n",
      "Epoch 1168/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0686 - accuracy: 0.9739 - val_loss: 1.6285 - val_accuracy: 0.7741\n",
      "Epoch 1169/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0584 - accuracy: 0.9793 - val_loss: 1.6633 - val_accuracy: 0.7804\n",
      "Epoch 1170/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0642 - accuracy: 0.9746 - val_loss: 1.6289 - val_accuracy: 0.7819\n",
      "Epoch 1171/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0860 - accuracy: 0.9686 - val_loss: 1.6622 - val_accuracy: 0.7695\n",
      "Epoch 1172/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0656 - accuracy: 0.9733 - val_loss: 1.6310 - val_accuracy: 0.7788\n",
      "Epoch 1173/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0573 - accuracy: 0.9773 - val_loss: 1.6377 - val_accuracy: 0.7788\n",
      "Epoch 1174/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0655 - accuracy: 0.9779 - val_loss: 1.6376 - val_accuracy: 0.7679\n",
      "Epoch 1175/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0705 - accuracy: 0.9713 - val_loss: 1.6639 - val_accuracy: 0.7882\n",
      "Epoch 1176/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0627 - accuracy: 0.9759 - val_loss: 1.6287 - val_accuracy: 0.7804\n",
      "Epoch 1177/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0561 - accuracy: 0.9773 - val_loss: 1.7040 - val_accuracy: 0.7850\n",
      "Epoch 1178/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0677 - accuracy: 0.9733 - val_loss: 1.6820 - val_accuracy: 0.7835\n",
      "Epoch 1179/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0817 - accuracy: 0.9706 - val_loss: 1.6760 - val_accuracy: 0.7741\n",
      "Epoch 1180/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0710 - accuracy: 0.9739 - val_loss: 1.6838 - val_accuracy: 0.7788\n",
      "Epoch 1181/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0651 - accuracy: 0.9753 - val_loss: 1.6488 - val_accuracy: 0.7726\n",
      "Epoch 1182/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0663 - accuracy: 0.9733 - val_loss: 1.5736 - val_accuracy: 0.7788\n",
      "Epoch 1183/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0764 - accuracy: 0.9699 - val_loss: 1.6025 - val_accuracy: 0.7788\n",
      "Epoch 1184/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0892 - accuracy: 0.9659 - val_loss: 1.6013 - val_accuracy: 0.7804\n",
      "Epoch 1185/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1074 - accuracy: 0.9619 - val_loss: 1.5248 - val_accuracy: 0.7788\n",
      "Epoch 1186/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0809 - accuracy: 0.9706 - val_loss: 1.5299 - val_accuracy: 0.7882\n",
      "Epoch 1187/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0852 - accuracy: 0.9672 - val_loss: 1.5672 - val_accuracy: 0.7866\n",
      "Epoch 1188/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0843 - accuracy: 0.9699 - val_loss: 1.5977 - val_accuracy: 0.7819\n",
      "Epoch 1189/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0628 - accuracy: 0.9779 - val_loss: 1.5979 - val_accuracy: 0.7850\n",
      "Epoch 1190/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0845 - accuracy: 0.9713 - val_loss: 1.6411 - val_accuracy: 0.7835\n",
      "Epoch 1191/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0757 - accuracy: 0.9706 - val_loss: 1.6129 - val_accuracy: 0.7850\n",
      "Epoch 1192/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0732 - accuracy: 0.9733 - val_loss: 1.6026 - val_accuracy: 0.7850\n",
      "Epoch 1193/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0826 - accuracy: 0.9599 - val_loss: 1.6144 - val_accuracy: 0.7788\n",
      "Epoch 1194/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0621 - accuracy: 0.9799 - val_loss: 1.6039 - val_accuracy: 0.7788\n",
      "Epoch 1195/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0773 - accuracy: 0.9686 - val_loss: 1.6509 - val_accuracy: 0.7819\n",
      "Epoch 1196/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0799 - accuracy: 0.9706 - val_loss: 1.5897 - val_accuracy: 0.7757\n",
      "Epoch 1197/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0724 - accuracy: 0.9786 - val_loss: 1.5778 - val_accuracy: 0.7866\n",
      "Epoch 1198/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1026 - accuracy: 0.9626 - val_loss: 1.5754 - val_accuracy: 0.7882\n",
      "Epoch 1199/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0961 - accuracy: 0.9672 - val_loss: 1.5073 - val_accuracy: 0.7850\n",
      "Epoch 1200/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0776 - accuracy: 0.9699 - val_loss: 1.6484 - val_accuracy: 0.7866\n",
      "Epoch 1201/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0659 - accuracy: 0.9739 - val_loss: 1.5885 - val_accuracy: 0.7835\n",
      "Epoch 1202/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0811 - accuracy: 0.9693 - val_loss: 1.5849 - val_accuracy: 0.7850\n",
      "Epoch 1203/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0987 - accuracy: 0.9659 - val_loss: 1.6022 - val_accuracy: 0.7866\n",
      "Epoch 1204/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0869 - accuracy: 0.9619 - val_loss: 1.5387 - val_accuracy: 0.7897\n",
      "Epoch 1205/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0766 - accuracy: 0.9686 - val_loss: 1.5602 - val_accuracy: 0.7788\n",
      "Epoch 1206/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0708 - accuracy: 0.9719 - val_loss: 1.5926 - val_accuracy: 0.7773\n",
      "Epoch 1207/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0725 - accuracy: 0.9713 - val_loss: 1.6609 - val_accuracy: 0.7819\n",
      "Epoch 1208/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0760 - accuracy: 0.9706 - val_loss: 1.6067 - val_accuracy: 0.7726\n",
      "Epoch 1209/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0607 - accuracy: 0.9786 - val_loss: 1.6917 - val_accuracy: 0.7773\n",
      "Epoch 1210/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0749 - accuracy: 0.9713 - val_loss: 1.6110 - val_accuracy: 0.7850\n",
      "Epoch 1211/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0605 - accuracy: 0.9766 - val_loss: 1.6499 - val_accuracy: 0.7835\n",
      "Epoch 1212/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0664 - accuracy: 0.9739 - val_loss: 1.6280 - val_accuracy: 0.7710\n",
      "Epoch 1213/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0699 - accuracy: 0.9746 - val_loss: 1.6652 - val_accuracy: 0.7835\n",
      "Epoch 1214/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0609 - accuracy: 0.9799 - val_loss: 1.6647 - val_accuracy: 0.7710\n",
      "Epoch 1215/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0541 - accuracy: 0.9799 - val_loss: 1.6677 - val_accuracy: 0.7804\n",
      "Epoch 1216/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0794 - accuracy: 0.9733 - val_loss: 1.6283 - val_accuracy: 0.7804\n",
      "Epoch 1217/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0623 - accuracy: 0.9746 - val_loss: 1.5936 - val_accuracy: 0.7819\n",
      "Epoch 1218/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0609 - accuracy: 0.9753 - val_loss: 1.6170 - val_accuracy: 0.7726\n",
      "Epoch 1219/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0848 - accuracy: 0.9652 - val_loss: 1.5922 - val_accuracy: 0.7757\n",
      "Epoch 1220/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0876 - accuracy: 0.9679 - val_loss: 1.5822 - val_accuracy: 0.7835\n",
      "Epoch 1221/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0581 - accuracy: 0.9759 - val_loss: 1.6166 - val_accuracy: 0.7804\n",
      "Epoch 1222/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0765 - accuracy: 0.9666 - val_loss: 1.6514 - val_accuracy: 0.7788\n",
      "Epoch 1223/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0899 - accuracy: 0.9639 - val_loss: 1.6544 - val_accuracy: 0.7850\n",
      "Epoch 1224/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0865 - accuracy: 0.9726 - val_loss: 1.6014 - val_accuracy: 0.7835\n",
      "Epoch 1225/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0816 - accuracy: 0.9726 - val_loss: 1.5298 - val_accuracy: 0.7726\n",
      "Epoch 1226/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1000 - accuracy: 0.9619 - val_loss: 1.6215 - val_accuracy: 0.7710\n",
      "Epoch 1227/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0959 - accuracy: 0.9646 - val_loss: 1.6444 - val_accuracy: 0.7726\n",
      "Epoch 1228/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0845 - accuracy: 0.9706 - val_loss: 1.6802 - val_accuracy: 0.7773\n",
      "Epoch 1229/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0701 - accuracy: 0.9719 - val_loss: 1.6361 - val_accuracy: 0.7819\n",
      "Epoch 1230/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0834 - accuracy: 0.9679 - val_loss: 1.5921 - val_accuracy: 0.7741\n",
      "Epoch 1231/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0628 - accuracy: 0.9753 - val_loss: 1.6284 - val_accuracy: 0.7819\n",
      "Epoch 1232/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0735 - accuracy: 0.9793 - val_loss: 1.5961 - val_accuracy: 0.7726\n",
      "Epoch 1233/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0667 - accuracy: 0.9773 - val_loss: 1.6486 - val_accuracy: 0.7804\n",
      "Epoch 1234/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0685 - accuracy: 0.9746 - val_loss: 1.6409 - val_accuracy: 0.7835\n",
      "Epoch 1235/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0576 - accuracy: 0.9766 - val_loss: 1.5766 - val_accuracy: 0.7819\n",
      "Epoch 1236/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0617 - accuracy: 0.9759 - val_loss: 1.6384 - val_accuracy: 0.7741\n",
      "Epoch 1237/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0551 - accuracy: 0.9786 - val_loss: 1.6511 - val_accuracy: 0.7804\n",
      "Epoch 1238/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0681 - accuracy: 0.9706 - val_loss: 1.6552 - val_accuracy: 0.7819\n",
      "Epoch 1239/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0635 - accuracy: 0.9793 - val_loss: 1.6975 - val_accuracy: 0.7773\n",
      "Epoch 1240/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0628 - accuracy: 0.9779 - val_loss: 1.6799 - val_accuracy: 0.7773\n",
      "Epoch 1241/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0763 - accuracy: 0.9713 - val_loss: 1.6657 - val_accuracy: 0.7788\n",
      "Epoch 1242/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0581 - accuracy: 0.9759 - val_loss: 1.6516 - val_accuracy: 0.7866\n",
      "Epoch 1243/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0776 - accuracy: 0.9766 - val_loss: 1.6159 - val_accuracy: 0.7710\n",
      "Epoch 1244/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1073 - accuracy: 0.9612 - val_loss: 1.6061 - val_accuracy: 0.7773\n",
      "Epoch 1245/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0763 - accuracy: 0.9713 - val_loss: 1.6166 - val_accuracy: 0.7741\n",
      "Epoch 1246/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0977 - accuracy: 0.9686 - val_loss: 1.7333 - val_accuracy: 0.7773\n",
      "Epoch 1247/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0715 - accuracy: 0.9733 - val_loss: 1.5965 - val_accuracy: 0.7788\n",
      "Epoch 1248/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0934 - accuracy: 0.9639 - val_loss: 1.5747 - val_accuracy: 0.7804\n",
      "Epoch 1249/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1144 - accuracy: 0.9612 - val_loss: 1.5762 - val_accuracy: 0.7788\n",
      "Epoch 1250/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0775 - accuracy: 0.9706 - val_loss: 1.6230 - val_accuracy: 0.7850\n",
      "Epoch 1251/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0775 - accuracy: 0.9646 - val_loss: 1.5445 - val_accuracy: 0.7741\n",
      "Epoch 1252/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0713 - accuracy: 0.9733 - val_loss: 1.5464 - val_accuracy: 0.7757\n",
      "Epoch 1253/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0613 - accuracy: 0.9766 - val_loss: 1.5654 - val_accuracy: 0.7773\n",
      "Epoch 1254/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0809 - accuracy: 0.9719 - val_loss: 1.5994 - val_accuracy: 0.7741\n",
      "Epoch 1255/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0790 - accuracy: 0.9759 - val_loss: 1.7033 - val_accuracy: 0.7850\n",
      "Epoch 1256/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0845 - accuracy: 0.9666 - val_loss: 1.6258 - val_accuracy: 0.7788\n",
      "Epoch 1257/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0686 - accuracy: 0.9779 - val_loss: 1.5884 - val_accuracy: 0.7773\n",
      "Epoch 1258/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0937 - accuracy: 0.9639 - val_loss: 1.5951 - val_accuracy: 0.7586\n",
      "Epoch 1259/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0688 - accuracy: 0.9699 - val_loss: 1.6023 - val_accuracy: 0.7741\n",
      "Epoch 1260/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0560 - accuracy: 0.9773 - val_loss: 1.6047 - val_accuracy: 0.7664\n",
      "Epoch 1261/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0778 - accuracy: 0.9693 - val_loss: 1.5326 - val_accuracy: 0.7679\n",
      "Epoch 1262/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0694 - accuracy: 0.9733 - val_loss: 1.5739 - val_accuracy: 0.7679\n",
      "Epoch 1263/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0669 - accuracy: 0.9759 - val_loss: 1.5615 - val_accuracy: 0.7773\n",
      "Epoch 1264/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0644 - accuracy: 0.9733 - val_loss: 1.5541 - val_accuracy: 0.7819\n",
      "Epoch 1265/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0493 - accuracy: 0.9820 - val_loss: 1.6173 - val_accuracy: 0.7741\n",
      "Epoch 1266/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0716 - accuracy: 0.9773 - val_loss: 1.6312 - val_accuracy: 0.7710\n",
      "Epoch 1267/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0551 - accuracy: 0.9753 - val_loss: 1.6678 - val_accuracy: 0.7819\n",
      "Epoch 1268/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0626 - accuracy: 0.9726 - val_loss: 1.5760 - val_accuracy: 0.7695\n",
      "Epoch 1269/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0702 - accuracy: 0.9739 - val_loss: 1.6314 - val_accuracy: 0.7695\n",
      "Epoch 1270/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0600 - accuracy: 0.9786 - val_loss: 1.6556 - val_accuracy: 0.7835\n",
      "Epoch 1271/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0502 - accuracy: 0.9806 - val_loss: 1.6468 - val_accuracy: 0.7788\n",
      "Epoch 1272/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0664 - accuracy: 0.9753 - val_loss: 1.7015 - val_accuracy: 0.7882\n",
      "Epoch 1273/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0587 - accuracy: 0.9813 - val_loss: 1.7092 - val_accuracy: 0.7741\n",
      "Epoch 1274/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0621 - accuracy: 0.9766 - val_loss: 1.7131 - val_accuracy: 0.7819\n",
      "Epoch 1275/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0783 - accuracy: 0.9713 - val_loss: 1.7428 - val_accuracy: 0.7897\n",
      "Epoch 1276/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0852 - accuracy: 0.9733 - val_loss: 1.5541 - val_accuracy: 0.7835\n",
      "Epoch 1277/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0708 - accuracy: 0.9679 - val_loss: 1.6347 - val_accuracy: 0.7960\n",
      "Epoch 1278/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0889 - accuracy: 0.9666 - val_loss: 1.6039 - val_accuracy: 0.7850\n",
      "Epoch 1279/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0432 - accuracy: 0.9860 - val_loss: 1.6478 - val_accuracy: 0.7757\n",
      "Epoch 1280/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0649 - accuracy: 0.9786 - val_loss: 1.7012 - val_accuracy: 0.7819\n",
      "Epoch 1281/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0834 - accuracy: 0.9766 - val_loss: 1.7131 - val_accuracy: 0.7897\n",
      "Epoch 1282/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0695 - accuracy: 0.9719 - val_loss: 1.6547 - val_accuracy: 0.7804\n",
      "Epoch 1283/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0787 - accuracy: 0.9706 - val_loss: 1.6229 - val_accuracy: 0.7835\n",
      "Epoch 1284/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0566 - accuracy: 0.9746 - val_loss: 1.6991 - val_accuracy: 0.7835\n",
      "Epoch 1285/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0802 - accuracy: 0.9666 - val_loss: 1.6798 - val_accuracy: 0.7757\n",
      "Epoch 1286/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0649 - accuracy: 0.9759 - val_loss: 1.6411 - val_accuracy: 0.7757\n",
      "Epoch 1287/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0737 - accuracy: 0.9753 - val_loss: 1.6572 - val_accuracy: 0.7804\n",
      "Epoch 1288/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0698 - accuracy: 0.9773 - val_loss: 1.6085 - val_accuracy: 0.7788\n",
      "Epoch 1289/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0898 - accuracy: 0.9626 - val_loss: 1.5707 - val_accuracy: 0.7710\n",
      "Epoch 1290/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0737 - accuracy: 0.9739 - val_loss: 1.5727 - val_accuracy: 0.7819\n",
      "Epoch 1291/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0705 - accuracy: 0.9686 - val_loss: 1.6656 - val_accuracy: 0.7679\n",
      "Epoch 1292/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0644 - accuracy: 0.9713 - val_loss: 1.6702 - val_accuracy: 0.7866\n",
      "Epoch 1293/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0703 - accuracy: 0.9766 - val_loss: 1.6906 - val_accuracy: 0.7773\n",
      "Epoch 1294/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0781 - accuracy: 0.9799 - val_loss: 1.6807 - val_accuracy: 0.7788\n",
      "Epoch 1295/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0759 - accuracy: 0.9672 - val_loss: 1.6520 - val_accuracy: 0.7726\n",
      "Epoch 1296/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0945 - accuracy: 0.9626 - val_loss: 1.6810 - val_accuracy: 0.7804\n",
      "Epoch 1297/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0861 - accuracy: 0.9733 - val_loss: 1.7049 - val_accuracy: 0.7788\n",
      "Epoch 1298/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0710 - accuracy: 0.9739 - val_loss: 1.5816 - val_accuracy: 0.7835\n",
      "Epoch 1299/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0622 - accuracy: 0.9766 - val_loss: 1.6517 - val_accuracy: 0.7882\n",
      "Epoch 1300/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0720 - accuracy: 0.9706 - val_loss: 1.6393 - val_accuracy: 0.7850\n",
      "Epoch 1301/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1000 - accuracy: 0.9699 - val_loss: 1.6916 - val_accuracy: 0.7882\n",
      "Epoch 1302/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0725 - accuracy: 0.9713 - val_loss: 1.6122 - val_accuracy: 0.7850\n",
      "Epoch 1303/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0737 - accuracy: 0.9746 - val_loss: 1.6356 - val_accuracy: 0.7866\n",
      "Epoch 1304/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0695 - accuracy: 0.9759 - val_loss: 1.5822 - val_accuracy: 0.7773\n",
      "Epoch 1305/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0987 - accuracy: 0.9713 - val_loss: 1.6166 - val_accuracy: 0.7913\n",
      "Epoch 1306/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0863 - accuracy: 0.9639 - val_loss: 1.5809 - val_accuracy: 0.7866\n",
      "Epoch 1307/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0660 - accuracy: 0.9786 - val_loss: 1.6150 - val_accuracy: 0.7773\n",
      "Epoch 1308/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0720 - accuracy: 0.9719 - val_loss: 1.7115 - val_accuracy: 0.7710\n",
      "Epoch 1309/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0641 - accuracy: 0.9733 - val_loss: 1.6690 - val_accuracy: 0.7850\n",
      "Epoch 1310/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0802 - accuracy: 0.9699 - val_loss: 1.5664 - val_accuracy: 0.7617\n",
      "Epoch 1311/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0840 - accuracy: 0.9739 - val_loss: 1.6140 - val_accuracy: 0.7710\n",
      "Epoch 1312/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0605 - accuracy: 0.9766 - val_loss: 1.6647 - val_accuracy: 0.7804\n",
      "Epoch 1313/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0782 - accuracy: 0.9699 - val_loss: 1.5817 - val_accuracy: 0.7773\n",
      "Epoch 1314/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0840 - accuracy: 0.9719 - val_loss: 1.6058 - val_accuracy: 0.7741\n",
      "Epoch 1315/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0630 - accuracy: 0.9779 - val_loss: 1.6795 - val_accuracy: 0.7788\n",
      "Epoch 1316/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0555 - accuracy: 0.9779 - val_loss: 1.6558 - val_accuracy: 0.7710\n",
      "Epoch 1317/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0649 - accuracy: 0.9793 - val_loss: 1.6761 - val_accuracy: 0.7726\n",
      "Epoch 1318/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0540 - accuracy: 0.9773 - val_loss: 1.6231 - val_accuracy: 0.7773\n",
      "Epoch 1319/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0749 - accuracy: 0.9693 - val_loss: 1.5976 - val_accuracy: 0.7648\n",
      "Epoch 1320/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0723 - accuracy: 0.9706 - val_loss: 1.6442 - val_accuracy: 0.7741\n",
      "Epoch 1321/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0635 - accuracy: 0.9733 - val_loss: 1.6937 - val_accuracy: 0.7726\n",
      "Epoch 1322/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0801 - accuracy: 0.9779 - val_loss: 1.6551 - val_accuracy: 0.7664\n",
      "Epoch 1323/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0672 - accuracy: 0.9746 - val_loss: 1.6296 - val_accuracy: 0.7741\n",
      "Epoch 1324/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0648 - accuracy: 0.9759 - val_loss: 1.6104 - val_accuracy: 0.7850\n",
      "Epoch 1325/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0667 - accuracy: 0.9773 - val_loss: 1.6139 - val_accuracy: 0.7944\n",
      "Epoch 1326/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0554 - accuracy: 0.9806 - val_loss: 1.6635 - val_accuracy: 0.7726\n",
      "Epoch 1327/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0542 - accuracy: 0.9826 - val_loss: 1.6862 - val_accuracy: 0.7819\n",
      "Epoch 1328/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0662 - accuracy: 0.9753 - val_loss: 1.6645 - val_accuracy: 0.7788\n",
      "Epoch 1329/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0628 - accuracy: 0.9779 - val_loss: 1.7348 - val_accuracy: 0.7913\n",
      "Epoch 1330/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0584 - accuracy: 0.9786 - val_loss: 1.7213 - val_accuracy: 0.7866\n",
      "Epoch 1331/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0732 - accuracy: 0.9686 - val_loss: 1.6359 - val_accuracy: 0.7850\n",
      "Epoch 1332/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0746 - accuracy: 0.9679 - val_loss: 1.7126 - val_accuracy: 0.7835\n",
      "Epoch 1333/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0715 - accuracy: 0.9693 - val_loss: 1.7399 - val_accuracy: 0.7819\n",
      "Epoch 1334/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0736 - accuracy: 0.9693 - val_loss: 1.6993 - val_accuracy: 0.7835\n",
      "Epoch 1335/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0772 - accuracy: 0.9733 - val_loss: 1.6674 - val_accuracy: 0.7850\n",
      "Epoch 1336/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0559 - accuracy: 0.9799 - val_loss: 1.6525 - val_accuracy: 0.7835\n",
      "Epoch 1337/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0667 - accuracy: 0.9759 - val_loss: 1.6366 - val_accuracy: 0.7819\n",
      "Epoch 1338/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0692 - accuracy: 0.9753 - val_loss: 1.7166 - val_accuracy: 0.7788\n",
      "Epoch 1339/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0658 - accuracy: 0.9759 - val_loss: 1.6600 - val_accuracy: 0.7741\n",
      "Epoch 1340/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0616 - accuracy: 0.9746 - val_loss: 1.6744 - val_accuracy: 0.7897\n",
      "Epoch 1341/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0878 - accuracy: 0.9686 - val_loss: 1.6822 - val_accuracy: 0.7773\n",
      "Epoch 1342/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0828 - accuracy: 0.9672 - val_loss: 1.7752 - val_accuracy: 0.7741\n",
      "Epoch 1343/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0916 - accuracy: 0.9646 - val_loss: 1.6597 - val_accuracy: 0.7788\n",
      "Epoch 1344/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0683 - accuracy: 0.9726 - val_loss: 1.6606 - val_accuracy: 0.7835\n",
      "Epoch 1345/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0764 - accuracy: 0.9719 - val_loss: 1.6771 - val_accuracy: 0.7773\n",
      "Epoch 1346/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0507 - accuracy: 0.9813 - val_loss: 1.7116 - val_accuracy: 0.7835\n",
      "Epoch 1347/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0547 - accuracy: 0.9813 - val_loss: 1.7327 - val_accuracy: 0.7819\n",
      "Epoch 1348/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0612 - accuracy: 0.9799 - val_loss: 1.8267 - val_accuracy: 0.7928\n",
      "Epoch 1349/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0737 - accuracy: 0.9726 - val_loss: 1.6992 - val_accuracy: 0.7757\n",
      "Epoch 1350/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0553 - accuracy: 0.9860 - val_loss: 1.6760 - val_accuracy: 0.7850\n",
      "Epoch 1351/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0624 - accuracy: 0.9759 - val_loss: 1.6338 - val_accuracy: 0.7850\n",
      "Epoch 1352/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0660 - accuracy: 0.9746 - val_loss: 1.7011 - val_accuracy: 0.7788\n",
      "Epoch 1353/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0773 - accuracy: 0.9713 - val_loss: 1.7200 - val_accuracy: 0.7835\n",
      "Epoch 1354/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0437 - accuracy: 0.9840 - val_loss: 1.7868 - val_accuracy: 0.7897\n",
      "Epoch 1355/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0539 - accuracy: 0.9773 - val_loss: 1.7083 - val_accuracy: 0.7835\n",
      "Epoch 1356/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0545 - accuracy: 0.9786 - val_loss: 1.7164 - val_accuracy: 0.7819\n",
      "Epoch 1357/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0571 - accuracy: 0.9793 - val_loss: 1.7396 - val_accuracy: 0.7757\n",
      "Epoch 1358/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0655 - accuracy: 0.9713 - val_loss: 1.7736 - val_accuracy: 0.7773\n",
      "Epoch 1359/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0626 - accuracy: 0.9793 - val_loss: 1.7602 - val_accuracy: 0.7835\n",
      "Epoch 1360/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0670 - accuracy: 0.9726 - val_loss: 1.7258 - val_accuracy: 0.7741\n",
      "Epoch 1361/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0751 - accuracy: 0.9719 - val_loss: 1.6837 - val_accuracy: 0.7788\n",
      "Epoch 1362/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0813 - accuracy: 0.9719 - val_loss: 1.6907 - val_accuracy: 0.7726\n",
      "Epoch 1363/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0792 - accuracy: 0.9733 - val_loss: 1.7309 - val_accuracy: 0.7726\n",
      "Epoch 1364/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0733 - accuracy: 0.9739 - val_loss: 1.8100 - val_accuracy: 0.7788\n",
      "Epoch 1365/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0653 - accuracy: 0.9773 - val_loss: 1.7679 - val_accuracy: 0.7695\n",
      "Epoch 1366/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0695 - accuracy: 0.9753 - val_loss: 1.7365 - val_accuracy: 0.7695\n",
      "Epoch 1367/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0574 - accuracy: 0.9793 - val_loss: 1.7425 - val_accuracy: 0.7648\n",
      "Epoch 1368/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0777 - accuracy: 0.9726 - val_loss: 1.7487 - val_accuracy: 0.7648\n",
      "Epoch 1369/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0719 - accuracy: 0.9766 - val_loss: 1.7283 - val_accuracy: 0.7648\n",
      "Epoch 1370/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0792 - accuracy: 0.9699 - val_loss: 1.6985 - val_accuracy: 0.7664\n",
      "Epoch 1371/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0824 - accuracy: 0.9713 - val_loss: 1.6991 - val_accuracy: 0.7617\n",
      "Epoch 1372/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0740 - accuracy: 0.9753 - val_loss: 1.7704 - val_accuracy: 0.7648\n",
      "Epoch 1373/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0692 - accuracy: 0.9733 - val_loss: 1.6871 - val_accuracy: 0.7726\n",
      "Epoch 1374/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0701 - accuracy: 0.9733 - val_loss: 1.7695 - val_accuracy: 0.7757\n",
      "Epoch 1375/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0790 - accuracy: 0.9713 - val_loss: 1.6761 - val_accuracy: 0.7773\n",
      "Epoch 1376/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0739 - accuracy: 0.9753 - val_loss: 1.7040 - val_accuracy: 0.7710\n",
      "Epoch 1377/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0780 - accuracy: 0.9693 - val_loss: 1.7657 - val_accuracy: 0.7773\n",
      "Epoch 1378/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0854 - accuracy: 0.9739 - val_loss: 1.6949 - val_accuracy: 0.7819\n",
      "Epoch 1379/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0805 - accuracy: 0.9666 - val_loss: 1.6946 - val_accuracy: 0.7726\n",
      "Epoch 1380/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0929 - accuracy: 0.9652 - val_loss: 1.6965 - val_accuracy: 0.7835\n",
      "Epoch 1381/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0735 - accuracy: 0.9739 - val_loss: 1.7111 - val_accuracy: 0.7804\n",
      "Epoch 1382/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0552 - accuracy: 0.9793 - val_loss: 1.6290 - val_accuracy: 0.7819\n",
      "Epoch 1383/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0720 - accuracy: 0.9753 - val_loss: 1.6394 - val_accuracy: 0.7866\n",
      "Epoch 1384/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0706 - accuracy: 0.9706 - val_loss: 1.6090 - val_accuracy: 0.7866\n",
      "Epoch 1385/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0652 - accuracy: 0.9766 - val_loss: 1.5515 - val_accuracy: 0.7788\n",
      "Epoch 1386/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0711 - accuracy: 0.9706 - val_loss: 1.6016 - val_accuracy: 0.7819\n",
      "Epoch 1387/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0582 - accuracy: 0.9746 - val_loss: 1.6195 - val_accuracy: 0.7741\n",
      "Epoch 1388/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0644 - accuracy: 0.9779 - val_loss: 1.7042 - val_accuracy: 0.7835\n",
      "Epoch 1389/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0779 - accuracy: 0.9693 - val_loss: 1.6192 - val_accuracy: 0.7804\n",
      "Epoch 1390/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0889 - accuracy: 0.9693 - val_loss: 1.5946 - val_accuracy: 0.7773\n",
      "Epoch 1391/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0717 - accuracy: 0.9753 - val_loss: 1.6415 - val_accuracy: 0.7928\n",
      "Epoch 1392/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0715 - accuracy: 0.9739 - val_loss: 1.5487 - val_accuracy: 0.7835\n",
      "Epoch 1393/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0739 - accuracy: 0.9706 - val_loss: 1.5885 - val_accuracy: 0.7804\n",
      "Epoch 1394/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0609 - accuracy: 0.9786 - val_loss: 1.7198 - val_accuracy: 0.7757\n",
      "Epoch 1395/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0850 - accuracy: 0.9759 - val_loss: 1.6592 - val_accuracy: 0.7773\n",
      "Epoch 1396/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0604 - accuracy: 0.9746 - val_loss: 1.7160 - val_accuracy: 0.7788\n",
      "Epoch 1397/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0634 - accuracy: 0.9753 - val_loss: 1.7107 - val_accuracy: 0.7788\n",
      "Epoch 1398/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0806 - accuracy: 0.9686 - val_loss: 1.6677 - val_accuracy: 0.7788\n",
      "Epoch 1399/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0662 - accuracy: 0.9746 - val_loss: 1.7440 - val_accuracy: 0.7804\n",
      "Epoch 1400/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0687 - accuracy: 0.9726 - val_loss: 1.7161 - val_accuracy: 0.7788\n",
      "Epoch 1401/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0638 - accuracy: 0.9753 - val_loss: 1.7523 - val_accuracy: 0.7757\n",
      "Epoch 1402/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0500 - accuracy: 0.9813 - val_loss: 1.7420 - val_accuracy: 0.7788\n",
      "Epoch 1403/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0682 - accuracy: 0.9779 - val_loss: 1.7806 - val_accuracy: 0.7835\n",
      "Epoch 1404/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0574 - accuracy: 0.9773 - val_loss: 1.7751 - val_accuracy: 0.7757\n",
      "Epoch 1405/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0755 - accuracy: 0.9713 - val_loss: 1.7507 - val_accuracy: 0.7819\n",
      "Epoch 1406/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0510 - accuracy: 0.9786 - val_loss: 1.6692 - val_accuracy: 0.7710\n",
      "Epoch 1407/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0829 - accuracy: 0.9679 - val_loss: 1.8642 - val_accuracy: 0.7804\n",
      "Epoch 1408/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0732 - accuracy: 0.9713 - val_loss: 1.7328 - val_accuracy: 0.7726\n",
      "Epoch 1409/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0771 - accuracy: 0.9719 - val_loss: 1.7395 - val_accuracy: 0.7741\n",
      "Epoch 1410/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0582 - accuracy: 0.9753 - val_loss: 1.7588 - val_accuracy: 0.7757\n",
      "Epoch 1411/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0627 - accuracy: 0.9773 - val_loss: 1.6924 - val_accuracy: 0.7850\n",
      "Epoch 1412/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0652 - accuracy: 0.9759 - val_loss: 1.7394 - val_accuracy: 0.7913\n",
      "Epoch 1413/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0695 - accuracy: 0.9746 - val_loss: 1.7204 - val_accuracy: 0.7819\n",
      "Epoch 1414/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0697 - accuracy: 0.9713 - val_loss: 1.7680 - val_accuracy: 0.7835\n",
      "Epoch 1415/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0895 - accuracy: 0.9719 - val_loss: 1.6678 - val_accuracy: 0.7850\n",
      "Epoch 1416/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0709 - accuracy: 0.9706 - val_loss: 1.6627 - val_accuracy: 0.7866\n",
      "Epoch 1417/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0586 - accuracy: 0.9793 - val_loss: 1.6533 - val_accuracy: 0.7757\n",
      "Epoch 1418/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0873 - accuracy: 0.9726 - val_loss: 1.7116 - val_accuracy: 0.7788\n",
      "Epoch 1419/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0807 - accuracy: 0.9699 - val_loss: 1.6474 - val_accuracy: 0.7897\n",
      "Epoch 1420/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0654 - accuracy: 0.9746 - val_loss: 1.6355 - val_accuracy: 0.7757\n",
      "Epoch 1421/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0467 - accuracy: 0.9866 - val_loss: 1.6722 - val_accuracy: 0.7695\n",
      "Epoch 1422/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0605 - accuracy: 0.9779 - val_loss: 1.7085 - val_accuracy: 0.7726\n",
      "Epoch 1423/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0786 - accuracy: 0.9726 - val_loss: 1.6617 - val_accuracy: 0.7757\n",
      "Epoch 1424/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0567 - accuracy: 0.9779 - val_loss: 1.7656 - val_accuracy: 0.7773\n",
      "Epoch 1425/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0771 - accuracy: 0.9739 - val_loss: 1.7004 - val_accuracy: 0.7741\n",
      "Epoch 1426/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0688 - accuracy: 0.9786 - val_loss: 1.6688 - val_accuracy: 0.7648\n",
      "Epoch 1427/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0670 - accuracy: 0.9739 - val_loss: 1.6811 - val_accuracy: 0.7819\n",
      "Epoch 1428/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0714 - accuracy: 0.9726 - val_loss: 1.6440 - val_accuracy: 0.7757\n",
      "Epoch 1429/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0647 - accuracy: 0.9753 - val_loss: 1.6280 - val_accuracy: 0.7913\n",
      "Epoch 1430/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0628 - accuracy: 0.9759 - val_loss: 1.7017 - val_accuracy: 0.7804\n",
      "Epoch 1431/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0747 - accuracy: 0.9713 - val_loss: 1.6769 - val_accuracy: 0.7835\n",
      "Epoch 1432/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0672 - accuracy: 0.9786 - val_loss: 1.6735 - val_accuracy: 0.7944\n",
      "Epoch 1433/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0836 - accuracy: 0.9739 - val_loss: 1.6468 - val_accuracy: 0.7632\n",
      "Epoch 1434/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0667 - accuracy: 0.9686 - val_loss: 1.7172 - val_accuracy: 0.7882\n",
      "Epoch 1435/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0563 - accuracy: 0.9793 - val_loss: 1.7018 - val_accuracy: 0.7835\n",
      "Epoch 1436/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0667 - accuracy: 0.9753 - val_loss: 1.7450 - val_accuracy: 0.7882\n",
      "Epoch 1437/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0657 - accuracy: 0.9766 - val_loss: 1.7454 - val_accuracy: 0.7773\n",
      "Epoch 1438/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0533 - accuracy: 0.9779 - val_loss: 1.6726 - val_accuracy: 0.7882\n",
      "Epoch 1439/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0587 - accuracy: 0.9786 - val_loss: 1.6908 - val_accuracy: 0.7928\n",
      "Epoch 1440/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0514 - accuracy: 0.9820 - val_loss: 1.7649 - val_accuracy: 0.7819\n",
      "Epoch 1441/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0554 - accuracy: 0.9773 - val_loss: 1.7491 - val_accuracy: 0.7866\n",
      "Epoch 1442/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0598 - accuracy: 0.9779 - val_loss: 1.7413 - val_accuracy: 0.7804\n",
      "Epoch 1443/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9713 - val_loss: 1.6443 - val_accuracy: 0.7819\n",
      "Epoch 1444/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0855 - accuracy: 0.9739 - val_loss: 1.6914 - val_accuracy: 0.7913\n",
      "Epoch 1445/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0885 - accuracy: 0.9666 - val_loss: 1.5864 - val_accuracy: 0.7741\n",
      "Epoch 1446/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0626 - accuracy: 0.9726 - val_loss: 1.7162 - val_accuracy: 0.7960\n",
      "Epoch 1447/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0679 - accuracy: 0.9779 - val_loss: 1.5793 - val_accuracy: 0.7866\n",
      "Epoch 1448/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0679 - accuracy: 0.9706 - val_loss: 1.6258 - val_accuracy: 0.7850\n",
      "Epoch 1449/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0674 - accuracy: 0.9726 - val_loss: 1.5875 - val_accuracy: 0.7741\n",
      "Epoch 1450/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0607 - accuracy: 0.9799 - val_loss: 1.6515 - val_accuracy: 0.7819\n",
      "Epoch 1451/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0668 - accuracy: 0.9759 - val_loss: 1.5937 - val_accuracy: 0.7726\n",
      "Epoch 1452/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0477 - accuracy: 0.9786 - val_loss: 1.5984 - val_accuracy: 0.7850\n",
      "Epoch 1453/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0635 - accuracy: 0.9766 - val_loss: 1.6526 - val_accuracy: 0.7710\n",
      "Epoch 1454/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0832 - accuracy: 0.9726 - val_loss: 1.6742 - val_accuracy: 0.7835\n",
      "Epoch 1455/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0733 - accuracy: 0.9753 - val_loss: 1.6864 - val_accuracy: 0.7882\n",
      "Epoch 1456/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0721 - accuracy: 0.9706 - val_loss: 1.7166 - val_accuracy: 0.7788\n",
      "Epoch 1457/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0767 - accuracy: 0.9672 - val_loss: 1.6631 - val_accuracy: 0.7835\n",
      "Epoch 1458/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0833 - accuracy: 0.9706 - val_loss: 1.5862 - val_accuracy: 0.7773\n",
      "Epoch 1459/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0627 - accuracy: 0.9820 - val_loss: 1.6489 - val_accuracy: 0.7866\n",
      "Epoch 1460/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0831 - accuracy: 0.9719 - val_loss: 1.6711 - val_accuracy: 0.7773\n",
      "Epoch 1461/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0508 - accuracy: 0.9753 - val_loss: 1.6245 - val_accuracy: 0.7741\n",
      "Epoch 1462/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0816 - accuracy: 0.9639 - val_loss: 1.6422 - val_accuracy: 0.7850\n",
      "Epoch 1463/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0686 - accuracy: 0.9753 - val_loss: 1.6918 - val_accuracy: 0.7819\n",
      "Epoch 1464/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0807 - accuracy: 0.9706 - val_loss: 1.6682 - val_accuracy: 0.7819\n",
      "Epoch 1465/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0628 - accuracy: 0.9719 - val_loss: 1.6229 - val_accuracy: 0.7757\n",
      "Epoch 1466/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0620 - accuracy: 0.9753 - val_loss: 1.6641 - val_accuracy: 0.7835\n",
      "Epoch 1467/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0813 - accuracy: 0.9739 - val_loss: 1.7253 - val_accuracy: 0.7819\n",
      "Epoch 1468/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0661 - accuracy: 0.9786 - val_loss: 1.6990 - val_accuracy: 0.7944\n",
      "Epoch 1469/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0775 - accuracy: 0.9739 - val_loss: 1.5748 - val_accuracy: 0.7866\n",
      "Epoch 1470/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0710 - accuracy: 0.9726 - val_loss: 1.6322 - val_accuracy: 0.7913\n",
      "Epoch 1471/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0695 - accuracy: 0.9753 - val_loss: 1.6568 - val_accuracy: 0.7773\n",
      "Epoch 1472/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0581 - accuracy: 0.9766 - val_loss: 1.6693 - val_accuracy: 0.7913\n",
      "Epoch 1473/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0547 - accuracy: 0.9820 - val_loss: 1.6548 - val_accuracy: 0.7850\n",
      "Epoch 1474/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0631 - accuracy: 0.9753 - val_loss: 1.6669 - val_accuracy: 0.7788\n",
      "Epoch 1475/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0744 - accuracy: 0.9746 - val_loss: 1.6603 - val_accuracy: 0.7741\n",
      "Epoch 1476/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9733 - val_loss: 1.7715 - val_accuracy: 0.7757\n",
      "Epoch 1477/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0725 - accuracy: 0.9759 - val_loss: 1.6774 - val_accuracy: 0.7804\n",
      "Epoch 1478/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0559 - accuracy: 0.9773 - val_loss: 1.6782 - val_accuracy: 0.7882\n",
      "Epoch 1479/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0642 - accuracy: 0.9753 - val_loss: 1.6605 - val_accuracy: 0.7897\n",
      "Epoch 1480/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0687 - accuracy: 0.9733 - val_loss: 1.7444 - val_accuracy: 0.7804\n",
      "Epoch 1481/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0721 - accuracy: 0.9726 - val_loss: 1.6544 - val_accuracy: 0.7804\n",
      "Epoch 1482/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0798 - accuracy: 0.9719 - val_loss: 1.6883 - val_accuracy: 0.7850\n",
      "Epoch 1483/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0735 - accuracy: 0.9753 - val_loss: 1.6816 - val_accuracy: 0.7897\n",
      "Epoch 1484/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0759 - accuracy: 0.9713 - val_loss: 1.6923 - val_accuracy: 0.7913\n",
      "Epoch 1485/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0634 - accuracy: 0.9766 - val_loss: 1.6540 - val_accuracy: 0.7866\n",
      "Epoch 1486/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0466 - accuracy: 0.9820 - val_loss: 1.6964 - val_accuracy: 0.7804\n",
      "Epoch 1487/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0534 - accuracy: 0.9773 - val_loss: 1.6942 - val_accuracy: 0.7726\n",
      "Epoch 1488/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0653 - accuracy: 0.9773 - val_loss: 1.6623 - val_accuracy: 0.7835\n",
      "Epoch 1489/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0506 - accuracy: 0.9799 - val_loss: 1.7006 - val_accuracy: 0.7788\n",
      "Epoch 1490/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0603 - accuracy: 0.9779 - val_loss: 1.7712 - val_accuracy: 0.7913\n",
      "Epoch 1491/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0711 - accuracy: 0.9739 - val_loss: 1.7210 - val_accuracy: 0.7850\n",
      "Epoch 1492/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0591 - accuracy: 0.9799 - val_loss: 1.7137 - val_accuracy: 0.7866\n",
      "Epoch 1493/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0624 - accuracy: 0.9766 - val_loss: 1.6991 - val_accuracy: 0.7788\n",
      "Epoch 1494/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0606 - accuracy: 0.9739 - val_loss: 1.7526 - val_accuracy: 0.7788\n",
      "Epoch 1495/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0490 - accuracy: 0.9820 - val_loss: 1.6536 - val_accuracy: 0.7882\n",
      "Epoch 1496/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0538 - accuracy: 0.9833 - val_loss: 1.7290 - val_accuracy: 0.7757\n",
      "Epoch 1497/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0637 - accuracy: 0.9799 - val_loss: 1.6787 - val_accuracy: 0.7710\n",
      "Epoch 1498/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0672 - accuracy: 0.9759 - val_loss: 1.7182 - val_accuracy: 0.7819\n",
      "Epoch 1499/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0499 - accuracy: 0.9806 - val_loss: 1.7039 - val_accuracy: 0.7773\n",
      "Epoch 1500/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0521 - accuracy: 0.9786 - val_loss: 1.6929 - val_accuracy: 0.7726\n"
     ]
    }
   ],
   "source": [
    "# Train the CNN\n",
    "#es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "history = model.fit(X_train_reshaped, y_train_onehot, epochs=1500, batch_size=40,\n",
    "                    validation_data=(X_test_reshaped, y_test_onehot))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fad3c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 4ms/step\n",
      "Accuracy: 0.7725856697819314\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the performance\n",
    "y_pred = model.predict(X_test_reshaped)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "accuracy = accuracy_score(y_test_encoded, y_pred_classes)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d17f6734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71748165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c637edb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.87       522\n",
      "           1       0.31      0.17      0.22       120\n",
      "\n",
      "    accuracy                           0.77       642\n",
      "   macro avg       0.57      0.54      0.55       642\n",
      "weighted avg       0.73      0.77      0.75       642\n",
      "\n",
      "Predict   0         1         \n",
      "Actual\n",
      "0         475       47        \n",
      "\n",
      "1         99        21        \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overall Statistics : \n",
      "\n",
      "95% CI                                                            (0.74016,0.80501)\n",
      "ACC Macro                                                         0.77259\n",
      "ARI                                                               0.07048\n",
      "AUNP                                                              0.54248\n",
      "AUNU                                                              0.54248\n",
      "Bangdiwala B                                                      0.73449\n",
      "Bennett S                                                         0.54517\n",
      "CBA                                                               0.50126\n",
      "CSI                                                               0.11066\n",
      "Chi-Squared                                                       7.43725\n",
      "Chi-Squared DF                                                    1\n",
      "Conditional Entropy                                               0.48004\n",
      "Cramer V                                                          0.10763\n",
      "Cross Entropy                                                     0.73675\n",
      "F1 Macro                                                          0.5451\n",
      "F1 Micro                                                          0.77259\n",
      "FNR Macro                                                         0.45752\n",
      "FNR Micro                                                         0.22741\n",
      "FPR Macro                                                         0.45752\n",
      "FPR Micro                                                         0.22741\n",
      "Gwet AC1                                                          0.6968\n",
      "Hamming Loss                                                      0.22741\n",
      "Joint Entropy                                                     1.17502\n",
      "KL Divergence                                                     0.04177\n",
      "Kappa                                                             0.10198\n",
      "Kappa 95% CI                                                      (-0.02606,0.23002)\n",
      "Kappa No Prevalence                                               0.54517\n",
      "Kappa Standard Error                                              0.06533\n",
      "Kappa Unbiased                                                    0.09019\n",
      "Krippendorff Alpha                                                0.0909\n",
      "Lambda A                                                          0.0\n",
      "Lambda B                                                          0.0\n",
      "Mutual Information                                                0.00744\n",
      "NIR                                                               0.81308\n",
      "Overall ACC                                                       0.77259\n",
      "Overall CEN                                                       0.5783\n",
      "Overall J                                                         (0.89064,0.44532)\n",
      "Overall MCC                                                       0.10763\n",
      "Overall MCEN                                                      0.46568\n",
      "Overall RACC                                                      0.74676\n",
      "Overall RACCU                                                     0.75004\n",
      "P-Value                                                           0.99565\n",
      "PPV Macro                                                         0.56817\n",
      "PPV Micro                                                         0.77259\n",
      "Pearson C                                                         0.10701\n",
      "Phi-Squared                                                       0.01158\n",
      "RCI                                                               0.01071\n",
      "RR                                                                321.0\n",
      "Reference Entropy                                                 0.69497\n",
      "Response Entropy                                                  0.48748\n",
      "SOA1(Landis & Koch)                                               Slight\n",
      "SOA2(Fleiss)                                                      Poor\n",
      "SOA3(Altman)                                                      Poor\n",
      "SOA4(Cicchetti)                                                   Poor\n",
      "SOA5(Cramer)                                                      Weak\n",
      "SOA6(Matthews)                                                    Negligible\n",
      "SOA7(Lambda A)                                                    None\n",
      "SOA8(Lambda B)                                                    None\n",
      "SOA9(Krippendorff Alpha)                                          Low\n",
      "SOA10(Pearson C)                                                  Weak\n",
      "Scott PI                                                          0.09019\n",
      "Standard Error                                                    0.01654\n",
      "TNR Macro                                                         0.54248\n",
      "TNR Micro                                                         0.77259\n",
      "TPR Macro                                                         0.54248\n",
      "TPR Micro                                                         0.77259\n",
      "Zero-one Loss                                                     146\n",
      "\n",
      "Class Statistics :\n",
      "\n",
      "Classes                                                           0             1             \n",
      "ACC(Accuracy)                                                     0.77259       0.77259       \n",
      "AGF(Adjusted F-score)                                             0.48885       0.40185       \n",
      "AGM(Adjusted geometric mean)                                      0.36377       0.62817       \n",
      "AM(Difference between automatic and manual classification)        52            -52           \n",
      "AUC(Area under the ROC curve)                                     0.54248       0.54248       \n",
      "AUCI(AUC value interpretation)                                    Poor          Poor          \n",
      "AUPR(Area under the PR curve)                                     0.86874       0.24191       \n",
      "BB(Braun-Blanquet similarity)                                     0.82753       0.175         \n",
      "BCD(Bray-Curtis dissimilarity)                                    0.0405        0.0405        \n",
      "BM(Informedness or bookmaker informedness)                        0.08496       0.08496       \n",
      "CEN(Confusion entropy)                                            0.50816       0.98722       \n",
      "DOR(Diagnostic odds ratio)                                        2.14378       2.14378       \n",
      "DP(Discriminant power)                                            0.18259       0.18259       \n",
      "DPI(Discriminant power interpretation)                            Poor          Poor          \n",
      "ERR(Error rate)                                                   0.22741       0.22741       \n",
      "F0.5(F0.5 score)                                                  0.8428        0.26786       \n",
      "F1(F1 score - harmonic mean of precision and sensitivity)         0.86679       0.2234        \n",
      "F2(F2 score)                                                      0.89219       0.19161       \n",
      "FDR(False discovery rate)                                         0.17247       0.69118       \n",
      "FN(False negative/miss/type 2 error)                              47            99            \n",
      "FNR(Miss rate or false negative rate)                             0.09004       0.825         \n",
      "FOR(False omission rate)                                          0.69118       0.17247       \n",
      "FP(False positive/type 1 error/false alarm)                       99            47            \n",
      "FPR(Fall-out or false positive rate)                              0.825         0.09004       \n",
      "G(G-measure geometric mean of precision and sensitivity)          0.86777       0.23247       \n",
      "GI(Gini index)                                                    0.08496       0.08496       \n",
      "GM(G-mean geometric mean of specificity and sensitivity)          0.39905       0.39905       \n",
      "HD(Hamming distance)                                              146           146           \n",
      "IBA(Index of balanced accuracy)                                   0.27628       0.04221       \n",
      "ICSI(Individual classification success index)                     0.73749       -0.51618      \n",
      "IS(Information score)                                             0.0254        0.72439       \n",
      "J(Jaccard index)                                                  0.7649        0.12575       \n",
      "LS(Lift score)                                                    1.01776       1.65221       \n",
      "MCC(Matthews correlation coefficient)                             0.10763       0.10763       \n",
      "MCCI(Matthews correlation coefficient interpretation)             Negligible    Negligible    \n",
      "MCEN(Modified confusion entropy)                                  0.70416       0.96197       \n",
      "MK(Markedness)                                                    0.13635       0.13635       \n",
      "N(Condition negative)                                             120           522           \n",
      "NLR(Negative likelihood ratio)                                    0.5145        0.90663       \n",
      "NLRI(Negative likelihood ratio interpretation)                    Negligible    Negligible    \n",
      "NPV(Negative predictive value)                                    0.30882       0.82753       \n",
      "OC(Overlap coefficient)                                           0.90996       0.30882       \n",
      "OOC(Otsuka-Ochiai coefficient)                                    0.86777       0.23247       \n",
      "OP(Optimized precision)                                           0.09518       0.09518       \n",
      "P(Condition positive or support)                                  522           120           \n",
      "PLR(Positive likelihood ratio)                                    1.10298       1.94362       \n",
      "PLRI(Positive likelihood ratio interpretation)                    Poor          Poor          \n",
      "POP(Population)                                                   642           642           \n",
      "PPV(Precision or positive predictive value)                       0.82753       0.30882       \n",
      "PRE(Prevalence)                                                   0.81308       0.18692       \n",
      "Q(Yule Q - coefficient of colligation)                            0.36382       0.36382       \n",
      "QI(Yule Q interpretation)                                         Weak          Weak          \n",
      "RACC(Random accuracy)                                             0.72696       0.0198        \n",
      "RACCU(Random accuracy unbiased)                                   0.7286        0.02144       \n",
      "TN(True negative/correct rejection)                               21            475           \n",
      "TNR(Specificity or true negative rate)                            0.175         0.90996       \n",
      "TON(Test outcome negative)                                        68            574           \n",
      "TOP(Test outcome positive)                                        574           68            \n",
      "TP(True positive/hit)                                             475           21            \n",
      "TPR(Sensitivity, recall, hit rate, or true positive rate)         0.90996       0.175         \n",
      "Y(Youden index)                                                   0.08496       0.08496       \n",
      "dInd(Distance index)                                              0.8299        0.8299        \n",
      "sInd(Similarity index)                                            0.41317       0.41317       \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pycm import ConfusionMatrix\n",
    "\n",
    "\n",
    "print(\"Report : \", classification_report(y_test_encoded, y_pred_classes))\n",
    "\n",
    "print(ConfusionMatrix(actual_vector=list(y_test_encoded),predict_vector=list(y_pred_classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3483e9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7725856697819314\n",
      "Precision:  0.7305723748355052\n",
      "Recall:  0.7725856697819314\n",
      "F1-score:  0.7465296172709236\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.87       522\n",
      "           1       0.31      0.17      0.22       120\n",
      "\n",
      "    accuracy                           0.77       642\n",
      "   macro avg       0.57      0.54      0.55       642\n",
      "weighted avg       0.73      0.77      0.75       642\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import plot_confusion_matrix, classification_report\n",
    "import warnings\n",
    "\n",
    "print(\"Accuracy: \", accuracy_score(y_test_encoded, y_pred_classes))\n",
    "print(\"Precision: \", precision_score(y_test_encoded, y_pred_classes, average='weighted'))\n",
    "print(\"Recall: \", recall_score(y_test_encoded, y_pred_classes, average='weighted'))\n",
    "print(\"F1-score: \", f1_score(y_test_encoded, y_pred_classes, average='weighted'))\n",
    "\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test_encoded, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d26b93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
