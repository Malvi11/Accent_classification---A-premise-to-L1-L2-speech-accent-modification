{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "960c61fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9814adcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mfcc_1</th>\n",
       "      <th>mfcc_2</th>\n",
       "      <th>mfcc_3</th>\n",
       "      <th>mfcc_4</th>\n",
       "      <th>mfcc_5</th>\n",
       "      <th>mfcc_6</th>\n",
       "      <th>mfcc_7</th>\n",
       "      <th>mfcc_8</th>\n",
       "      <th>mfcc_9</th>\n",
       "      <th>mfcc_10</th>\n",
       "      <th>...</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>English Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-330.49750</td>\n",
       "      <td>-5.631140e-02</td>\n",
       "      <td>-1.305158e-02</td>\n",
       "      <td>129.82634</td>\n",
       "      <td>5.654399e-04</td>\n",
       "      <td>-1.087543e-03</td>\n",
       "      <td>-4.971954</td>\n",
       "      <td>3.198393e-02</td>\n",
       "      <td>1.747995e-03</td>\n",
       "      <td>31.724367</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.752345</td>\n",
       "      <td>-1.821501e-03</td>\n",
       "      <td>9.363368e-04</td>\n",
       "      <td>-4.558670</td>\n",
       "      <td>6.158995e-03</td>\n",
       "      <td>3.925575e-03</td>\n",
       "      <td>-0.389210</td>\n",
       "      <td>1.502641e-03</td>\n",
       "      <td>2.480886e-03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-322.01425</td>\n",
       "      <td>-3.602875e-03</td>\n",
       "      <td>-2.423903e-02</td>\n",
       "      <td>128.47772</td>\n",
       "      <td>-6.527488e-03</td>\n",
       "      <td>-9.426854e-03</td>\n",
       "      <td>-19.397339</td>\n",
       "      <td>-2.809185e-05</td>\n",
       "      <td>6.502475e-03</td>\n",
       "      <td>38.388363</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.544018</td>\n",
       "      <td>7.676435e-03</td>\n",
       "      <td>7.934333e-04</td>\n",
       "      <td>-1.401703</td>\n",
       "      <td>5.644315e-03</td>\n",
       "      <td>-5.167238e-04</td>\n",
       "      <td>-5.707905</td>\n",
       "      <td>-2.998314e-03</td>\n",
       "      <td>1.379392e-04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-340.64084</td>\n",
       "      <td>-1.116015e-02</td>\n",
       "      <td>-1.194324e-02</td>\n",
       "      <td>97.25810</td>\n",
       "      <td>-4.836332e-03</td>\n",
       "      <td>-6.452511e-03</td>\n",
       "      <td>-5.416280</td>\n",
       "      <td>-8.388211e-03</td>\n",
       "      <td>1.998641e-03</td>\n",
       "      <td>21.495487</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.403498</td>\n",
       "      <td>-6.431966e-03</td>\n",
       "      <td>6.693075e-04</td>\n",
       "      <td>0.850455</td>\n",
       "      <td>-6.629119e-04</td>\n",
       "      <td>-1.358620e-03</td>\n",
       "      <td>-11.889046</td>\n",
       "      <td>-1.693906e-03</td>\n",
       "      <td>1.692394e-04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-377.72028</td>\n",
       "      <td>2.176717e-08</td>\n",
       "      <td>-6.462130e-09</td>\n",
       "      <td>140.99352</td>\n",
       "      <td>3.265076e-08</td>\n",
       "      <td>-5.951962e-09</td>\n",
       "      <td>-15.099728</td>\n",
       "      <td>-1.020336e-09</td>\n",
       "      <td>1.360448e-09</td>\n",
       "      <td>19.818373</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.418817</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-2.380785e-09</td>\n",
       "      <td>-4.824514</td>\n",
       "      <td>-3.401121e-10</td>\n",
       "      <td>1.020336e-09</td>\n",
       "      <td>-3.209569</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.211649e-09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-330.79733</td>\n",
       "      <td>-9.279275e-03</td>\n",
       "      <td>3.626792e-03</td>\n",
       "      <td>98.38888</td>\n",
       "      <td>2.809254e-03</td>\n",
       "      <td>2.656345e-03</td>\n",
       "      <td>-2.800510</td>\n",
       "      <td>7.261699e-03</td>\n",
       "      <td>1.559843e-03</td>\n",
       "      <td>30.394365</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.268788</td>\n",
       "      <td>-2.190437e-03</td>\n",
       "      <td>1.166201e-03</td>\n",
       "      <td>-1.180020</td>\n",
       "      <td>-6.167702e-04</td>\n",
       "      <td>-1.668033e-03</td>\n",
       "      <td>0.379468</td>\n",
       "      <td>-3.115617e-03</td>\n",
       "      <td>2.192514e-03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2133</th>\n",
       "      <td>-321.37543</td>\n",
       "      <td>2.145348e-08</td>\n",
       "      <td>-1.592251e-09</td>\n",
       "      <td>125.37948</td>\n",
       "      <td>8.045056e-09</td>\n",
       "      <td>5.195765e-09</td>\n",
       "      <td>-18.120020</td>\n",
       "      <td>6.704213e-10</td>\n",
       "      <td>8.380267e-10</td>\n",
       "      <td>24.798357</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.950925</td>\n",
       "      <td>2.681685e-09</td>\n",
       "      <td>-2.430277e-09</td>\n",
       "      <td>-10.296289</td>\n",
       "      <td>6.704213e-10</td>\n",
       "      <td>5.195765e-09</td>\n",
       "      <td>-6.076538</td>\n",
       "      <td>-1.340843e-09</td>\n",
       "      <td>4.190133e-11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2134</th>\n",
       "      <td>-334.67572</td>\n",
       "      <td>2.969725e-03</td>\n",
       "      <td>-7.079506e-03</td>\n",
       "      <td>115.60187</td>\n",
       "      <td>2.633094e-03</td>\n",
       "      <td>-3.973560e-03</td>\n",
       "      <td>-10.139031</td>\n",
       "      <td>-6.183048e-04</td>\n",
       "      <td>-9.918020e-04</td>\n",
       "      <td>27.466146</td>\n",
       "      <td>...</td>\n",
       "      <td>-22.601553</td>\n",
       "      <td>-3.429410e-03</td>\n",
       "      <td>-3.406802e-04</td>\n",
       "      <td>-8.010031</td>\n",
       "      <td>3.347575e-04</td>\n",
       "      <td>1.722395e-04</td>\n",
       "      <td>-8.633924</td>\n",
       "      <td>2.589215e-03</td>\n",
       "      <td>-7.905327e-05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2135</th>\n",
       "      <td>-237.90643</td>\n",
       "      <td>2.993488e-02</td>\n",
       "      <td>-6.727289e-03</td>\n",
       "      <td>103.26113</td>\n",
       "      <td>3.290961e-02</td>\n",
       "      <td>-5.506047e-03</td>\n",
       "      <td>-23.400814</td>\n",
       "      <td>1.604700e-02</td>\n",
       "      <td>-2.868054e-04</td>\n",
       "      <td>33.581520</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.508986</td>\n",
       "      <td>-5.677356e-04</td>\n",
       "      <td>-7.979744e-04</td>\n",
       "      <td>-8.856752</td>\n",
       "      <td>3.319585e-05</td>\n",
       "      <td>-1.515660e-04</td>\n",
       "      <td>-2.979901</td>\n",
       "      <td>-5.256697e-04</td>\n",
       "      <td>1.029256e-03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2136</th>\n",
       "      <td>-312.73398</td>\n",
       "      <td>5.774686e-02</td>\n",
       "      <td>2.157346e-04</td>\n",
       "      <td>130.01166</td>\n",
       "      <td>4.117964e-02</td>\n",
       "      <td>-3.729525e-04</td>\n",
       "      <td>-6.817431</td>\n",
       "      <td>5.208343e-03</td>\n",
       "      <td>-5.306819e-04</td>\n",
       "      <td>19.614530</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.335617</td>\n",
       "      <td>-9.031654e-05</td>\n",
       "      <td>2.355064e-03</td>\n",
       "      <td>-6.252686</td>\n",
       "      <td>-1.106754e-03</td>\n",
       "      <td>1.026079e-03</td>\n",
       "      <td>-0.870628</td>\n",
       "      <td>-1.179720e-03</td>\n",
       "      <td>-9.064542e-04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2137</th>\n",
       "      <td>-307.59650</td>\n",
       "      <td>6.353763e-02</td>\n",
       "      <td>1.284335e-02</td>\n",
       "      <td>123.73421</td>\n",
       "      <td>1.195807e-02</td>\n",
       "      <td>9.860430e-03</td>\n",
       "      <td>-18.446918</td>\n",
       "      <td>-1.816876e-02</td>\n",
       "      <td>5.292204e-03</td>\n",
       "      <td>65.722305</td>\n",
       "      <td>...</td>\n",
       "      <td>3.844791</td>\n",
       "      <td>-1.532581e-03</td>\n",
       "      <td>8.469080e-04</td>\n",
       "      <td>2.360198</td>\n",
       "      <td>5.612976e-03</td>\n",
       "      <td>2.984365e-04</td>\n",
       "      <td>-4.568026</td>\n",
       "      <td>-1.764863e-03</td>\n",
       "      <td>1.253004e-03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2138 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         mfcc_1        mfcc_2        mfcc_3     mfcc_4        mfcc_5  \\\n",
       "0    -330.49750 -5.631140e-02 -1.305158e-02  129.82634  5.654399e-04   \n",
       "1    -322.01425 -3.602875e-03 -2.423903e-02  128.47772 -6.527488e-03   \n",
       "2    -340.64084 -1.116015e-02 -1.194324e-02   97.25810 -4.836332e-03   \n",
       "3    -377.72028  2.176717e-08 -6.462130e-09  140.99352  3.265076e-08   \n",
       "4    -330.79733 -9.279275e-03  3.626792e-03   98.38888  2.809254e-03   \n",
       "...         ...           ...           ...        ...           ...   \n",
       "2133 -321.37543  2.145348e-08 -1.592251e-09  125.37948  8.045056e-09   \n",
       "2134 -334.67572  2.969725e-03 -7.079506e-03  115.60187  2.633094e-03   \n",
       "2135 -237.90643  2.993488e-02 -6.727289e-03  103.26113  3.290961e-02   \n",
       "2136 -312.73398  5.774686e-02  2.157346e-04  130.01166  4.117964e-02   \n",
       "2137 -307.59650  6.353763e-02  1.284335e-02  123.73421  1.195807e-02   \n",
       "\n",
       "            mfcc_6     mfcc_7        mfcc_8        mfcc_9    mfcc_10  ...  \\\n",
       "0    -1.087543e-03  -4.971954  3.198393e-02  1.747995e-03  31.724367  ...   \n",
       "1    -9.426854e-03 -19.397339 -2.809185e-05  6.502475e-03  38.388363  ...   \n",
       "2    -6.452511e-03  -5.416280 -8.388211e-03  1.998641e-03  21.495487  ...   \n",
       "3    -5.951962e-09 -15.099728 -1.020336e-09  1.360448e-09  19.818373  ...   \n",
       "4     2.656345e-03  -2.800510  7.261699e-03  1.559843e-03  30.394365  ...   \n",
       "...            ...        ...           ...           ...        ...  ...   \n",
       "2133  5.195765e-09 -18.120020  6.704213e-10  8.380267e-10  24.798357  ...   \n",
       "2134 -3.973560e-03 -10.139031 -6.183048e-04 -9.918020e-04  27.466146  ...   \n",
       "2135 -5.506047e-03 -23.400814  1.604700e-02 -2.868054e-04  33.581520  ...   \n",
       "2136 -3.729525e-04  -6.817431  5.208343e-03 -5.306819e-04  19.614530  ...   \n",
       "2137  9.860430e-03 -18.446918 -1.816876e-02  5.292204e-03  65.722305  ...   \n",
       "\n",
       "             35            36            37         38            39  \\\n",
       "0     -2.752345 -1.821501e-03  9.363368e-04  -4.558670  6.158995e-03   \n",
       "1     -1.544018  7.676435e-03  7.934333e-04  -1.401703  5.644315e-03   \n",
       "2    -10.403498 -6.431966e-03  6.693075e-04   0.850455 -6.629119e-04   \n",
       "3     -4.418817  0.000000e+00 -2.380785e-09  -4.824514 -3.401121e-10   \n",
       "4     -0.268788 -2.190437e-03  1.166201e-03  -1.180020 -6.167702e-04   \n",
       "...         ...           ...           ...        ...           ...   \n",
       "2133  -5.950925  2.681685e-09 -2.430277e-09 -10.296289  6.704213e-10   \n",
       "2134 -22.601553 -3.429410e-03 -3.406802e-04  -8.010031  3.347575e-04   \n",
       "2135  -3.508986 -5.677356e-04 -7.979744e-04  -8.856752  3.319585e-05   \n",
       "2136  -1.335617 -9.031654e-05  2.355064e-03  -6.252686 -1.106754e-03   \n",
       "2137   3.844791 -1.532581e-03  8.469080e-04   2.360198  5.612976e-03   \n",
       "\n",
       "                40         41            42            43  English Type  \n",
       "0     3.925575e-03  -0.389210  1.502641e-03  2.480886e-03             1  \n",
       "1    -5.167238e-04  -5.707905 -2.998314e-03  1.379392e-04             0  \n",
       "2    -1.358620e-03 -11.889046 -1.693906e-03  1.692394e-04             0  \n",
       "3     1.020336e-09  -3.209569  0.000000e+00  1.211649e-09             0  \n",
       "4    -1.668033e-03   0.379468 -3.115617e-03  2.192514e-03             0  \n",
       "...            ...        ...           ...           ...           ...  \n",
       "2133  5.195765e-09  -6.076538 -1.340843e-09  4.190133e-11             0  \n",
       "2134  1.722395e-04  -8.633924  2.589215e-03 -7.905327e-05             0  \n",
       "2135 -1.515660e-04  -2.979901 -5.256697e-04  1.029256e-03             0  \n",
       "2136  1.026079e-03  -0.870628 -1.179720e-03 -9.064542e-04             0  \n",
       "2137  2.984365e-04  -4.568026 -1.764863e-03  1.253004e-03             0  \n",
       "\n",
       "[2138 rows x 40 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the features from the CSV file\n",
    "df = pd.read_csv(r'Original_Features8.csv')\n",
    "df=df.drop(['rolloff','zero_crossing_rate','chroma_stft','spectral_centroid','spectral_bandwidth'],axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d99f810",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,0:39]\n",
    "y = df.iloc[:,39]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "101a0a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1710, 39) (1710,)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(X_train.shape,y_train.shape)\n",
    "\n",
    "# scale data\n",
    "t = MinMaxScaler()\n",
    "t.fit(X_train)\n",
    "X_train = t.transform(X_train)\n",
    "X_test = t.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2516a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the input features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "889ff4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "43/43 [==============================] - 1s 6ms/step - loss: 1.1369 - val_loss: 1.0047\n",
      "Epoch 2/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.9942 - val_loss: 0.9059\n",
      "Epoch 3/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.9167 - val_loss: 0.8481\n",
      "Epoch 4/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.8664 - val_loss: 0.8058\n",
      "Epoch 5/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.8269 - val_loss: 0.7729\n",
      "Epoch 6/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.7962 - val_loss: 0.7477\n",
      "Epoch 7/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.7725 - val_loss: 0.7282\n",
      "Epoch 8/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.7538 - val_loss: 0.7126\n",
      "Epoch 9/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.7387 - val_loss: 0.6998\n",
      "Epoch 10/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.7263 - val_loss: 0.6892\n",
      "Epoch 11/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.7158 - val_loss: 0.6799\n",
      "Epoch 12/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.7069 - val_loss: 0.6720\n",
      "Epoch 13/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6991 - val_loss: 0.6651\n",
      "Epoch 14/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6923 - val_loss: 0.6591\n",
      "Epoch 15/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6863 - val_loss: 0.6536\n",
      "Epoch 16/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6810 - val_loss: 0.6487\n",
      "Epoch 17/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6763 - val_loss: 0.6443\n",
      "Epoch 18/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6720 - val_loss: 0.6405\n",
      "Epoch 19/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6682 - val_loss: 0.6367\n",
      "Epoch 20/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6647 - val_loss: 0.6334\n",
      "Epoch 21/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6616 - val_loss: 0.6305\n",
      "Epoch 22/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6588 - val_loss: 0.6276\n",
      "Epoch 23/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6562 - val_loss: 0.6252\n",
      "Epoch 24/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6538 - val_loss: 0.6229\n",
      "Epoch 25/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6516 - val_loss: 0.6207\n",
      "Epoch 26/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6496 - val_loss: 0.6185\n",
      "Epoch 27/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6478 - val_loss: 0.6166\n",
      "Epoch 28/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6461 - val_loss: 0.6149\n",
      "Epoch 29/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6445 - val_loss: 0.6133\n",
      "Epoch 30/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6431 - val_loss: 0.6116\n",
      "Epoch 31/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6417 - val_loss: 0.6103\n",
      "Epoch 32/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6405 - val_loss: 0.6090\n",
      "Epoch 33/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6393 - val_loss: 0.6079\n",
      "Epoch 34/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6382 - val_loss: 0.6067\n",
      "Epoch 35/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6372 - val_loss: 0.6057\n",
      "Epoch 36/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6363 - val_loss: 0.6046\n",
      "Epoch 37/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6354 - val_loss: 0.6037\n",
      "Epoch 38/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6346 - val_loss: 0.6027\n",
      "Epoch 39/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6338 - val_loss: 0.6019\n",
      "Epoch 40/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6331 - val_loss: 0.6011\n",
      "Epoch 41/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6324 - val_loss: 0.6004\n",
      "Epoch 42/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6317 - val_loss: 0.5997\n",
      "Epoch 43/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6311 - val_loss: 0.5989\n",
      "Epoch 44/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6306 - val_loss: 0.5983\n",
      "Epoch 45/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6300 - val_loss: 0.5978\n",
      "Epoch 46/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6295 - val_loss: 0.5974\n",
      "Epoch 47/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6290 - val_loss: 0.5967\n",
      "Epoch 48/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6286 - val_loss: 0.5962\n",
      "Epoch 49/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6281 - val_loss: 0.5958\n",
      "Epoch 50/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6277 - val_loss: 0.5953\n",
      "Epoch 51/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6274 - val_loss: 0.5948\n",
      "Epoch 52/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6270 - val_loss: 0.5944\n",
      "Epoch 53/1500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6266 - val_loss: 0.5939\n",
      "Epoch 54/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6263 - val_loss: 0.5936\n",
      "Epoch 55/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6260 - val_loss: 0.5933\n",
      "Epoch 56/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6257 - val_loss: 0.5929\n",
      "Epoch 57/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6254 - val_loss: 0.5926\n",
      "Epoch 58/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6252 - val_loss: 0.5923\n",
      "Epoch 59/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6249 - val_loss: 0.5920\n",
      "Epoch 60/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6246 - val_loss: 0.5916\n",
      "Epoch 61/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6244 - val_loss: 0.5913\n",
      "Epoch 62/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6242 - val_loss: 0.5910\n",
      "Epoch 63/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6239 - val_loss: 0.5908\n",
      "Epoch 64/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6237 - val_loss: 0.5906\n",
      "Epoch 65/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6235 - val_loss: 0.5903\n",
      "Epoch 66/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6233 - val_loss: 0.5901\n",
      "Epoch 67/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6231 - val_loss: 0.5898\n",
      "Epoch 68/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6230 - val_loss: 0.5896\n",
      "Epoch 69/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6228 - val_loss: 0.5895\n",
      "Epoch 70/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6226 - val_loss: 0.5893\n",
      "Epoch 71/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6224 - val_loss: 0.5891\n",
      "Epoch 72/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6223 - val_loss: 0.5888\n",
      "Epoch 73/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6221 - val_loss: 0.5887\n",
      "Epoch 74/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6220 - val_loss: 0.5885\n",
      "Epoch 75/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6219 - val_loss: 0.5883\n",
      "Epoch 76/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6217 - val_loss: 0.5881\n",
      "Epoch 77/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6216 - val_loss: 0.5879\n",
      "Epoch 78/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6215 - val_loss: 0.5878\n",
      "Epoch 79/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6214 - val_loss: 0.5876\n",
      "Epoch 80/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6212 - val_loss: 0.5875\n",
      "Epoch 81/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6211 - val_loss: 0.5874\n",
      "Epoch 82/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6210 - val_loss: 0.5873\n",
      "Epoch 83/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6209 - val_loss: 0.5871\n",
      "Epoch 84/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6208 - val_loss: 0.5870\n",
      "Epoch 85/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6207 - val_loss: 0.5868\n",
      "Epoch 86/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6206 - val_loss: 0.5867\n",
      "Epoch 87/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6205 - val_loss: 0.5866\n",
      "Epoch 88/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6204 - val_loss: 0.5864\n",
      "Epoch 89/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6203 - val_loss: 0.5863\n",
      "Epoch 90/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6202 - val_loss: 0.5863\n",
      "Epoch 91/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6201 - val_loss: 0.5861\n",
      "Epoch 92/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6200 - val_loss: 0.5860\n",
      "Epoch 93/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6200 - val_loss: 0.5859\n",
      "Epoch 94/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6199 - val_loss: 0.5858\n",
      "Epoch 95/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6198 - val_loss: 0.5857\n",
      "Epoch 96/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6197 - val_loss: 0.5856\n",
      "Epoch 97/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6196 - val_loss: 0.5856\n",
      "Epoch 98/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6196 - val_loss: 0.5854\n",
      "Epoch 99/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6195 - val_loss: 0.5854\n",
      "Epoch 100/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6194 - val_loss: 0.5853\n",
      "Epoch 101/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6194 - val_loss: 0.5852\n",
      "Epoch 102/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6193 - val_loss: 0.5851\n",
      "Epoch 103/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6192 - val_loss: 0.5850\n",
      "Epoch 104/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6191 - val_loss: 0.5849\n",
      "Epoch 105/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6191 - val_loss: 0.5848\n",
      "Epoch 106/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6190 - val_loss: 0.5848\n",
      "Epoch 107/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6190 - val_loss: 0.5847\n",
      "Epoch 108/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6189 - val_loss: 0.5846\n",
      "Epoch 109/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6189 - val_loss: 0.5846\n",
      "Epoch 110/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6188 - val_loss: 0.5846\n",
      "Epoch 111/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6188 - val_loss: 0.5845\n",
      "Epoch 112/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6187 - val_loss: 0.5844\n",
      "Epoch 113/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6186 - val_loss: 0.5843\n",
      "Epoch 114/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6186 - val_loss: 0.5842\n",
      "Epoch 115/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6185 - val_loss: 0.5842\n",
      "Epoch 116/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6185 - val_loss: 0.5841\n",
      "Epoch 117/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6184 - val_loss: 0.5841\n",
      "Epoch 118/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6184 - val_loss: 0.5840\n",
      "Epoch 119/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6184 - val_loss: 0.5840\n",
      "Epoch 120/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6183 - val_loss: 0.5839\n",
      "Epoch 121/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6183 - val_loss: 0.5839\n",
      "Epoch 122/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6182 - val_loss: 0.5837\n",
      "Epoch 123/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6182 - val_loss: 0.5837\n",
      "Epoch 124/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6181 - val_loss: 0.5837\n",
      "Epoch 125/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6181 - val_loss: 0.5836\n",
      "Epoch 126/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6180 - val_loss: 0.5835\n",
      "Epoch 127/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6180 - val_loss: 0.5835\n",
      "Epoch 128/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6180 - val_loss: 0.5834\n",
      "Epoch 129/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6179 - val_loss: 0.5834\n",
      "Epoch 130/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6179 - val_loss: 0.5833\n",
      "Epoch 131/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6178 - val_loss: 0.5833\n",
      "Epoch 132/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6178 - val_loss: 0.5833\n",
      "Epoch 133/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6178 - val_loss: 0.5832\n",
      "Epoch 134/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6177 - val_loss: 0.5832\n",
      "Epoch 135/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6177 - val_loss: 0.5831\n",
      "Epoch 136/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6177 - val_loss: 0.5830\n",
      "Epoch 137/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6176 - val_loss: 0.5830\n",
      "Epoch 138/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6176 - val_loss: 0.5830\n",
      "Epoch 139/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6176 - val_loss: 0.5829\n",
      "Epoch 140/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6176 - val_loss: 0.5830\n",
      "Epoch 141/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6175 - val_loss: 0.5829\n",
      "Epoch 142/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6175 - val_loss: 0.5828\n",
      "Epoch 143/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6175 - val_loss: 0.5828\n",
      "Epoch 144/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6174 - val_loss: 0.5827\n",
      "Epoch 145/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6174 - val_loss: 0.5827\n",
      "Epoch 146/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6174 - val_loss: 0.5827\n",
      "Epoch 147/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6174 - val_loss: 0.5826\n",
      "Epoch 148/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6173 - val_loss: 0.5826\n",
      "Epoch 149/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6173 - val_loss: 0.5826\n",
      "Epoch 150/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6173 - val_loss: 0.5825\n",
      "Epoch 151/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6173 - val_loss: 0.5825\n",
      "Epoch 152/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6172 - val_loss: 0.5825\n",
      "Epoch 153/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6172 - val_loss: 0.5825\n",
      "Epoch 154/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6172 - val_loss: 0.5824\n",
      "Epoch 155/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6172 - val_loss: 0.5824\n",
      "Epoch 156/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6171 - val_loss: 0.5823\n",
      "Epoch 157/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6171 - val_loss: 0.5823\n",
      "Epoch 158/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6171 - val_loss: 0.5822\n",
      "Epoch 159/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6171 - val_loss: 0.5822\n",
      "Epoch 160/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6170 - val_loss: 0.5822\n",
      "Epoch 161/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6170 - val_loss: 0.5822\n",
      "Epoch 162/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6170 - val_loss: 0.5821\n",
      "Epoch 163/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6170 - val_loss: 0.5821\n",
      "Epoch 164/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6170 - val_loss: 0.5821\n",
      "Epoch 165/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6169 - val_loss: 0.5821\n",
      "Epoch 166/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6169 - val_loss: 0.5821\n",
      "Epoch 167/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6169 - val_loss: 0.5820\n",
      "Epoch 168/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6169 - val_loss: 0.5820\n",
      "Epoch 169/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6169 - val_loss: 0.5819\n",
      "Epoch 170/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6168 - val_loss: 0.5819\n",
      "Epoch 171/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6168 - val_loss: 0.5819\n",
      "Epoch 172/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6168 - val_loss: 0.5819\n",
      "Epoch 173/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6168 - val_loss: 0.5818\n",
      "Epoch 174/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6168 - val_loss: 0.5818\n",
      "Epoch 175/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6168 - val_loss: 0.5818\n",
      "Epoch 176/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6167 - val_loss: 0.5818\n",
      "Epoch 177/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6167 - val_loss: 0.5817\n",
      "Epoch 178/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6167 - val_loss: 0.5817\n",
      "Epoch 179/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6167 - val_loss: 0.5817\n",
      "Epoch 180/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6167 - val_loss: 0.5816\n",
      "Epoch 181/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6167 - val_loss: 0.5816\n",
      "Epoch 182/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6166 - val_loss: 0.5816\n",
      "Epoch 183/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6166 - val_loss: 0.5816\n",
      "Epoch 184/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6166 - val_loss: 0.5815\n",
      "Epoch 185/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6166 - val_loss: 0.5815\n",
      "Epoch 186/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6166 - val_loss: 0.5815\n",
      "Epoch 187/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6166 - val_loss: 0.5815\n",
      "Epoch 188/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6165 - val_loss: 0.5815\n",
      "Epoch 189/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6165 - val_loss: 0.5814\n",
      "Epoch 190/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6165 - val_loss: 0.5814\n",
      "Epoch 191/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6165 - val_loss: 0.5814\n",
      "Epoch 192/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6165 - val_loss: 0.5814\n",
      "Epoch 193/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6165 - val_loss: 0.5814\n",
      "Epoch 194/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6165 - val_loss: 0.5813\n",
      "Epoch 195/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6165 - val_loss: 0.5813\n",
      "Epoch 196/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6164 - val_loss: 0.5813\n",
      "Epoch 197/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6164 - val_loss: 0.5813\n",
      "Epoch 198/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6164 - val_loss: 0.5813\n",
      "Epoch 199/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6164 - val_loss: 0.5812\n",
      "Epoch 200/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6164 - val_loss: 0.5812\n",
      "Epoch 201/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6164 - val_loss: 0.5812\n",
      "Epoch 202/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6164 - val_loss: 0.5812\n",
      "Epoch 203/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6163 - val_loss: 0.5812\n",
      "Epoch 204/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6163 - val_loss: 0.5812\n",
      "Epoch 205/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6163 - val_loss: 0.5811\n",
      "Epoch 206/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6163 - val_loss: 0.5811\n",
      "Epoch 207/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6163 - val_loss: 0.5811\n",
      "Epoch 208/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6163 - val_loss: 0.5811\n",
      "Epoch 209/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6163 - val_loss: 0.5810\n",
      "Epoch 210/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6163 - val_loss: 0.5811\n",
      "Epoch 211/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6163 - val_loss: 0.5810\n",
      "Epoch 212/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6162 - val_loss: 0.5811\n",
      "Epoch 213/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6162 - val_loss: 0.5810\n",
      "Epoch 214/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6162 - val_loss: 0.5810\n",
      "Epoch 215/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6162 - val_loss: 0.5810\n",
      "Epoch 216/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6162 - val_loss: 0.5810\n",
      "Epoch 217/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6162 - val_loss: 0.5810\n",
      "Epoch 218/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6162 - val_loss: 0.5810\n",
      "Epoch 219/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6162 - val_loss: 0.5809\n",
      "Epoch 220/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6162 - val_loss: 0.5809\n",
      "Epoch 221/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6162 - val_loss: 0.5809\n",
      "Epoch 222/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6161 - val_loss: 0.5809\n",
      "Epoch 223/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6161 - val_loss: 0.5809\n",
      "Epoch 224/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6161 - val_loss: 0.5808\n",
      "Epoch 225/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6161 - val_loss: 0.5808\n",
      "Epoch 226/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6161 - val_loss: 0.5808\n",
      "Epoch 227/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6161 - val_loss: 0.5808\n",
      "Epoch 228/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6161 - val_loss: 0.5808\n",
      "Epoch 229/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6161 - val_loss: 0.5808\n",
      "Epoch 230/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6161 - val_loss: 0.5808\n",
      "Epoch 231/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6161 - val_loss: 0.5808\n",
      "Epoch 232/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6161 - val_loss: 0.5808\n",
      "Epoch 233/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6160 - val_loss: 0.5807\n",
      "Epoch 234/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6160 - val_loss: 0.5807\n",
      "Epoch 235/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6160 - val_loss: 0.5807\n",
      "Epoch 236/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6160 - val_loss: 0.5807\n",
      "Epoch 237/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6160 - val_loss: 0.5807\n",
      "Epoch 238/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6160 - val_loss: 0.5807\n",
      "Epoch 239/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6160 - val_loss: 0.5807\n",
      "Epoch 240/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6160 - val_loss: 0.5807\n",
      "Epoch 241/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6160 - val_loss: 0.5806\n",
      "Epoch 242/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6160 - val_loss: 0.5806\n",
      "Epoch 243/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6160 - val_loss: 0.5806\n",
      "Epoch 244/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6160 - val_loss: 0.5806\n",
      "Epoch 245/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6160 - val_loss: 0.5806\n",
      "Epoch 246/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6159 - val_loss: 0.5806\n",
      "Epoch 247/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6159 - val_loss: 0.5806\n",
      "Epoch 248/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6159 - val_loss: 0.5806\n",
      "Epoch 249/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6159 - val_loss: 0.5805\n",
      "Epoch 250/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6159 - val_loss: 0.5806\n",
      "Epoch 251/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6159 - val_loss: 0.5805\n",
      "Epoch 252/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6159 - val_loss: 0.5805\n",
      "Epoch 253/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6159 - val_loss: 0.5805\n",
      "Epoch 254/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6159 - val_loss: 0.5805\n",
      "Epoch 255/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6159 - val_loss: 0.5805\n",
      "Epoch 256/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6159 - val_loss: 0.5805\n",
      "Epoch 257/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6159 - val_loss: 0.5805\n",
      "Epoch 258/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6159 - val_loss: 0.5805\n",
      "Epoch 259/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6159 - val_loss: 0.5804\n",
      "Epoch 260/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6159 - val_loss: 0.5804\n",
      "Epoch 261/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6159 - val_loss: 0.5804\n",
      "Epoch 262/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6158 - val_loss: 0.5804\n",
      "Epoch 263/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6158 - val_loss: 0.5804\n",
      "Epoch 264/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6158 - val_loss: 0.5804\n",
      "Epoch 265/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6158 - val_loss: 0.5804\n",
      "Epoch 266/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6158 - val_loss: 0.5804\n",
      "Epoch 267/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6158 - val_loss: 0.5803\n",
      "Epoch 268/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6158 - val_loss: 0.5803\n",
      "Epoch 269/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6158 - val_loss: 0.5803\n",
      "Epoch 270/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6158 - val_loss: 0.5803\n",
      "Epoch 271/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6158 - val_loss: 0.5803\n",
      "Epoch 272/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6158 - val_loss: 0.5803\n",
      "Epoch 273/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6158 - val_loss: 0.5803\n",
      "Epoch 274/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6158 - val_loss: 0.5803\n",
      "Epoch 275/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6158 - val_loss: 0.5803\n",
      "Epoch 276/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6158 - val_loss: 0.5803\n",
      "Epoch 277/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6158 - val_loss: 0.5802\n",
      "Epoch 278/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6158 - val_loss: 0.5802\n",
      "Epoch 279/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6158 - val_loss: 0.5802\n",
      "Epoch 280/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6157 - val_loss: 0.5802\n",
      "Epoch 281/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6157 - val_loss: 0.5802\n",
      "Epoch 282/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6157 - val_loss: 0.5802\n",
      "Epoch 283/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6157 - val_loss: 0.5802\n",
      "Epoch 284/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6157 - val_loss: 0.5802\n",
      "Epoch 285/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6157 - val_loss: 0.5801\n",
      "Epoch 286/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6157 - val_loss: 0.5802\n",
      "Epoch 287/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6157 - val_loss: 0.5802\n",
      "Epoch 288/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6157 - val_loss: 0.5801\n",
      "Epoch 289/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6157 - val_loss: 0.5801\n",
      "Epoch 290/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6157 - val_loss: 0.5801\n",
      "Epoch 291/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6157 - val_loss: 0.5801\n",
      "Epoch 292/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6157 - val_loss: 0.5801\n",
      "Epoch 293/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6157 - val_loss: 0.5802\n",
      "Epoch 294/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6157 - val_loss: 0.5801\n",
      "Epoch 295/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6157 - val_loss: 0.5801\n",
      "Epoch 296/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6157 - val_loss: 0.5801\n",
      "Epoch 297/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6157 - val_loss: 0.5800\n",
      "Epoch 298/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6157 - val_loss: 0.5801\n",
      "Epoch 299/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6157 - val_loss: 0.5801\n",
      "Epoch 300/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6157 - val_loss: 0.5801\n",
      "Epoch 301/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6157 - val_loss: 0.5801\n",
      "Epoch 302/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6157 - val_loss: 0.5800\n",
      "Epoch 303/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6156 - val_loss: 0.5801\n",
      "Epoch 304/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6156 - val_loss: 0.5801\n",
      "Epoch 305/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6156 - val_loss: 0.5800\n",
      "Epoch 306/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6156 - val_loss: 0.5800\n",
      "Epoch 307/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6156 - val_loss: 0.5800\n",
      "Epoch 308/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6156 - val_loss: 0.5800\n",
      "Epoch 309/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6156 - val_loss: 0.5800\n",
      "Epoch 310/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6156 - val_loss: 0.5800\n",
      "Epoch 311/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6156 - val_loss: 0.5800\n",
      "Epoch 312/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6156 - val_loss: 0.5800\n",
      "Epoch 313/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6156 - val_loss: 0.5800\n",
      "Epoch 314/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6156 - val_loss: 0.5800\n",
      "Epoch 315/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6156 - val_loss: 0.5799\n",
      "Epoch 316/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6156 - val_loss: 0.5799\n",
      "Epoch 317/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6156 - val_loss: 0.5799\n",
      "Epoch 318/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6156 - val_loss: 0.5799\n",
      "Epoch 319/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6156 - val_loss: 0.5799\n",
      "Epoch 320/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6156 - val_loss: 0.5799\n",
      "Epoch 321/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6156 - val_loss: 0.5799\n",
      "Epoch 322/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6156 - val_loss: 0.5799\n",
      "Epoch 323/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6156 - val_loss: 0.5799\n",
      "Epoch 324/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6156 - val_loss: 0.5799\n",
      "Epoch 325/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6156 - val_loss: 0.5799\n",
      "Epoch 326/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6156 - val_loss: 0.5798\n",
      "Epoch 327/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6156 - val_loss: 0.5799\n",
      "Epoch 328/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6156 - val_loss: 0.5799\n",
      "Epoch 329/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6156 - val_loss: 0.5799\n",
      "Epoch 330/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6156 - val_loss: 0.5798\n",
      "Epoch 331/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6155 - val_loss: 0.5798\n",
      "Epoch 332/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6155 - val_loss: 0.5799\n",
      "Epoch 333/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6155 - val_loss: 0.5798\n",
      "Epoch 334/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6155 - val_loss: 0.5798\n",
      "Epoch 335/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6155 - val_loss: 0.5798\n",
      "Epoch 336/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6155 - val_loss: 0.5798\n",
      "Epoch 337/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6155 - val_loss: 0.5798\n",
      "Epoch 338/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6155 - val_loss: 0.5798\n",
      "Epoch 339/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6155 - val_loss: 0.5798\n",
      "Epoch 340/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6155 - val_loss: 0.5798\n",
      "Epoch 341/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6155 - val_loss: 0.5798\n",
      "Epoch 342/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6155 - val_loss: 0.5798\n",
      "Epoch 343/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6155 - val_loss: 0.5798\n",
      "Epoch 344/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6155 - val_loss: 0.5798\n",
      "Epoch 345/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6155 - val_loss: 0.5797\n",
      "Epoch 346/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6155 - val_loss: 0.5797\n",
      "Epoch 347/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6155 - val_loss: 0.5798\n",
      "Epoch 348/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6155 - val_loss: 0.5797\n",
      "Epoch 349/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6155 - val_loss: 0.5797\n",
      "Epoch 350/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6155 - val_loss: 0.5797\n",
      "Epoch 351/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6155 - val_loss: 0.5797\n",
      "Epoch 352/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6155 - val_loss: 0.5797\n",
      "Epoch 353/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6155 - val_loss: 0.5797\n",
      "Epoch 354/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6155 - val_loss: 0.5797\n",
      "Epoch 355/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6155 - val_loss: 0.5797\n",
      "Epoch 356/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6155 - val_loss: 0.5797\n",
      "Epoch 357/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6155 - val_loss: 0.5797\n",
      "Epoch 358/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6155 - val_loss: 0.5797\n",
      "Epoch 359/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6155 - val_loss: 0.5796\n",
      "Epoch 360/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6155 - val_loss: 0.5796\n",
      "Epoch 361/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6155 - val_loss: 0.5796\n",
      "Epoch 362/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6155 - val_loss: 0.5797\n",
      "Epoch 363/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6155 - val_loss: 0.5796\n",
      "Epoch 364/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6155 - val_loss: 0.5796\n",
      "Epoch 365/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6155 - val_loss: 0.5796\n",
      "Epoch 366/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6155 - val_loss: 0.5796\n",
      "Epoch 367/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6155 - val_loss: 0.5796\n",
      "Epoch 368/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6155 - val_loss: 0.5796\n",
      "Epoch 369/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6155 - val_loss: 0.5796\n",
      "Epoch 370/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6155 - val_loss: 0.5796\n",
      "Epoch 371/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6154 - val_loss: 0.5796\n",
      "Epoch 372/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 0.5796\n",
      "Epoch 373/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 0.5796\n",
      "Epoch 374/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 0.5796\n",
      "Epoch 375/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 0.5796\n",
      "Epoch 376/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 0.5796\n",
      "Epoch 377/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 0.5796\n",
      "Epoch 378/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 0.5796\n",
      "Epoch 379/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 0.5796\n",
      "Epoch 380/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 0.5796\n",
      "Epoch 381/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 0.5796\n",
      "Epoch 382/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 0.5796\n",
      "Epoch 383/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6154 - val_loss: 0.5795\n",
      "Epoch 384/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 0.5796\n",
      "Epoch 385/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 0.5795\n",
      "Epoch 386/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 0.5795\n",
      "Epoch 387/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 0.5795\n",
      "Epoch 388/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 0.5795\n",
      "Epoch 389/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 0.5795\n",
      "Epoch 390/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 0.5795\n",
      "Epoch 391/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 0.5795\n",
      "Epoch 392/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 0.5795\n",
      "Epoch 393/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 0.5795\n",
      "Epoch 394/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 0.5795\n",
      "Epoch 395/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 0.5795\n",
      "Epoch 396/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 0.5795\n",
      "Epoch 397/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 0.5795\n",
      "Epoch 398/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 0.5795\n",
      "Epoch 399/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 0.5795\n",
      "Epoch 400/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 0.5795\n",
      "Epoch 401/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 0.5795\n",
      "Epoch 402/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 0.5795\n",
      "Epoch 403/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 0.5795\n",
      "Epoch 404/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 0.5794\n",
      "Epoch 405/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 0.5794\n",
      "Epoch 406/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 0.5794\n",
      "Epoch 407/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 0.5794\n",
      "Epoch 408/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 0.5794\n",
      "Epoch 409/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 0.5794\n",
      "Epoch 410/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 0.5794\n",
      "Epoch 411/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 0.5794\n",
      "Epoch 412/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 0.5794\n",
      "Epoch 413/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 0.5794\n",
      "Epoch 414/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 0.5794\n",
      "Epoch 415/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 0.5794\n",
      "Epoch 416/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 0.5794\n",
      "Epoch 417/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 0.5794\n",
      "Epoch 418/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 0.5794\n",
      "Epoch 419/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 0.5794\n",
      "Epoch 420/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 0.5794\n",
      "Epoch 421/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 0.5794\n",
      "Epoch 422/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 0.5794\n",
      "Epoch 423/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 0.5794\n",
      "Epoch 424/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 0.5794\n",
      "Epoch 425/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 0.5794\n",
      "Epoch 426/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 0.5794\n",
      "Epoch 427/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5793\n",
      "Epoch 428/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5793\n",
      "Epoch 429/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5794\n",
      "Epoch 430/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5794\n",
      "Epoch 431/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5793\n",
      "Epoch 432/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5793\n",
      "Epoch 433/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5793\n",
      "Epoch 434/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5793\n",
      "Epoch 435/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5793\n",
      "Epoch 436/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5793\n",
      "Epoch 437/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5793\n",
      "Epoch 438/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5793\n",
      "Epoch 439/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5793\n",
      "Epoch 440/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5793\n",
      "Epoch 441/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5793\n",
      "Epoch 442/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5793\n",
      "Epoch 443/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5793\n",
      "Epoch 444/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5793\n",
      "Epoch 445/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5793\n",
      "Epoch 446/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5794\n",
      "Epoch 447/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5793\n",
      "Epoch 448/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5793\n",
      "Epoch 449/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5793\n",
      "Epoch 450/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5793\n",
      "Epoch 451/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5793\n",
      "Epoch 452/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5793\n",
      "Epoch 453/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5793\n",
      "Epoch 454/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5793\n",
      "Epoch 455/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5793\n",
      "Epoch 456/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5793\n",
      "Epoch 457/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5793\n",
      "Epoch 458/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5793\n",
      "Epoch 459/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5792\n",
      "Epoch 460/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5793\n",
      "Epoch 461/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5793\n",
      "Epoch 462/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5793\n",
      "Epoch 463/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5792\n",
      "Epoch 464/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5792\n",
      "Epoch 465/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5792\n",
      "Epoch 466/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5792\n",
      "Epoch 467/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5793\n",
      "Epoch 468/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5792\n",
      "Epoch 469/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5792\n",
      "Epoch 470/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5792\n",
      "Epoch 471/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5792\n",
      "Epoch 472/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5793\n",
      "Epoch 473/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5792\n",
      "Epoch 474/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5792\n",
      "Epoch 475/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5792\n",
      "Epoch 476/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5792\n",
      "Epoch 477/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5792\n",
      "Epoch 478/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5792\n",
      "Epoch 479/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5792\n",
      "Epoch 480/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5793\n",
      "Epoch 481/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5792\n",
      "Epoch 482/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5792\n",
      "Epoch 483/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5792\n",
      "Epoch 484/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5792\n",
      "Epoch 485/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5792\n",
      "Epoch 486/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5792\n",
      "Epoch 487/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5792\n",
      "Epoch 488/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5792\n",
      "Epoch 489/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5792\n",
      "Epoch 490/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5792\n",
      "Epoch 491/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5792\n",
      "Epoch 492/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5792\n",
      "Epoch 493/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5792\n",
      "Epoch 494/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5792\n",
      "Epoch 495/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5792\n",
      "Epoch 496/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5792\n",
      "Epoch 497/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5792\n",
      "Epoch 498/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5792\n",
      "Epoch 499/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5792\n",
      "Epoch 500/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5792\n",
      "Epoch 501/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5792\n",
      "Epoch 502/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5792\n",
      "Epoch 503/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5792\n",
      "Epoch 504/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5792\n",
      "Epoch 505/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5791\n",
      "Epoch 506/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5791\n",
      "Epoch 507/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5792\n",
      "Epoch 508/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5791\n",
      "Epoch 509/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5792\n",
      "Epoch 510/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5792\n",
      "Epoch 511/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5792\n",
      "Epoch 512/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5791\n",
      "Epoch 513/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5792\n",
      "Epoch 514/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5792\n",
      "Epoch 515/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5792\n",
      "Epoch 516/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5791\n",
      "Epoch 517/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5791\n",
      "Epoch 518/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5791\n",
      "Epoch 519/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5791\n",
      "Epoch 520/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.5791\n",
      "Epoch 521/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 522/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 523/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 524/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5792\n",
      "Epoch 525/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 526/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 527/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 528/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 529/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 530/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 531/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 532/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 533/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 534/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 535/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 536/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 537/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 538/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 539/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 540/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 541/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 542/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 543/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 544/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 545/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 546/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 547/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 548/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 549/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 550/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 551/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 552/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 553/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 554/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 555/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 556/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 557/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 558/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 559/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 560/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 561/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 562/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 563/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 564/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 565/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 566/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 567/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 568/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 569/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 570/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 571/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 572/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 573/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 574/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 575/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 576/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 577/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 578/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 579/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 580/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 581/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 582/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 583/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 584/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 585/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 586/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 587/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 588/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 589/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5791\n",
      "Epoch 590/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 591/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 592/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 593/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 594/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 595/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 596/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 597/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 598/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 599/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 600/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 601/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 602/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 603/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 604/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 605/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 606/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 607/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 608/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 609/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 610/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 611/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 612/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 613/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 614/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 615/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 616/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 617/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 618/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 619/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 620/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 621/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 622/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 623/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 624/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 625/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 626/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 627/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 628/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 629/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 630/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 631/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 632/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 633/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 634/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 635/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 636/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 637/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 638/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 639/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 640/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 641/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 642/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 643/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 644/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 645/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 646/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 647/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 648/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 649/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 650/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 651/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 652/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 653/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 654/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 655/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 656/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 657/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 658/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 659/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 660/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 661/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 662/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 663/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 664/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 665/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 666/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 667/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 668/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 669/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 670/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 671/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 672/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 673/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 674/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 675/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 676/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 677/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 678/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 679/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 680/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 681/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 682/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 683/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 684/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 685/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 686/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5790\n",
      "Epoch 687/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 688/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 689/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 690/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 691/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 692/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 693/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 694/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 695/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 696/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 697/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 698/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 699/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 700/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 701/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 702/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 703/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 704/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 705/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 706/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 707/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 708/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 709/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 710/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 711/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 712/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 713/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 714/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 715/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 716/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 717/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 718/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 719/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 720/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 721/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 722/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 723/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 724/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 725/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 726/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 727/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5790\n",
      "Epoch 728/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 729/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5790\n",
      "Epoch 730/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 731/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 732/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 733/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 734/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 735/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 736/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 737/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.5789\n",
      "Epoch 738/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 739/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 740/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 741/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 742/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 743/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 744/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 745/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 746/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 747/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 748/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 749/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 750/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 751/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 752/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 753/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 754/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 755/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 756/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 757/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 758/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 759/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 760/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 761/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 762/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 763/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 764/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 765/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 766/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 767/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 768/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 769/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 770/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 771/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 772/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 773/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 774/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 775/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 776/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 777/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 778/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 779/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 780/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 781/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 782/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 783/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 784/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 785/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 786/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 787/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 788/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 789/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 790/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 791/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 792/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 793/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 794/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 795/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 796/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 797/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 798/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 799/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 800/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 801/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 802/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 803/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 804/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 805/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 806/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 807/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 808/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 809/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 810/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 811/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 812/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 813/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 814/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 815/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 816/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 817/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 818/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 819/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 820/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 821/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 822/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 823/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 824/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 825/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 826/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 827/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 828/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 829/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 830/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 831/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 832/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 833/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 834/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 835/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 836/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 837/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 838/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 839/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 840/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 841/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 842/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 843/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 844/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 845/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 846/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 847/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 848/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 849/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 850/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 851/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 852/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 853/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 854/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 855/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 856/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 857/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 858/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 859/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 860/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 861/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 862/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 863/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 864/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 865/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 866/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 867/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 868/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 869/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 870/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 871/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 872/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 873/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 874/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 875/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 876/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 877/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 878/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 879/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 880/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 881/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 882/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 883/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 884/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 885/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 886/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 887/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 888/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 889/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 890/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 891/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 892/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 893/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 894/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 895/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 896/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 897/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 898/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 899/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 900/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 901/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 902/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 903/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 904/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 905/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 906/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 907/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 908/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 909/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 910/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 911/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 912/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 913/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 914/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 915/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 916/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 917/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 918/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 919/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 920/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 921/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 922/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 923/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 924/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 925/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 926/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 927/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 928/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 929/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 930/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 931/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 932/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 933/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 934/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 935/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 936/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 937/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 938/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 939/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 940/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 941/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 942/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 943/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 944/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 945/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 946/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 947/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 948/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 949/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 950/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 951/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 952/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 953/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 954/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 955/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 956/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 957/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 958/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 959/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 960/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 961/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 962/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 963/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 964/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 965/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 966/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 967/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 968/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 969/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 970/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 971/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 972/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 973/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 974/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 975/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 976/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 977/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 978/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 979/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 980/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 981/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 982/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 983/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 984/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 985/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 986/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 987/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 988/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 989/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 990/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 991/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 992/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 993/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 994/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 995/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 996/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 997/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 998/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 999/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1000/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1001/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1002/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1003/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1004/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1005/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1006/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1007/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1008/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1009/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1010/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1011/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1012/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1013/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1014/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1015/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1016/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1017/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1018/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1019/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1020/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1021/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1022/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1023/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1024/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 1025/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1026/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1027/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1028/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1029/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1030/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1031/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1032/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1033/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1034/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1035/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1036/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1037/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1038/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1039/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1040/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1041/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1042/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1043/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1044/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1045/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1046/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1047/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1048/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1049/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1050/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1051/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1052/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1053/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1054/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1055/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1056/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1057/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1058/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1059/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1060/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1061/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1062/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1063/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1064/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1065/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1066/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1067/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1068/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1069/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1070/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1071/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1072/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1073/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1074/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1075/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1076/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1077/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1078/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1079/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1080/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1081/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1082/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1083/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1084/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1085/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1086/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1087/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1088/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1089/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1090/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1091/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1092/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1093/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1094/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1095/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1096/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1097/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1098/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1099/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1100/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1101/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1102/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1103/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1104/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1105/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1106/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1107/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1108/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1109/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1110/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1111/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1112/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1113/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1114/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1115/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1116/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1117/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1118/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1119/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1120/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1121/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1122/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1123/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1124/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1125/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1126/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1127/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1128/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1129/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1130/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1131/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1132/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1133/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1134/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1135/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1136/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1137/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1138/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1139/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1140/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1141/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1142/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1143/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1144/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1145/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1146/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1147/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1148/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1149/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1150/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1151/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1152/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1153/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1154/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1155/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1156/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1157/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1158/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1159/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1160/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1161/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1162/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1163/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1164/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1165/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1166/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1167/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1168/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1169/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1170/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1171/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1172/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1173/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1174/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 1175/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1176/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1177/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1178/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1179/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1180/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1181/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1182/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1183/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1184/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1185/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1186/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1187/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1188/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1189/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1190/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1191/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1192/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1193/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1194/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1195/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1196/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1197/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1198/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1199/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1200/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1201/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1202/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1203/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1204/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1205/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1206/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1207/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1208/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1209/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1210/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1211/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1212/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1213/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1214/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1215/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1216/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1217/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1218/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1219/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1220/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1221/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1222/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1223/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1224/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1225/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1226/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1227/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1228/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1229/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1230/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1231/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1232/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1233/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1234/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1235/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1236/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1237/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1238/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1239/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1240/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1241/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1242/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1243/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1244/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1245/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1246/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1247/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1248/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1249/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1250/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1251/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1252/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1253/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1254/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1255/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1256/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1257/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1258/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1259/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1260/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1261/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1262/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1263/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1264/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1265/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1266/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1267/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1268/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1269/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1270/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1271/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1272/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1273/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1274/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1275/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1276/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1277/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1278/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1279/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1280/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1281/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1282/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1283/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1284/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1285/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1286/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1287/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1288/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1289/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1290/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1291/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1292/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1293/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1294/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1295/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1296/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1297/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1298/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1299/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1300/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1301/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1302/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1303/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1304/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1305/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1306/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1307/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1308/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1309/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 1310/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1311/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1312/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1313/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1314/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1315/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1316/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1317/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1318/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1319/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1320/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1321/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1322/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1323/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1324/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1325/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1326/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1327/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1328/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 1329/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1330/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1331/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1332/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1333/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1334/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1335/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1336/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1337/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1338/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1339/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1340/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1341/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1342/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1343/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1344/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1345/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1346/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1347/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1348/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1349/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1350/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1351/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1352/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1353/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1354/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1355/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1356/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1357/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1358/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1359/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1360/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1361/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1362/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1363/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1364/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1365/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1366/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1367/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1368/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1369/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1370/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1371/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1372/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1373/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1374/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1375/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1376/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1377/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1378/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1379/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1380/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1381/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1382/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1383/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1384/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1385/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1386/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1387/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1388/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1389/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1390/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1391/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1392/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1393/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1394/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1395/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1396/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1397/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1398/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1399/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1400/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1401/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1402/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1403/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1404/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5789\n",
      "Epoch 1405/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1406/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1407/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1408/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1409/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1410/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1411/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1412/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1413/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1414/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1415/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1416/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1417/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1418/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1419/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1420/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1421/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1422/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1423/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1424/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1425/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1426/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1427/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1428/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1429/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1430/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1431/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1432/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1433/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1434/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1435/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1436/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1437/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1438/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1439/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1440/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1441/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1442/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1443/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1444/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1445/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1446/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1447/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1448/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1449/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1450/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1451/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1452/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1453/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1454/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1455/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1456/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1457/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1458/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1459/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1460/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1461/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1462/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1463/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1464/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1465/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1466/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1467/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1468/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1469/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1470/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1471/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1472/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1473/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1474/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1475/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1476/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1477/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1478/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1479/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5787\n",
      "Epoch 1480/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5787\n",
      "Epoch 1481/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1482/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1483/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1484/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1485/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1486/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1487/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1488/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1489/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1490/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1491/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1492/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1493/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1494/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1495/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1496/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1497/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1498/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1499/1500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "Epoch 1500/1500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.5788\n",
      "54/54 [==============================] - 0s 1ms/step\n",
      "14/14 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Define the autoencoder architecture\n",
    "input_dim = X_train_scaled.shape[1]\n",
    "encoding_dim = 64\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "encoder = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "decoder = Dense(input_dim, activation='sigmoid')(encoder)\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
    "autoencoder.compile(optimizer='rmsprop', loss='mse')\n",
    "\n",
    "# Train the autoencoder\n",
    "autoencoder.fit(X_train_scaled, X_train_scaled, epochs=1500, batch_size=40,\n",
    "                validation_data=(X_test_scaled, X_test_scaled))\n",
    "\n",
    "# Extract the encoded representations\n",
    "encoder = Model(inputs=input_layer, outputs=encoder)\n",
    "X_train_encoded = encoder.predict(X_train_scaled)\n",
    "X_test_encoded = encoder.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "968e24a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8457943925233645\n",
      "Precision:  0.7153681544239672\n",
      "Recall:  0.8457943925233645\n",
      "F1-score:  0.7751330888441973\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       362\n",
      "           1       0.00      0.00      0.00        66\n",
      "\n",
      "    accuracy                           0.85       428\n",
      "   macro avg       0.42      0.50      0.46       428\n",
      "weighted avg       0.72      0.85      0.78       428\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Train a classifier\n",
    "from sklearn.svm import SVC\n",
    "clf = SVC()\n",
    "clf.fit(X_train_encoded, y_train)\n",
    "\n",
    "# Evaluate the performance\n",
    "y_pred = clf.predict(X_test_encoded)\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision: \", precision_score(y_test, y_pred, average='weighted'))\n",
    "print(\"Recall: \", recall_score(y_test, y_pred, average='weighted'))\n",
    "print(\"F1-score: \", f1_score(y_test, y_pred, average='weighted'))\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import plot_confusion_matrix, classification_report\n",
    "import warnings\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "859c689c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 84.58%\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "model = XGBClassifier()\n",
    "history = model.fit(X_train_encoded, y_train)\n",
    "#print(model)\n",
    "\n",
    "y_pred = model.predict(X_test_encoded)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fe7a26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.99      0.92       362\n",
      "           1       0.50      0.05      0.08        66\n",
      "\n",
      "    accuracy                           0.85       428\n",
      "   macro avg       0.68      0.52      0.50       428\n",
      "weighted avg       0.80      0.85      0.79       428\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import plot_confusion_matrix, classification_report\n",
    "import warnings\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a25a5f",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70ed4e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9405b9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,0:39]\n",
    "y = df.iloc[:,39]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca662d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the accent labels to integers\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Convert the accent labels to one-hot vectors\n",
    "num_classes = len(np.unique(y_train_encoded))\n",
    "y_train_onehot = to_categorical(y_train_encoded, num_classes)\n",
    "y_test_onehot = to_categorical(y_test_encoded, num_classes)\n",
    "\n",
    "# Reshape the input features for the CNN\n",
    "n_timesteps, n_features = X_train.shape[1], 1\n",
    "X_train_reshaped = X_train.values.reshape((X_train.shape[0], n_timesteps, n_features))\n",
    "X_test_reshaped = X_test.values.reshape((X_test.shape[0], n_timesteps, n_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16bed7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN architecture\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(n_timesteps, n_features)))\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99978040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "38/38 [==============================] - 1s 11ms/step - loss: 1.0579 - accuracy: 0.7553 - val_loss: 0.4560 - val_accuracy: 0.8287\n",
      "Epoch 2/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.5245 - accuracy: 0.7948 - val_loss: 0.4726 - val_accuracy: 0.8302\n",
      "Epoch 3/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4959 - accuracy: 0.8061 - val_loss: 0.4553 - val_accuracy: 0.8287\n",
      "Epoch 4/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.4790 - accuracy: 0.8195 - val_loss: 0.4431 - val_accuracy: 0.8271\n",
      "Epoch 5/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4675 - accuracy: 0.8195 - val_loss: 0.4469 - val_accuracy: 0.8287\n",
      "Epoch 6/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4672 - accuracy: 0.8215 - val_loss: 0.4719 - val_accuracy: 0.8287\n",
      "Epoch 7/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4577 - accuracy: 0.8215 - val_loss: 0.4411 - val_accuracy: 0.8287\n",
      "Epoch 8/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4644 - accuracy: 0.8148 - val_loss: 0.4398 - val_accuracy: 0.8287\n",
      "Epoch 9/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4633 - accuracy: 0.8242 - val_loss: 0.4675 - val_accuracy: 0.8318\n",
      "Epoch 10/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.4612 - accuracy: 0.8222 - val_loss: 0.4515 - val_accuracy: 0.8287\n",
      "Epoch 11/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4568 - accuracy: 0.8229 - val_loss: 0.4424 - val_accuracy: 0.8287\n",
      "Epoch 12/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4517 - accuracy: 0.8262 - val_loss: 0.4536 - val_accuracy: 0.8287\n",
      "Epoch 13/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4475 - accuracy: 0.8262 - val_loss: 0.4468 - val_accuracy: 0.8287\n",
      "Epoch 14/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4537 - accuracy: 0.8229 - val_loss: 0.4484 - val_accuracy: 0.8287\n",
      "Epoch 15/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4617 - accuracy: 0.8242 - val_loss: 0.4742 - val_accuracy: 0.8287\n",
      "Epoch 16/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4435 - accuracy: 0.8269 - val_loss: 0.4512 - val_accuracy: 0.8287\n",
      "Epoch 17/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4506 - accuracy: 0.8229 - val_loss: 0.4784 - val_accuracy: 0.8287\n",
      "Epoch 18/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.4552 - accuracy: 0.8249 - val_loss: 0.4722 - val_accuracy: 0.8287\n",
      "Epoch 19/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4556 - accuracy: 0.8242 - val_loss: 0.4869 - val_accuracy: 0.8287\n",
      "Epoch 20/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4419 - accuracy: 0.8229 - val_loss: 0.4454 - val_accuracy: 0.8287\n",
      "Epoch 21/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4502 - accuracy: 0.8235 - val_loss: 0.4545 - val_accuracy: 0.8333\n",
      "Epoch 22/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4497 - accuracy: 0.8222 - val_loss: 0.4656 - val_accuracy: 0.8302\n",
      "Epoch 23/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4456 - accuracy: 0.8229 - val_loss: 0.4453 - val_accuracy: 0.8287\n",
      "Epoch 24/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4505 - accuracy: 0.8235 - val_loss: 0.4491 - val_accuracy: 0.8287\n",
      "Epoch 25/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4440 - accuracy: 0.8269 - val_loss: 0.4706 - val_accuracy: 0.8287\n",
      "Epoch 26/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.4330 - accuracy: 0.8275 - val_loss: 0.4515 - val_accuracy: 0.8302\n",
      "Epoch 27/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.4427 - accuracy: 0.8275 - val_loss: 0.4564 - val_accuracy: 0.8287\n",
      "Epoch 28/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4434 - accuracy: 0.8215 - val_loss: 0.4739 - val_accuracy: 0.8287\n",
      "Epoch 29/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.4472 - accuracy: 0.8229 - val_loss: 0.4486 - val_accuracy: 0.8287\n",
      "Epoch 30/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4412 - accuracy: 0.8255 - val_loss: 0.4617 - val_accuracy: 0.8271\n",
      "Epoch 31/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4377 - accuracy: 0.8195 - val_loss: 0.4473 - val_accuracy: 0.8287\n",
      "Epoch 32/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4354 - accuracy: 0.8275 - val_loss: 0.4455 - val_accuracy: 0.8287\n",
      "Epoch 33/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4328 - accuracy: 0.8235 - val_loss: 0.4835 - val_accuracy: 0.8287\n",
      "Epoch 34/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4360 - accuracy: 0.8269 - val_loss: 0.4542 - val_accuracy: 0.8302\n",
      "Epoch 35/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4414 - accuracy: 0.8255 - val_loss: 0.4521 - val_accuracy: 0.8318\n",
      "Epoch 36/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4406 - accuracy: 0.8282 - val_loss: 0.4449 - val_accuracy: 0.8302\n",
      "Epoch 37/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.4360 - accuracy: 0.8209 - val_loss: 0.4763 - val_accuracy: 0.8287\n",
      "Epoch 38/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4309 - accuracy: 0.8322 - val_loss: 0.4479 - val_accuracy: 0.8287\n",
      "Epoch 39/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4321 - accuracy: 0.8249 - val_loss: 0.4604 - val_accuracy: 0.8287\n",
      "Epoch 40/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4329 - accuracy: 0.8309 - val_loss: 0.4555 - val_accuracy: 0.8287\n",
      "Epoch 41/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4275 - accuracy: 0.8302 - val_loss: 0.4635 - val_accuracy: 0.8255\n",
      "Epoch 42/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.4206 - accuracy: 0.8309 - val_loss: 0.4436 - val_accuracy: 0.8318\n",
      "Epoch 43/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.4323 - accuracy: 0.8242 - val_loss: 0.4675 - val_accuracy: 0.8224\n",
      "Epoch 44/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4313 - accuracy: 0.8269 - val_loss: 0.4578 - val_accuracy: 0.8287\n",
      "Epoch 45/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4247 - accuracy: 0.8235 - val_loss: 0.4643 - val_accuracy: 0.8255\n",
      "Epoch 46/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4249 - accuracy: 0.8289 - val_loss: 0.4691 - val_accuracy: 0.8287\n",
      "Epoch 47/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4258 - accuracy: 0.8329 - val_loss: 0.4527 - val_accuracy: 0.8302\n",
      "Epoch 48/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4256 - accuracy: 0.8309 - val_loss: 0.4490 - val_accuracy: 0.8287\n",
      "Epoch 49/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4254 - accuracy: 0.8295 - val_loss: 0.4567 - val_accuracy: 0.8209\n",
      "Epoch 50/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4266 - accuracy: 0.8302 - val_loss: 0.4689 - val_accuracy: 0.8287\n",
      "Epoch 51/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4287 - accuracy: 0.8255 - val_loss: 0.4528 - val_accuracy: 0.8287\n",
      "Epoch 52/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4280 - accuracy: 0.8356 - val_loss: 0.4503 - val_accuracy: 0.8271\n",
      "Epoch 53/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4232 - accuracy: 0.8382 - val_loss: 0.4514 - val_accuracy: 0.8302\n",
      "Epoch 54/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4241 - accuracy: 0.8255 - val_loss: 0.4496 - val_accuracy: 0.8287\n",
      "Epoch 55/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4222 - accuracy: 0.8329 - val_loss: 0.4595 - val_accuracy: 0.8318\n",
      "Epoch 56/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4110 - accuracy: 0.8349 - val_loss: 0.4705 - val_accuracy: 0.8271\n",
      "Epoch 57/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4165 - accuracy: 0.8349 - val_loss: 0.4510 - val_accuracy: 0.8287\n",
      "Epoch 58/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4176 - accuracy: 0.8322 - val_loss: 0.4532 - val_accuracy: 0.8287\n",
      "Epoch 59/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4148 - accuracy: 0.8422 - val_loss: 0.4533 - val_accuracy: 0.8287\n",
      "Epoch 60/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4154 - accuracy: 0.8282 - val_loss: 0.4492 - val_accuracy: 0.8302\n",
      "Epoch 61/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4096 - accuracy: 0.8342 - val_loss: 0.4533 - val_accuracy: 0.8302\n",
      "Epoch 62/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4070 - accuracy: 0.8369 - val_loss: 0.4500 - val_accuracy: 0.8287\n",
      "Epoch 63/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.4113 - accuracy: 0.8316 - val_loss: 0.4615 - val_accuracy: 0.8287\n",
      "Epoch 64/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.4105 - accuracy: 0.8289 - val_loss: 0.4515 - val_accuracy: 0.8287\n",
      "Epoch 65/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.4078 - accuracy: 0.8309 - val_loss: 0.4585 - val_accuracy: 0.8287\n",
      "Epoch 66/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4097 - accuracy: 0.8356 - val_loss: 0.4605 - val_accuracy: 0.8318\n",
      "Epoch 67/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4119 - accuracy: 0.8336 - val_loss: 0.4642 - val_accuracy: 0.8240\n",
      "Epoch 68/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.4040 - accuracy: 0.8302 - val_loss: 0.4536 - val_accuracy: 0.8302\n",
      "Epoch 69/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.4026 - accuracy: 0.8369 - val_loss: 0.4496 - val_accuracy: 0.8271\n",
      "Epoch 70/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.4022 - accuracy: 0.8356 - val_loss: 0.4548 - val_accuracy: 0.8287\n",
      "Epoch 71/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4037 - accuracy: 0.8382 - val_loss: 0.4602 - val_accuracy: 0.8255\n",
      "Epoch 72/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3975 - accuracy: 0.8336 - val_loss: 0.4635 - val_accuracy: 0.8271\n",
      "Epoch 73/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4029 - accuracy: 0.8362 - val_loss: 0.4604 - val_accuracy: 0.8224\n",
      "Epoch 74/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3990 - accuracy: 0.8409 - val_loss: 0.4499 - val_accuracy: 0.8318\n",
      "Epoch 75/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3954 - accuracy: 0.8356 - val_loss: 0.4601 - val_accuracy: 0.8224\n",
      "Epoch 76/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.4003 - accuracy: 0.8289 - val_loss: 0.4697 - val_accuracy: 0.8255\n",
      "Epoch 77/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3980 - accuracy: 0.8409 - val_loss: 0.4613 - val_accuracy: 0.8333\n",
      "Epoch 78/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3893 - accuracy: 0.8443 - val_loss: 0.4642 - val_accuracy: 0.8302\n",
      "Epoch 79/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3939 - accuracy: 0.8396 - val_loss: 0.4551 - val_accuracy: 0.8287\n",
      "Epoch 80/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3930 - accuracy: 0.8369 - val_loss: 0.4665 - val_accuracy: 0.8240\n",
      "Epoch 81/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3962 - accuracy: 0.8422 - val_loss: 0.4591 - val_accuracy: 0.8318\n",
      "Epoch 82/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3842 - accuracy: 0.8402 - val_loss: 0.4608 - val_accuracy: 0.8287\n",
      "Epoch 83/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3927 - accuracy: 0.8349 - val_loss: 0.4808 - val_accuracy: 0.8302\n",
      "Epoch 84/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3967 - accuracy: 0.8336 - val_loss: 0.4687 - val_accuracy: 0.8271\n",
      "Epoch 85/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3924 - accuracy: 0.8369 - val_loss: 0.4678 - val_accuracy: 0.8287\n",
      "Epoch 86/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3844 - accuracy: 0.8336 - val_loss: 0.4548 - val_accuracy: 0.8318\n",
      "Epoch 87/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3801 - accuracy: 0.8463 - val_loss: 0.4613 - val_accuracy: 0.8224\n",
      "Epoch 88/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3802 - accuracy: 0.8416 - val_loss: 0.4689 - val_accuracy: 0.8240\n",
      "Epoch 89/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3779 - accuracy: 0.8483 - val_loss: 0.4733 - val_accuracy: 0.8209\n",
      "Epoch 90/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3706 - accuracy: 0.8402 - val_loss: 0.4623 - val_accuracy: 0.8271\n",
      "Epoch 91/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3711 - accuracy: 0.8529 - val_loss: 0.4817 - val_accuracy: 0.8287\n",
      "Epoch 92/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3725 - accuracy: 0.8396 - val_loss: 0.5102 - val_accuracy: 0.8209\n",
      "Epoch 93/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3827 - accuracy: 0.8416 - val_loss: 0.4576 - val_accuracy: 0.8271\n",
      "Epoch 94/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3927 - accuracy: 0.8382 - val_loss: 0.4613 - val_accuracy: 0.8178\n",
      "Epoch 95/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3778 - accuracy: 0.8409 - val_loss: 0.4612 - val_accuracy: 0.8287\n",
      "Epoch 96/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3781 - accuracy: 0.8483 - val_loss: 0.4638 - val_accuracy: 0.8255\n",
      "Epoch 97/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3723 - accuracy: 0.8523 - val_loss: 0.4612 - val_accuracy: 0.8240\n",
      "Epoch 98/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3656 - accuracy: 0.8463 - val_loss: 0.4743 - val_accuracy: 0.8178\n",
      "Epoch 99/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3691 - accuracy: 0.8476 - val_loss: 0.4571 - val_accuracy: 0.8255\n",
      "Epoch 100/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3625 - accuracy: 0.8436 - val_loss: 0.4755 - val_accuracy: 0.8240\n",
      "Epoch 101/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3759 - accuracy: 0.8549 - val_loss: 0.4704 - val_accuracy: 0.8318\n",
      "Epoch 102/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3558 - accuracy: 0.8496 - val_loss: 0.4558 - val_accuracy: 0.8255\n",
      "Epoch 103/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3641 - accuracy: 0.8509 - val_loss: 0.4696 - val_accuracy: 0.8287\n",
      "Epoch 104/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3595 - accuracy: 0.8536 - val_loss: 0.4571 - val_accuracy: 0.8240\n",
      "Epoch 105/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3565 - accuracy: 0.8549 - val_loss: 0.4859 - val_accuracy: 0.8271\n",
      "Epoch 106/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3635 - accuracy: 0.8549 - val_loss: 0.4676 - val_accuracy: 0.8271\n",
      "Epoch 107/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3573 - accuracy: 0.8456 - val_loss: 0.4933 - val_accuracy: 0.8318\n",
      "Epoch 108/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3452 - accuracy: 0.8489 - val_loss: 0.5147 - val_accuracy: 0.8240\n",
      "Epoch 109/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3659 - accuracy: 0.8489 - val_loss: 0.4685 - val_accuracy: 0.8209\n",
      "Epoch 110/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3563 - accuracy: 0.8529 - val_loss: 0.4810 - val_accuracy: 0.8287\n",
      "Epoch 111/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3477 - accuracy: 0.8489 - val_loss: 0.4880 - val_accuracy: 0.8255\n",
      "Epoch 112/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3625 - accuracy: 0.8489 - val_loss: 0.4891 - val_accuracy: 0.8209\n",
      "Epoch 113/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3500 - accuracy: 0.8523 - val_loss: 0.4600 - val_accuracy: 0.8193\n",
      "Epoch 114/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3432 - accuracy: 0.8616 - val_loss: 0.4875 - val_accuracy: 0.8255\n",
      "Epoch 115/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3458 - accuracy: 0.8469 - val_loss: 0.4851 - val_accuracy: 0.8255\n",
      "Epoch 116/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3431 - accuracy: 0.8536 - val_loss: 0.5031 - val_accuracy: 0.8209\n",
      "Epoch 117/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3269 - accuracy: 0.8556 - val_loss: 0.4871 - val_accuracy: 0.8271\n",
      "Epoch 118/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3460 - accuracy: 0.8523 - val_loss: 0.4876 - val_accuracy: 0.8271\n",
      "Epoch 119/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3410 - accuracy: 0.8536 - val_loss: 0.4943 - val_accuracy: 0.8224\n",
      "Epoch 120/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3511 - accuracy: 0.8549 - val_loss: 0.4854 - val_accuracy: 0.8255\n",
      "Epoch 121/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3335 - accuracy: 0.8543 - val_loss: 0.5104 - val_accuracy: 0.8240\n",
      "Epoch 122/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3319 - accuracy: 0.8516 - val_loss: 0.5024 - val_accuracy: 0.8209\n",
      "Epoch 123/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3374 - accuracy: 0.8570 - val_loss: 0.4990 - val_accuracy: 0.8224\n",
      "Epoch 124/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3324 - accuracy: 0.8576 - val_loss: 0.5134 - val_accuracy: 0.8178\n",
      "Epoch 125/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3254 - accuracy: 0.8563 - val_loss: 0.5143 - val_accuracy: 0.8084\n",
      "Epoch 126/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3237 - accuracy: 0.8623 - val_loss: 0.4988 - val_accuracy: 0.8240\n",
      "Epoch 127/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3251 - accuracy: 0.8623 - val_loss: 0.4973 - val_accuracy: 0.8255\n",
      "Epoch 128/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3332 - accuracy: 0.8576 - val_loss: 0.5244 - val_accuracy: 0.8255\n",
      "Epoch 129/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3274 - accuracy: 0.8616 - val_loss: 0.5413 - val_accuracy: 0.8240\n",
      "Epoch 130/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3170 - accuracy: 0.8663 - val_loss: 0.5141 - val_accuracy: 0.8178\n",
      "Epoch 131/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3179 - accuracy: 0.8610 - val_loss: 0.5147 - val_accuracy: 0.8255\n",
      "Epoch 132/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3237 - accuracy: 0.8656 - val_loss: 0.5267 - val_accuracy: 0.8209\n",
      "Epoch 133/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3160 - accuracy: 0.8676 - val_loss: 0.5466 - val_accuracy: 0.8209\n",
      "Epoch 134/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3200 - accuracy: 0.8676 - val_loss: 0.5115 - val_accuracy: 0.8146\n",
      "Epoch 135/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3094 - accuracy: 0.8710 - val_loss: 0.5256 - val_accuracy: 0.8287\n",
      "Epoch 136/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3050 - accuracy: 0.8703 - val_loss: 0.5456 - val_accuracy: 0.8162\n",
      "Epoch 137/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3180 - accuracy: 0.8643 - val_loss: 0.5174 - val_accuracy: 0.8209\n",
      "Epoch 138/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3025 - accuracy: 0.8670 - val_loss: 0.5421 - val_accuracy: 0.8209\n",
      "Epoch 139/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3022 - accuracy: 0.8703 - val_loss: 0.5406 - val_accuracy: 0.8115\n",
      "Epoch 140/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3035 - accuracy: 0.8663 - val_loss: 0.5274 - val_accuracy: 0.7913\n",
      "Epoch 141/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3022 - accuracy: 0.8610 - val_loss: 0.5522 - val_accuracy: 0.8053\n",
      "Epoch 142/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3040 - accuracy: 0.8670 - val_loss: 0.5685 - val_accuracy: 0.8209\n",
      "Epoch 143/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2923 - accuracy: 0.8783 - val_loss: 0.5641 - val_accuracy: 0.8100\n",
      "Epoch 144/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3030 - accuracy: 0.8743 - val_loss: 0.5421 - val_accuracy: 0.8146\n",
      "Epoch 145/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2921 - accuracy: 0.8757 - val_loss: 0.5618 - val_accuracy: 0.7819\n",
      "Epoch 146/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2999 - accuracy: 0.8803 - val_loss: 0.5695 - val_accuracy: 0.8084\n",
      "Epoch 147/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2996 - accuracy: 0.8663 - val_loss: 0.5457 - val_accuracy: 0.8178\n",
      "Epoch 148/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2812 - accuracy: 0.8864 - val_loss: 0.5545 - val_accuracy: 0.8115\n",
      "Epoch 149/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3030 - accuracy: 0.8770 - val_loss: 0.5510 - val_accuracy: 0.8084\n",
      "Epoch 150/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2961 - accuracy: 0.8777 - val_loss: 0.5447 - val_accuracy: 0.8209\n",
      "Epoch 151/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2837 - accuracy: 0.8817 - val_loss: 0.5589 - val_accuracy: 0.8053\n",
      "Epoch 152/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2862 - accuracy: 0.8797 - val_loss: 0.5583 - val_accuracy: 0.7975\n",
      "Epoch 153/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2863 - accuracy: 0.8757 - val_loss: 0.5953 - val_accuracy: 0.7928\n",
      "Epoch 154/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2665 - accuracy: 0.8890 - val_loss: 0.5507 - val_accuracy: 0.8240\n",
      "Epoch 155/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2688 - accuracy: 0.8884 - val_loss: 0.5709 - val_accuracy: 0.8146\n",
      "Epoch 156/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2727 - accuracy: 0.8830 - val_loss: 0.5766 - val_accuracy: 0.8115\n",
      "Epoch 157/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2881 - accuracy: 0.8904 - val_loss: 0.5639 - val_accuracy: 0.8069\n",
      "Epoch 158/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2652 - accuracy: 0.8910 - val_loss: 0.5813 - val_accuracy: 0.8162\n",
      "Epoch 159/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2756 - accuracy: 0.8857 - val_loss: 0.5871 - val_accuracy: 0.8006\n",
      "Epoch 160/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2694 - accuracy: 0.8870 - val_loss: 0.5980 - val_accuracy: 0.8240\n",
      "Epoch 161/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2713 - accuracy: 0.8817 - val_loss: 0.5868 - val_accuracy: 0.8162\n",
      "Epoch 162/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2713 - accuracy: 0.8844 - val_loss: 0.6307 - val_accuracy: 0.8178\n",
      "Epoch 163/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2492 - accuracy: 0.8904 - val_loss: 0.6393 - val_accuracy: 0.8209\n",
      "Epoch 164/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2587 - accuracy: 0.8930 - val_loss: 0.6206 - val_accuracy: 0.8162\n",
      "Epoch 165/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2670 - accuracy: 0.8877 - val_loss: 0.6243 - val_accuracy: 0.8178\n",
      "Epoch 166/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2768 - accuracy: 0.8917 - val_loss: 0.5969 - val_accuracy: 0.7913\n",
      "Epoch 167/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2541 - accuracy: 0.9037 - val_loss: 0.6196 - val_accuracy: 0.7991\n",
      "Epoch 168/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2605 - accuracy: 0.8897 - val_loss: 0.5943 - val_accuracy: 0.7882\n",
      "Epoch 169/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2439 - accuracy: 0.9031 - val_loss: 0.6238 - val_accuracy: 0.7773\n",
      "Epoch 170/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2567 - accuracy: 0.9024 - val_loss: 0.6042 - val_accuracy: 0.8084\n",
      "Epoch 171/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2512 - accuracy: 0.8957 - val_loss: 0.6636 - val_accuracy: 0.8131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2562 - accuracy: 0.8904 - val_loss: 0.6030 - val_accuracy: 0.7897\n",
      "Epoch 173/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2579 - accuracy: 0.8897 - val_loss: 0.6261 - val_accuracy: 0.8084\n",
      "Epoch 174/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2499 - accuracy: 0.9017 - val_loss: 0.5908 - val_accuracy: 0.8209\n",
      "Epoch 175/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2446 - accuracy: 0.9004 - val_loss: 0.6739 - val_accuracy: 0.8193\n",
      "Epoch 176/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2477 - accuracy: 0.9004 - val_loss: 0.6310 - val_accuracy: 0.8069\n",
      "Epoch 177/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2461 - accuracy: 0.9078 - val_loss: 0.6010 - val_accuracy: 0.8053\n",
      "Epoch 178/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2585 - accuracy: 0.8951 - val_loss: 0.6283 - val_accuracy: 0.8069\n",
      "Epoch 179/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2362 - accuracy: 0.9078 - val_loss: 0.6532 - val_accuracy: 0.8131\n",
      "Epoch 180/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2566 - accuracy: 0.9031 - val_loss: 0.6404 - val_accuracy: 0.8100\n",
      "Epoch 181/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2349 - accuracy: 0.9024 - val_loss: 0.6755 - val_accuracy: 0.8162\n",
      "Epoch 182/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2323 - accuracy: 0.8964 - val_loss: 0.7633 - val_accuracy: 0.8287\n",
      "Epoch 183/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2378 - accuracy: 0.9011 - val_loss: 0.6381 - val_accuracy: 0.8053\n",
      "Epoch 184/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2338 - accuracy: 0.9031 - val_loss: 0.6857 - val_accuracy: 0.7632\n",
      "Epoch 185/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2388 - accuracy: 0.9057 - val_loss: 0.6310 - val_accuracy: 0.7866\n",
      "Epoch 186/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2154 - accuracy: 0.9151 - val_loss: 0.6842 - val_accuracy: 0.8069\n",
      "Epoch 187/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2193 - accuracy: 0.9078 - val_loss: 0.6940 - val_accuracy: 0.8022\n",
      "Epoch 188/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2356 - accuracy: 0.8930 - val_loss: 0.7207 - val_accuracy: 0.8162\n",
      "Epoch 189/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2315 - accuracy: 0.9044 - val_loss: 0.6770 - val_accuracy: 0.7897\n",
      "Epoch 190/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2218 - accuracy: 0.9064 - val_loss: 0.6985 - val_accuracy: 0.7850\n",
      "Epoch 191/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2335 - accuracy: 0.9078 - val_loss: 0.6577 - val_accuracy: 0.7773\n",
      "Epoch 192/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2153 - accuracy: 0.9057 - val_loss: 0.7343 - val_accuracy: 0.8084\n",
      "Epoch 193/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2294 - accuracy: 0.8964 - val_loss: 0.6737 - val_accuracy: 0.8209\n",
      "Epoch 194/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2249 - accuracy: 0.9031 - val_loss: 0.6603 - val_accuracy: 0.8115\n",
      "Epoch 195/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2069 - accuracy: 0.9057 - val_loss: 0.6678 - val_accuracy: 0.7819\n",
      "Epoch 196/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2220 - accuracy: 0.9144 - val_loss: 0.6843 - val_accuracy: 0.7928\n",
      "Epoch 197/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2193 - accuracy: 0.9024 - val_loss: 0.6518 - val_accuracy: 0.7991\n",
      "Epoch 198/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2230 - accuracy: 0.9071 - val_loss: 0.6953 - val_accuracy: 0.8069\n",
      "Epoch 199/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2088 - accuracy: 0.9138 - val_loss: 0.6967 - val_accuracy: 0.8069\n",
      "Epoch 200/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2076 - accuracy: 0.9178 - val_loss: 0.7184 - val_accuracy: 0.7866\n",
      "Epoch 201/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2210 - accuracy: 0.9205 - val_loss: 0.6755 - val_accuracy: 0.8084\n",
      "Epoch 202/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1924 - accuracy: 0.9131 - val_loss: 0.6971 - val_accuracy: 0.8006\n",
      "Epoch 203/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2204 - accuracy: 0.9071 - val_loss: 0.7840 - val_accuracy: 0.8193\n",
      "Epoch 204/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2324 - accuracy: 0.9078 - val_loss: 0.7081 - val_accuracy: 0.8115\n",
      "Epoch 205/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2083 - accuracy: 0.9098 - val_loss: 0.7661 - val_accuracy: 0.8069\n",
      "Epoch 206/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2108 - accuracy: 0.9104 - val_loss: 0.7995 - val_accuracy: 0.7913\n",
      "Epoch 207/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2193 - accuracy: 0.9138 - val_loss: 0.6992 - val_accuracy: 0.7788\n",
      "Epoch 208/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1969 - accuracy: 0.9205 - val_loss: 0.7393 - val_accuracy: 0.7928\n",
      "Epoch 209/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2102 - accuracy: 0.9164 - val_loss: 0.7670 - val_accuracy: 0.8006\n",
      "Epoch 210/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1850 - accuracy: 0.9278 - val_loss: 0.7309 - val_accuracy: 0.8053\n",
      "Epoch 211/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1967 - accuracy: 0.9191 - val_loss: 0.7138 - val_accuracy: 0.7508\n",
      "Epoch 212/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1855 - accuracy: 0.9178 - val_loss: 0.7843 - val_accuracy: 0.7695\n",
      "Epoch 213/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2075 - accuracy: 0.9191 - val_loss: 0.7125 - val_accuracy: 0.7975\n",
      "Epoch 214/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1951 - accuracy: 0.9231 - val_loss: 0.7302 - val_accuracy: 0.7928\n",
      "Epoch 215/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2058 - accuracy: 0.9144 - val_loss: 0.7095 - val_accuracy: 0.7695\n",
      "Epoch 216/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1858 - accuracy: 0.9365 - val_loss: 0.7670 - val_accuracy: 0.7897\n",
      "Epoch 217/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1891 - accuracy: 0.9178 - val_loss: 0.7930 - val_accuracy: 0.8053\n",
      "Epoch 218/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1953 - accuracy: 0.9171 - val_loss: 0.7859 - val_accuracy: 0.7726\n",
      "Epoch 219/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1955 - accuracy: 0.9184 - val_loss: 0.7422 - val_accuracy: 0.7555\n",
      "Epoch 220/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1879 - accuracy: 0.9171 - val_loss: 0.7715 - val_accuracy: 0.7601\n",
      "Epoch 221/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1920 - accuracy: 0.9231 - val_loss: 0.8026 - val_accuracy: 0.7695\n",
      "Epoch 222/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1849 - accuracy: 0.9265 - val_loss: 0.7838 - val_accuracy: 0.7897\n",
      "Epoch 223/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2033 - accuracy: 0.9231 - val_loss: 0.8197 - val_accuracy: 0.7477\n",
      "Epoch 224/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1831 - accuracy: 0.9178 - val_loss: 0.7756 - val_accuracy: 0.7960\n",
      "Epoch 225/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2006 - accuracy: 0.9191 - val_loss: 0.8394 - val_accuracy: 0.7975\n",
      "Epoch 226/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1824 - accuracy: 0.9231 - val_loss: 0.7590 - val_accuracy: 0.7788\n",
      "Epoch 227/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1867 - accuracy: 0.9311 - val_loss: 0.7736 - val_accuracy: 0.7227\n",
      "Epoch 228/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1982 - accuracy: 0.9265 - val_loss: 0.8258 - val_accuracy: 0.7773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1866 - accuracy: 0.9198 - val_loss: 0.8269 - val_accuracy: 0.7804\n",
      "Epoch 230/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1813 - accuracy: 0.9285 - val_loss: 0.7889 - val_accuracy: 0.7477\n",
      "Epoch 231/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1978 - accuracy: 0.9211 - val_loss: 0.7966 - val_accuracy: 0.7866\n",
      "Epoch 232/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1706 - accuracy: 0.9245 - val_loss: 0.7661 - val_accuracy: 0.7897\n",
      "Epoch 233/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1808 - accuracy: 0.9184 - val_loss: 0.8523 - val_accuracy: 0.7804\n",
      "Epoch 234/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1947 - accuracy: 0.9298 - val_loss: 0.8996 - val_accuracy: 0.7695\n",
      "Epoch 235/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1759 - accuracy: 0.9238 - val_loss: 0.8819 - val_accuracy: 0.8069\n",
      "Epoch 236/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1675 - accuracy: 0.9352 - val_loss: 0.8408 - val_accuracy: 0.8178\n",
      "Epoch 237/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1620 - accuracy: 0.9291 - val_loss: 0.8444 - val_accuracy: 0.8115\n",
      "Epoch 238/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1970 - accuracy: 0.9251 - val_loss: 0.8108 - val_accuracy: 0.7897\n",
      "Epoch 239/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1659 - accuracy: 0.9385 - val_loss: 0.8138 - val_accuracy: 0.7586\n",
      "Epoch 240/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1755 - accuracy: 0.9305 - val_loss: 0.8550 - val_accuracy: 0.7664\n",
      "Epoch 241/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1492 - accuracy: 0.9405 - val_loss: 0.8702 - val_accuracy: 0.7975\n",
      "Epoch 242/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1675 - accuracy: 0.9352 - val_loss: 0.9428 - val_accuracy: 0.7991\n",
      "Epoch 243/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1914 - accuracy: 0.9318 - val_loss: 0.7987 - val_accuracy: 0.7414\n",
      "Epoch 244/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1601 - accuracy: 0.9325 - val_loss: 0.8585 - val_accuracy: 0.7664\n",
      "Epoch 245/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1718 - accuracy: 0.9251 - val_loss: 0.8779 - val_accuracy: 0.8178\n",
      "Epoch 246/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1627 - accuracy: 0.9332 - val_loss: 0.8190 - val_accuracy: 0.7726\n",
      "Epoch 247/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1704 - accuracy: 0.9305 - val_loss: 0.8776 - val_accuracy: 0.7944\n",
      "Epoch 248/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1514 - accuracy: 0.9358 - val_loss: 0.9092 - val_accuracy: 0.7804\n",
      "Epoch 249/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1690 - accuracy: 0.9338 - val_loss: 0.8282 - val_accuracy: 0.7430\n",
      "Epoch 250/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1566 - accuracy: 0.9338 - val_loss: 0.8638 - val_accuracy: 0.7664\n",
      "Epoch 251/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1557 - accuracy: 0.9405 - val_loss: 0.9259 - val_accuracy: 0.7773\n",
      "Epoch 252/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1610 - accuracy: 0.9345 - val_loss: 0.8456 - val_accuracy: 0.7710\n",
      "Epoch 253/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1657 - accuracy: 0.9372 - val_loss: 0.9413 - val_accuracy: 0.7492\n",
      "Epoch 254/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1716 - accuracy: 0.9358 - val_loss: 0.8269 - val_accuracy: 0.7134\n",
      "Epoch 255/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1726 - accuracy: 0.9398 - val_loss: 0.8766 - val_accuracy: 0.7850\n",
      "Epoch 256/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1711 - accuracy: 0.9311 - val_loss: 0.8747 - val_accuracy: 0.7710\n",
      "Epoch 257/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1602 - accuracy: 0.9291 - val_loss: 0.8617 - val_accuracy: 0.7710\n",
      "Epoch 258/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1538 - accuracy: 0.9372 - val_loss: 0.9659 - val_accuracy: 0.7648\n",
      "Epoch 259/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1602 - accuracy: 0.9298 - val_loss: 0.8938 - val_accuracy: 0.7150\n",
      "Epoch 260/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1571 - accuracy: 0.9345 - val_loss: 0.9696 - val_accuracy: 0.7866\n",
      "Epoch 261/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1559 - accuracy: 0.9392 - val_loss: 0.8995 - val_accuracy: 0.7508\n",
      "Epoch 262/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1547 - accuracy: 0.9405 - val_loss: 0.8470 - val_accuracy: 0.7773\n",
      "Epoch 263/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1504 - accuracy: 0.9385 - val_loss: 0.9775 - val_accuracy: 0.7975\n",
      "Epoch 264/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1504 - accuracy: 0.9392 - val_loss: 0.8729 - val_accuracy: 0.7695\n",
      "Epoch 265/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.1527 - accuracy: 0.9365 - val_loss: 0.8995 - val_accuracy: 0.7913\n",
      "Epoch 266/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.1524 - accuracy: 0.9372 - val_loss: 0.9346 - val_accuracy: 0.6916\n",
      "Epoch 267/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1509 - accuracy: 0.9345 - val_loss: 0.8767 - val_accuracy: 0.7492\n",
      "Epoch 268/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1631 - accuracy: 0.9385 - val_loss: 0.8518 - val_accuracy: 0.7913\n",
      "Epoch 269/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1536 - accuracy: 0.9372 - val_loss: 0.9286 - val_accuracy: 0.7352\n",
      "Epoch 270/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1443 - accuracy: 0.9465 - val_loss: 0.9125 - val_accuracy: 0.7321\n",
      "Epoch 271/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1666 - accuracy: 0.9365 - val_loss: 0.8699 - val_accuracy: 0.7664\n",
      "Epoch 272/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1615 - accuracy: 0.9352 - val_loss: 0.8692 - val_accuracy: 0.7477\n",
      "Epoch 273/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1327 - accuracy: 0.9479 - val_loss: 0.9685 - val_accuracy: 0.7913\n",
      "Epoch 274/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1574 - accuracy: 0.9358 - val_loss: 0.8869 - val_accuracy: 0.7679\n",
      "Epoch 275/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.1581 - accuracy: 0.9311 - val_loss: 0.9387 - val_accuracy: 0.7570\n",
      "Epoch 276/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1409 - accuracy: 0.9392 - val_loss: 0.9792 - val_accuracy: 0.7960\n",
      "Epoch 277/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.1328 - accuracy: 0.9385 - val_loss: 0.9704 - val_accuracy: 0.7991\n",
      "Epoch 278/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1422 - accuracy: 0.9432 - val_loss: 0.9232 - val_accuracy: 0.7570\n",
      "Epoch 279/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.1348 - accuracy: 0.9425 - val_loss: 0.9539 - val_accuracy: 0.7960\n",
      "Epoch 280/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.1556 - accuracy: 0.9392 - val_loss: 0.9573 - val_accuracy: 0.7508\n",
      "Epoch 281/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.1255 - accuracy: 0.9432 - val_loss: 1.0145 - val_accuracy: 0.8115\n",
      "Epoch 282/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1485 - accuracy: 0.9418 - val_loss: 0.9860 - val_accuracy: 0.7944\n",
      "Epoch 283/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1359 - accuracy: 0.9465 - val_loss: 0.9614 - val_accuracy: 0.7882\n",
      "Epoch 284/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1417 - accuracy: 0.9459 - val_loss: 1.0004 - val_accuracy: 0.7897\n",
      "Epoch 285/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1441 - accuracy: 0.9398 - val_loss: 0.9455 - val_accuracy: 0.8146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.1634 - accuracy: 0.9325 - val_loss: 0.9300 - val_accuracy: 0.7741\n",
      "Epoch 287/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1513 - accuracy: 0.9412 - val_loss: 1.0050 - val_accuracy: 0.7975\n",
      "Epoch 288/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1397 - accuracy: 0.9499 - val_loss: 0.9417 - val_accuracy: 0.7648\n",
      "Epoch 289/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.1302 - accuracy: 0.9459 - val_loss: 1.0528 - val_accuracy: 0.7991\n",
      "Epoch 290/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1422 - accuracy: 0.9459 - val_loss: 0.9687 - val_accuracy: 0.7819\n",
      "Epoch 291/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.1394 - accuracy: 0.9398 - val_loss: 0.9468 - val_accuracy: 0.7352\n",
      "Epoch 292/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1367 - accuracy: 0.9439 - val_loss: 0.9730 - val_accuracy: 0.7710\n",
      "Epoch 293/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1620 - accuracy: 0.9365 - val_loss: 0.9259 - val_accuracy: 0.7555\n",
      "Epoch 294/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.1190 - accuracy: 0.9512 - val_loss: 0.9901 - val_accuracy: 0.7414\n",
      "Epoch 295/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.1302 - accuracy: 0.9432 - val_loss: 0.9885 - val_accuracy: 0.7882\n",
      "Epoch 296/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.1346 - accuracy: 0.9512 - val_loss: 1.0180 - val_accuracy: 0.6963\n",
      "Epoch 297/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.1294 - accuracy: 0.9512 - val_loss: 0.9869 - val_accuracy: 0.7835\n",
      "Epoch 298/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1487 - accuracy: 0.9439 - val_loss: 0.9979 - val_accuracy: 0.7679\n",
      "Epoch 299/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1398 - accuracy: 0.9539 - val_loss: 1.0148 - val_accuracy: 0.7508\n",
      "Epoch 300/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1470 - accuracy: 0.9405 - val_loss: 1.0127 - val_accuracy: 0.6994\n",
      "Epoch 301/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.1331 - accuracy: 0.9519 - val_loss: 0.9492 - val_accuracy: 0.7523\n",
      "Epoch 302/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1299 - accuracy: 0.9532 - val_loss: 0.9672 - val_accuracy: 0.7928\n",
      "Epoch 303/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1384 - accuracy: 0.9439 - val_loss: 0.9973 - val_accuracy: 0.7788\n",
      "Epoch 304/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.1130 - accuracy: 0.9592 - val_loss: 1.0024 - val_accuracy: 0.8069\n",
      "Epoch 305/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.1162 - accuracy: 0.9532 - val_loss: 1.0989 - val_accuracy: 0.8131\n",
      "Epoch 306/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.1281 - accuracy: 0.9445 - val_loss: 0.9603 - val_accuracy: 0.7788\n",
      "Epoch 307/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1302 - accuracy: 0.9452 - val_loss: 0.9997 - val_accuracy: 0.7866\n",
      "Epoch 308/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.1316 - accuracy: 0.9525 - val_loss: 0.9795 - val_accuracy: 0.7679\n",
      "Epoch 309/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.1165 - accuracy: 0.9485 - val_loss: 1.0401 - val_accuracy: 0.7414\n",
      "Epoch 310/1500\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.1292 - accuracy: 0.9485 - val_loss: 0.9451 - val_accuracy: 0.7804\n",
      "Epoch 311/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1222 - accuracy: 0.9525 - val_loss: 1.0367 - val_accuracy: 0.8084\n",
      "Epoch 312/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.1158 - accuracy: 0.9566 - val_loss: 1.1108 - val_accuracy: 0.8131\n",
      "Epoch 313/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1224 - accuracy: 0.9545 - val_loss: 1.0979 - val_accuracy: 0.7928\n",
      "Epoch 314/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1256 - accuracy: 0.9539 - val_loss: 0.9962 - val_accuracy: 0.7897\n",
      "Epoch 315/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1017 - accuracy: 0.9579 - val_loss: 1.0071 - val_accuracy: 0.7570\n",
      "Epoch 316/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1275 - accuracy: 0.9465 - val_loss: 1.0634 - val_accuracy: 0.7539\n",
      "Epoch 317/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1359 - accuracy: 0.9439 - val_loss: 1.0388 - val_accuracy: 0.7103\n",
      "Epoch 318/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1274 - accuracy: 0.9459 - val_loss: 1.0341 - val_accuracy: 0.7461\n",
      "Epoch 319/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1143 - accuracy: 0.9559 - val_loss: 0.9970 - val_accuracy: 0.7150\n",
      "Epoch 320/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1319 - accuracy: 0.9465 - val_loss: 1.0237 - val_accuracy: 0.7913\n",
      "Epoch 321/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1452 - accuracy: 0.9499 - val_loss: 1.1232 - val_accuracy: 0.8053\n",
      "Epoch 322/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1081 - accuracy: 0.9579 - val_loss: 1.0744 - val_accuracy: 0.7118\n",
      "Epoch 323/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1179 - accuracy: 0.9579 - val_loss: 1.2161 - val_accuracy: 0.8053\n",
      "Epoch 324/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1028 - accuracy: 0.9612 - val_loss: 1.1405 - val_accuracy: 0.7882\n",
      "Epoch 325/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1199 - accuracy: 0.9479 - val_loss: 1.0809 - val_accuracy: 0.7897\n",
      "Epoch 326/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1175 - accuracy: 0.9572 - val_loss: 0.9825 - val_accuracy: 0.7913\n",
      "Epoch 327/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1310 - accuracy: 0.9512 - val_loss: 0.9633 - val_accuracy: 0.7586\n",
      "Epoch 328/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1233 - accuracy: 0.9552 - val_loss: 1.0705 - val_accuracy: 0.7555\n",
      "Epoch 329/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1117 - accuracy: 0.9552 - val_loss: 1.0628 - val_accuracy: 0.7726\n",
      "Epoch 330/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1209 - accuracy: 0.9525 - val_loss: 0.9767 - val_accuracy: 0.7212\n",
      "Epoch 331/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1354 - accuracy: 0.9412 - val_loss: 0.9427 - val_accuracy: 0.7617\n",
      "Epoch 332/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1158 - accuracy: 0.9566 - val_loss: 1.1452 - val_accuracy: 0.7991\n",
      "Epoch 333/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1373 - accuracy: 0.9472 - val_loss: 1.0484 - val_accuracy: 0.7882\n",
      "Epoch 334/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1071 - accuracy: 0.9606 - val_loss: 1.1279 - val_accuracy: 0.7850\n",
      "Epoch 335/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1316 - accuracy: 0.9499 - val_loss: 1.0870 - val_accuracy: 0.7555\n",
      "Epoch 336/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1236 - accuracy: 0.9525 - val_loss: 1.0661 - val_accuracy: 0.7290\n",
      "Epoch 337/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1189 - accuracy: 0.9519 - val_loss: 1.0609 - val_accuracy: 0.7882\n",
      "Epoch 338/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1365 - accuracy: 0.9465 - val_loss: 1.1057 - val_accuracy: 0.7773\n",
      "Epoch 339/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1262 - accuracy: 0.9519 - val_loss: 1.0657 - val_accuracy: 0.6931\n",
      "Epoch 340/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1146 - accuracy: 0.9619 - val_loss: 1.1697 - val_accuracy: 0.7710\n",
      "Epoch 341/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1131 - accuracy: 0.9545 - val_loss: 1.1510 - val_accuracy: 0.7773\n",
      "Epoch 342/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1179 - accuracy: 0.9559 - val_loss: 1.1591 - val_accuracy: 0.7944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1190 - accuracy: 0.9566 - val_loss: 1.0642 - val_accuracy: 0.7383\n",
      "Epoch 344/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1022 - accuracy: 0.9572 - val_loss: 1.0932 - val_accuracy: 0.7726\n",
      "Epoch 345/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0979 - accuracy: 0.9679 - val_loss: 1.1494 - val_accuracy: 0.7944\n",
      "Epoch 346/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1215 - accuracy: 0.9612 - val_loss: 1.1356 - val_accuracy: 0.7804\n",
      "Epoch 347/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1231 - accuracy: 0.9492 - val_loss: 1.0512 - val_accuracy: 0.7882\n",
      "Epoch 348/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1094 - accuracy: 0.9579 - val_loss: 1.2133 - val_accuracy: 0.6978\n",
      "Epoch 349/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1257 - accuracy: 0.9445 - val_loss: 1.0891 - val_accuracy: 0.7570\n",
      "Epoch 350/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1087 - accuracy: 0.9592 - val_loss: 1.1125 - val_accuracy: 0.7882\n",
      "Epoch 351/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1259 - accuracy: 0.9519 - val_loss: 1.0500 - val_accuracy: 0.7648\n",
      "Epoch 352/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1180 - accuracy: 0.9479 - val_loss: 1.1226 - val_accuracy: 0.7757\n",
      "Epoch 353/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0995 - accuracy: 0.9612 - val_loss: 1.0921 - val_accuracy: 0.7773\n",
      "Epoch 354/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0982 - accuracy: 0.9632 - val_loss: 1.2436 - val_accuracy: 0.7975\n",
      "Epoch 355/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1034 - accuracy: 0.9552 - val_loss: 1.2853 - val_accuracy: 0.7835\n",
      "Epoch 356/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0951 - accuracy: 0.9599 - val_loss: 1.3778 - val_accuracy: 0.8146\n",
      "Epoch 357/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1152 - accuracy: 0.9559 - val_loss: 1.3204 - val_accuracy: 0.8069\n",
      "Epoch 358/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1296 - accuracy: 0.9525 - val_loss: 1.1567 - val_accuracy: 0.7928\n",
      "Epoch 359/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1077 - accuracy: 0.9619 - val_loss: 1.2274 - val_accuracy: 0.8053\n",
      "Epoch 360/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1024 - accuracy: 0.9626 - val_loss: 1.1898 - val_accuracy: 0.7897\n",
      "Epoch 361/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1009 - accuracy: 0.9599 - val_loss: 1.2691 - val_accuracy: 0.7539\n",
      "Epoch 362/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0913 - accuracy: 0.9606 - val_loss: 1.2454 - val_accuracy: 0.7866\n",
      "Epoch 363/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1109 - accuracy: 0.9545 - val_loss: 1.2111 - val_accuracy: 0.7960\n",
      "Epoch 364/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.1275 - accuracy: 0.9579 - val_loss: 1.1490 - val_accuracy: 0.7773\n",
      "Epoch 365/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0884 - accuracy: 0.9672 - val_loss: 1.1831 - val_accuracy: 0.7804\n",
      "Epoch 366/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1042 - accuracy: 0.9586 - val_loss: 1.1785 - val_accuracy: 0.7586\n",
      "Epoch 367/1500\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.0969 - accuracy: 0.9639 - val_loss: 1.1521 - val_accuracy: 0.7695\n",
      "Epoch 368/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0970 - accuracy: 0.9639 - val_loss: 1.1560 - val_accuracy: 0.7944\n",
      "Epoch 369/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1118 - accuracy: 0.9539 - val_loss: 1.1624 - val_accuracy: 0.7804\n",
      "Epoch 370/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1002 - accuracy: 0.9572 - val_loss: 1.1830 - val_accuracy: 0.7835\n",
      "Epoch 371/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1072 - accuracy: 0.9619 - val_loss: 1.3008 - val_accuracy: 0.7695\n",
      "Epoch 372/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1102 - accuracy: 0.9626 - val_loss: 1.2121 - val_accuracy: 0.7632\n",
      "Epoch 373/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0909 - accuracy: 0.9646 - val_loss: 1.3429 - val_accuracy: 0.7975\n",
      "Epoch 374/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1183 - accuracy: 0.9592 - val_loss: 1.2951 - val_accuracy: 0.7757\n",
      "Epoch 375/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1120 - accuracy: 0.9612 - val_loss: 1.1880 - val_accuracy: 0.7632\n",
      "Epoch 376/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0938 - accuracy: 0.9599 - val_loss: 1.2779 - val_accuracy: 0.7601\n",
      "Epoch 377/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1009 - accuracy: 0.9666 - val_loss: 1.2663 - val_accuracy: 0.7773\n",
      "Epoch 378/1500\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.0950 - accuracy: 0.9606 - val_loss: 1.3194 - val_accuracy: 0.7913\n",
      "Epoch 379/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1141 - accuracy: 0.9566 - val_loss: 1.3365 - val_accuracy: 0.8069\n",
      "Epoch 380/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.1010 - accuracy: 0.9612 - val_loss: 1.2700 - val_accuracy: 0.7944\n",
      "Epoch 381/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1026 - accuracy: 0.9626 - val_loss: 1.1703 - val_accuracy: 0.6931\n",
      "Epoch 382/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0951 - accuracy: 0.9646 - val_loss: 1.4234 - val_accuracy: 0.7866\n",
      "Epoch 383/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.1141 - accuracy: 0.9572 - val_loss: 1.2655 - val_accuracy: 0.7913\n",
      "Epoch 384/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0954 - accuracy: 0.9632 - val_loss: 1.1938 - val_accuracy: 0.7882\n",
      "Epoch 385/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0895 - accuracy: 0.9639 - val_loss: 1.2200 - val_accuracy: 0.7726\n",
      "Epoch 386/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0950 - accuracy: 0.9652 - val_loss: 1.2979 - val_accuracy: 0.8022\n",
      "Epoch 387/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.1106 - accuracy: 0.9552 - val_loss: 1.2830 - val_accuracy: 0.7882\n",
      "Epoch 388/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0899 - accuracy: 0.9713 - val_loss: 1.3568 - val_accuracy: 0.7960\n",
      "Epoch 389/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0971 - accuracy: 0.9619 - val_loss: 1.2685 - val_accuracy: 0.7741\n",
      "Epoch 390/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0895 - accuracy: 0.9646 - val_loss: 1.2833 - val_accuracy: 0.7477\n",
      "Epoch 391/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0863 - accuracy: 0.9599 - val_loss: 1.2876 - val_accuracy: 0.7913\n",
      "Epoch 392/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.1022 - accuracy: 0.9619 - val_loss: 1.2360 - val_accuracy: 0.7819\n",
      "Epoch 393/1500\n",
      "38/38 [==============================] - 0s 13ms/step - loss: 0.0906 - accuracy: 0.9646 - val_loss: 1.1954 - val_accuracy: 0.7570\n",
      "Epoch 394/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0882 - accuracy: 0.9646 - val_loss: 1.4031 - val_accuracy: 0.7788\n",
      "Epoch 395/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0866 - accuracy: 0.9679 - val_loss: 1.3136 - val_accuracy: 0.7664\n",
      "Epoch 396/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0875 - accuracy: 0.9699 - val_loss: 1.3232 - val_accuracy: 0.8069\n",
      "Epoch 397/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.1122 - accuracy: 0.9572 - val_loss: 1.2688 - val_accuracy: 0.7492\n",
      "Epoch 398/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1019 - accuracy: 0.9612 - val_loss: 1.2553 - val_accuracy: 0.7430\n",
      "Epoch 399/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1021 - accuracy: 0.9619 - val_loss: 1.3302 - val_accuracy: 0.7134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1059 - accuracy: 0.9646 - val_loss: 1.2894 - val_accuracy: 0.7850\n",
      "Epoch 401/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0835 - accuracy: 0.9706 - val_loss: 1.2518 - val_accuracy: 0.7508\n",
      "Epoch 402/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0827 - accuracy: 0.9706 - val_loss: 1.2832 - val_accuracy: 0.7352\n",
      "Epoch 403/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0880 - accuracy: 0.9659 - val_loss: 1.2757 - val_accuracy: 0.7383\n",
      "Epoch 404/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1154 - accuracy: 0.9659 - val_loss: 1.2161 - val_accuracy: 0.7835\n",
      "Epoch 405/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1137 - accuracy: 0.9599 - val_loss: 1.3468 - val_accuracy: 0.7882\n",
      "Epoch 406/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1092 - accuracy: 0.9619 - val_loss: 1.2018 - val_accuracy: 0.7710\n",
      "Epoch 407/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0803 - accuracy: 0.9713 - val_loss: 1.4322 - val_accuracy: 0.7508\n",
      "Epoch 408/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0890 - accuracy: 0.9659 - val_loss: 1.2585 - val_accuracy: 0.7757\n",
      "Epoch 409/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0969 - accuracy: 0.9672 - val_loss: 1.4095 - val_accuracy: 0.7975\n",
      "Epoch 410/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1019 - accuracy: 0.9659 - val_loss: 1.2059 - val_accuracy: 0.7430\n",
      "Epoch 411/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0730 - accuracy: 0.9733 - val_loss: 1.4289 - val_accuracy: 0.7944\n",
      "Epoch 412/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0932 - accuracy: 0.9672 - val_loss: 1.3209 - val_accuracy: 0.7290\n",
      "Epoch 413/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0946 - accuracy: 0.9652 - val_loss: 1.2590 - val_accuracy: 0.7741\n",
      "Epoch 414/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0821 - accuracy: 0.9706 - val_loss: 1.2678 - val_accuracy: 0.7523\n",
      "Epoch 415/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0961 - accuracy: 0.9666 - val_loss: 1.3759 - val_accuracy: 0.7928\n",
      "Epoch 416/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0949 - accuracy: 0.9632 - val_loss: 1.5505 - val_accuracy: 0.8053\n",
      "Epoch 417/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0922 - accuracy: 0.9652 - val_loss: 1.2339 - val_accuracy: 0.7773\n",
      "Epoch 418/1500\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.0908 - accuracy: 0.9672 - val_loss: 1.2500 - val_accuracy: 0.7368\n",
      "Epoch 419/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.1019 - accuracy: 0.9632 - val_loss: 1.3352 - val_accuracy: 0.7539\n",
      "Epoch 420/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0759 - accuracy: 0.9713 - val_loss: 1.5052 - val_accuracy: 0.8131\n",
      "Epoch 421/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1027 - accuracy: 0.9652 - val_loss: 1.3333 - val_accuracy: 0.7679\n",
      "Epoch 422/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0776 - accuracy: 0.9713 - val_loss: 1.3626 - val_accuracy: 0.7539\n",
      "Epoch 423/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1256 - accuracy: 0.9606 - val_loss: 1.3475 - val_accuracy: 0.7539\n",
      "Epoch 424/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0788 - accuracy: 0.9693 - val_loss: 1.2598 - val_accuracy: 0.7290\n",
      "Epoch 425/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0953 - accuracy: 0.9639 - val_loss: 1.4071 - val_accuracy: 0.7523\n",
      "Epoch 426/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0710 - accuracy: 0.9713 - val_loss: 1.4447 - val_accuracy: 0.7741\n",
      "Epoch 427/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0930 - accuracy: 0.9686 - val_loss: 1.3606 - val_accuracy: 0.7601\n",
      "Epoch 428/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0937 - accuracy: 0.9686 - val_loss: 1.4045 - val_accuracy: 0.7586\n",
      "Epoch 429/1500\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.0883 - accuracy: 0.9652 - val_loss: 1.4066 - val_accuracy: 0.7555\n",
      "Epoch 430/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0826 - accuracy: 0.9659 - val_loss: 1.3397 - val_accuracy: 0.7632\n",
      "Epoch 431/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0869 - accuracy: 0.9666 - val_loss: 1.3395 - val_accuracy: 0.7523\n",
      "Epoch 432/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0888 - accuracy: 0.9652 - val_loss: 1.4547 - val_accuracy: 0.7913\n",
      "Epoch 433/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0860 - accuracy: 0.9726 - val_loss: 1.3381 - val_accuracy: 0.7617\n",
      "Epoch 434/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0977 - accuracy: 0.9599 - val_loss: 1.3773 - val_accuracy: 0.7492\n",
      "Epoch 435/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0741 - accuracy: 0.9719 - val_loss: 1.3141 - val_accuracy: 0.7461\n",
      "Epoch 436/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0997 - accuracy: 0.9599 - val_loss: 1.3094 - val_accuracy: 0.7710\n",
      "Epoch 437/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0812 - accuracy: 0.9706 - val_loss: 1.2905 - val_accuracy: 0.7555\n",
      "Epoch 438/1500\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.0931 - accuracy: 0.9639 - val_loss: 1.3599 - val_accuracy: 0.7804\n",
      "Epoch 439/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.1018 - accuracy: 0.9632 - val_loss: 1.2999 - val_accuracy: 0.7477\n",
      "Epoch 440/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0835 - accuracy: 0.9713 - val_loss: 1.4461 - val_accuracy: 0.7648\n",
      "Epoch 441/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0822 - accuracy: 0.9786 - val_loss: 1.3212 - val_accuracy: 0.7118\n",
      "Epoch 442/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1178 - accuracy: 0.9606 - val_loss: 1.3960 - val_accuracy: 0.7741\n",
      "Epoch 443/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0728 - accuracy: 0.9773 - val_loss: 1.4600 - val_accuracy: 0.7757\n",
      "Epoch 444/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0955 - accuracy: 0.9626 - val_loss: 1.2994 - val_accuracy: 0.7648\n",
      "Epoch 445/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1121 - accuracy: 0.9626 - val_loss: 1.1846 - val_accuracy: 0.7710\n",
      "Epoch 446/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1083 - accuracy: 0.9579 - val_loss: 1.2318 - val_accuracy: 0.7695\n",
      "Epoch 447/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0934 - accuracy: 0.9706 - val_loss: 1.3778 - val_accuracy: 0.7835\n",
      "Epoch 448/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0660 - accuracy: 0.9753 - val_loss: 1.3503 - val_accuracy: 0.7648\n",
      "Epoch 449/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0879 - accuracy: 0.9679 - val_loss: 1.2780 - val_accuracy: 0.7477\n",
      "Epoch 450/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0883 - accuracy: 0.9699 - val_loss: 1.3633 - val_accuracy: 0.7695\n",
      "Epoch 451/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0869 - accuracy: 0.9713 - val_loss: 1.2798 - val_accuracy: 0.7461\n",
      "Epoch 452/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0965 - accuracy: 0.9612 - val_loss: 1.3343 - val_accuracy: 0.7617\n",
      "Epoch 453/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0776 - accuracy: 0.9679 - val_loss: 1.3574 - val_accuracy: 0.7414\n",
      "Epoch 454/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0731 - accuracy: 0.9779 - val_loss: 1.2831 - val_accuracy: 0.7850\n",
      "Epoch 455/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0695 - accuracy: 0.9719 - val_loss: 1.4134 - val_accuracy: 0.8037\n",
      "Epoch 456/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0969 - accuracy: 0.9686 - val_loss: 1.3196 - val_accuracy: 0.7477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0817 - accuracy: 0.9706 - val_loss: 1.2493 - val_accuracy: 0.7570\n",
      "Epoch 458/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0833 - accuracy: 0.9699 - val_loss: 1.3167 - val_accuracy: 0.7227\n",
      "Epoch 459/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0685 - accuracy: 0.9746 - val_loss: 1.3494 - val_accuracy: 0.7570\n",
      "Epoch 460/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0975 - accuracy: 0.9686 - val_loss: 1.3236 - val_accuracy: 0.7648\n",
      "Epoch 461/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0969 - accuracy: 0.9746 - val_loss: 1.4641 - val_accuracy: 0.7804\n",
      "Epoch 462/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0947 - accuracy: 0.9713 - val_loss: 1.3401 - val_accuracy: 0.7368\n",
      "Epoch 463/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0916 - accuracy: 0.9719 - val_loss: 1.4104 - val_accuracy: 0.7866\n",
      "Epoch 464/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0777 - accuracy: 0.9733 - val_loss: 1.3361 - val_accuracy: 0.7819\n",
      "Epoch 465/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0979 - accuracy: 0.9686 - val_loss: 1.2475 - val_accuracy: 0.7570\n",
      "Epoch 466/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0899 - accuracy: 0.9619 - val_loss: 1.3734 - val_accuracy: 0.7492\n",
      "Epoch 467/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0551 - accuracy: 0.9813 - val_loss: 1.5172 - val_accuracy: 0.7523\n",
      "Epoch 468/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0714 - accuracy: 0.9713 - val_loss: 1.4674 - val_accuracy: 0.7913\n",
      "Epoch 469/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0699 - accuracy: 0.9799 - val_loss: 1.3990 - val_accuracy: 0.7960\n",
      "Epoch 470/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0799 - accuracy: 0.9686 - val_loss: 1.3224 - val_accuracy: 0.7835\n",
      "Epoch 471/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0629 - accuracy: 0.9726 - val_loss: 1.5094 - val_accuracy: 0.7804\n",
      "Epoch 472/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0779 - accuracy: 0.9693 - val_loss: 1.4557 - val_accuracy: 0.7523\n",
      "Epoch 473/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0803 - accuracy: 0.9739 - val_loss: 1.4493 - val_accuracy: 0.7819\n",
      "Epoch 474/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0643 - accuracy: 0.9739 - val_loss: 1.4256 - val_accuracy: 0.7009\n",
      "Epoch 475/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0981 - accuracy: 0.9679 - val_loss: 1.4640 - val_accuracy: 0.7305\n",
      "Epoch 476/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0770 - accuracy: 0.9733 - val_loss: 1.3809 - val_accuracy: 0.7757\n",
      "Epoch 477/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0807 - accuracy: 0.9693 - val_loss: 1.4634 - val_accuracy: 0.7804\n",
      "Epoch 478/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0897 - accuracy: 0.9686 - val_loss: 1.3629 - val_accuracy: 0.7819\n",
      "Epoch 479/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0829 - accuracy: 0.9706 - val_loss: 1.3961 - val_accuracy: 0.7819\n",
      "Epoch 480/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0791 - accuracy: 0.9719 - val_loss: 1.4600 - val_accuracy: 0.7726\n",
      "Epoch 481/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0665 - accuracy: 0.9753 - val_loss: 1.4710 - val_accuracy: 0.7368\n",
      "Epoch 482/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0649 - accuracy: 0.9759 - val_loss: 1.6253 - val_accuracy: 0.8006\n",
      "Epoch 483/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0811 - accuracy: 0.9719 - val_loss: 1.5242 - val_accuracy: 0.7882\n",
      "Epoch 484/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0796 - accuracy: 0.9713 - val_loss: 1.5054 - val_accuracy: 0.7850\n",
      "Epoch 485/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0736 - accuracy: 0.9753 - val_loss: 1.3341 - val_accuracy: 0.7336\n",
      "Epoch 486/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0698 - accuracy: 0.9779 - val_loss: 1.3507 - val_accuracy: 0.7523\n",
      "Epoch 487/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0787 - accuracy: 0.9686 - val_loss: 1.4208 - val_accuracy: 0.7726\n",
      "Epoch 488/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0890 - accuracy: 0.9646 - val_loss: 1.5572 - val_accuracy: 0.7788\n",
      "Epoch 489/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0606 - accuracy: 0.9759 - val_loss: 1.5837 - val_accuracy: 0.7835\n",
      "Epoch 490/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0691 - accuracy: 0.9713 - val_loss: 1.4951 - val_accuracy: 0.7648\n",
      "Epoch 491/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0779 - accuracy: 0.9726 - val_loss: 1.5444 - val_accuracy: 0.7773\n",
      "Epoch 492/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0620 - accuracy: 0.9813 - val_loss: 1.5674 - val_accuracy: 0.7695\n",
      "Epoch 493/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0845 - accuracy: 0.9646 - val_loss: 1.5173 - val_accuracy: 0.7773\n",
      "Epoch 494/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0861 - accuracy: 0.9706 - val_loss: 1.4523 - val_accuracy: 0.7679\n",
      "Epoch 495/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0611 - accuracy: 0.9786 - val_loss: 1.4457 - val_accuracy: 0.7648\n",
      "Epoch 496/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0840 - accuracy: 0.9699 - val_loss: 1.5590 - val_accuracy: 0.7897\n",
      "Epoch 497/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0827 - accuracy: 0.9719 - val_loss: 1.3937 - val_accuracy: 0.7352\n",
      "Epoch 498/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0756 - accuracy: 0.9706 - val_loss: 1.4079 - val_accuracy: 0.6947\n",
      "Epoch 499/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0802 - accuracy: 0.9719 - val_loss: 1.3633 - val_accuracy: 0.7492\n",
      "Epoch 500/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0667 - accuracy: 0.9739 - val_loss: 1.4976 - val_accuracy: 0.7212\n",
      "Epoch 501/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0777 - accuracy: 0.9733 - val_loss: 1.4478 - val_accuracy: 0.6885\n",
      "Epoch 502/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0924 - accuracy: 0.9672 - val_loss: 1.6176 - val_accuracy: 0.7975\n",
      "Epoch 503/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0590 - accuracy: 0.9719 - val_loss: 1.4643 - val_accuracy: 0.7788\n",
      "Epoch 504/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0785 - accuracy: 0.9699 - val_loss: 1.4249 - val_accuracy: 0.7773\n",
      "Epoch 505/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0863 - accuracy: 0.9699 - val_loss: 1.4942 - val_accuracy: 0.6916\n",
      "Epoch 506/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0513 - accuracy: 0.9820 - val_loss: 1.6689 - val_accuracy: 0.8006\n",
      "Epoch 507/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0866 - accuracy: 0.9679 - val_loss: 1.4591 - val_accuracy: 0.7539\n",
      "Epoch 508/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0669 - accuracy: 0.9786 - val_loss: 1.4397 - val_accuracy: 0.7726\n",
      "Epoch 509/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0613 - accuracy: 0.9753 - val_loss: 1.5693 - val_accuracy: 0.7227\n",
      "Epoch 510/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0710 - accuracy: 0.9813 - val_loss: 1.4370 - val_accuracy: 0.7788\n",
      "Epoch 511/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0865 - accuracy: 0.9713 - val_loss: 1.3798 - val_accuracy: 0.7726\n",
      "Epoch 512/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0738 - accuracy: 0.9773 - val_loss: 1.4421 - val_accuracy: 0.7804\n",
      "Epoch 513/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0701 - accuracy: 0.9786 - val_loss: 1.4955 - val_accuracy: 0.7819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 514/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0682 - accuracy: 0.9806 - val_loss: 1.4199 - val_accuracy: 0.7461\n",
      "Epoch 515/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0704 - accuracy: 0.9719 - val_loss: 1.4586 - val_accuracy: 0.7960\n",
      "Epoch 516/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0596 - accuracy: 0.9779 - val_loss: 1.5133 - val_accuracy: 0.7492\n",
      "Epoch 517/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0587 - accuracy: 0.9779 - val_loss: 1.5674 - val_accuracy: 0.7928\n",
      "Epoch 518/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0911 - accuracy: 0.9759 - val_loss: 1.4214 - val_accuracy: 0.7212\n",
      "Epoch 519/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0683 - accuracy: 0.9779 - val_loss: 1.5580 - val_accuracy: 0.7882\n",
      "Epoch 520/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1051 - accuracy: 0.9626 - val_loss: 1.4576 - val_accuracy: 0.7710\n",
      "Epoch 521/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0543 - accuracy: 0.9786 - val_loss: 1.4292 - val_accuracy: 0.7773\n",
      "Epoch 522/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0519 - accuracy: 0.9820 - val_loss: 1.5851 - val_accuracy: 0.7913\n",
      "Epoch 523/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0865 - accuracy: 0.9713 - val_loss: 1.3608 - val_accuracy: 0.7523\n",
      "Epoch 524/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0680 - accuracy: 0.9753 - val_loss: 1.5338 - val_accuracy: 0.7477\n",
      "Epoch 525/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0612 - accuracy: 0.9793 - val_loss: 1.6984 - val_accuracy: 0.7960\n",
      "Epoch 526/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0758 - accuracy: 0.9746 - val_loss: 1.6055 - val_accuracy: 0.7913\n",
      "Epoch 527/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0629 - accuracy: 0.9759 - val_loss: 1.6026 - val_accuracy: 0.7383\n",
      "Epoch 528/1500\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.0886 - accuracy: 0.9719 - val_loss: 1.5151 - val_accuracy: 0.7882\n",
      "Epoch 529/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0692 - accuracy: 0.9779 - val_loss: 1.5128 - val_accuracy: 0.7601\n",
      "Epoch 530/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0741 - accuracy: 0.9726 - val_loss: 1.4069 - val_accuracy: 0.7461\n",
      "Epoch 531/1500\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.0730 - accuracy: 0.9739 - val_loss: 1.3400 - val_accuracy: 0.7679\n",
      "Epoch 532/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0647 - accuracy: 0.9753 - val_loss: 1.4521 - val_accuracy: 0.7679\n",
      "Epoch 533/1500\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.0608 - accuracy: 0.9759 - val_loss: 1.6891 - val_accuracy: 0.7960\n",
      "Epoch 534/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0833 - accuracy: 0.9713 - val_loss: 1.3396 - val_accuracy: 0.7414\n",
      "Epoch 535/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0668 - accuracy: 0.9773 - val_loss: 1.4295 - val_accuracy: 0.7352\n",
      "Epoch 536/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0830 - accuracy: 0.9759 - val_loss: 1.5231 - val_accuracy: 0.7757\n",
      "Epoch 537/1500\n",
      "38/38 [==============================] - 0s 13ms/step - loss: 0.0863 - accuracy: 0.9693 - val_loss: 1.3378 - val_accuracy: 0.7757\n",
      "Epoch 538/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0695 - accuracy: 0.9753 - val_loss: 1.5395 - val_accuracy: 0.7726\n",
      "Epoch 539/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0782 - accuracy: 0.9773 - val_loss: 1.3331 - val_accuracy: 0.7570\n",
      "Epoch 540/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0923 - accuracy: 0.9706 - val_loss: 1.2492 - val_accuracy: 0.7336\n",
      "Epoch 541/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0564 - accuracy: 0.9786 - val_loss: 1.3416 - val_accuracy: 0.7414\n",
      "Epoch 542/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0663 - accuracy: 0.9733 - val_loss: 1.3975 - val_accuracy: 0.7617\n",
      "Epoch 543/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0584 - accuracy: 0.9799 - val_loss: 1.4696 - val_accuracy: 0.7150\n",
      "Epoch 544/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0756 - accuracy: 0.9706 - val_loss: 1.5646 - val_accuracy: 0.7617\n",
      "Epoch 545/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0689 - accuracy: 0.9766 - val_loss: 1.5732 - val_accuracy: 0.7710\n",
      "Epoch 546/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0634 - accuracy: 0.9806 - val_loss: 1.4435 - val_accuracy: 0.7726\n",
      "Epoch 547/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0766 - accuracy: 0.9746 - val_loss: 1.4467 - val_accuracy: 0.7617\n",
      "Epoch 548/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0685 - accuracy: 0.9713 - val_loss: 1.4323 - val_accuracy: 0.7368\n",
      "Epoch 549/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0613 - accuracy: 0.9759 - val_loss: 1.4682 - val_accuracy: 0.7928\n",
      "Epoch 550/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0587 - accuracy: 0.9739 - val_loss: 1.4144 - val_accuracy: 0.7664\n",
      "Epoch 551/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0885 - accuracy: 0.9672 - val_loss: 1.4531 - val_accuracy: 0.7741\n",
      "Epoch 552/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0746 - accuracy: 0.9713 - val_loss: 1.4021 - val_accuracy: 0.7336\n",
      "Epoch 553/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0705 - accuracy: 0.9719 - val_loss: 1.6017 - val_accuracy: 0.7445\n",
      "Epoch 554/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0482 - accuracy: 0.9826 - val_loss: 1.5839 - val_accuracy: 0.7850\n",
      "Epoch 555/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0650 - accuracy: 0.9779 - val_loss: 1.4897 - val_accuracy: 0.7757\n",
      "Epoch 556/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0814 - accuracy: 0.9726 - val_loss: 1.4518 - val_accuracy: 0.7555\n",
      "Epoch 557/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0575 - accuracy: 0.9820 - val_loss: 1.5188 - val_accuracy: 0.7617\n",
      "Epoch 558/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0618 - accuracy: 0.9779 - val_loss: 1.5044 - val_accuracy: 0.7555\n",
      "Epoch 559/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0664 - accuracy: 0.9820 - val_loss: 1.4896 - val_accuracy: 0.7648\n",
      "Epoch 560/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0554 - accuracy: 0.9793 - val_loss: 1.5684 - val_accuracy: 0.7960\n",
      "Epoch 561/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0627 - accuracy: 0.9759 - val_loss: 1.5969 - val_accuracy: 0.7586\n",
      "Epoch 562/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0560 - accuracy: 0.9779 - val_loss: 1.5626 - val_accuracy: 0.7850\n",
      "Epoch 563/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0737 - accuracy: 0.9753 - val_loss: 1.5777 - val_accuracy: 0.7975\n",
      "Epoch 564/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0740 - accuracy: 0.9779 - val_loss: 1.4039 - val_accuracy: 0.7819\n",
      "Epoch 565/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0579 - accuracy: 0.9806 - val_loss: 1.5504 - val_accuracy: 0.7461\n",
      "Epoch 566/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0659 - accuracy: 0.9773 - val_loss: 1.6427 - val_accuracy: 0.7960\n",
      "Epoch 567/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0804 - accuracy: 0.9753 - val_loss: 1.5433 - val_accuracy: 0.7461\n",
      "Epoch 568/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0736 - accuracy: 0.9706 - val_loss: 1.6459 - val_accuracy: 0.7897\n",
      "Epoch 569/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0684 - accuracy: 0.9753 - val_loss: 1.4919 - val_accuracy: 0.7414\n",
      "Epoch 570/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0538 - accuracy: 0.9813 - val_loss: 1.5442 - val_accuracy: 0.7726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 571/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1077 - accuracy: 0.9666 - val_loss: 1.4939 - val_accuracy: 0.7586\n",
      "Epoch 572/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0559 - accuracy: 0.9799 - val_loss: 1.4865 - val_accuracy: 0.7383\n",
      "Epoch 573/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0486 - accuracy: 0.9840 - val_loss: 1.6099 - val_accuracy: 0.7819\n",
      "Epoch 574/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0566 - accuracy: 0.9773 - val_loss: 1.6669 - val_accuracy: 0.7570\n",
      "Epoch 575/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0634 - accuracy: 0.9799 - val_loss: 1.5176 - val_accuracy: 0.7336\n",
      "Epoch 576/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0543 - accuracy: 0.9813 - val_loss: 1.5942 - val_accuracy: 0.7866\n",
      "Epoch 577/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0537 - accuracy: 0.9786 - val_loss: 1.5548 - val_accuracy: 0.7757\n",
      "Epoch 578/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0754 - accuracy: 0.9766 - val_loss: 1.5545 - val_accuracy: 0.7274\n",
      "Epoch 579/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0557 - accuracy: 0.9793 - val_loss: 1.6949 - val_accuracy: 0.7835\n",
      "Epoch 580/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0647 - accuracy: 0.9753 - val_loss: 1.8330 - val_accuracy: 0.7944\n",
      "Epoch 581/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0586 - accuracy: 0.9820 - val_loss: 1.8630 - val_accuracy: 0.7913\n",
      "Epoch 582/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0665 - accuracy: 0.9820 - val_loss: 1.5858 - val_accuracy: 0.7632\n",
      "Epoch 583/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0599 - accuracy: 0.9786 - val_loss: 1.7448 - val_accuracy: 0.7726\n",
      "Epoch 584/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0658 - accuracy: 0.9779 - val_loss: 1.5788 - val_accuracy: 0.7726\n",
      "Epoch 585/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0713 - accuracy: 0.9786 - val_loss: 1.4259 - val_accuracy: 0.7617\n",
      "Epoch 586/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0848 - accuracy: 0.9753 - val_loss: 1.5012 - val_accuracy: 0.7196\n",
      "Epoch 587/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0546 - accuracy: 0.9820 - val_loss: 1.6487 - val_accuracy: 0.7695\n",
      "Epoch 588/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0511 - accuracy: 0.9840 - val_loss: 1.6099 - val_accuracy: 0.7632\n",
      "Epoch 589/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0421 - accuracy: 0.9866 - val_loss: 1.6936 - val_accuracy: 0.7305\n",
      "Epoch 590/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0623 - accuracy: 0.9779 - val_loss: 1.6943 - val_accuracy: 0.7757\n",
      "Epoch 591/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0494 - accuracy: 0.9786 - val_loss: 1.6575 - val_accuracy: 0.7757\n",
      "Epoch 592/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0457 - accuracy: 0.9813 - val_loss: 1.6182 - val_accuracy: 0.7773\n",
      "Epoch 593/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0775 - accuracy: 0.9719 - val_loss: 1.5739 - val_accuracy: 0.7788\n",
      "Epoch 594/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0638 - accuracy: 0.9786 - val_loss: 1.6212 - val_accuracy: 0.7726\n",
      "Epoch 595/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0710 - accuracy: 0.9813 - val_loss: 1.5835 - val_accuracy: 0.7040\n",
      "Epoch 596/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0731 - accuracy: 0.9739 - val_loss: 1.5941 - val_accuracy: 0.7757\n",
      "Epoch 597/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0720 - accuracy: 0.9779 - val_loss: 1.5350 - val_accuracy: 0.7850\n",
      "Epoch 598/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0479 - accuracy: 0.9813 - val_loss: 1.7884 - val_accuracy: 0.7570\n",
      "Epoch 599/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0610 - accuracy: 0.9739 - val_loss: 1.6518 - val_accuracy: 0.7555\n",
      "Epoch 600/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0624 - accuracy: 0.9799 - val_loss: 1.5362 - val_accuracy: 0.7290\n",
      "Epoch 601/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0543 - accuracy: 0.9753 - val_loss: 1.6765 - val_accuracy: 0.7523\n",
      "Epoch 602/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0598 - accuracy: 0.9799 - val_loss: 1.7343 - val_accuracy: 0.7679\n",
      "Epoch 603/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0826 - accuracy: 0.9693 - val_loss: 1.6149 - val_accuracy: 0.7586\n",
      "Epoch 604/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0601 - accuracy: 0.9773 - val_loss: 1.7259 - val_accuracy: 0.7648\n",
      "Epoch 605/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0401 - accuracy: 0.9833 - val_loss: 1.7618 - val_accuracy: 0.7695\n",
      "Epoch 606/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0447 - accuracy: 0.9840 - val_loss: 1.7307 - val_accuracy: 0.7321\n",
      "Epoch 607/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0607 - accuracy: 0.9820 - val_loss: 1.5833 - val_accuracy: 0.7336\n",
      "Epoch 608/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0470 - accuracy: 0.9846 - val_loss: 1.8488 - val_accuracy: 0.7928\n",
      "Epoch 609/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0532 - accuracy: 0.9813 - val_loss: 1.5337 - val_accuracy: 0.7632\n",
      "Epoch 610/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0797 - accuracy: 0.9739 - val_loss: 1.4905 - val_accuracy: 0.7586\n",
      "Epoch 611/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0475 - accuracy: 0.9793 - val_loss: 1.5369 - val_accuracy: 0.7726\n",
      "Epoch 612/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0605 - accuracy: 0.9786 - val_loss: 1.5295 - val_accuracy: 0.7274\n",
      "Epoch 613/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0533 - accuracy: 0.9806 - val_loss: 1.6657 - val_accuracy: 0.7757\n",
      "Epoch 614/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0645 - accuracy: 0.9739 - val_loss: 1.6680 - val_accuracy: 0.7866\n",
      "Epoch 615/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0645 - accuracy: 0.9759 - val_loss: 1.6059 - val_accuracy: 0.7617\n",
      "Epoch 616/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0594 - accuracy: 0.9786 - val_loss: 1.5405 - val_accuracy: 0.7648\n",
      "Epoch 617/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0569 - accuracy: 0.9759 - val_loss: 1.5369 - val_accuracy: 0.7336\n",
      "Epoch 618/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0742 - accuracy: 0.9753 - val_loss: 1.4695 - val_accuracy: 0.7601\n",
      "Epoch 619/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0432 - accuracy: 0.9873 - val_loss: 1.6840 - val_accuracy: 0.7601\n",
      "Epoch 620/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0538 - accuracy: 0.9786 - val_loss: 1.5320 - val_accuracy: 0.7757\n",
      "Epoch 621/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0779 - accuracy: 0.9759 - val_loss: 1.5432 - val_accuracy: 0.7477\n",
      "Epoch 622/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0689 - accuracy: 0.9746 - val_loss: 1.6607 - val_accuracy: 0.7773\n",
      "Epoch 623/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0690 - accuracy: 0.9746 - val_loss: 1.7058 - val_accuracy: 0.7726\n",
      "Epoch 624/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0518 - accuracy: 0.9840 - val_loss: 1.6019 - val_accuracy: 0.7773\n",
      "Epoch 625/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0436 - accuracy: 0.9840 - val_loss: 1.6631 - val_accuracy: 0.7804\n",
      "Epoch 626/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0585 - accuracy: 0.9799 - val_loss: 1.4892 - val_accuracy: 0.7773\n",
      "Epoch 627/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0652 - accuracy: 0.9793 - val_loss: 1.6437 - val_accuracy: 0.7741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 628/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0551 - accuracy: 0.9833 - val_loss: 1.5162 - val_accuracy: 0.7757\n",
      "Epoch 629/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0697 - accuracy: 0.9799 - val_loss: 1.5958 - val_accuracy: 0.7804\n",
      "Epoch 630/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0711 - accuracy: 0.9786 - val_loss: 1.5768 - val_accuracy: 0.7492\n",
      "Epoch 631/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0746 - accuracy: 0.9759 - val_loss: 1.4438 - val_accuracy: 0.7492\n",
      "Epoch 632/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0495 - accuracy: 0.9793 - val_loss: 1.6458 - val_accuracy: 0.7913\n",
      "Epoch 633/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0654 - accuracy: 0.9773 - val_loss: 1.4693 - val_accuracy: 0.7492\n",
      "Epoch 634/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0503 - accuracy: 0.9840 - val_loss: 1.7938 - val_accuracy: 0.8069\n",
      "Epoch 635/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0710 - accuracy: 0.9826 - val_loss: 1.7271 - val_accuracy: 0.7788\n",
      "Epoch 636/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0739 - accuracy: 0.9773 - val_loss: 1.6342 - val_accuracy: 0.7897\n",
      "Epoch 637/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0558 - accuracy: 0.9826 - val_loss: 1.6378 - val_accuracy: 0.7897\n",
      "Epoch 638/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0647 - accuracy: 0.9759 - val_loss: 1.5283 - val_accuracy: 0.7586\n",
      "Epoch 639/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0532 - accuracy: 0.9840 - val_loss: 1.6400 - val_accuracy: 0.7492\n",
      "Epoch 640/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0489 - accuracy: 0.9840 - val_loss: 1.7059 - val_accuracy: 0.7477\n",
      "Epoch 641/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0427 - accuracy: 0.9840 - val_loss: 1.5444 - val_accuracy: 0.7679\n",
      "Epoch 642/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0707 - accuracy: 0.9759 - val_loss: 1.6049 - val_accuracy: 0.7835\n",
      "Epoch 643/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0432 - accuracy: 0.9873 - val_loss: 1.6542 - val_accuracy: 0.7336\n",
      "Epoch 644/1500\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.0433 - accuracy: 0.9860 - val_loss: 1.6102 - val_accuracy: 0.7788\n",
      "Epoch 645/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0638 - accuracy: 0.9773 - val_loss: 1.5585 - val_accuracy: 0.7539\n",
      "Epoch 646/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0389 - accuracy: 0.9866 - val_loss: 1.5892 - val_accuracy: 0.7913\n",
      "Epoch 647/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0550 - accuracy: 0.9759 - val_loss: 1.6436 - val_accuracy: 0.7882\n",
      "Epoch 648/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0628 - accuracy: 0.9766 - val_loss: 1.5572 - val_accuracy: 0.7819\n",
      "Epoch 649/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0427 - accuracy: 0.9833 - val_loss: 1.6368 - val_accuracy: 0.7882\n",
      "Epoch 650/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0569 - accuracy: 0.9773 - val_loss: 1.6702 - val_accuracy: 0.7679\n",
      "Epoch 651/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0457 - accuracy: 0.9853 - val_loss: 1.7176 - val_accuracy: 0.7259\n",
      "Epoch 652/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0554 - accuracy: 0.9840 - val_loss: 1.8175 - val_accuracy: 0.7850\n",
      "Epoch 653/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0555 - accuracy: 0.9786 - val_loss: 1.6235 - val_accuracy: 0.7695\n",
      "Epoch 654/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0677 - accuracy: 0.9773 - val_loss: 1.6976 - val_accuracy: 0.7944\n",
      "Epoch 655/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0606 - accuracy: 0.9806 - val_loss: 1.5532 - val_accuracy: 0.7679\n",
      "Epoch 656/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0715 - accuracy: 0.9766 - val_loss: 1.5657 - val_accuracy: 0.7150\n",
      "Epoch 657/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0527 - accuracy: 0.9793 - val_loss: 1.8570 - val_accuracy: 0.8053\n",
      "Epoch 658/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0666 - accuracy: 0.9833 - val_loss: 1.8454 - val_accuracy: 0.7695\n",
      "Epoch 659/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0508 - accuracy: 0.9779 - val_loss: 1.6479 - val_accuracy: 0.7648\n",
      "Epoch 660/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0441 - accuracy: 0.9853 - val_loss: 1.6601 - val_accuracy: 0.7664\n",
      "Epoch 661/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0594 - accuracy: 0.9806 - val_loss: 1.5267 - val_accuracy: 0.7336\n",
      "Epoch 662/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0468 - accuracy: 0.9853 - val_loss: 1.5680 - val_accuracy: 0.7492\n",
      "Epoch 663/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0596 - accuracy: 0.9786 - val_loss: 1.6501 - val_accuracy: 0.7570\n",
      "Epoch 664/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0623 - accuracy: 0.9753 - val_loss: 1.5883 - val_accuracy: 0.7586\n",
      "Epoch 665/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0587 - accuracy: 0.9820 - val_loss: 1.7667 - val_accuracy: 0.7819\n",
      "Epoch 666/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0482 - accuracy: 0.9853 - val_loss: 1.6935 - val_accuracy: 0.7399\n",
      "Epoch 667/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0480 - accuracy: 0.9873 - val_loss: 1.6930 - val_accuracy: 0.7399\n",
      "Epoch 668/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0554 - accuracy: 0.9813 - val_loss: 1.5917 - val_accuracy: 0.7259\n",
      "Epoch 669/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0709 - accuracy: 0.9773 - val_loss: 1.6180 - val_accuracy: 0.7788\n",
      "Epoch 670/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0624 - accuracy: 0.9813 - val_loss: 1.5244 - val_accuracy: 0.7773\n",
      "Epoch 671/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0776 - accuracy: 0.9726 - val_loss: 1.6055 - val_accuracy: 0.7523\n",
      "Epoch 672/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0473 - accuracy: 0.9799 - val_loss: 1.5076 - val_accuracy: 0.7601\n",
      "Epoch 673/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0694 - accuracy: 0.9779 - val_loss: 1.6256 - val_accuracy: 0.7243\n",
      "Epoch 674/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0581 - accuracy: 0.9793 - val_loss: 1.8257 - val_accuracy: 0.7804\n",
      "Epoch 675/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0507 - accuracy: 0.9826 - val_loss: 1.7030 - val_accuracy: 0.7866\n",
      "Epoch 676/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0572 - accuracy: 0.9793 - val_loss: 1.4934 - val_accuracy: 0.7710\n",
      "Epoch 677/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0575 - accuracy: 0.9813 - val_loss: 1.6174 - val_accuracy: 0.7741\n",
      "Epoch 678/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0651 - accuracy: 0.9813 - val_loss: 1.4863 - val_accuracy: 0.7710\n",
      "Epoch 679/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0691 - accuracy: 0.9806 - val_loss: 1.5078 - val_accuracy: 0.7321\n",
      "Epoch 680/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0575 - accuracy: 0.9833 - val_loss: 1.5997 - val_accuracy: 0.7586\n",
      "Epoch 681/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0693 - accuracy: 0.9739 - val_loss: 1.5940 - val_accuracy: 0.6931\n",
      "Epoch 682/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0513 - accuracy: 0.9840 - val_loss: 1.5524 - val_accuracy: 0.7445\n",
      "Epoch 683/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0490 - accuracy: 0.9840 - val_loss: 1.6537 - val_accuracy: 0.7305\n",
      "Epoch 684/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0574 - accuracy: 0.9786 - val_loss: 1.5934 - val_accuracy: 0.7928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 685/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0439 - accuracy: 0.9860 - val_loss: 1.7950 - val_accuracy: 0.7679\n",
      "Epoch 686/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0462 - accuracy: 0.9840 - val_loss: 1.6622 - val_accuracy: 0.7523\n",
      "Epoch 687/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0444 - accuracy: 0.9853 - val_loss: 1.7159 - val_accuracy: 0.7648\n",
      "Epoch 688/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0605 - accuracy: 0.9759 - val_loss: 1.5736 - val_accuracy: 0.7850\n",
      "Epoch 689/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0421 - accuracy: 0.9846 - val_loss: 1.6233 - val_accuracy: 0.7555\n",
      "Epoch 690/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0616 - accuracy: 0.9793 - val_loss: 1.5766 - val_accuracy: 0.7523\n",
      "Epoch 691/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0480 - accuracy: 0.9806 - val_loss: 1.6643 - val_accuracy: 0.7897\n",
      "Epoch 692/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0620 - accuracy: 0.9846 - val_loss: 1.5847 - val_accuracy: 0.7773\n",
      "Epoch 693/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0432 - accuracy: 0.9826 - val_loss: 1.8032 - val_accuracy: 0.7352\n",
      "Epoch 694/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0470 - accuracy: 0.9840 - val_loss: 1.8199 - val_accuracy: 0.7586\n",
      "Epoch 695/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0501 - accuracy: 0.9826 - val_loss: 1.8466 - val_accuracy: 0.7399\n",
      "Epoch 696/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0633 - accuracy: 0.9806 - val_loss: 1.7270 - val_accuracy: 0.7523\n",
      "Epoch 697/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0483 - accuracy: 0.9840 - val_loss: 1.7213 - val_accuracy: 0.7664\n",
      "Epoch 698/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0809 - accuracy: 0.9739 - val_loss: 1.6649 - val_accuracy: 0.7664\n",
      "Epoch 699/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0486 - accuracy: 0.9786 - val_loss: 1.6842 - val_accuracy: 0.7944\n",
      "Epoch 700/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0538 - accuracy: 0.9820 - val_loss: 1.7191 - val_accuracy: 0.7259\n",
      "Epoch 701/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0722 - accuracy: 0.9773 - val_loss: 1.5752 - val_accuracy: 0.7508\n",
      "Epoch 702/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0396 - accuracy: 0.9860 - val_loss: 1.7380 - val_accuracy: 0.7819\n",
      "Epoch 703/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0463 - accuracy: 0.9880 - val_loss: 1.6220 - val_accuracy: 0.7196\n",
      "Epoch 704/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0546 - accuracy: 0.9813 - val_loss: 1.7339 - val_accuracy: 0.7523\n",
      "Epoch 705/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0356 - accuracy: 0.9866 - val_loss: 1.7513 - val_accuracy: 0.7679\n",
      "Epoch 706/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0409 - accuracy: 0.9880 - val_loss: 1.9141 - val_accuracy: 0.7850\n",
      "Epoch 707/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0419 - accuracy: 0.9860 - val_loss: 1.7424 - val_accuracy: 0.7726\n",
      "Epoch 708/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0673 - accuracy: 0.9766 - val_loss: 1.6222 - val_accuracy: 0.7508\n",
      "Epoch 709/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0456 - accuracy: 0.9833 - val_loss: 1.7285 - val_accuracy: 0.7430\n",
      "Epoch 710/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0473 - accuracy: 0.9820 - val_loss: 1.7470 - val_accuracy: 0.7508\n",
      "Epoch 711/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0525 - accuracy: 0.9840 - val_loss: 1.8319 - val_accuracy: 0.7617\n",
      "Epoch 712/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0606 - accuracy: 0.9759 - val_loss: 1.8531 - val_accuracy: 0.7336\n",
      "Epoch 713/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0518 - accuracy: 0.9813 - val_loss: 1.7168 - val_accuracy: 0.7741\n",
      "Epoch 714/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0385 - accuracy: 0.9886 - val_loss: 1.8216 - val_accuracy: 0.7586\n",
      "Epoch 715/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0790 - accuracy: 0.9799 - val_loss: 1.8055 - val_accuracy: 0.7788\n",
      "Epoch 716/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0435 - accuracy: 0.9833 - val_loss: 1.7197 - val_accuracy: 0.7414\n",
      "Epoch 717/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0524 - accuracy: 0.9813 - val_loss: 1.7600 - val_accuracy: 0.7804\n",
      "Epoch 718/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0375 - accuracy: 0.9873 - val_loss: 1.7324 - val_accuracy: 0.7586\n",
      "Epoch 719/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0298 - accuracy: 0.9860 - val_loss: 1.7807 - val_accuracy: 0.7555\n",
      "Epoch 720/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0723 - accuracy: 0.9820 - val_loss: 1.7171 - val_accuracy: 0.7601\n",
      "Epoch 721/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0586 - accuracy: 0.9820 - val_loss: 1.7163 - val_accuracy: 0.7399\n",
      "Epoch 722/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0445 - accuracy: 0.9880 - val_loss: 1.5876 - val_accuracy: 0.7399\n",
      "Epoch 723/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0397 - accuracy: 0.9840 - val_loss: 1.7666 - val_accuracy: 0.7741\n",
      "Epoch 724/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0581 - accuracy: 0.9826 - val_loss: 1.8643 - val_accuracy: 0.8006\n",
      "Epoch 725/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0416 - accuracy: 0.9813 - val_loss: 1.7182 - val_accuracy: 0.7664\n",
      "Epoch 726/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0610 - accuracy: 0.9773 - val_loss: 1.6348 - val_accuracy: 0.7570\n",
      "Epoch 727/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0608 - accuracy: 0.9813 - val_loss: 1.7424 - val_accuracy: 0.7882\n",
      "Epoch 728/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0630 - accuracy: 0.9826 - val_loss: 1.5718 - val_accuracy: 0.7539\n",
      "Epoch 729/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0427 - accuracy: 0.9840 - val_loss: 1.7159 - val_accuracy: 0.7648\n",
      "Epoch 730/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0327 - accuracy: 0.9900 - val_loss: 1.9012 - val_accuracy: 0.7368\n",
      "Epoch 731/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0602 - accuracy: 0.9826 - val_loss: 1.7160 - val_accuracy: 0.7555\n",
      "Epoch 732/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0594 - accuracy: 0.9820 - val_loss: 1.7793 - val_accuracy: 0.7290\n",
      "Epoch 733/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0382 - accuracy: 0.9853 - val_loss: 1.8968 - val_accuracy: 0.7632\n",
      "Epoch 734/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0442 - accuracy: 0.9880 - val_loss: 1.6307 - val_accuracy: 0.7695\n",
      "Epoch 735/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0402 - accuracy: 0.9853 - val_loss: 1.7267 - val_accuracy: 0.7819\n",
      "Epoch 736/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0567 - accuracy: 0.9766 - val_loss: 1.6814 - val_accuracy: 0.7181\n",
      "Epoch 737/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0386 - accuracy: 0.9860 - val_loss: 1.7365 - val_accuracy: 0.7399\n",
      "Epoch 738/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0710 - accuracy: 0.9739 - val_loss: 1.7354 - val_accuracy: 0.7523\n",
      "Epoch 739/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0422 - accuracy: 0.9853 - val_loss: 1.8234 - val_accuracy: 0.7368\n",
      "Epoch 740/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0547 - accuracy: 0.9806 - val_loss: 1.7230 - val_accuracy: 0.7804\n",
      "Epoch 741/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0533 - accuracy: 0.9840 - val_loss: 1.8604 - val_accuracy: 0.7632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 742/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0421 - accuracy: 0.9860 - val_loss: 1.7146 - val_accuracy: 0.7383\n",
      "Epoch 743/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0529 - accuracy: 0.9820 - val_loss: 1.7023 - val_accuracy: 0.7227\n",
      "Epoch 744/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0653 - accuracy: 0.9813 - val_loss: 1.5270 - val_accuracy: 0.7555\n",
      "Epoch 745/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0559 - accuracy: 0.9866 - val_loss: 1.5340 - val_accuracy: 0.7695\n",
      "Epoch 746/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0427 - accuracy: 0.9846 - val_loss: 1.7650 - val_accuracy: 0.7960\n",
      "Epoch 747/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0525 - accuracy: 0.9820 - val_loss: 1.6648 - val_accuracy: 0.7430\n",
      "Epoch 748/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0545 - accuracy: 0.9779 - val_loss: 1.7325 - val_accuracy: 0.7523\n",
      "Epoch 749/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0431 - accuracy: 0.9820 - val_loss: 1.8308 - val_accuracy: 0.7897\n",
      "Epoch 750/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0521 - accuracy: 0.9826 - val_loss: 1.7676 - val_accuracy: 0.7897\n",
      "Epoch 751/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0309 - accuracy: 0.9886 - val_loss: 1.8544 - val_accuracy: 0.6869\n",
      "Epoch 752/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0382 - accuracy: 0.9860 - val_loss: 1.9494 - val_accuracy: 0.7788\n",
      "Epoch 753/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0715 - accuracy: 0.9793 - val_loss: 1.5920 - val_accuracy: 0.7103\n",
      "Epoch 754/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0552 - accuracy: 0.9826 - val_loss: 1.8383 - val_accuracy: 0.7913\n",
      "Epoch 755/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0442 - accuracy: 0.9846 - val_loss: 1.6051 - val_accuracy: 0.7508\n",
      "Epoch 756/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0669 - accuracy: 0.9826 - val_loss: 1.8060 - val_accuracy: 0.7523\n",
      "Epoch 757/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0590 - accuracy: 0.9820 - val_loss: 1.7719 - val_accuracy: 0.7773\n",
      "Epoch 758/1500\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.0543 - accuracy: 0.9873 - val_loss: 1.7162 - val_accuracy: 0.7773\n",
      "Epoch 759/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0402 - accuracy: 0.9860 - val_loss: 1.6605 - val_accuracy: 0.7726\n",
      "Epoch 760/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0478 - accuracy: 0.9806 - val_loss: 1.7049 - val_accuracy: 0.7523\n",
      "Epoch 761/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0533 - accuracy: 0.9833 - val_loss: 1.7959 - val_accuracy: 0.7882\n",
      "Epoch 762/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0470 - accuracy: 0.9840 - val_loss: 1.7121 - val_accuracy: 0.7617\n",
      "Epoch 763/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0564 - accuracy: 0.9853 - val_loss: 1.6477 - val_accuracy: 0.7570\n",
      "Epoch 764/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0500 - accuracy: 0.9853 - val_loss: 1.8765 - val_accuracy: 0.7352\n",
      "Epoch 765/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0397 - accuracy: 0.9846 - val_loss: 1.8080 - val_accuracy: 0.7632\n",
      "Epoch 766/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0372 - accuracy: 0.9873 - val_loss: 1.9077 - val_accuracy: 0.7835\n",
      "Epoch 767/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0748 - accuracy: 0.9786 - val_loss: 1.7406 - val_accuracy: 0.7617\n",
      "Epoch 768/1500\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.0424 - accuracy: 0.9860 - val_loss: 1.8256 - val_accuracy: 0.7632\n",
      "Epoch 769/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0608 - accuracy: 0.9759 - val_loss: 1.6441 - val_accuracy: 0.7555\n",
      "Epoch 770/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0387 - accuracy: 0.9860 - val_loss: 1.8921 - val_accuracy: 0.7741\n",
      "Epoch 771/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0402 - accuracy: 0.9820 - val_loss: 1.8676 - val_accuracy: 0.7741\n",
      "Epoch 772/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0530 - accuracy: 0.9860 - val_loss: 1.6958 - val_accuracy: 0.7570\n",
      "Epoch 773/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0383 - accuracy: 0.9840 - val_loss: 1.7735 - val_accuracy: 0.7539\n",
      "Epoch 774/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0497 - accuracy: 0.9846 - val_loss: 1.8064 - val_accuracy: 0.7555\n",
      "Epoch 775/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0451 - accuracy: 0.9826 - val_loss: 1.7528 - val_accuracy: 0.7586\n",
      "Epoch 776/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0427 - accuracy: 0.9853 - val_loss: 1.7322 - val_accuracy: 0.7632\n",
      "Epoch 777/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0752 - accuracy: 0.9799 - val_loss: 1.7411 - val_accuracy: 0.7430\n",
      "Epoch 778/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0378 - accuracy: 0.9846 - val_loss: 1.8215 - val_accuracy: 0.7773\n",
      "Epoch 779/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0502 - accuracy: 0.9813 - val_loss: 1.8257 - val_accuracy: 0.7461\n",
      "Epoch 780/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0478 - accuracy: 0.9806 - val_loss: 1.8233 - val_accuracy: 0.7726\n",
      "Epoch 781/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0664 - accuracy: 0.9820 - val_loss: 1.7757 - val_accuracy: 0.7570\n",
      "Epoch 782/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0354 - accuracy: 0.9886 - val_loss: 1.9399 - val_accuracy: 0.7477\n",
      "Epoch 783/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0636 - accuracy: 0.9813 - val_loss: 2.0023 - val_accuracy: 0.7975\n",
      "Epoch 784/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0629 - accuracy: 0.9826 - val_loss: 2.0327 - val_accuracy: 0.7928\n",
      "Epoch 785/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0439 - accuracy: 0.9846 - val_loss: 1.7996 - val_accuracy: 0.7897\n",
      "Epoch 786/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0382 - accuracy: 0.9880 - val_loss: 1.8010 - val_accuracy: 0.7710\n",
      "Epoch 787/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0533 - accuracy: 0.9786 - val_loss: 2.1367 - val_accuracy: 0.7975\n",
      "Epoch 788/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0337 - accuracy: 0.9873 - val_loss: 2.0587 - val_accuracy: 0.7632\n",
      "Epoch 789/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0441 - accuracy: 0.9866 - val_loss: 1.7698 - val_accuracy: 0.7368\n",
      "Epoch 790/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0550 - accuracy: 0.9840 - val_loss: 1.9071 - val_accuracy: 0.7695\n",
      "Epoch 791/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0427 - accuracy: 0.9840 - val_loss: 1.9516 - val_accuracy: 0.7757\n",
      "Epoch 792/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0304 - accuracy: 0.9866 - val_loss: 2.0092 - val_accuracy: 0.7741\n",
      "Epoch 793/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0367 - accuracy: 0.9873 - val_loss: 1.7231 - val_accuracy: 0.7664\n",
      "Epoch 794/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0505 - accuracy: 0.9833 - val_loss: 1.7702 - val_accuracy: 0.7664\n",
      "Epoch 795/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0445 - accuracy: 0.9906 - val_loss: 1.7474 - val_accuracy: 0.7773\n",
      "Epoch 796/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0471 - accuracy: 0.9840 - val_loss: 1.6423 - val_accuracy: 0.7601\n",
      "Epoch 797/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0328 - accuracy: 0.9886 - val_loss: 1.9405 - val_accuracy: 0.7570\n",
      "Epoch 798/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0455 - accuracy: 0.9833 - val_loss: 1.9468 - val_accuracy: 0.7850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 799/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0349 - accuracy: 0.9860 - val_loss: 1.9974 - val_accuracy: 0.7991\n",
      "Epoch 800/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0565 - accuracy: 0.9820 - val_loss: 1.9545 - val_accuracy: 0.7741\n",
      "Epoch 801/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0266 - accuracy: 0.9886 - val_loss: 1.9008 - val_accuracy: 0.7555\n",
      "Epoch 802/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0553 - accuracy: 0.9840 - val_loss: 1.9633 - val_accuracy: 0.7664\n",
      "Epoch 803/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0492 - accuracy: 0.9866 - val_loss: 1.9351 - val_accuracy: 0.7850\n",
      "Epoch 804/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0444 - accuracy: 0.9866 - val_loss: 1.9020 - val_accuracy: 0.7570\n",
      "Epoch 805/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0601 - accuracy: 0.9846 - val_loss: 1.8524 - val_accuracy: 0.7882\n",
      "Epoch 806/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0475 - accuracy: 0.9846 - val_loss: 1.9243 - val_accuracy: 0.7025\n",
      "Epoch 807/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0546 - accuracy: 0.9786 - val_loss: 1.8794 - val_accuracy: 0.7882\n",
      "Epoch 808/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0389 - accuracy: 0.9893 - val_loss: 2.0270 - val_accuracy: 0.7664\n",
      "Epoch 809/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0430 - accuracy: 0.9853 - val_loss: 1.8367 - val_accuracy: 0.7461\n",
      "Epoch 810/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0380 - accuracy: 0.9886 - val_loss: 1.8467 - val_accuracy: 0.7850\n",
      "Epoch 811/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0430 - accuracy: 0.9866 - val_loss: 1.8298 - val_accuracy: 0.7352\n",
      "Epoch 812/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0376 - accuracy: 0.9866 - val_loss: 1.9586 - val_accuracy: 0.7913\n",
      "Epoch 813/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0616 - accuracy: 0.9813 - val_loss: 1.9308 - val_accuracy: 0.7710\n",
      "Epoch 814/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0611 - accuracy: 0.9840 - val_loss: 1.9178 - val_accuracy: 0.7741\n",
      "Epoch 815/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0353 - accuracy: 0.9866 - val_loss: 1.8162 - val_accuracy: 0.7601\n",
      "Epoch 816/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0274 - accuracy: 0.9886 - val_loss: 1.8534 - val_accuracy: 0.7897\n",
      "Epoch 817/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0542 - accuracy: 0.9826 - val_loss: 1.9115 - val_accuracy: 0.7710\n",
      "Epoch 818/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0253 - accuracy: 0.9906 - val_loss: 1.9621 - val_accuracy: 0.7555\n",
      "Epoch 819/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0411 - accuracy: 0.9866 - val_loss: 1.9279 - val_accuracy: 0.7710\n",
      "Epoch 820/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0461 - accuracy: 0.9873 - val_loss: 1.8872 - val_accuracy: 0.7757\n",
      "Epoch 821/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0407 - accuracy: 0.9866 - val_loss: 1.9433 - val_accuracy: 0.7492\n",
      "Epoch 822/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0576 - accuracy: 0.9820 - val_loss: 1.9696 - val_accuracy: 0.7773\n",
      "Epoch 823/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0430 - accuracy: 0.9880 - val_loss: 1.9960 - val_accuracy: 0.7664\n",
      "Epoch 824/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0430 - accuracy: 0.9840 - val_loss: 1.9641 - val_accuracy: 0.7741\n",
      "Epoch 825/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0490 - accuracy: 0.9853 - val_loss: 2.0411 - val_accuracy: 0.7586\n",
      "Epoch 826/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0451 - accuracy: 0.9846 - val_loss: 1.9255 - val_accuracy: 0.7679\n",
      "Epoch 827/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0517 - accuracy: 0.9840 - val_loss: 1.9036 - val_accuracy: 0.7508\n",
      "Epoch 828/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0323 - accuracy: 0.9900 - val_loss: 1.8543 - val_accuracy: 0.7695\n",
      "Epoch 829/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0480 - accuracy: 0.9840 - val_loss: 1.9085 - val_accuracy: 0.7336\n",
      "Epoch 830/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0262 - accuracy: 0.9906 - val_loss: 1.8772 - val_accuracy: 0.7321\n",
      "Epoch 831/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0369 - accuracy: 0.9880 - val_loss: 2.0098 - val_accuracy: 0.7601\n",
      "Epoch 832/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0408 - accuracy: 0.9886 - val_loss: 1.9200 - val_accuracy: 0.7508\n",
      "Epoch 833/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0348 - accuracy: 0.9860 - val_loss: 1.9126 - val_accuracy: 0.7539\n",
      "Epoch 834/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0380 - accuracy: 0.9860 - val_loss: 1.9877 - val_accuracy: 0.7804\n",
      "Epoch 835/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0490 - accuracy: 0.9826 - val_loss: 1.9084 - val_accuracy: 0.7850\n",
      "Epoch 836/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0389 - accuracy: 0.9893 - val_loss: 1.8088 - val_accuracy: 0.7679\n",
      "Epoch 837/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0485 - accuracy: 0.9846 - val_loss: 1.7625 - val_accuracy: 0.7539\n",
      "Epoch 838/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0436 - accuracy: 0.9860 - val_loss: 1.9301 - val_accuracy: 0.7679\n",
      "Epoch 839/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0603 - accuracy: 0.9786 - val_loss: 1.7970 - val_accuracy: 0.7321\n",
      "Epoch 840/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0492 - accuracy: 0.9833 - val_loss: 1.9651 - val_accuracy: 0.7399\n",
      "Epoch 841/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0425 - accuracy: 0.9860 - val_loss: 1.8071 - val_accuracy: 0.7773\n",
      "Epoch 842/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0346 - accuracy: 0.9886 - val_loss: 1.8578 - val_accuracy: 0.7773\n",
      "Epoch 843/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0446 - accuracy: 0.9853 - val_loss: 1.8448 - val_accuracy: 0.7710\n",
      "Epoch 844/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0356 - accuracy: 0.9880 - val_loss: 1.8681 - val_accuracy: 0.7352\n",
      "Epoch 845/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0482 - accuracy: 0.9813 - val_loss: 1.9863 - val_accuracy: 0.7648\n",
      "Epoch 846/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0341 - accuracy: 0.9866 - val_loss: 1.8964 - val_accuracy: 0.7664\n",
      "Epoch 847/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0299 - accuracy: 0.9906 - val_loss: 1.9979 - val_accuracy: 0.7259\n",
      "Epoch 848/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0373 - accuracy: 0.9873 - val_loss: 1.9968 - val_accuracy: 0.7741\n",
      "Epoch 849/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0518 - accuracy: 0.9806 - val_loss: 1.9428 - val_accuracy: 0.7679\n",
      "Epoch 850/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0452 - accuracy: 0.9860 - val_loss: 1.8138 - val_accuracy: 0.7601\n",
      "Epoch 851/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0412 - accuracy: 0.9880 - val_loss: 2.0114 - val_accuracy: 0.7710\n",
      "Epoch 852/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0431 - accuracy: 0.9906 - val_loss: 1.8077 - val_accuracy: 0.7555\n",
      "Epoch 853/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0279 - accuracy: 0.9893 - val_loss: 1.8497 - val_accuracy: 0.7601\n",
      "Epoch 854/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0301 - accuracy: 0.9880 - val_loss: 2.0120 - val_accuracy: 0.7726\n",
      "Epoch 855/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0450 - accuracy: 0.9880 - val_loss: 1.9495 - val_accuracy: 0.7679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 856/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0391 - accuracy: 0.9860 - val_loss: 1.7483 - val_accuracy: 0.7617\n",
      "Epoch 857/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0427 - accuracy: 0.9853 - val_loss: 1.9146 - val_accuracy: 0.7679\n",
      "Epoch 858/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0365 - accuracy: 0.9873 - val_loss: 1.9113 - val_accuracy: 0.7352\n",
      "Epoch 859/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0397 - accuracy: 0.9886 - val_loss: 2.0827 - val_accuracy: 0.7757\n",
      "Epoch 860/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0456 - accuracy: 0.9880 - val_loss: 1.8068 - val_accuracy: 0.7648\n",
      "Epoch 861/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0688 - accuracy: 0.9813 - val_loss: 1.9503 - val_accuracy: 0.7414\n",
      "Epoch 862/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0447 - accuracy: 0.9853 - val_loss: 1.8735 - val_accuracy: 0.7648\n",
      "Epoch 863/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0242 - accuracy: 0.9926 - val_loss: 2.1010 - val_accuracy: 0.7819\n",
      "Epoch 864/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0532 - accuracy: 0.9860 - val_loss: 1.9280 - val_accuracy: 0.7118\n",
      "Epoch 865/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0500 - accuracy: 0.9853 - val_loss: 1.8456 - val_accuracy: 0.7430\n",
      "Epoch 866/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0568 - accuracy: 0.9826 - val_loss: 1.9090 - val_accuracy: 0.7664\n",
      "Epoch 867/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0628 - accuracy: 0.9873 - val_loss: 1.8062 - val_accuracy: 0.7710\n",
      "Epoch 868/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0525 - accuracy: 0.9813 - val_loss: 2.0609 - val_accuracy: 0.7944\n",
      "Epoch 869/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0504 - accuracy: 0.9833 - val_loss: 1.9583 - val_accuracy: 0.7819\n",
      "Epoch 870/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0498 - accuracy: 0.9873 - val_loss: 1.7442 - val_accuracy: 0.7882\n",
      "Epoch 871/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0383 - accuracy: 0.9846 - val_loss: 1.8386 - val_accuracy: 0.7056\n",
      "Epoch 872/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0541 - accuracy: 0.9853 - val_loss: 1.8348 - val_accuracy: 0.7679\n",
      "Epoch 873/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0254 - accuracy: 0.9926 - val_loss: 1.8175 - val_accuracy: 0.7586\n",
      "Epoch 874/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0485 - accuracy: 0.9820 - val_loss: 1.9337 - val_accuracy: 0.7897\n",
      "Epoch 875/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0353 - accuracy: 0.9873 - val_loss: 1.8013 - val_accuracy: 0.7679\n",
      "Epoch 876/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0325 - accuracy: 0.9880 - val_loss: 1.7735 - val_accuracy: 0.7212\n",
      "Epoch 877/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0445 - accuracy: 0.9866 - val_loss: 2.0366 - val_accuracy: 0.7788\n",
      "Epoch 878/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0253 - accuracy: 0.9913 - val_loss: 2.0013 - val_accuracy: 0.7648\n",
      "Epoch 879/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0354 - accuracy: 0.9880 - val_loss: 2.0758 - val_accuracy: 0.7710\n",
      "Epoch 880/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0729 - accuracy: 0.9799 - val_loss: 1.8353 - val_accuracy: 0.7508\n",
      "Epoch 881/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0311 - accuracy: 0.9886 - val_loss: 1.8579 - val_accuracy: 0.7866\n",
      "Epoch 882/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0427 - accuracy: 0.9833 - val_loss: 1.9359 - val_accuracy: 0.7586\n",
      "Epoch 883/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0365 - accuracy: 0.9900 - val_loss: 2.0253 - val_accuracy: 0.7975\n",
      "Epoch 884/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0576 - accuracy: 0.9786 - val_loss: 1.8282 - val_accuracy: 0.7445\n",
      "Epoch 885/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0463 - accuracy: 0.9826 - val_loss: 2.0824 - val_accuracy: 0.7804\n",
      "Epoch 886/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0494 - accuracy: 0.9846 - val_loss: 1.9136 - val_accuracy: 0.7430\n",
      "Epoch 887/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0405 - accuracy: 0.9886 - val_loss: 1.8475 - val_accuracy: 0.7477\n",
      "Epoch 888/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0514 - accuracy: 0.9880 - val_loss: 1.6309 - val_accuracy: 0.7648\n",
      "Epoch 889/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0352 - accuracy: 0.9900 - val_loss: 1.7778 - val_accuracy: 0.7882\n",
      "Epoch 890/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0348 - accuracy: 0.9913 - val_loss: 2.2130 - val_accuracy: 0.7835\n",
      "Epoch 891/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0433 - accuracy: 0.9853 - val_loss: 1.8596 - val_accuracy: 0.7368\n",
      "Epoch 892/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0511 - accuracy: 0.9853 - val_loss: 1.7867 - val_accuracy: 0.7383\n",
      "Epoch 893/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0265 - accuracy: 0.9920 - val_loss: 1.7269 - val_accuracy: 0.7508\n",
      "Epoch 894/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0338 - accuracy: 0.9906 - val_loss: 1.8369 - val_accuracy: 0.7679\n",
      "Epoch 895/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0328 - accuracy: 0.9866 - val_loss: 2.0309 - val_accuracy: 0.7648\n",
      "Epoch 896/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0150 - accuracy: 0.9960 - val_loss: 1.9962 - val_accuracy: 0.7196\n",
      "Epoch 897/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0416 - accuracy: 0.9880 - val_loss: 1.9508 - val_accuracy: 0.7679\n",
      "Epoch 898/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0475 - accuracy: 0.9886 - val_loss: 1.7583 - val_accuracy: 0.7508\n",
      "Epoch 899/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0416 - accuracy: 0.9886 - val_loss: 1.8864 - val_accuracy: 0.7866\n",
      "Epoch 900/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0496 - accuracy: 0.9853 - val_loss: 1.8233 - val_accuracy: 0.7726\n",
      "Epoch 901/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0387 - accuracy: 0.9840 - val_loss: 2.0815 - val_accuracy: 0.7773\n",
      "Epoch 902/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0290 - accuracy: 0.9920 - val_loss: 1.8945 - val_accuracy: 0.7695\n",
      "Epoch 903/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0349 - accuracy: 0.9886 - val_loss: 2.0711 - val_accuracy: 0.7882\n",
      "Epoch 904/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0377 - accuracy: 0.9866 - val_loss: 2.0247 - val_accuracy: 0.7445\n",
      "Epoch 905/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0277 - accuracy: 0.9886 - val_loss: 2.0021 - val_accuracy: 0.7399\n",
      "Epoch 906/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0311 - accuracy: 0.9880 - val_loss: 2.1802 - val_accuracy: 0.7570\n",
      "Epoch 907/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0523 - accuracy: 0.9866 - val_loss: 2.0022 - val_accuracy: 0.7866\n",
      "Epoch 908/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0295 - accuracy: 0.9920 - val_loss: 2.0226 - val_accuracy: 0.7399\n",
      "Epoch 909/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0408 - accuracy: 0.9873 - val_loss: 1.9108 - val_accuracy: 0.7617\n",
      "Epoch 910/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0386 - accuracy: 0.9880 - val_loss: 1.9784 - val_accuracy: 0.7664\n",
      "Epoch 911/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0261 - accuracy: 0.9926 - val_loss: 2.0509 - val_accuracy: 0.7570\n",
      "Epoch 912/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0279 - accuracy: 0.9900 - val_loss: 1.9450 - val_accuracy: 0.7601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 913/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0299 - accuracy: 0.9893 - val_loss: 2.1914 - val_accuracy: 0.7570\n",
      "Epoch 914/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0367 - accuracy: 0.9860 - val_loss: 1.9834 - val_accuracy: 0.7664\n",
      "Epoch 915/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0494 - accuracy: 0.9893 - val_loss: 1.8924 - val_accuracy: 0.7586\n",
      "Epoch 916/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0456 - accuracy: 0.9853 - val_loss: 1.8055 - val_accuracy: 0.7508\n",
      "Epoch 917/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0461 - accuracy: 0.9860 - val_loss: 1.8703 - val_accuracy: 0.7539\n",
      "Epoch 918/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0448 - accuracy: 0.9866 - val_loss: 2.0416 - val_accuracy: 0.7679\n",
      "Epoch 919/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0498 - accuracy: 0.9893 - val_loss: 1.8901 - val_accuracy: 0.7710\n",
      "Epoch 920/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0574 - accuracy: 0.9840 - val_loss: 1.9266 - val_accuracy: 0.7305\n",
      "Epoch 921/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0341 - accuracy: 0.9893 - val_loss: 1.9313 - val_accuracy: 0.7539\n",
      "Epoch 922/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0275 - accuracy: 0.9940 - val_loss: 1.8258 - val_accuracy: 0.7445\n",
      "Epoch 923/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0448 - accuracy: 0.9833 - val_loss: 1.9249 - val_accuracy: 0.7461\n",
      "Epoch 924/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0313 - accuracy: 0.9886 - val_loss: 1.9971 - val_accuracy: 0.7757\n",
      "Epoch 925/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0414 - accuracy: 0.9880 - val_loss: 2.0289 - val_accuracy: 0.7913\n",
      "Epoch 926/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0260 - accuracy: 0.9886 - val_loss: 1.9956 - val_accuracy: 0.7773\n",
      "Epoch 927/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0461 - accuracy: 0.9840 - val_loss: 1.9438 - val_accuracy: 0.7539\n",
      "Epoch 928/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0322 - accuracy: 0.9893 - val_loss: 2.0356 - val_accuracy: 0.7726\n",
      "Epoch 929/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0332 - accuracy: 0.9873 - val_loss: 1.9424 - val_accuracy: 0.7835\n",
      "Epoch 930/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0607 - accuracy: 0.9813 - val_loss: 2.0809 - val_accuracy: 0.7757\n",
      "Epoch 931/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0505 - accuracy: 0.9840 - val_loss: 2.0950 - val_accuracy: 0.7741\n",
      "Epoch 932/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0252 - accuracy: 0.9893 - val_loss: 2.1921 - val_accuracy: 0.7882\n",
      "Epoch 933/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0693 - accuracy: 0.9826 - val_loss: 2.1162 - val_accuracy: 0.7664\n",
      "Epoch 934/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0343 - accuracy: 0.9886 - val_loss: 2.0243 - val_accuracy: 0.7601\n",
      "Epoch 935/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0428 - accuracy: 0.9853 - val_loss: 2.0071 - val_accuracy: 0.7757\n",
      "Epoch 936/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0382 - accuracy: 0.9853 - val_loss: 1.9786 - val_accuracy: 0.7586\n",
      "Epoch 937/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0354 - accuracy: 0.9853 - val_loss: 2.1003 - val_accuracy: 0.7290\n",
      "Epoch 938/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0515 - accuracy: 0.9833 - val_loss: 2.2009 - val_accuracy: 0.7850\n",
      "Epoch 939/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0411 - accuracy: 0.9833 - val_loss: 2.0063 - val_accuracy: 0.7695\n",
      "Epoch 940/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0335 - accuracy: 0.9873 - val_loss: 2.1584 - val_accuracy: 0.7882\n",
      "Epoch 941/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0470 - accuracy: 0.9880 - val_loss: 2.1703 - val_accuracy: 0.7882\n",
      "Epoch 942/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0380 - accuracy: 0.9860 - val_loss: 1.8969 - val_accuracy: 0.7741\n",
      "Epoch 943/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0290 - accuracy: 0.9926 - val_loss: 1.8808 - val_accuracy: 0.7601\n",
      "Epoch 944/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0286 - accuracy: 0.9900 - val_loss: 2.0910 - val_accuracy: 0.7897\n",
      "Epoch 945/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0456 - accuracy: 0.9866 - val_loss: 1.9101 - val_accuracy: 0.7165\n",
      "Epoch 946/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0272 - accuracy: 0.9900 - val_loss: 1.9921 - val_accuracy: 0.7882\n",
      "Epoch 947/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0454 - accuracy: 0.9873 - val_loss: 1.9932 - val_accuracy: 0.7601\n",
      "Epoch 948/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0265 - accuracy: 0.9906 - val_loss: 1.9506 - val_accuracy: 0.7336\n",
      "Epoch 949/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0275 - accuracy: 0.9900 - val_loss: 1.9588 - val_accuracy: 0.7679\n",
      "Epoch 950/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0300 - accuracy: 0.9886 - val_loss: 1.9204 - val_accuracy: 0.7664\n",
      "Epoch 951/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0358 - accuracy: 0.9913 - val_loss: 2.0138 - val_accuracy: 0.7726\n",
      "Epoch 952/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0475 - accuracy: 0.9860 - val_loss: 1.8421 - val_accuracy: 0.7445\n",
      "Epoch 953/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0402 - accuracy: 0.9880 - val_loss: 1.8066 - val_accuracy: 0.7430\n",
      "Epoch 954/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0326 - accuracy: 0.9900 - val_loss: 1.9274 - val_accuracy: 0.7804\n",
      "Epoch 955/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0373 - accuracy: 0.9853 - val_loss: 2.0374 - val_accuracy: 0.7960\n",
      "Epoch 956/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0380 - accuracy: 0.9873 - val_loss: 1.9448 - val_accuracy: 0.6900\n",
      "Epoch 957/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0397 - accuracy: 0.9866 - val_loss: 2.0007 - val_accuracy: 0.7679\n",
      "Epoch 958/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0510 - accuracy: 0.9873 - val_loss: 1.9213 - val_accuracy: 0.7695\n",
      "Epoch 959/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0282 - accuracy: 0.9920 - val_loss: 1.8429 - val_accuracy: 0.7601\n",
      "Epoch 960/1500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0441 - accuracy: 0.9886 - val_loss: 1.8689 - val_accuracy: 0.7492\n",
      "Epoch 961/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0396 - accuracy: 0.9833 - val_loss: 1.9805 - val_accuracy: 0.7445\n",
      "Epoch 962/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0288 - accuracy: 0.9906 - val_loss: 2.1000 - val_accuracy: 0.7570\n",
      "Epoch 963/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0471 - accuracy: 0.9860 - val_loss: 1.9580 - val_accuracy: 0.7695\n",
      "Epoch 964/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0417 - accuracy: 0.9880 - val_loss: 1.9833 - val_accuracy: 0.7679\n",
      "Epoch 965/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0280 - accuracy: 0.9906 - val_loss: 1.9725 - val_accuracy: 0.7523\n",
      "Epoch 966/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0268 - accuracy: 0.9906 - val_loss: 2.1020 - val_accuracy: 0.7710\n",
      "Epoch 967/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0266 - accuracy: 0.9926 - val_loss: 1.9995 - val_accuracy: 0.7586\n",
      "Epoch 968/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0351 - accuracy: 0.9886 - val_loss: 1.9623 - val_accuracy: 0.7664\n",
      "Epoch 969/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0338 - accuracy: 0.9880 - val_loss: 2.0278 - val_accuracy: 0.7336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 970/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0384 - accuracy: 0.9860 - val_loss: 1.9906 - val_accuracy: 0.7695\n",
      "Epoch 971/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0345 - accuracy: 0.9886 - val_loss: 1.9402 - val_accuracy: 0.7741\n",
      "Epoch 972/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0369 - accuracy: 0.9846 - val_loss: 1.9464 - val_accuracy: 0.7274\n",
      "Epoch 973/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0439 - accuracy: 0.9866 - val_loss: 1.9154 - val_accuracy: 0.7508\n",
      "Epoch 974/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0320 - accuracy: 0.9900 - val_loss: 1.7536 - val_accuracy: 0.7664\n",
      "Epoch 975/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0392 - accuracy: 0.9900 - val_loss: 1.8761 - val_accuracy: 0.7570\n",
      "Epoch 976/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0257 - accuracy: 0.9906 - val_loss: 1.9543 - val_accuracy: 0.7741\n",
      "Epoch 977/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0388 - accuracy: 0.9893 - val_loss: 2.0213 - val_accuracy: 0.7897\n",
      "Epoch 978/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0407 - accuracy: 0.9873 - val_loss: 2.1059 - val_accuracy: 0.7617\n",
      "Epoch 979/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0351 - accuracy: 0.9913 - val_loss: 2.0719 - val_accuracy: 0.7850\n",
      "Epoch 980/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0237 - accuracy: 0.9906 - val_loss: 2.0799 - val_accuracy: 0.7741\n",
      "Epoch 981/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0461 - accuracy: 0.9826 - val_loss: 2.0263 - val_accuracy: 0.7882\n",
      "Epoch 982/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0249 - accuracy: 0.9933 - val_loss: 2.3113 - val_accuracy: 0.7866\n",
      "Epoch 983/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0372 - accuracy: 0.9866 - val_loss: 2.1621 - val_accuracy: 0.7928\n",
      "Epoch 984/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0449 - accuracy: 0.9853 - val_loss: 2.2529 - val_accuracy: 0.7897\n",
      "Epoch 985/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0346 - accuracy: 0.9886 - val_loss: 2.2803 - val_accuracy: 0.7866\n",
      "Epoch 986/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0367 - accuracy: 0.9900 - val_loss: 2.2249 - val_accuracy: 0.7804\n",
      "Epoch 987/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0246 - accuracy: 0.9933 - val_loss: 2.0234 - val_accuracy: 0.7773\n",
      "Epoch 988/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0403 - accuracy: 0.9826 - val_loss: 2.1927 - val_accuracy: 0.7897\n",
      "Epoch 989/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0349 - accuracy: 0.9866 - val_loss: 2.2075 - val_accuracy: 0.7897\n",
      "Epoch 990/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0215 - accuracy: 0.9906 - val_loss: 2.1675 - val_accuracy: 0.7804\n",
      "Epoch 991/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0221 - accuracy: 0.9933 - val_loss: 2.1806 - val_accuracy: 0.7882\n",
      "Epoch 992/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0312 - accuracy: 0.9873 - val_loss: 2.1508 - val_accuracy: 0.7819\n",
      "Epoch 993/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0391 - accuracy: 0.9913 - val_loss: 2.0295 - val_accuracy: 0.7835\n",
      "Epoch 994/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0393 - accuracy: 0.9873 - val_loss: 2.0330 - val_accuracy: 0.7850\n",
      "Epoch 995/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0462 - accuracy: 0.9820 - val_loss: 2.0765 - val_accuracy: 0.7741\n",
      "Epoch 996/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0350 - accuracy: 0.9886 - val_loss: 2.0003 - val_accuracy: 0.7710\n",
      "Epoch 997/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0374 - accuracy: 0.9873 - val_loss: 1.9869 - val_accuracy: 0.7710\n",
      "Epoch 998/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0215 - accuracy: 0.9920 - val_loss: 2.0366 - val_accuracy: 0.7679\n",
      "Epoch 999/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0485 - accuracy: 0.9873 - val_loss: 2.1155 - val_accuracy: 0.7866\n",
      "Epoch 1000/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0254 - accuracy: 0.9900 - val_loss: 2.1290 - val_accuracy: 0.7586\n",
      "Epoch 1001/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0279 - accuracy: 0.9913 - val_loss: 2.3510 - val_accuracy: 0.7944\n",
      "Epoch 1002/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0272 - accuracy: 0.9900 - val_loss: 2.1775 - val_accuracy: 0.7617\n",
      "Epoch 1003/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0336 - accuracy: 0.9886 - val_loss: 2.1920 - val_accuracy: 0.7960\n",
      "Epoch 1004/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0467 - accuracy: 0.9860 - val_loss: 2.0408 - val_accuracy: 0.7913\n",
      "Epoch 1005/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0188 - accuracy: 0.9920 - val_loss: 2.0720 - val_accuracy: 0.7523\n",
      "Epoch 1006/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0354 - accuracy: 0.9900 - val_loss: 2.1138 - val_accuracy: 0.7445\n",
      "Epoch 1007/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0395 - accuracy: 0.9860 - val_loss: 2.0925 - val_accuracy: 0.7648\n",
      "Epoch 1008/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0214 - accuracy: 0.9933 - val_loss: 2.1980 - val_accuracy: 0.7897\n",
      "Epoch 1009/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0421 - accuracy: 0.9860 - val_loss: 2.0725 - val_accuracy: 0.7710\n",
      "Epoch 1010/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0206 - accuracy: 0.9947 - val_loss: 2.2353 - val_accuracy: 0.7866\n",
      "Epoch 1011/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0476 - accuracy: 0.9860 - val_loss: 2.0983 - val_accuracy: 0.7664\n",
      "Epoch 1012/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0466 - accuracy: 0.9860 - val_loss: 2.0437 - val_accuracy: 0.7850\n",
      "Epoch 1013/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0392 - accuracy: 0.9926 - val_loss: 1.9984 - val_accuracy: 0.7726\n",
      "Epoch 1014/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0510 - accuracy: 0.9906 - val_loss: 2.2374 - val_accuracy: 0.7773\n",
      "Epoch 1015/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0300 - accuracy: 0.9913 - val_loss: 2.1471 - val_accuracy: 0.7757\n",
      "Epoch 1016/1500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0254 - accuracy: 0.9913 - val_loss: 1.9996 - val_accuracy: 0.7664\n",
      "Epoch 1017/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0352 - accuracy: 0.9886 - val_loss: 2.1491 - val_accuracy: 0.7586\n",
      "Epoch 1018/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0377 - accuracy: 0.9873 - val_loss: 2.2069 - val_accuracy: 0.7882\n",
      "Epoch 1019/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0270 - accuracy: 0.9920 - val_loss: 2.2432 - val_accuracy: 0.7928\n",
      "Epoch 1020/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0406 - accuracy: 0.9893 - val_loss: 2.2143 - val_accuracy: 0.7882\n",
      "Epoch 1021/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0244 - accuracy: 0.9920 - val_loss: 2.2053 - val_accuracy: 0.7913\n",
      "Epoch 1022/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0350 - accuracy: 0.9906 - val_loss: 2.2496 - val_accuracy: 0.7695\n",
      "Epoch 1023/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0478 - accuracy: 0.9846 - val_loss: 2.2644 - val_accuracy: 0.7882\n",
      "Epoch 1024/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0336 - accuracy: 0.9880 - val_loss: 2.6770 - val_accuracy: 0.7975\n",
      "Epoch 1025/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0499 - accuracy: 0.9886 - val_loss: 2.0943 - val_accuracy: 0.7788\n",
      "Epoch 1026/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0342 - accuracy: 0.9880 - val_loss: 2.0517 - val_accuracy: 0.7445\n",
      "Epoch 1027/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0486 - accuracy: 0.9860 - val_loss: 2.2400 - val_accuracy: 0.7913\n",
      "Epoch 1028/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0353 - accuracy: 0.9886 - val_loss: 2.1461 - val_accuracy: 0.7773\n",
      "Epoch 1029/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0398 - accuracy: 0.9893 - val_loss: 2.0549 - val_accuracy: 0.7601\n",
      "Epoch 1030/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0150 - accuracy: 0.9940 - val_loss: 1.9790 - val_accuracy: 0.7835\n",
      "Epoch 1031/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0313 - accuracy: 0.9913 - val_loss: 1.9316 - val_accuracy: 0.7648\n",
      "Epoch 1032/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0411 - accuracy: 0.9893 - val_loss: 2.0948 - val_accuracy: 0.7710\n",
      "Epoch 1033/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0342 - accuracy: 0.9880 - val_loss: 2.3914 - val_accuracy: 0.8069\n",
      "Epoch 1034/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0345 - accuracy: 0.9866 - val_loss: 2.1853 - val_accuracy: 0.7928\n",
      "Epoch 1035/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0305 - accuracy: 0.9880 - val_loss: 2.1904 - val_accuracy: 0.7835\n",
      "Epoch 1036/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0342 - accuracy: 0.9886 - val_loss: 2.1913 - val_accuracy: 0.7913\n",
      "Epoch 1037/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0226 - accuracy: 0.9913 - val_loss: 2.3160 - val_accuracy: 0.7773\n",
      "Epoch 1038/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0399 - accuracy: 0.9906 - val_loss: 2.2659 - val_accuracy: 0.7586\n",
      "Epoch 1039/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0386 - accuracy: 0.9886 - val_loss: 2.1845 - val_accuracy: 0.7570\n",
      "Epoch 1040/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0298 - accuracy: 0.9926 - val_loss: 2.3825 - val_accuracy: 0.7928\n",
      "Epoch 1041/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0258 - accuracy: 0.9900 - val_loss: 2.1341 - val_accuracy: 0.7570\n",
      "Epoch 1042/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0332 - accuracy: 0.9853 - val_loss: 2.0338 - val_accuracy: 0.7648\n",
      "Epoch 1043/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0281 - accuracy: 0.9900 - val_loss: 2.4336 - val_accuracy: 0.7679\n",
      "Epoch 1044/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0429 - accuracy: 0.9873 - val_loss: 2.5182 - val_accuracy: 0.8006\n",
      "Epoch 1045/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0210 - accuracy: 0.9913 - val_loss: 2.1684 - val_accuracy: 0.7741\n",
      "Epoch 1046/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0207 - accuracy: 0.9920 - val_loss: 2.1592 - val_accuracy: 0.7243\n",
      "Epoch 1047/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0312 - accuracy: 0.9873 - val_loss: 2.1245 - val_accuracy: 0.7570\n",
      "Epoch 1048/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0322 - accuracy: 0.9933 - val_loss: 2.6094 - val_accuracy: 0.8022\n",
      "Epoch 1049/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0415 - accuracy: 0.9880 - val_loss: 2.0876 - val_accuracy: 0.7383\n",
      "Epoch 1050/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0614 - accuracy: 0.9826 - val_loss: 1.9894 - val_accuracy: 0.7523\n",
      "Epoch 1051/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0229 - accuracy: 0.9926 - val_loss: 2.1556 - val_accuracy: 0.7648\n",
      "Epoch 1052/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0244 - accuracy: 0.9920 - val_loss: 2.0466 - val_accuracy: 0.7445\n",
      "Epoch 1053/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0288 - accuracy: 0.9873 - val_loss: 2.1010 - val_accuracy: 0.7632\n",
      "Epoch 1054/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0369 - accuracy: 0.9913 - val_loss: 2.1722 - val_accuracy: 0.7321\n",
      "Epoch 1055/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0183 - accuracy: 0.9913 - val_loss: 2.1945 - val_accuracy: 0.7617\n",
      "Epoch 1056/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0303 - accuracy: 0.9933 - val_loss: 2.2808 - val_accuracy: 0.7648\n",
      "Epoch 1057/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0318 - accuracy: 0.9900 - val_loss: 2.2895 - val_accuracy: 0.7617\n",
      "Epoch 1058/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0384 - accuracy: 0.9873 - val_loss: 2.2589 - val_accuracy: 0.7773\n",
      "Epoch 1059/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0362 - accuracy: 0.9880 - val_loss: 2.0846 - val_accuracy: 0.7679\n",
      "Epoch 1060/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0186 - accuracy: 0.9933 - val_loss: 2.2806 - val_accuracy: 0.7492\n",
      "Epoch 1061/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0363 - accuracy: 0.9900 - val_loss: 2.1611 - val_accuracy: 0.7539\n",
      "Epoch 1062/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0366 - accuracy: 0.9900 - val_loss: 2.1878 - val_accuracy: 0.7835\n",
      "Epoch 1063/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0238 - accuracy: 0.9913 - val_loss: 2.1816 - val_accuracy: 0.7523\n",
      "Epoch 1064/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0233 - accuracy: 0.9913 - val_loss: 2.2572 - val_accuracy: 0.7368\n",
      "Epoch 1065/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0389 - accuracy: 0.9893 - val_loss: 2.3002 - val_accuracy: 0.7586\n",
      "Epoch 1066/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0406 - accuracy: 0.9900 - val_loss: 2.2478 - val_accuracy: 0.7773\n",
      "Epoch 1067/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0310 - accuracy: 0.9900 - val_loss: 2.1507 - val_accuracy: 0.7928\n",
      "Epoch 1068/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0340 - accuracy: 0.9893 - val_loss: 2.1041 - val_accuracy: 0.7477\n",
      "Epoch 1069/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0526 - accuracy: 0.9866 - val_loss: 2.2031 - val_accuracy: 0.7975\n",
      "Epoch 1070/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0256 - accuracy: 0.9920 - val_loss: 2.1389 - val_accuracy: 0.7632\n",
      "Epoch 1071/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0211 - accuracy: 0.9933 - val_loss: 2.1697 - val_accuracy: 0.7539\n",
      "Epoch 1072/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0478 - accuracy: 0.9860 - val_loss: 2.1415 - val_accuracy: 0.7695\n",
      "Epoch 1073/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0316 - accuracy: 0.9906 - val_loss: 2.2853 - val_accuracy: 0.7850\n",
      "Epoch 1074/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0242 - accuracy: 0.9926 - val_loss: 2.2752 - val_accuracy: 0.7710\n",
      "Epoch 1075/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0226 - accuracy: 0.9947 - val_loss: 2.4454 - val_accuracy: 0.7835\n",
      "Epoch 1076/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0606 - accuracy: 0.9833 - val_loss: 2.2513 - val_accuracy: 0.7617\n",
      "Epoch 1077/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0268 - accuracy: 0.9873 - val_loss: 2.2570 - val_accuracy: 0.7710\n",
      "Epoch 1078/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0466 - accuracy: 0.9886 - val_loss: 2.1753 - val_accuracy: 0.7632\n",
      "Epoch 1079/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0237 - accuracy: 0.9913 - val_loss: 2.2716 - val_accuracy: 0.7835\n",
      "Epoch 1080/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0254 - accuracy: 0.9906 - val_loss: 2.1680 - val_accuracy: 0.7835\n",
      "Epoch 1081/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0295 - accuracy: 0.9913 - val_loss: 2.2325 - val_accuracy: 0.7710\n",
      "Epoch 1082/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0363 - accuracy: 0.9880 - val_loss: 2.0617 - val_accuracy: 0.7991\n",
      "Epoch 1083/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0437 - accuracy: 0.9846 - val_loss: 2.0049 - val_accuracy: 0.7508\n",
      "Epoch 1084/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0216 - accuracy: 0.9926 - val_loss: 2.1446 - val_accuracy: 0.7835\n",
      "Epoch 1085/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0306 - accuracy: 0.9926 - val_loss: 2.1373 - val_accuracy: 0.7928\n",
      "Epoch 1086/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0370 - accuracy: 0.9880 - val_loss: 2.1388 - val_accuracy: 0.7741\n",
      "Epoch 1087/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0216 - accuracy: 0.9913 - val_loss: 2.3567 - val_accuracy: 0.7897\n",
      "Epoch 1088/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0173 - accuracy: 0.9940 - val_loss: 2.2629 - val_accuracy: 0.7757\n",
      "Epoch 1089/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0298 - accuracy: 0.9906 - val_loss: 2.3118 - val_accuracy: 0.7835\n",
      "Epoch 1090/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0459 - accuracy: 0.9840 - val_loss: 2.0837 - val_accuracy: 0.7788\n",
      "Epoch 1091/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0126 - accuracy: 0.9947 - val_loss: 2.1909 - val_accuracy: 0.7804\n",
      "Epoch 1092/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0493 - accuracy: 0.9853 - val_loss: 2.2993 - val_accuracy: 0.7492\n",
      "Epoch 1093/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0335 - accuracy: 0.9906 - val_loss: 2.3533 - val_accuracy: 0.7741\n",
      "Epoch 1094/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0262 - accuracy: 0.9920 - val_loss: 2.3750 - val_accuracy: 0.7835\n",
      "Epoch 1095/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0398 - accuracy: 0.9880 - val_loss: 2.3739 - val_accuracy: 0.7850\n",
      "Epoch 1096/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0187 - accuracy: 0.9940 - val_loss: 2.3471 - val_accuracy: 0.7804\n",
      "Epoch 1097/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0263 - accuracy: 0.9880 - val_loss: 2.2869 - val_accuracy: 0.7819\n",
      "Epoch 1098/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0253 - accuracy: 0.9920 - val_loss: 2.2707 - val_accuracy: 0.7710\n",
      "Epoch 1099/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0210 - accuracy: 0.9906 - val_loss: 2.2794 - val_accuracy: 0.7648\n",
      "Epoch 1100/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0324 - accuracy: 0.9886 - val_loss: 2.2272 - val_accuracy: 0.7835\n",
      "Epoch 1101/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0422 - accuracy: 0.9866 - val_loss: 2.1020 - val_accuracy: 0.7523\n",
      "Epoch 1102/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0464 - accuracy: 0.9866 - val_loss: 2.2470 - val_accuracy: 0.7804\n",
      "Epoch 1103/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0288 - accuracy: 0.9913 - val_loss: 2.2368 - val_accuracy: 0.7648\n",
      "Epoch 1104/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0243 - accuracy: 0.9920 - val_loss: 2.2699 - val_accuracy: 0.7632\n",
      "Epoch 1105/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0329 - accuracy: 0.9900 - val_loss: 2.3084 - val_accuracy: 0.7601\n",
      "Epoch 1106/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0231 - accuracy: 0.9933 - val_loss: 2.1562 - val_accuracy: 0.7399\n",
      "Epoch 1107/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0324 - accuracy: 0.9920 - val_loss: 2.2138 - val_accuracy: 0.7882\n",
      "Epoch 1108/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0282 - accuracy: 0.9913 - val_loss: 2.1183 - val_accuracy: 0.7601\n",
      "Epoch 1109/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0356 - accuracy: 0.9886 - val_loss: 2.0700 - val_accuracy: 0.7695\n",
      "Epoch 1110/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0191 - accuracy: 0.9933 - val_loss: 2.1690 - val_accuracy: 0.8006\n",
      "Epoch 1111/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0282 - accuracy: 0.9913 - val_loss: 2.1571 - val_accuracy: 0.7430\n",
      "Epoch 1112/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0319 - accuracy: 0.9920 - val_loss: 2.1580 - val_accuracy: 0.7648\n",
      "Epoch 1113/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0254 - accuracy: 0.9893 - val_loss: 2.2398 - val_accuracy: 0.7726\n",
      "Epoch 1114/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0310 - accuracy: 0.9873 - val_loss: 2.1352 - val_accuracy: 0.7508\n",
      "Epoch 1115/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0230 - accuracy: 0.9933 - val_loss: 2.4638 - val_accuracy: 0.7882\n",
      "Epoch 1116/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0389 - accuracy: 0.9880 - val_loss: 2.3437 - val_accuracy: 0.7632\n",
      "Epoch 1117/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0215 - accuracy: 0.9947 - val_loss: 2.3542 - val_accuracy: 0.7632\n",
      "Epoch 1118/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0211 - accuracy: 0.9933 - val_loss: 2.1846 - val_accuracy: 0.7866\n",
      "Epoch 1119/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0245 - accuracy: 0.9906 - val_loss: 2.4133 - val_accuracy: 0.7897\n",
      "Epoch 1120/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0177 - accuracy: 0.9933 - val_loss: 2.2708 - val_accuracy: 0.7850\n",
      "Epoch 1121/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0239 - accuracy: 0.9913 - val_loss: 2.1451 - val_accuracy: 0.7679\n",
      "Epoch 1122/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0376 - accuracy: 0.9913 - val_loss: 2.3397 - val_accuracy: 0.7804\n",
      "Epoch 1123/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0403 - accuracy: 0.9906 - val_loss: 2.3196 - val_accuracy: 0.7850\n",
      "Epoch 1124/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0375 - accuracy: 0.9873 - val_loss: 2.1024 - val_accuracy: 0.7664\n",
      "Epoch 1125/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0444 - accuracy: 0.9866 - val_loss: 1.8854 - val_accuracy: 0.7601\n",
      "Epoch 1126/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0201 - accuracy: 0.9933 - val_loss: 2.1223 - val_accuracy: 0.7336\n",
      "Epoch 1127/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0330 - accuracy: 0.9880 - val_loss: 2.1364 - val_accuracy: 0.7601\n",
      "Epoch 1128/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0283 - accuracy: 0.9940 - val_loss: 2.0948 - val_accuracy: 0.7523\n",
      "Epoch 1129/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0304 - accuracy: 0.9926 - val_loss: 2.3179 - val_accuracy: 0.7523\n",
      "Epoch 1130/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0183 - accuracy: 0.9960 - val_loss: 2.5134 - val_accuracy: 0.7773\n",
      "Epoch 1131/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0192 - accuracy: 0.9926 - val_loss: 2.4199 - val_accuracy: 0.7882\n",
      "Epoch 1132/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0319 - accuracy: 0.9913 - val_loss: 2.2874 - val_accuracy: 0.7695\n",
      "Epoch 1133/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0320 - accuracy: 0.9900 - val_loss: 2.3623 - val_accuracy: 0.7788\n",
      "Epoch 1134/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0199 - accuracy: 0.9913 - val_loss: 2.4530 - val_accuracy: 0.7960\n",
      "Epoch 1135/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0205 - accuracy: 0.9893 - val_loss: 2.1669 - val_accuracy: 0.7757\n",
      "Epoch 1136/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0335 - accuracy: 0.9900 - val_loss: 2.3068 - val_accuracy: 0.7835\n",
      "Epoch 1137/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0280 - accuracy: 0.9900 - val_loss: 2.3156 - val_accuracy: 0.7773\n",
      "Epoch 1138/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0277 - accuracy: 0.9900 - val_loss: 2.2450 - val_accuracy: 0.7664\n",
      "Epoch 1139/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0356 - accuracy: 0.9893 - val_loss: 2.3802 - val_accuracy: 0.7913\n",
      "Epoch 1140/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0241 - accuracy: 0.9947 - val_loss: 2.3261 - val_accuracy: 0.7648\n",
      "Epoch 1141/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0313 - accuracy: 0.9900 - val_loss: 2.1020 - val_accuracy: 0.7664\n",
      "Epoch 1142/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0316 - accuracy: 0.9920 - val_loss: 2.1545 - val_accuracy: 0.7788\n",
      "Epoch 1143/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0322 - accuracy: 0.9913 - val_loss: 2.1827 - val_accuracy: 0.7866\n",
      "Epoch 1144/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0183 - accuracy: 0.9920 - val_loss: 2.1880 - val_accuracy: 0.7741\n",
      "Epoch 1145/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0361 - accuracy: 0.9886 - val_loss: 2.5059 - val_accuracy: 0.7866\n",
      "Epoch 1146/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0418 - accuracy: 0.9866 - val_loss: 2.3649 - val_accuracy: 0.7804\n",
      "Epoch 1147/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0405 - accuracy: 0.9873 - val_loss: 2.2760 - val_accuracy: 0.7726\n",
      "Epoch 1148/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0221 - accuracy: 0.9926 - val_loss: 2.2175 - val_accuracy: 0.7741\n",
      "Epoch 1149/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0235 - accuracy: 0.9913 - val_loss: 2.3881 - val_accuracy: 0.7741\n",
      "Epoch 1150/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0201 - accuracy: 0.9926 - val_loss: 2.4218 - val_accuracy: 0.7586\n",
      "Epoch 1151/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0373 - accuracy: 0.9893 - val_loss: 2.2615 - val_accuracy: 0.7601\n",
      "Epoch 1152/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0099 - accuracy: 0.9967 - val_loss: 2.3973 - val_accuracy: 0.7850\n",
      "Epoch 1153/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0266 - accuracy: 0.9913 - val_loss: 2.1819 - val_accuracy: 0.7757\n",
      "Epoch 1154/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0139 - accuracy: 0.9920 - val_loss: 2.2626 - val_accuracy: 0.7866\n",
      "Epoch 1155/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0166 - accuracy: 0.9933 - val_loss: 2.3208 - val_accuracy: 0.7819\n",
      "Epoch 1156/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0281 - accuracy: 0.9926 - val_loss: 2.3023 - val_accuracy: 0.7570\n",
      "Epoch 1157/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0149 - accuracy: 0.9960 - val_loss: 2.3166 - val_accuracy: 0.7960\n",
      "Epoch 1158/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0375 - accuracy: 0.9893 - val_loss: 2.0766 - val_accuracy: 0.7835\n",
      "Epoch 1159/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0339 - accuracy: 0.9913 - val_loss: 2.3101 - val_accuracy: 0.7897\n",
      "Epoch 1160/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0383 - accuracy: 0.9913 - val_loss: 2.2027 - val_accuracy: 0.7321\n",
      "Epoch 1161/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0257 - accuracy: 0.9900 - val_loss: 2.3074 - val_accuracy: 0.7555\n",
      "Epoch 1162/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0301 - accuracy: 0.9886 - val_loss: 2.2848 - val_accuracy: 0.7819\n",
      "Epoch 1163/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0293 - accuracy: 0.9900 - val_loss: 2.0876 - val_accuracy: 0.7586\n",
      "Epoch 1164/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0365 - accuracy: 0.9893 - val_loss: 2.1189 - val_accuracy: 0.7290\n",
      "Epoch 1165/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0479 - accuracy: 0.9860 - val_loss: 2.0887 - val_accuracy: 0.7897\n",
      "Epoch 1166/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0239 - accuracy: 0.9926 - val_loss: 2.0729 - val_accuracy: 0.7601\n",
      "Epoch 1167/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0210 - accuracy: 0.9920 - val_loss: 2.2490 - val_accuracy: 0.7897\n",
      "Epoch 1168/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0218 - accuracy: 0.9926 - val_loss: 2.1967 - val_accuracy: 0.7726\n",
      "Epoch 1169/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0385 - accuracy: 0.9853 - val_loss: 2.0710 - val_accuracy: 0.7632\n",
      "Epoch 1170/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0239 - accuracy: 0.9926 - val_loss: 2.1889 - val_accuracy: 0.7897\n",
      "Epoch 1171/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0293 - accuracy: 0.9913 - val_loss: 1.9789 - val_accuracy: 0.7679\n",
      "Epoch 1172/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0348 - accuracy: 0.9913 - val_loss: 2.0478 - val_accuracy: 0.7695\n",
      "Epoch 1173/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0269 - accuracy: 0.9906 - val_loss: 2.1104 - val_accuracy: 0.7679\n",
      "Epoch 1174/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0341 - accuracy: 0.9886 - val_loss: 2.0600 - val_accuracy: 0.7539\n",
      "Epoch 1175/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0281 - accuracy: 0.9926 - val_loss: 2.2413 - val_accuracy: 0.7928\n",
      "Epoch 1176/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0411 - accuracy: 0.9893 - val_loss: 2.2888 - val_accuracy: 0.7897\n",
      "Epoch 1177/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0300 - accuracy: 0.9906 - val_loss: 2.1345 - val_accuracy: 0.7695\n",
      "Epoch 1178/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0464 - accuracy: 0.9853 - val_loss: 2.0375 - val_accuracy: 0.7850\n",
      "Epoch 1179/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0263 - accuracy: 0.9920 - val_loss: 2.1818 - val_accuracy: 0.7835\n",
      "Epoch 1180/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0163 - accuracy: 0.9940 - val_loss: 2.2655 - val_accuracy: 0.7866\n",
      "Epoch 1181/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0232 - accuracy: 0.9933 - val_loss: 2.1860 - val_accuracy: 0.7788\n",
      "Epoch 1182/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0360 - accuracy: 0.9893 - val_loss: 2.2557 - val_accuracy: 0.7928\n",
      "Epoch 1183/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0288 - accuracy: 0.9920 - val_loss: 2.1114 - val_accuracy: 0.7710\n",
      "Epoch 1184/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0287 - accuracy: 0.9933 - val_loss: 2.2847 - val_accuracy: 0.7944\n",
      "Epoch 1185/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0282 - accuracy: 0.9913 - val_loss: 2.1258 - val_accuracy: 0.7866\n",
      "Epoch 1186/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0199 - accuracy: 0.9933 - val_loss: 2.1077 - val_accuracy: 0.7835\n",
      "Epoch 1187/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0306 - accuracy: 0.9886 - val_loss: 2.1212 - val_accuracy: 0.7632\n",
      "Epoch 1188/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0319 - accuracy: 0.9900 - val_loss: 2.0953 - val_accuracy: 0.7305\n",
      "Epoch 1189/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0484 - accuracy: 0.9840 - val_loss: 2.2316 - val_accuracy: 0.7757\n",
      "Epoch 1190/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0375 - accuracy: 0.9893 - val_loss: 2.2291 - val_accuracy: 0.7726\n",
      "Epoch 1191/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0203 - accuracy: 0.9933 - val_loss: 2.3205 - val_accuracy: 0.7913\n",
      "Epoch 1192/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0454 - accuracy: 0.9920 - val_loss: 2.2886 - val_accuracy: 0.7757\n",
      "Epoch 1193/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0395 - accuracy: 0.9886 - val_loss: 2.1691 - val_accuracy: 0.7087\n",
      "Epoch 1194/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0241 - accuracy: 0.9900 - val_loss: 2.2973 - val_accuracy: 0.7555\n",
      "Epoch 1195/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0221 - accuracy: 0.9920 - val_loss: 2.1246 - val_accuracy: 0.7788\n",
      "Epoch 1196/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0396 - accuracy: 0.9920 - val_loss: 2.3086 - val_accuracy: 0.7492\n",
      "Epoch 1197/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0407 - accuracy: 0.9900 - val_loss: 2.3302 - val_accuracy: 0.7741\n",
      "Epoch 1198/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0236 - accuracy: 0.9926 - val_loss: 2.1681 - val_accuracy: 0.7695\n",
      "Epoch 1199/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0439 - accuracy: 0.9873 - val_loss: 2.0506 - val_accuracy: 0.7523\n",
      "Epoch 1200/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0318 - accuracy: 0.9920 - val_loss: 2.2013 - val_accuracy: 0.7804\n",
      "Epoch 1201/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0166 - accuracy: 0.9947 - val_loss: 2.2231 - val_accuracy: 0.7679\n",
      "Epoch 1202/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0205 - accuracy: 0.9947 - val_loss: 2.3742 - val_accuracy: 0.7897\n",
      "Epoch 1203/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0301 - accuracy: 0.9893 - val_loss: 2.2643 - val_accuracy: 0.7773\n",
      "Epoch 1204/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0199 - accuracy: 0.9947 - val_loss: 2.4467 - val_accuracy: 0.7928\n",
      "Epoch 1205/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0293 - accuracy: 0.9906 - val_loss: 2.2709 - val_accuracy: 0.7897\n",
      "Epoch 1206/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0307 - accuracy: 0.9906 - val_loss: 2.1134 - val_accuracy: 0.7850\n",
      "Epoch 1207/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0308 - accuracy: 0.9913 - val_loss: 2.1700 - val_accuracy: 0.7461\n",
      "Epoch 1208/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0144 - accuracy: 0.9940 - val_loss: 2.4048 - val_accuracy: 0.7788\n",
      "Epoch 1209/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0289 - accuracy: 0.9920 - val_loss: 2.4550 - val_accuracy: 0.7726\n",
      "Epoch 1210/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0153 - accuracy: 0.9947 - val_loss: 2.4677 - val_accuracy: 0.7928\n",
      "Epoch 1211/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0193 - accuracy: 0.9933 - val_loss: 2.7047 - val_accuracy: 0.7913\n",
      "Epoch 1212/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0233 - accuracy: 0.9906 - val_loss: 2.5142 - val_accuracy: 0.7850\n",
      "Epoch 1213/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0197 - accuracy: 0.9893 - val_loss: 2.3006 - val_accuracy: 0.7570\n",
      "Epoch 1214/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0445 - accuracy: 0.9886 - val_loss: 2.2514 - val_accuracy: 0.7773\n",
      "Epoch 1215/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0232 - accuracy: 0.9920 - val_loss: 2.4061 - val_accuracy: 0.7710\n",
      "Epoch 1216/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0200 - accuracy: 0.9940 - val_loss: 2.3830 - val_accuracy: 0.7819\n",
      "Epoch 1217/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0225 - accuracy: 0.9953 - val_loss: 2.3946 - val_accuracy: 0.7897\n",
      "Epoch 1218/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0278 - accuracy: 0.9886 - val_loss: 2.1890 - val_accuracy: 0.7788\n",
      "Epoch 1219/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0285 - accuracy: 0.9920 - val_loss: 2.4244 - val_accuracy: 0.7928\n",
      "Epoch 1220/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0312 - accuracy: 0.9913 - val_loss: 2.1631 - val_accuracy: 0.7539\n",
      "Epoch 1221/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0400 - accuracy: 0.9900 - val_loss: 2.4858 - val_accuracy: 0.7913\n",
      "Epoch 1222/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0336 - accuracy: 0.9913 - val_loss: 2.2919 - val_accuracy: 0.7960\n",
      "Epoch 1223/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0301 - accuracy: 0.9900 - val_loss: 2.1426 - val_accuracy: 0.7383\n",
      "Epoch 1224/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0425 - accuracy: 0.9860 - val_loss: 2.2289 - val_accuracy: 0.7726\n",
      "Epoch 1225/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0274 - accuracy: 0.9913 - val_loss: 2.3098 - val_accuracy: 0.7773\n",
      "Epoch 1226/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0291 - accuracy: 0.9906 - val_loss: 2.3127 - val_accuracy: 0.7788\n",
      "Epoch 1227/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0272 - accuracy: 0.9940 - val_loss: 2.2592 - val_accuracy: 0.7695\n",
      "Epoch 1228/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0458 - accuracy: 0.9900 - val_loss: 2.2576 - val_accuracy: 0.7788\n",
      "Epoch 1229/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0451 - accuracy: 0.9880 - val_loss: 2.2606 - val_accuracy: 0.7928\n",
      "Epoch 1230/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0323 - accuracy: 0.9920 - val_loss: 2.2683 - val_accuracy: 0.7741\n",
      "Epoch 1231/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0454 - accuracy: 0.9920 - val_loss: 2.2955 - val_accuracy: 0.7695\n",
      "Epoch 1232/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0356 - accuracy: 0.9926 - val_loss: 2.2835 - val_accuracy: 0.7695\n",
      "Epoch 1233/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0325 - accuracy: 0.9893 - val_loss: 2.3050 - val_accuracy: 0.7414\n",
      "Epoch 1234/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0309 - accuracy: 0.9906 - val_loss: 2.1836 - val_accuracy: 0.7741\n",
      "Epoch 1235/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0271 - accuracy: 0.9926 - val_loss: 2.0843 - val_accuracy: 0.7804\n",
      "Epoch 1236/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0161 - accuracy: 0.9953 - val_loss: 2.2902 - val_accuracy: 0.7835\n",
      "Epoch 1237/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0331 - accuracy: 0.9893 - val_loss: 2.3876 - val_accuracy: 0.7866\n",
      "Epoch 1238/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0298 - accuracy: 0.9900 - val_loss: 2.2644 - val_accuracy: 0.7866\n",
      "Epoch 1239/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0090 - accuracy: 0.9947 - val_loss: 2.4361 - val_accuracy: 0.7866\n",
      "Epoch 1240/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0343 - accuracy: 0.9893 - val_loss: 2.4390 - val_accuracy: 0.7788\n",
      "Epoch 1241/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0343 - accuracy: 0.9920 - val_loss: 2.2624 - val_accuracy: 0.7508\n",
      "Epoch 1242/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0113 - accuracy: 0.9973 - val_loss: 2.4053 - val_accuracy: 0.7414\n",
      "Epoch 1243/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0398 - accuracy: 0.9926 - val_loss: 2.3209 - val_accuracy: 0.7695\n",
      "Epoch 1244/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0269 - accuracy: 0.9926 - val_loss: 2.3388 - val_accuracy: 0.7757\n",
      "Epoch 1245/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0237 - accuracy: 0.9933 - val_loss: 2.3659 - val_accuracy: 0.7850\n",
      "Epoch 1246/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0279 - accuracy: 0.9920 - val_loss: 2.3353 - val_accuracy: 0.7866\n",
      "Epoch 1247/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0180 - accuracy: 0.9940 - val_loss: 2.4013 - val_accuracy: 0.7726\n",
      "Epoch 1248/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0140 - accuracy: 0.9947 - val_loss: 2.4390 - val_accuracy: 0.7757\n",
      "Epoch 1249/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0228 - accuracy: 0.9940 - val_loss: 2.3035 - val_accuracy: 0.7726\n",
      "Epoch 1250/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0308 - accuracy: 0.9880 - val_loss: 2.2168 - val_accuracy: 0.7819\n",
      "Epoch 1251/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0346 - accuracy: 0.9900 - val_loss: 2.2456 - val_accuracy: 0.7710\n",
      "Epoch 1252/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0246 - accuracy: 0.9940 - val_loss: 2.2102 - val_accuracy: 0.7710\n",
      "Epoch 1253/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0157 - accuracy: 0.9940 - val_loss: 2.3439 - val_accuracy: 0.7741\n",
      "Epoch 1254/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0429 - accuracy: 0.9933 - val_loss: 2.4558 - val_accuracy: 0.7788\n",
      "Epoch 1255/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0118 - accuracy: 0.9960 - val_loss: 2.3165 - val_accuracy: 0.7726\n",
      "Epoch 1256/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0477 - accuracy: 0.9866 - val_loss: 2.2451 - val_accuracy: 0.7944\n",
      "Epoch 1257/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0200 - accuracy: 0.9947 - val_loss: 2.2999 - val_accuracy: 0.7757\n",
      "Epoch 1258/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0269 - accuracy: 0.9926 - val_loss: 2.1309 - val_accuracy: 0.7570\n",
      "Epoch 1259/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0153 - accuracy: 0.9940 - val_loss: 2.3408 - val_accuracy: 0.7788\n",
      "Epoch 1260/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0188 - accuracy: 0.9953 - val_loss: 2.3272 - val_accuracy: 0.7695\n",
      "Epoch 1261/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0245 - accuracy: 0.9920 - val_loss: 2.4673 - val_accuracy: 0.7648\n",
      "Epoch 1262/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0336 - accuracy: 0.9880 - val_loss: 2.3065 - val_accuracy: 0.7726\n",
      "Epoch 1263/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0408 - accuracy: 0.9860 - val_loss: 2.2579 - val_accuracy: 0.7586\n",
      "Epoch 1264/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0131 - accuracy: 0.9953 - val_loss: 2.4627 - val_accuracy: 0.7866\n",
      "Epoch 1265/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0309 - accuracy: 0.9880 - val_loss: 2.2724 - val_accuracy: 0.7788\n",
      "Epoch 1266/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0133 - accuracy: 0.9953 - val_loss: 2.3241 - val_accuracy: 0.7757\n",
      "Epoch 1267/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0134 - accuracy: 0.9953 - val_loss: 2.1853 - val_accuracy: 0.7632\n",
      "Epoch 1268/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0365 - accuracy: 0.9900 - val_loss: 2.4620 - val_accuracy: 0.7928\n",
      "Epoch 1269/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0236 - accuracy: 0.9926 - val_loss: 2.3497 - val_accuracy: 0.7913\n",
      "Epoch 1270/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0258 - accuracy: 0.9933 - val_loss: 2.1753 - val_accuracy: 0.7383\n",
      "Epoch 1271/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0217 - accuracy: 0.9920 - val_loss: 2.3948 - val_accuracy: 0.7773\n",
      "Epoch 1272/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0233 - accuracy: 0.9913 - val_loss: 2.3969 - val_accuracy: 0.7757\n",
      "Epoch 1273/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0302 - accuracy: 0.9926 - val_loss: 2.3869 - val_accuracy: 0.7804\n",
      "Epoch 1274/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0400 - accuracy: 0.9900 - val_loss: 2.2705 - val_accuracy: 0.7757\n",
      "Epoch 1275/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0377 - accuracy: 0.9886 - val_loss: 2.2520 - val_accuracy: 0.7835\n",
      "Epoch 1276/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0144 - accuracy: 0.9933 - val_loss: 2.3510 - val_accuracy: 0.7897\n",
      "Epoch 1277/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0268 - accuracy: 0.9900 - val_loss: 2.3809 - val_accuracy: 0.7835\n",
      "Epoch 1278/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0107 - accuracy: 0.9933 - val_loss: 2.2616 - val_accuracy: 0.7741\n",
      "Epoch 1279/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0307 - accuracy: 0.9913 - val_loss: 2.4209 - val_accuracy: 0.7928\n",
      "Epoch 1280/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0290 - accuracy: 0.9913 - val_loss: 2.4063 - val_accuracy: 0.7819\n",
      "Epoch 1281/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0465 - accuracy: 0.9926 - val_loss: 2.4336 - val_accuracy: 0.7679\n",
      "Epoch 1282/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0195 - accuracy: 0.9953 - val_loss: 2.5056 - val_accuracy: 0.7804\n",
      "Epoch 1283/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0211 - accuracy: 0.9933 - val_loss: 2.3162 - val_accuracy: 0.7804\n",
      "Epoch 1284/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0236 - accuracy: 0.9920 - val_loss: 2.0753 - val_accuracy: 0.7804\n",
      "Epoch 1285/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0202 - accuracy: 0.9926 - val_loss: 2.2390 - val_accuracy: 0.7679\n",
      "Epoch 1286/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0144 - accuracy: 0.9953 - val_loss: 2.2830 - val_accuracy: 0.7928\n",
      "Epoch 1287/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0254 - accuracy: 0.9926 - val_loss: 2.4517 - val_accuracy: 0.7897\n",
      "Epoch 1288/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0310 - accuracy: 0.9900 - val_loss: 2.2725 - val_accuracy: 0.7664\n",
      "Epoch 1289/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0344 - accuracy: 0.9886 - val_loss: 2.3641 - val_accuracy: 0.7819\n",
      "Epoch 1290/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0249 - accuracy: 0.9920 - val_loss: 2.3484 - val_accuracy: 0.7508\n",
      "Epoch 1291/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0222 - accuracy: 0.9947 - val_loss: 2.2840 - val_accuracy: 0.7679\n",
      "Epoch 1292/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0284 - accuracy: 0.9933 - val_loss: 2.3078 - val_accuracy: 0.7710\n",
      "Epoch 1293/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0151 - accuracy: 0.9953 - val_loss: 2.6218 - val_accuracy: 0.8006\n",
      "Epoch 1294/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0235 - accuracy: 0.9926 - val_loss: 2.4163 - val_accuracy: 0.7897\n",
      "Epoch 1295/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0404 - accuracy: 0.9906 - val_loss: 2.4590 - val_accuracy: 0.7741\n",
      "Epoch 1296/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0163 - accuracy: 0.9947 - val_loss: 2.3111 - val_accuracy: 0.7835\n",
      "Epoch 1297/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0205 - accuracy: 0.9933 - val_loss: 2.4907 - val_accuracy: 0.7664\n",
      "Epoch 1298/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0248 - accuracy: 0.9953 - val_loss: 2.7373 - val_accuracy: 0.7944\n",
      "Epoch 1299/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0259 - accuracy: 0.9933 - val_loss: 2.4546 - val_accuracy: 0.7944\n",
      "Epoch 1300/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0184 - accuracy: 0.9947 - val_loss: 2.2266 - val_accuracy: 0.7726\n",
      "Epoch 1301/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0310 - accuracy: 0.9893 - val_loss: 2.3681 - val_accuracy: 0.7617\n",
      "Epoch 1302/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0339 - accuracy: 0.9913 - val_loss: 2.3130 - val_accuracy: 0.7508\n",
      "Epoch 1303/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0356 - accuracy: 0.9913 - val_loss: 2.4008 - val_accuracy: 0.7897\n",
      "Epoch 1304/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0373 - accuracy: 0.9880 - val_loss: 2.3504 - val_accuracy: 0.7928\n",
      "Epoch 1305/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0249 - accuracy: 0.9926 - val_loss: 2.1556 - val_accuracy: 0.7632\n",
      "Epoch 1306/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0339 - accuracy: 0.9873 - val_loss: 2.5403 - val_accuracy: 0.7913\n",
      "Epoch 1307/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0164 - accuracy: 0.9947 - val_loss: 2.5384 - val_accuracy: 0.7773\n",
      "Epoch 1308/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0267 - accuracy: 0.9940 - val_loss: 2.4396 - val_accuracy: 0.7804\n",
      "Epoch 1309/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0401 - accuracy: 0.9900 - val_loss: 2.4542 - val_accuracy: 0.7897\n",
      "Epoch 1310/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0380 - accuracy: 0.9913 - val_loss: 2.4334 - val_accuracy: 0.7897\n",
      "Epoch 1311/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0374 - accuracy: 0.9900 - val_loss: 2.2273 - val_accuracy: 0.7804\n",
      "Epoch 1312/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0278 - accuracy: 0.9940 - val_loss: 2.4540 - val_accuracy: 0.7804\n",
      "Epoch 1313/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0207 - accuracy: 0.9967 - val_loss: 2.3970 - val_accuracy: 0.7882\n",
      "Epoch 1314/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0326 - accuracy: 0.9913 - val_loss: 2.4152 - val_accuracy: 0.7523\n",
      "Epoch 1315/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0108 - accuracy: 0.9967 - val_loss: 2.4053 - val_accuracy: 0.7741\n",
      "Epoch 1316/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0149 - accuracy: 0.9933 - val_loss: 2.4154 - val_accuracy: 0.7632\n",
      "Epoch 1317/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0278 - accuracy: 0.9900 - val_loss: 2.2766 - val_accuracy: 0.7897\n",
      "Epoch 1318/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0250 - accuracy: 0.9873 - val_loss: 2.4171 - val_accuracy: 0.7710\n",
      "Epoch 1319/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0126 - accuracy: 0.9973 - val_loss: 2.3959 - val_accuracy: 0.7835\n",
      "Epoch 1320/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0291 - accuracy: 0.9926 - val_loss: 2.8252 - val_accuracy: 0.8053\n",
      "Epoch 1321/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0403 - accuracy: 0.9900 - val_loss: 2.5784 - val_accuracy: 0.8006\n",
      "Epoch 1322/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0285 - accuracy: 0.9926 - val_loss: 2.4322 - val_accuracy: 0.7695\n",
      "Epoch 1323/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0270 - accuracy: 0.9920 - val_loss: 2.6369 - val_accuracy: 0.7882\n",
      "Epoch 1324/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0240 - accuracy: 0.9947 - val_loss: 2.5198 - val_accuracy: 0.7726\n",
      "Epoch 1325/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0222 - accuracy: 0.9913 - val_loss: 2.2933 - val_accuracy: 0.7928\n",
      "Epoch 1326/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0216 - accuracy: 0.9926 - val_loss: 2.2074 - val_accuracy: 0.7617\n",
      "Epoch 1327/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0159 - accuracy: 0.9960 - val_loss: 2.5328 - val_accuracy: 0.7928\n",
      "Epoch 1328/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0271 - accuracy: 0.9913 - val_loss: 2.8273 - val_accuracy: 0.8084\n",
      "Epoch 1329/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0294 - accuracy: 0.9933 - val_loss: 2.3717 - val_accuracy: 0.7804\n",
      "Epoch 1330/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0226 - accuracy: 0.9920 - val_loss: 2.4883 - val_accuracy: 0.7960\n",
      "Epoch 1331/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0200 - accuracy: 0.9960 - val_loss: 2.5761 - val_accuracy: 0.7944\n",
      "Epoch 1332/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0149 - accuracy: 0.9933 - val_loss: 2.5237 - val_accuracy: 0.7928\n",
      "Epoch 1333/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0328 - accuracy: 0.9913 - val_loss: 2.5258 - val_accuracy: 0.8022\n",
      "Epoch 1334/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0255 - accuracy: 0.9920 - val_loss: 2.5111 - val_accuracy: 0.7882\n",
      "Epoch 1335/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0229 - accuracy: 0.9893 - val_loss: 2.5240 - val_accuracy: 0.7944\n",
      "Epoch 1336/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0258 - accuracy: 0.9933 - val_loss: 2.6809 - val_accuracy: 0.7975\n",
      "Epoch 1337/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0136 - accuracy: 0.9953 - val_loss: 2.5975 - val_accuracy: 0.7788\n",
      "Epoch 1338/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0285 - accuracy: 0.9926 - val_loss: 2.5379 - val_accuracy: 0.7913\n",
      "Epoch 1339/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0305 - accuracy: 0.9900 - val_loss: 2.6246 - val_accuracy: 0.7928\n",
      "Epoch 1340/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0270 - accuracy: 0.9900 - val_loss: 2.4973 - val_accuracy: 0.7835\n",
      "Epoch 1341/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0132 - accuracy: 0.9940 - val_loss: 2.4133 - val_accuracy: 0.7882\n",
      "Epoch 1342/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0359 - accuracy: 0.9906 - val_loss: 2.5013 - val_accuracy: 0.7991\n",
      "Epoch 1343/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0318 - accuracy: 0.9906 - val_loss: 2.3039 - val_accuracy: 0.7804\n",
      "Epoch 1344/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0137 - accuracy: 0.9933 - val_loss: 2.5004 - val_accuracy: 0.7928\n",
      "Epoch 1345/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0411 - accuracy: 0.9913 - val_loss: 2.5586 - val_accuracy: 0.7960\n",
      "Epoch 1346/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0252 - accuracy: 0.9920 - val_loss: 2.3921 - val_accuracy: 0.7866\n",
      "Epoch 1347/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0285 - accuracy: 0.9933 - val_loss: 2.3690 - val_accuracy: 0.7788\n",
      "Epoch 1348/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0138 - accuracy: 0.9953 - val_loss: 2.6596 - val_accuracy: 0.7944\n",
      "Epoch 1349/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0246 - accuracy: 0.9906 - val_loss: 2.6326 - val_accuracy: 0.7773\n",
      "Epoch 1350/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0227 - accuracy: 0.9940 - val_loss: 2.6967 - val_accuracy: 0.7944\n",
      "Epoch 1351/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0222 - accuracy: 0.9947 - val_loss: 2.6200 - val_accuracy: 0.8022\n",
      "Epoch 1352/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0378 - accuracy: 0.9913 - val_loss: 2.5795 - val_accuracy: 0.7819\n",
      "Epoch 1353/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0339 - accuracy: 0.9920 - val_loss: 2.4558 - val_accuracy: 0.7741\n",
      "Epoch 1354/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0356 - accuracy: 0.9913 - val_loss: 2.5573 - val_accuracy: 0.7944\n",
      "Epoch 1355/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0419 - accuracy: 0.9853 - val_loss: 2.6335 - val_accuracy: 0.8006\n",
      "Epoch 1356/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0486 - accuracy: 0.9853 - val_loss: 2.3661 - val_accuracy: 0.7555\n",
      "Epoch 1357/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0283 - accuracy: 0.9933 - val_loss: 2.5454 - val_accuracy: 0.8022\n",
      "Epoch 1358/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0288 - accuracy: 0.9920 - val_loss: 2.4132 - val_accuracy: 0.7913\n",
      "Epoch 1359/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0320 - accuracy: 0.9893 - val_loss: 2.4576 - val_accuracy: 0.7882\n",
      "Epoch 1360/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0310 - accuracy: 0.9913 - val_loss: 2.5766 - val_accuracy: 0.7788\n",
      "Epoch 1361/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0204 - accuracy: 0.9926 - val_loss: 2.5862 - val_accuracy: 0.7975\n",
      "Epoch 1362/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0157 - accuracy: 0.9926 - val_loss: 2.7195 - val_accuracy: 0.7897\n",
      "Epoch 1363/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0397 - accuracy: 0.9913 - val_loss: 2.2808 - val_accuracy: 0.7679\n",
      "Epoch 1364/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0259 - accuracy: 0.9926 - val_loss: 2.2499 - val_accuracy: 0.7601\n",
      "Epoch 1365/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0235 - accuracy: 0.9933 - val_loss: 2.5806 - val_accuracy: 0.7975\n",
      "Epoch 1366/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0181 - accuracy: 0.9913 - val_loss: 2.4263 - val_accuracy: 0.7835\n",
      "Epoch 1367/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0326 - accuracy: 0.9926 - val_loss: 2.4773 - val_accuracy: 0.8022\n",
      "Epoch 1368/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0389 - accuracy: 0.9866 - val_loss: 2.3534 - val_accuracy: 0.7664\n",
      "Epoch 1369/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0250 - accuracy: 0.9947 - val_loss: 2.3803 - val_accuracy: 0.7960\n",
      "Epoch 1370/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0307 - accuracy: 0.9920 - val_loss: 2.2709 - val_accuracy: 0.7664\n",
      "Epoch 1371/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0167 - accuracy: 0.9947 - val_loss: 2.6405 - val_accuracy: 0.7726\n",
      "Epoch 1372/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0212 - accuracy: 0.9926 - val_loss: 2.4519 - val_accuracy: 0.7741\n",
      "Epoch 1373/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0164 - accuracy: 0.9953 - val_loss: 2.3496 - val_accuracy: 0.7726\n",
      "Epoch 1374/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0205 - accuracy: 0.9947 - val_loss: 2.4083 - val_accuracy: 0.7679\n",
      "Epoch 1375/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0280 - accuracy: 0.9900 - val_loss: 2.5115 - val_accuracy: 0.7944\n",
      "Epoch 1376/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0151 - accuracy: 0.9933 - val_loss: 2.1974 - val_accuracy: 0.7430\n",
      "Epoch 1377/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0169 - accuracy: 0.9940 - val_loss: 2.2693 - val_accuracy: 0.7835\n",
      "Epoch 1378/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0160 - accuracy: 0.9933 - val_loss: 2.1566 - val_accuracy: 0.7741\n",
      "Epoch 1379/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0219 - accuracy: 0.9953 - val_loss: 2.2212 - val_accuracy: 0.7726\n",
      "Epoch 1380/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0211 - accuracy: 0.9926 - val_loss: 2.2710 - val_accuracy: 0.7632\n",
      "Epoch 1381/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0383 - accuracy: 0.9913 - val_loss: 2.5370 - val_accuracy: 0.7835\n",
      "Epoch 1382/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0394 - accuracy: 0.9906 - val_loss: 2.3404 - val_accuracy: 0.7913\n",
      "Epoch 1383/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0243 - accuracy: 0.9913 - val_loss: 2.3752 - val_accuracy: 0.8037\n",
      "Epoch 1384/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0334 - accuracy: 0.9926 - val_loss: 2.3324 - val_accuracy: 0.7383\n",
      "Epoch 1385/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0296 - accuracy: 0.9900 - val_loss: 2.2853 - val_accuracy: 0.7773\n",
      "Epoch 1386/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0121 - accuracy: 0.9947 - val_loss: 2.2699 - val_accuracy: 0.7726\n",
      "Epoch 1387/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0293 - accuracy: 0.9920 - val_loss: 2.3224 - val_accuracy: 0.7648\n",
      "Epoch 1388/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0215 - accuracy: 0.9926 - val_loss: 2.2563 - val_accuracy: 0.7539\n",
      "Epoch 1389/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0251 - accuracy: 0.9920 - val_loss: 2.3109 - val_accuracy: 0.7882\n",
      "Epoch 1390/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0163 - accuracy: 0.9933 - val_loss: 2.2244 - val_accuracy: 0.7586\n",
      "Epoch 1391/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0172 - accuracy: 0.9940 - val_loss: 2.2953 - val_accuracy: 0.7773\n",
      "Epoch 1392/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0240 - accuracy: 0.9900 - val_loss: 2.2246 - val_accuracy: 0.7960\n",
      "Epoch 1393/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 2.4379 - val_accuracy: 0.7913\n",
      "Epoch 1394/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0309 - accuracy: 0.9953 - val_loss: 2.4078 - val_accuracy: 0.7788\n",
      "Epoch 1395/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0180 - accuracy: 0.9953 - val_loss: 2.4849 - val_accuracy: 0.7726\n",
      "Epoch 1396/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0326 - accuracy: 0.9920 - val_loss: 2.5539 - val_accuracy: 0.7835\n",
      "Epoch 1397/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0300 - accuracy: 0.9926 - val_loss: 2.3761 - val_accuracy: 0.7383\n",
      "Epoch 1398/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0370 - accuracy: 0.9913 - val_loss: 2.3101 - val_accuracy: 0.7804\n",
      "Epoch 1399/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0309 - accuracy: 0.9913 - val_loss: 2.2116 - val_accuracy: 0.7695\n",
      "Epoch 1400/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0094 - accuracy: 0.9947 - val_loss: 2.3722 - val_accuracy: 0.7850\n",
      "Epoch 1401/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0161 - accuracy: 0.9953 - val_loss: 2.4877 - val_accuracy: 0.7695\n",
      "Epoch 1402/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0185 - accuracy: 0.9920 - val_loss: 2.6185 - val_accuracy: 0.7882\n",
      "Epoch 1403/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0369 - accuracy: 0.9926 - val_loss: 2.7088 - val_accuracy: 0.7960\n",
      "Epoch 1404/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0394 - accuracy: 0.9900 - val_loss: 2.4203 - val_accuracy: 0.7695\n",
      "Epoch 1405/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0080 - accuracy: 0.9973 - val_loss: 2.4176 - val_accuracy: 0.7570\n",
      "Epoch 1406/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0210 - accuracy: 0.9940 - val_loss: 2.3817 - val_accuracy: 0.7804\n",
      "Epoch 1407/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0233 - accuracy: 0.9933 - val_loss: 2.6837 - val_accuracy: 0.7866\n",
      "Epoch 1408/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0296 - accuracy: 0.9906 - val_loss: 2.7974 - val_accuracy: 0.7913\n",
      "Epoch 1409/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0233 - accuracy: 0.9906 - val_loss: 2.5155 - val_accuracy: 0.7679\n",
      "Epoch 1410/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0367 - accuracy: 0.9920 - val_loss: 2.5258 - val_accuracy: 0.7866\n",
      "Epoch 1411/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0146 - accuracy: 0.9973 - val_loss: 2.4349 - val_accuracy: 0.7819\n",
      "Epoch 1412/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0234 - accuracy: 0.9947 - val_loss: 2.4039 - val_accuracy: 0.7710\n",
      "Epoch 1413/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0087 - accuracy: 0.9953 - val_loss: 2.5277 - val_accuracy: 0.7819\n",
      "Epoch 1414/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0617 - accuracy: 0.9860 - val_loss: 2.4535 - val_accuracy: 0.7804\n",
      "Epoch 1415/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0245 - accuracy: 0.9926 - val_loss: 2.5074 - val_accuracy: 0.7695\n",
      "Epoch 1416/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0385 - accuracy: 0.9906 - val_loss: 2.4171 - val_accuracy: 0.7632\n",
      "Epoch 1417/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0125 - accuracy: 0.9960 - val_loss: 2.6153 - val_accuracy: 0.7928\n",
      "Epoch 1418/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0312 - accuracy: 0.9913 - val_loss: 2.3324 - val_accuracy: 0.7679\n",
      "Epoch 1419/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0199 - accuracy: 0.9940 - val_loss: 2.5610 - val_accuracy: 0.7741\n",
      "Epoch 1420/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0235 - accuracy: 0.9906 - val_loss: 2.3977 - val_accuracy: 0.7617\n",
      "Epoch 1421/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0395 - accuracy: 0.9900 - val_loss: 2.6180 - val_accuracy: 0.7944\n",
      "Epoch 1422/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0265 - accuracy: 0.9920 - val_loss: 2.4361 - val_accuracy: 0.7819\n",
      "Epoch 1423/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0150 - accuracy: 0.9926 - val_loss: 2.5409 - val_accuracy: 0.7757\n",
      "Epoch 1424/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0395 - accuracy: 0.9900 - val_loss: 2.3570 - val_accuracy: 0.7617\n",
      "Epoch 1425/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0299 - accuracy: 0.9920 - val_loss: 2.4364 - val_accuracy: 0.7710\n",
      "Epoch 1426/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0371 - accuracy: 0.9906 - val_loss: 2.7689 - val_accuracy: 0.7819\n",
      "Epoch 1427/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0432 - accuracy: 0.9873 - val_loss: 2.4759 - val_accuracy: 0.7695\n",
      "Epoch 1428/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0298 - accuracy: 0.9906 - val_loss: 2.4521 - val_accuracy: 0.7835\n",
      "Epoch 1429/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0126 - accuracy: 0.9973 - val_loss: 2.3332 - val_accuracy: 0.7882\n",
      "Epoch 1430/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0201 - accuracy: 0.9926 - val_loss: 2.5952 - val_accuracy: 0.7866\n",
      "Epoch 1431/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0343 - accuracy: 0.9906 - val_loss: 2.4977 - val_accuracy: 0.7741\n",
      "Epoch 1432/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0233 - accuracy: 0.9933 - val_loss: 2.3806 - val_accuracy: 0.7679\n",
      "Epoch 1433/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0247 - accuracy: 0.9926 - val_loss: 2.4403 - val_accuracy: 0.7726\n",
      "Epoch 1434/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0205 - accuracy: 0.9947 - val_loss: 2.5200 - val_accuracy: 0.7695\n",
      "Epoch 1435/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0216 - accuracy: 0.9940 - val_loss: 2.4228 - val_accuracy: 0.7726\n",
      "Epoch 1436/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0406 - accuracy: 0.9933 - val_loss: 2.3494 - val_accuracy: 0.7695\n",
      "Epoch 1437/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0242 - accuracy: 0.9947 - val_loss: 2.3094 - val_accuracy: 0.7601\n",
      "Epoch 1438/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0461 - accuracy: 0.9913 - val_loss: 2.2952 - val_accuracy: 0.7741\n",
      "Epoch 1439/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0218 - accuracy: 0.9947 - val_loss: 2.3919 - val_accuracy: 0.7788\n",
      "Epoch 1440/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0268 - accuracy: 0.9906 - val_loss: 2.4154 - val_accuracy: 0.7835\n",
      "Epoch 1441/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0113 - accuracy: 0.9967 - val_loss: 2.3717 - val_accuracy: 0.7757\n",
      "Epoch 1442/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0335 - accuracy: 0.9933 - val_loss: 2.4361 - val_accuracy: 0.7866\n",
      "Epoch 1443/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0150 - accuracy: 0.9953 - val_loss: 2.3820 - val_accuracy: 0.7944\n",
      "Epoch 1444/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0191 - accuracy: 0.9906 - val_loss: 2.4329 - val_accuracy: 0.7850\n",
      "Epoch 1445/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0094 - accuracy: 0.9967 - val_loss: 2.5055 - val_accuracy: 0.7835\n",
      "Epoch 1446/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0131 - accuracy: 0.9967 - val_loss: 2.5609 - val_accuracy: 0.7804\n",
      "Epoch 1447/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0072 - accuracy: 0.9973 - val_loss: 2.4596 - val_accuracy: 0.7788\n",
      "Epoch 1448/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0080 - accuracy: 0.9980 - val_loss: 2.7855 - val_accuracy: 0.7710\n",
      "Epoch 1449/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0148 - accuracy: 0.9960 - val_loss: 2.8496 - val_accuracy: 0.7866\n",
      "Epoch 1450/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0504 - accuracy: 0.9886 - val_loss: 2.5194 - val_accuracy: 0.7570\n",
      "Epoch 1451/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0192 - accuracy: 0.9947 - val_loss: 2.7064 - val_accuracy: 0.7757\n",
      "Epoch 1452/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0362 - accuracy: 0.9880 - val_loss: 2.5848 - val_accuracy: 0.7897\n",
      "Epoch 1453/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0237 - accuracy: 0.9920 - val_loss: 2.3208 - val_accuracy: 0.7710\n",
      "Epoch 1454/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0212 - accuracy: 0.9906 - val_loss: 2.4529 - val_accuracy: 0.7835\n",
      "Epoch 1455/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0232 - accuracy: 0.9913 - val_loss: 2.6558 - val_accuracy: 0.7835\n",
      "Epoch 1456/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0280 - accuracy: 0.9940 - val_loss: 2.7513 - val_accuracy: 0.7897\n",
      "Epoch 1457/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0236 - accuracy: 0.9926 - val_loss: 2.4562 - val_accuracy: 0.7757\n",
      "Epoch 1458/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0160 - accuracy: 0.9953 - val_loss: 2.5203 - val_accuracy: 0.7773\n",
      "Epoch 1459/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0246 - accuracy: 0.9920 - val_loss: 2.6022 - val_accuracy: 0.7741\n",
      "Epoch 1460/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0189 - accuracy: 0.9933 - val_loss: 2.5706 - val_accuracy: 0.7819\n",
      "Epoch 1461/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0180 - accuracy: 0.9947 - val_loss: 2.5297 - val_accuracy: 0.7788\n",
      "Epoch 1462/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0124 - accuracy: 0.9980 - val_loss: 2.6006 - val_accuracy: 0.7632\n",
      "Epoch 1463/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0185 - accuracy: 0.9953 - val_loss: 2.6210 - val_accuracy: 0.7835\n",
      "Epoch 1464/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0208 - accuracy: 0.9953 - val_loss: 2.8083 - val_accuracy: 0.7804\n",
      "Epoch 1465/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0185 - accuracy: 0.9940 - val_loss: 2.7931 - val_accuracy: 0.7882\n",
      "Epoch 1466/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0232 - accuracy: 0.9947 - val_loss: 2.5793 - val_accuracy: 0.7850\n",
      "Epoch 1467/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0170 - accuracy: 0.9953 - val_loss: 2.5472 - val_accuracy: 0.7866\n",
      "Epoch 1468/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0162 - accuracy: 0.9960 - val_loss: 2.7489 - val_accuracy: 0.7835\n",
      "Epoch 1469/1500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0201 - accuracy: 0.9933 - val_loss: 2.5655 - val_accuracy: 0.7913\n",
      "Epoch 1470/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0215 - accuracy: 0.9947 - val_loss: 2.5486 - val_accuracy: 0.7897\n",
      "Epoch 1471/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0084 - accuracy: 0.9973 - val_loss: 2.7255 - val_accuracy: 0.7897\n",
      "Epoch 1472/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0181 - accuracy: 0.9967 - val_loss: 2.6996 - val_accuracy: 0.7882\n",
      "Epoch 1473/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0077 - accuracy: 0.9973 - val_loss: 2.6463 - val_accuracy: 0.7726\n",
      "Epoch 1474/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0096 - accuracy: 0.9953 - val_loss: 2.8930 - val_accuracy: 0.7773\n",
      "Epoch 1475/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0363 - accuracy: 0.9913 - val_loss: 2.7440 - val_accuracy: 0.7882\n",
      "Epoch 1476/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0266 - accuracy: 0.9933 - val_loss: 2.6437 - val_accuracy: 0.7757\n",
      "Epoch 1477/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0242 - accuracy: 0.9913 - val_loss: 2.6170 - val_accuracy: 0.7897\n",
      "Epoch 1478/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0151 - accuracy: 0.9940 - val_loss: 2.5537 - val_accuracy: 0.7586\n",
      "Epoch 1479/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0075 - accuracy: 0.9980 - val_loss: 2.6641 - val_accuracy: 0.7960\n",
      "Epoch 1480/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0277 - accuracy: 0.9940 - val_loss: 2.6066 - val_accuracy: 0.7679\n",
      "Epoch 1481/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0163 - accuracy: 0.9947 - val_loss: 2.6918 - val_accuracy: 0.7882\n",
      "Epoch 1482/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0114 - accuracy: 0.9960 - val_loss: 2.5422 - val_accuracy: 0.7788\n",
      "Epoch 1483/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0205 - accuracy: 0.9967 - val_loss: 2.5968 - val_accuracy: 0.7913\n",
      "Epoch 1484/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0184 - accuracy: 0.9953 - val_loss: 2.7497 - val_accuracy: 0.7991\n",
      "Epoch 1485/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0063 - accuracy: 0.9967 - val_loss: 2.7237 - val_accuracy: 0.7928\n",
      "Epoch 1486/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0364 - accuracy: 0.9893 - val_loss: 2.7787 - val_accuracy: 0.7944\n",
      "Epoch 1487/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0278 - accuracy: 0.9913 - val_loss: 2.6834 - val_accuracy: 0.7586\n",
      "Epoch 1488/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0177 - accuracy: 0.9933 - val_loss: 2.9805 - val_accuracy: 0.7944\n",
      "Epoch 1489/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0339 - accuracy: 0.9920 - val_loss: 2.6493 - val_accuracy: 0.7944\n",
      "Epoch 1490/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0091 - accuracy: 0.9967 - val_loss: 2.5458 - val_accuracy: 0.7804\n",
      "Epoch 1491/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0186 - accuracy: 0.9926 - val_loss: 2.5426 - val_accuracy: 0.7804\n",
      "Epoch 1492/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0211 - accuracy: 0.9947 - val_loss: 2.5112 - val_accuracy: 0.7913\n",
      "Epoch 1493/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0235 - accuracy: 0.9926 - val_loss: 2.5929 - val_accuracy: 0.7617\n",
      "Epoch 1494/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0158 - accuracy: 0.9926 - val_loss: 2.6954 - val_accuracy: 0.7664\n",
      "Epoch 1495/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0390 - accuracy: 0.9900 - val_loss: 2.6683 - val_accuracy: 0.7866\n",
      "Epoch 1496/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0207 - accuracy: 0.9940 - val_loss: 2.5138 - val_accuracy: 0.7539\n",
      "Epoch 1497/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0194 - accuracy: 0.9926 - val_loss: 2.6134 - val_accuracy: 0.7710\n",
      "Epoch 1498/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0128 - accuracy: 0.9960 - val_loss: 2.5535 - val_accuracy: 0.7819\n",
      "Epoch 1499/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0163 - accuracy: 0.9953 - val_loss: 2.4431 - val_accuracy: 0.7679\n",
      "Epoch 1500/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0303 - accuracy: 0.9920 - val_loss: 2.5501 - val_accuracy: 0.7757\n"
     ]
    }
   ],
   "source": [
    "# Train the CNN\n",
    "#es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "history = model.fit(X_train_reshaped, y_train_onehot, epochs=1500, batch_size=40,\n",
    "                    validation_data=(X_test_reshaped, y_test_onehot))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1fad3c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 2ms/step\n",
      "Accuracy: 0.7757009345794392\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the performance\n",
    "y_pred = model.predict(X_test_reshaped)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "accuracy = accuracy_score(y_test_encoded, y_pred_classes)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d17f6734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "71748165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c637edb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87       532\n",
      "           1       0.33      0.29      0.31       110\n",
      "\n",
      "    accuracy                           0.78       642\n",
      "   macro avg       0.59      0.58      0.59       642\n",
      "weighted avg       0.77      0.78      0.77       642\n",
      "\n",
      "Predict   0         1         \n",
      "Actual\n",
      "0         466       66        \n",
      "\n",
      "1         78        32        \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overall Statistics : \n",
      "\n",
      "95% CI                                                            (0.74343,0.80797)\n",
      "ACC Macro                                                         0.7757\n",
      "ARI                                                               0.12018\n",
      "AUNP                                                              0.58342\n",
      "AUNU                                                              0.58342\n",
      "Bangdiwala B                                                      0.72681\n",
      "Bennett S                                                         0.5514\n",
      "CBA                                                               0.57376\n",
      "CSI                                                               0.175\n",
      "Chi-Squared                                                       19.6183\n",
      "Chi-Squared DF                                                    1\n",
      "Conditional Entropy                                               0.59729\n",
      "Cramer V                                                          0.17481\n",
      "Cross Entropy                                                     0.66265\n",
      "F1 Macro                                                          0.58693\n",
      "F1 Micro                                                          0.7757\n",
      "FNR Macro                                                         0.41658\n",
      "FNR Micro                                                         0.2243\n",
      "FPR Macro                                                         0.41658\n",
      "FPR Micro                                                         0.2243\n",
      "Gwet AC1                                                          0.69211\n",
      "Hamming Loss                                                      0.2243\n",
      "Joint Entropy                                                     1.25805\n",
      "KL Divergence                                                     0.00189\n",
      "Kappa                                                             0.17439\n",
      "Kappa 95% CI                                                      (0.05563,0.29316)\n",
      "Kappa No Prevalence                                               0.5514\n",
      "Kappa Standard Error                                              0.0606\n",
      "Kappa Unbiased                                                    0.17386\n",
      "Krippendorff Alpha                                                0.17451\n",
      "Lambda A                                                          0.0\n",
      "Lambda B                                                          0.0\n",
      "Mutual Information                                                0.01914\n",
      "NIR                                                               0.82866\n",
      "Overall ACC                                                       0.7757\n",
      "Overall CEN                                                       0.60808\n",
      "Overall J                                                         (0.94575,0.47288)\n",
      "Overall MCC                                                       0.17481\n",
      "Overall MCEN                                                      0.48922\n",
      "Overall RACC                                                      0.72832\n",
      "Overall RACCU                                                     0.7285\n",
      "P-Value                                                           0.99976\n",
      "PPV Macro                                                         0.59157\n",
      "PPV Micro                                                         0.7757\n",
      "Pearson C                                                         0.1722\n",
      "Phi-Squared                                                       0.03056\n",
      "RCI                                                               0.02897\n",
      "RR                                                                321.0\n",
      "Reference Entropy                                                 0.66076\n",
      "Response Entropy                                                  0.61643\n",
      "SOA1(Landis & Koch)                                               Slight\n",
      "SOA2(Fleiss)                                                      Poor\n",
      "SOA3(Altman)                                                      Poor\n",
      "SOA4(Cicchetti)                                                   Poor\n",
      "SOA5(Cramer)                                                      Weak\n",
      "SOA6(Matthews)                                                    Negligible\n",
      "SOA7(Lambda A)                                                    None\n",
      "SOA8(Lambda B)                                                    None\n",
      "SOA9(Krippendorff Alpha)                                          Low\n",
      "SOA10(Pearson C)                                                  Weak\n",
      "Scott PI                                                          0.17386\n",
      "Standard Error                                                    0.01646\n",
      "TNR Macro                                                         0.58342\n",
      "TNR Micro                                                         0.7757\n",
      "TPR Macro                                                         0.58342\n",
      "TPR Micro                                                         0.7757\n",
      "Zero-one Loss                                                     144\n",
      "\n",
      "Class Statistics :\n",
      "\n",
      "Classes                                                           0             1             \n",
      "ACC(Accuracy)                                                     0.7757        0.7757        \n",
      "AGF(Adjusted F-score)                                             0.52719       0.50585       \n",
      "AGM(Adjusted geometric mean)                                      0.47351       0.67298       \n",
      "AM(Difference between automatic and manual classification)        12            -12           \n",
      "AUC(Area under the ROC curve)                                     0.58342       0.58342       \n",
      "AUCI(AUC value interpretation)                                    Poor          Poor          \n",
      "AUPR(Area under the PR curve)                                     0.86628       0.30872       \n",
      "BB(Braun-Blanquet similarity)                                     0.85662       0.29091       \n",
      "BCD(Bray-Curtis dissimilarity)                                    0.00935       0.00935       \n",
      "BM(Informedness or bookmaker informedness)                        0.16685       0.16685       \n",
      "CEN(Confusion entropy)                                            0.52147       1.05612       \n",
      "DOR(Diagnostic odds ratio)                                        2.89666       2.89666       \n",
      "DP(Discriminant power)                                            0.25466       0.25466       \n",
      "DPI(Discriminant power interpretation)                            Poor          Poor          \n",
      "ERR(Error rate)                                                   0.2243        0.2243        \n",
      "F0.5(F0.5 score)                                                  0.86041       0.31873       \n",
      "F1(F1 score - harmonic mean of precision and sensitivity)         0.86617       0.30769       \n",
      "F2(F2 score)                                                      0.87201       0.2974        \n",
      "FDR(False discovery rate)                                         0.14338       0.67347       \n",
      "FN(False negative/miss/type 2 error)                              66            78            \n",
      "FNR(Miss rate or false negative rate)                             0.12406       0.70909       \n",
      "FOR(False omission rate)                                          0.67347       0.14338       \n",
      "FP(False positive/type 1 error/false alarm)                       78            66            \n",
      "FPR(Fall-out or false positive rate)                              0.70909       0.12406       \n",
      "G(G-measure geometric mean of precision and sensitivity)          0.86622       0.30821       \n",
      "GI(Gini index)                                                    0.16685       0.16685       \n",
      "GM(G-mean geometric mean of specificity and sensitivity)          0.5048        0.5048        \n",
      "HD(Hamming distance)                                              144           144           \n",
      "IBA(Index of balanced accuracy)                                   0.4039        0.10574       \n",
      "ICSI(Individual classification success index)                     0.73256       -0.38256      \n",
      "IS(Information score)                                             0.04787       0.93036       \n",
      "J(Jaccard index)                                                  0.76393       0.18182       \n",
      "LS(Lift score)                                                    1.03374       1.90575       \n",
      "MCC(Matthews correlation coefficient)                             0.17481       0.17481       \n",
      "MCCI(Matthews correlation coefficient interpretation)             Negligible    Negligible    \n",
      "MCEN(Modified confusion entropy)                                  0.72654       1.05095       \n",
      "MK(Markedness)                                                    0.18315       0.18315       \n",
      "N(Condition negative)                                             110           532           \n",
      "NLR(Negative likelihood ratio)                                    0.42646       0.80952       \n",
      "NLRI(Negative likelihood ratio interpretation)                    Poor          Negligible    \n",
      "NPV(Negative predictive value)                                    0.32653       0.85662       \n",
      "OC(Overlap coefficient)                                           0.87594       0.32653       \n",
      "OOC(Otsuka-Ochiai coefficient)                                    0.86622       0.30821       \n",
      "OP(Optimized precision)                                           0.27432       0.27432       \n",
      "P(Condition positive or support)                                  532           110           \n",
      "PLR(Positive likelihood ratio)                                    1.2353        2.3449        \n",
      "PLRI(Positive likelihood ratio interpretation)                    Poor          Poor          \n",
      "POP(Population)                                                   642           642           \n",
      "PPV(Precision or positive predictive value)                       0.85662       0.32653       \n",
      "PRE(Prevalence)                                                   0.82866       0.17134       \n",
      "Q(Yule Q - coefficient of colligation)                            0.48674       0.48674       \n",
      "QI(Yule Q interpretation)                                         Weak          Weak          \n",
      "RACC(Random accuracy)                                             0.70217       0.02615       \n",
      "RACCU(Random accuracy unbiased)                                   0.70225       0.02624       \n",
      "TN(True negative/correct rejection)                               32            466           \n",
      "TNR(Specificity or true negative rate)                            0.29091       0.87594       \n",
      "TON(Test outcome negative)                                        98            544           \n",
      "TOP(Test outcome positive)                                        544           98            \n",
      "TP(True positive/hit)                                             466           32            \n",
      "TPR(Sensitivity, recall, hit rate, or true positive rate)         0.87594       0.29091       \n",
      "Y(Youden index)                                                   0.16685       0.16685       \n",
      "dInd(Distance index)                                              0.71986       0.71986       \n",
      "sInd(Similarity index)                                            0.49098       0.49098       \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pycm import ConfusionMatrix\n",
    "\n",
    "\n",
    "print(\"Report : \", classification_report(y_test_encoded, y_pred_classes))\n",
    "\n",
    "print(ConfusionMatrix(actual_vector=list(y_test_encoded),predict_vector=list(y_pred_classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3483e9ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
